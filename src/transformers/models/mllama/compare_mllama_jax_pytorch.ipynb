{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using the `SDPA` attention implementation on multi-gpu setup with ROCM may lead to performance issues due to the FA backend. Disabling it to use alternative backends.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  6.54it/s]\n",
      "E1123 06:34:49.478979 1227008 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1123 06:34:49.479017 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.479020 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.479023 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.479025 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.479117 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.479120 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.479122 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.479125 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.479127 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-23 06:34:49.479139: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.481405 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.481418 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.481420 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.481423 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.481425 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.481517 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.481520 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.481523 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.481525 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.481527 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-23 06:34:49.481531: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.484132 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.484144 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.484146 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.484149 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.484151 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.484153 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.484156 1227008 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1123 06:34:49.484158 1227008 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1123 06:34:49.484249 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.484252 1227008 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-23 06:34:49.484256: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.486665 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.486679 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.486681 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.486684 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.486686 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.486777 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.486781 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.486783 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.486785 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.486788 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-23 06:34:49.486792: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.489438 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.489447 1227008 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1123 06:34:49.489450 1227008 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1123 06:34:49.489453 1227008 buffer_comparator.cc:157] Difference at 20665: -inf, expected -2.76479e+38\n",
      "E1123 06:34:49.489455 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.489458 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.489460 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.489463 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.489554 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.489557 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "2024-11-23 06:34:49.489562: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.492022 1227008 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1123 06:34:49.492034 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.492036 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.492039 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.492041 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.492133 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.492136 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.492138 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.492141 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.492143 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-23 06:34:49.492146: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.495157 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.495169 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.495171 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.495174 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.495176 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.495178 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.495181 1227008 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1123 06:34:49.495183 1227008 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1123 06:34:49.495274 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.495277 1227008 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-23 06:34:49.495281: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.497690 1227008 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1123 06:34:49.497702 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.497704 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.497706 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.497708 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.497800 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.497804 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.497806 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.497808 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.497810 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-23 06:34:49.497813: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.499995 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.500006 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.500009 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.500011 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.500014 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.500105 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.500108 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.500110 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.500112 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.500114 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-23 06:34:49.500118: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.502694 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.502707 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.502709 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.502711 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.502713 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.502716 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.502718 1227008 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1123 06:34:49.502720 1227008 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1123 06:34:49.502806 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.502810 1227008 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-23 06:34:49.502814: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.505162 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.505174 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.505176 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.505179 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.505181 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.505273 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.505276 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.505278 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.505280 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.505282 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-23 06:34:49.505286: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.507917 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.507929 1227008 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1123 06:34:49.507932 1227008 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1123 06:34:49.507935 1227008 buffer_comparator.cc:157] Difference at 20665: -inf, expected -2.76479e+38\n",
      "E1123 06:34:49.507938 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.507940 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.507942 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.507945 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.508036 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.508039 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "2024-11-23 06:34:49.508043: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.510496 1227008 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1123 06:34:49.510506 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.510509 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.510511 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.510513 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.510605 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.510608 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.510610 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.510612 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.510615 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-23 06:34:49.510618: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.513601 1227008 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1123 06:34:49.513611 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.513614 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.513616 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.513618 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.513621 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.513623 1227008 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1123 06:34:49.513625 1227008 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1123 06:34:49.513716 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.513719 1227008 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-23 06:34:49.513723: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.515326 1227008 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1123 06:34:49.515336 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.515338 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.515341 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.515432 1227008 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1123 06:34:49.515435 1227008 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1123 06:34:49.515437 1227008 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1123 06:34:49.515439 1227008 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "E1123 06:34:49.515441 1227008 buffer_comparator.cc:157] Difference at 83353: inf, expected 4.38645e+37\n",
      "E1123 06:34:49.515443 1227008 buffer_comparator.cc:157] Difference at 83361: 9.03875e+37, expected inf\n",
      "2024-11-23 06:34:49.515447: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.517039 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.517047 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.517050 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.517052 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.517143 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1123 06:34:49.517147 1227008 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1123 06:34:49.517149 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.517151 1227008 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1123 06:34:49.517153 1227008 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1123 06:34:49.517155 1227008 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-23 06:34:49.517159: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.518762 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.518771 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.518774 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.518776 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.518868 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.518872 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.518875 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.518877 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "E1123 06:34:49.518880 1227008 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1123 06:34:49.518882 1227008 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "2024-11-23 06:34:49.518885: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.520469 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.520479 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.520481 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.520484 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.520575 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1123 06:34:49.520578 1227008 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1123 06:34:49.520580 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.520582 1227008 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1123 06:34:49.520584 1227008 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1123 06:34:49.520587 1227008 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-23 06:34:49.520590: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.522186 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.522196 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.522198 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.522201 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.522292 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1123 06:34:49.522302 1227008 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1123 06:34:49.522304 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.522306 1227008 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1123 06:34:49.522309 1227008 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1123 06:34:49.522311 1227008 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-23 06:34:49.522315: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.523921 1227008 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1123 06:34:49.523931 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.523934 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.523937 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.524028 1227008 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1123 06:34:49.524031 1227008 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1123 06:34:49.524034 1227008 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1123 06:34:49.524036 1227008 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "E1123 06:34:49.524038 1227008 buffer_comparator.cc:157] Difference at 83353: inf, expected 4.38645e+37\n",
      "E1123 06:34:49.524040 1227008 buffer_comparator.cc:157] Difference at 83361: 9.03875e+37, expected inf\n",
      "2024-11-23 06:34:49.524043: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.525634 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.525643 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.525645 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.525647 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.525739 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1123 06:34:49.525742 1227008 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1123 06:34:49.525744 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.525746 1227008 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1123 06:34:49.525748 1227008 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1123 06:34:49.525750 1227008 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-23 06:34:49.525754: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.527507 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.527516 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.527518 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.527522 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.527613 1227008 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.527616 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.527618 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.527620 1227008 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1123 06:34:49.527622 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1123 06:34:49.527624 1227008 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-23 06:34:49.527628: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.529282 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.529289 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.529292 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.529384 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.529387 1227008 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.529389 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.529391 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.529393 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.529395 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.529397 1227008 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "2024-11-23 06:34:49.529401: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.531164 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.531174 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.531177 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.531179 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.531270 1227008 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.531273 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.531275 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.531277 1227008 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1123 06:34:49.531279 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1123 06:34:49.531282 1227008 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-23 06:34:49.531285: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.533062 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.533072 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.533074 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.533077 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.533168 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1123 06:34:49.533171 1227008 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1123 06:34:49.533173 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.533175 1227008 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1123 06:34:49.533177 1227008 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1123 06:34:49.533179 1227008 buffer_comparator.cc:157] Difference at 83305: inf, expected 2.03372e+38\n",
      "2024-11-23 06:34:49.533183: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.534832 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.534840 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.534843 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.534845 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.534936 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1123 06:34:49.534940 1227008 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1123 06:34:49.534942 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.534944 1227008 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1123 06:34:49.534946 1227008 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1123 06:34:49.534948 1227008 buffer_comparator.cc:157] Difference at 83305: inf, expected 2.03372e+38\n",
      "2024-11-23 06:34:49.534951: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.536541 1227008 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1123 06:34:49.536550 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.536553 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.536556 1227008 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1123 06:34:49.536558 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.536649 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.536652 1227008 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1123 06:34:49.536654 1227008 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1123 06:34:49.536656 1227008 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1123 06:34:49.536659 1227008 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "2024-11-23 06:34:49.536662: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.538248 1227008 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1123 06:34:49.538257 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.538259 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.538262 1227008 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1123 06:34:49.538264 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.538362 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.538365 1227008 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1123 06:34:49.538367 1227008 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1123 06:34:49.538369 1227008 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1123 06:34:49.538371 1227008 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "2024-11-23 06:34:49.538375: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.539946 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.539954 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.539956 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.539959 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.539961 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.540052 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.540056 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.540058 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.540060 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.540063 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.540067: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.541598 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.541606 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.541608 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.541611 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.541703 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.541707 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.541709 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.541712 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.541714 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.541716 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.541720: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.543253 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.543263 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.543265 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.543268 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.543270 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.543361 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.543364 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.543366 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.543369 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.543371 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.543374: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.544940 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.544948 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.544950 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.544953 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.544955 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.545046 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.545050 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.545052 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.545054 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.545056 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.545059: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.546576 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.546585 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.546587 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.546589 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.546593 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.546684 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.546687 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.546689 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.546692 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.546695 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.546698: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.548223 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.548232 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.548234 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.548237 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.548239 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.548330 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.548334 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.548336 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.548338 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.548343 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.548348: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.549911 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.549920 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.549922 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.549925 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.550016 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.550019 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.550021 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.550023 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.550025 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.550028 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.550031: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.551553 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.551563 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.551565 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.551568 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.551570 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.551661 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.551665 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.551667 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.551669 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.551671 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.551675: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.553236 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.553245 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.553248 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.553250 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.553341 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.553345 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.553347 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.553349 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.553351 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.553354 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.553358: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.554929 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.554939 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.554942 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.554944 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.554947 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.555039 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.555042 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.555044 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.555046 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.555048 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.555052: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.556615 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.556626 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.556628 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.556630 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.556633 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.556724 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.556727 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.556729 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.556731 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.556734 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.556738: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.558302 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.558311 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.558313 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.558316 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.558319 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.558418 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.558423 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.558425 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.558428 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.558430 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.558433: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.559966 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.559975 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.559977 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.559980 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.559983 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.560073 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.560076 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.560078 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.560080 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.560083 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.560086: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.561651 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.561662 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.561664 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.561667 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.561753 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.561756 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.561758 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.561760 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.561763 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.561765 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.561769: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.563298 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.563308 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.563310 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.563313 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.563315 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.563406 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.563409 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.563411 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.563413 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.563416 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.563419: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.564989 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.564999 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.565001 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.565004 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.565006 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.565097 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.565100 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.565103 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.565105 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.565107 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.565111: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.566644 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.566653 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.566656 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.566658 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.566749 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.566753 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.566755 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.566757 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.566759 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.566762 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.566765: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.568332 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.568341 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.568343 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.568346 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.568437 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.568440 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.568442 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.568444 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.568447 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.568449 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.568452: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.570022 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.570031 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.570033 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.570036 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.570127 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.570130 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.570132 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.570134 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.570136 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.570139 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.570142: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.571708 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.571716 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.571719 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.571722 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.571813 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.571816 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.571818 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.571821 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.571823 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.571825 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.571829: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.573406 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.573415 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.573417 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.573420 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.573422 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.573513 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.573516 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.573518 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.573520 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.573523 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.573527: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.575107 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.575117 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.575119 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.575122 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.575124 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.575215 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.575218 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.575220 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.575223 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.575225 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.575228: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.576801 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.576810 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.576813 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.576815 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.576906 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.576909 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.576911 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.576913 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.576916 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.576918 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.576921: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.578504 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.578513 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.578516 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.578519 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.578610 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.578613 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.578615 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.578617 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.578620 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.578622 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.578626: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.580210 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.580220 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.580222 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.580225 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.580227 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.580313 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.580317 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.580319 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.580321 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.580323 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.580327: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.581908 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.581917 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.581919 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.581922 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.581925 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.582015 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.582019 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.582021 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.582023 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.582025 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.582029: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.583601 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.583610 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.583612 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.583614 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.583617 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.583708 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.583711 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.583714 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.583716 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.583718 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.583721: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.586617 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.586716 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.586721 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.586723 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.586725 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.586727 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.586730 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.586732 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.586734 1227008 buffer_comparator.cc:157] Difference at 83723: -inf, expected -2.76479e+38\n",
      "E1123 06:34:49.586736 1227008 buffer_comparator.cc:157] Difference at 83777: -2.32615e+38, expected -inf\n",
      "2024-11-23 06:34:49.586740: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.588379 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.588387 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.588390 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.588393 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.588484 1227008 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.588487 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.588491 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.588495 1227008 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1123 06:34:49.588497 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1123 06:34:49.588499 1227008 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-23 06:34:49.588503: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.590141 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.590150 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.590153 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.590156 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.590247 1227008 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.590250 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.590252 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.590255 1227008 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1123 06:34:49.590257 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1123 06:34:49.590259 1227008 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-23 06:34:49.590263: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.591895 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.591905 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.591908 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.591911 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.592004 1227008 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1123 06:34:49.592008 1227008 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1123 06:34:49.592010 1227008 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "E1123 06:34:49.592012 1227008 buffer_comparator.cc:157] Difference at 83911: inf, expected 3.36295e+38\n",
      "E1123 06:34:49.592015 1227008 buffer_comparator.cc:157] Difference at 83917: 2.65846e+38, expected inf\n",
      "E1123 06:34:49.592017 1227008 buffer_comparator.cc:157] Difference at 83925: 2.44578e+38, expected inf\n",
      "2024-11-23 06:34:49.592020: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.593606 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.593614 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.593617 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.593619 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.593711 1227008 buffer_comparator.cc:157] Difference at 83521: -inf, expected -2.28627e+38\n",
      "E1123 06:34:49.593715 1227008 buffer_comparator.cc:157] Difference at 83535: inf, expected 2.68504e+38\n",
      "E1123 06:34:49.593717 1227008 buffer_comparator.cc:157] Difference at 83565: 1.22289e+38, expected inf\n",
      "E1123 06:34:49.593719 1227008 buffer_comparator.cc:157] Difference at 83585: -inf, expected inf\n",
      "E1123 06:34:49.593721 1227008 buffer_comparator.cc:157] Difference at 83593: -2.87113e+38, expected -inf\n",
      "E1123 06:34:49.593724 1227008 buffer_comparator.cc:157] Difference at 83605: inf, expected 2.45907e+38\n",
      "2024-11-23 06:34:49.593727: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.595548 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.595557 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.595559 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.595562 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.595653 1227008 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1123 06:34:49.595657 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.595659 1227008 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1123 06:34:49.595661 1227008 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1123 06:34:49.595663 1227008 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1123 06:34:49.595665 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-23 06:34:49.595669: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.597482 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.597491 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.597493 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.597496 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.597587 1227008 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1123 06:34:49.597590 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.597592 1227008 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1123 06:34:49.597594 1227008 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1123 06:34:49.597597 1227008 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1123 06:34:49.597599 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-23 06:34:49.597603: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.599419 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.599428 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.599431 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.599433 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.599525 1227008 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1123 06:34:49.599528 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.599531 1227008 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1123 06:34:49.599533 1227008 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1123 06:34:49.599535 1227008 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1123 06:34:49.599537 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-23 06:34:49.599541: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.601357 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.601366 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.601368 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.601371 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.601462 1227008 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1123 06:34:49.601466 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.601468 1227008 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1123 06:34:49.601470 1227008 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1123 06:34:49.601472 1227008 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1123 06:34:49.601475 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-23 06:34:49.601478: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.603051 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.603060 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.603062 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.603065 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.603156 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.603160 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.603162 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.603164 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.603166 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.603168 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-23 06:34:49.603172: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.604730 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.604741 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.604743 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.604745 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.604837 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.604840 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.604842 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.604844 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.604847 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.604849 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-23 06:34:49.604852: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.606410 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.606421 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.606424 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.606426 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.606518 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.606522 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.606524 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.606526 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.606528 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.606531 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-23 06:34:49.606534: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.608102 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.608110 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.608112 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.608115 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.608207 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.608210 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.608212 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.608215 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.608217 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.608219 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-23 06:34:49.608222: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.609941 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.609950 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.609953 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.609955 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.610046 1227008 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1123 06:34:49.610050 1227008 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1123 06:34:49.610052 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.610054 1227008 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1123 06:34:49.610056 1227008 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1123 06:34:49.610059 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-23 06:34:49.610062: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.611873 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.611883 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.611886 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.611888 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.611891 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.611893 1227008 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1123 06:34:49.611895 1227008 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1123 06:34:49.611986 1227008 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "E1123 06:34:49.611990 1227008 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1123 06:34:49.611992 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "2024-11-23 06:34:49.611995: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.613699 1227008 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1123 06:34:49.613709 1227008 buffer_comparator.cc:157] Difference at 20665: -inf, expected -2.76479e+38\n",
      "E1123 06:34:49.613712 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.613714 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.613716 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.613719 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.613722 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.613813 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.613816 1227008 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1123 06:34:49.613818 1227008 buffer_comparator.cc:157] Difference at 83327: inf, expected 3.04393e+38\n",
      "2024-11-23 06:34:49.613821: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.615432 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.615442 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.615445 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.615447 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.615538 1227008 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1123 06:34:49.615542 1227008 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1123 06:34:49.615544 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.615546 1227008 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1123 06:34:49.615548 1227008 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1123 06:34:49.615550 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-23 06:34:49.615553: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.617247 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.617257 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.617260 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.617262 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.617354 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.617358 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.617360 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.617362 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.617364 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.617366 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-23 06:34:49.617370: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.618982 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.618991 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.618993 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.618996 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.618999 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.619090 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.619093 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.619095 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.619098 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.619100 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.619104: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.620714 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.620722 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.620725 1227008 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1123 06:34:49.620727 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.620819 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.620822 1227008 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1123 06:34:49.620825 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.620827 1227008 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1123 06:34:49.620829 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.620831 1227008 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-23 06:34:49.620835: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.622415 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.622423 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.622425 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.622428 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.622431 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.622522 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.622525 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.622527 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.622530 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.622532 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.622536: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.624074 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.624082 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.624085 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.624088 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.624090 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.624181 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.624185 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.624187 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.624189 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.624191 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.624195: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.625732 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.625741 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.625743 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.625746 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.625749 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.625839 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.625844 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.625846 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.625848 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.625850 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.625854: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.627548 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.627557 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.627560 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.627562 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.627654 1227008 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1123 06:34:49.627657 1227008 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1123 06:34:49.627659 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.627661 1227008 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1123 06:34:49.627664 1227008 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1123 06:34:49.627666 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-23 06:34:49.627669: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.629386 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.629394 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.629396 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.629399 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.629490 1227008 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1123 06:34:49.629493 1227008 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1123 06:34:49.629495 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.629498 1227008 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1123 06:34:49.629500 1227008 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1123 06:34:49.629502 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-23 06:34:49.629505: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.631094 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.631104 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.631106 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.631109 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.631200 1227008 buffer_comparator.cc:157] Difference at 83215: -inf, expected -9.03875e+37\n",
      "E1123 06:34:49.631203 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.631206 1227008 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1123 06:34:49.631208 1227008 buffer_comparator.cc:157] Difference at 83247: -inf, expected -1.14978e+38\n",
      "E1123 06:34:49.631210 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.631212 1227008 buffer_comparator.cc:157] Difference at 83291: 4.85168e+37, expected inf\n",
      "2024-11-23 06:34:49.631216: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.632793 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.632801 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.632804 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.632806 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.632898 1227008 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1123 06:34:49.632902 1227008 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1123 06:34:49.632904 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.632906 1227008 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1123 06:34:49.632908 1227008 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1123 06:34:49.632910 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-23 06:34:49.632914: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.634485 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.634494 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.634497 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.634499 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.634591 1227008 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1123 06:34:49.634595 1227008 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1123 06:34:49.634597 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.634599 1227008 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1123 06:34:49.634601 1227008 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1123 06:34:49.634603 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-23 06:34:49.634607: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.636206 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.636216 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.636218 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.636221 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.636313 1227008 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1123 06:34:49.636316 1227008 buffer_comparator.cc:157] Difference at 83213: inf, expected -1.15643e+38\n",
      "E1123 06:34:49.636318 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.636321 1227008 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1123 06:34:49.636323 1227008 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1123 06:34:49.636325 1227008 buffer_comparator.cc:157] Difference at 83259: inf, expected 1.7147e+38\n",
      "2024-11-23 06:34:49.636329: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.637905 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.637914 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.637917 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.637919 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.638011 1227008 buffer_comparator.cc:157] Difference at 83215: -inf, expected -9.03875e+37\n",
      "E1123 06:34:49.638014 1227008 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1123 06:34:49.638016 1227008 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1123 06:34:49.638018 1227008 buffer_comparator.cc:157] Difference at 83247: -inf, expected -1.14978e+38\n",
      "E1123 06:34:49.638021 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.638023 1227008 buffer_comparator.cc:157] Difference at 83291: 4.85168e+37, expected inf\n",
      "2024-11-23 06:34:49.638027: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.639577 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.639587 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.639590 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.639593 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.639684 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.639687 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.639690 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.639692 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.639694 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.639697 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.639701: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.641261 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.641271 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.641273 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.641276 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.641279 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.641370 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.641373 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.641376 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.641378 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.641381 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.641384: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.642959 1227008 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1123 06:34:49.642969 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.642972 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.642974 1227008 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1123 06:34:49.642976 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.643068 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.643072 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.643074 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.643077 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.643079 1227008 buffer_comparator.cc:157] Difference at 83585: -inf, expected inf\n",
      "2024-11-23 06:34:49.643082: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.644621 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.644631 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.644633 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.644636 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.644727 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.644731 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.644733 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.644735 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.644738 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.644740 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.644744: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.646275 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.646285 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.646287 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.646290 1227008 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1123 06:34:49.646388 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.646392 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.646394 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.646396 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.646399 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1123 06:34:49.646401 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-23 06:34:49.646405: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.647981 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.647991 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.647994 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.648084 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.648088 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.648090 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.648093 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "E1123 06:34:49.648095 1227008 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1123 06:34:49.648097 1227008 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1123 06:34:49.648099 1227008 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "2024-11-23 06:34:49.648103: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.649664 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.649674 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.649676 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.649678 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.649681 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.649684 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.649776 1227008 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1123 06:34:49.649779 1227008 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1123 06:34:49.649781 1227008 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "E1123 06:34:49.649784 1227008 buffer_comparator.cc:157] Difference at 83911: inf, expected 3.36295e+38\n",
      "2024-11-23 06:34:49.649787: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.651387 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.651396 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.651398 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.651401 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.651403 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.651494 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.651497 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.651500 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.651502 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.651505 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.651508: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.662206 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.662223 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.662227 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.662230 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.662233 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.662324 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.662327 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.662329 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.662332 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.662334 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.662339: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.663951 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.663960 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.663963 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.663966 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.663968 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.664056 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.664062 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.664065 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.664068 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.664070 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.664074: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.665654 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.665663 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.665665 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.665668 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.665670 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.665756 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.665760 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.665763 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.665766 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.665768 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.665772: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.667364 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.667374 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.667376 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.667379 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.667382 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.667473 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.667476 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.667478 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.667480 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.667482 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.667486: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.669066 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.669075 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.669078 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.669080 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.669083 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.669169 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.669173 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.669175 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.669178 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.669180 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.669184: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.670765 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.670774 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.670777 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.670779 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.670782 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.670873 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.670877 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.670879 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.670881 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.670883 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.670887: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.672460 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.672469 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.672471 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.672474 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.672476 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.672567 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.672571 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.672573 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.672576 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.672578 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.672581: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.674180 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.674189 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.674191 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.674194 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.674197 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.674287 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.674291 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.674293 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.674296 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.674298 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.674302: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.675899 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.675910 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.675912 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.675915 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.675918 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.676009 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.676013 1227008 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1123 06:34:49.676015 1227008 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1123 06:34:49.676018 1227008 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1123 06:34:49.676020 1227008 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-23 06:34:49.676024: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.677625 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.677634 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.677637 1227008 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1123 06:34:49.677728 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.677733 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.677735 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.677738 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "E1123 06:34:49.677740 1227008 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1123 06:34:49.677742 1227008 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1123 06:34:49.677744 1227008 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "2024-11-23 06:34:49.677748: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.679338 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.679346 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.679348 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.679350 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.679353 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.679355 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.679441 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.679445 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.679447 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.679449 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-23 06:34:49.679453: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.681038 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.681049 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.681051 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.681053 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.681056 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.681058 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.681149 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.681152 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.681154 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.681157 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-23 06:34:49.681161: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.682766 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.682777 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.682779 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.682781 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.682784 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.682787 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.682878 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.682881 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.682883 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.682885 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-23 06:34:49.682890: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.684477 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.684487 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.684490 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.684492 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.684494 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.684497 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.684588 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.684591 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.684594 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.684596 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-23 06:34:49.684600: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.686188 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.686197 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.686199 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.686201 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.686203 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.686206 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.686297 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.686301 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.686303 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.686305 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-23 06:34:49.686309: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.687901 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.687912 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.687914 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.687917 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.687919 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.687922 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.688013 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.688016 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.688018 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.688021 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-23 06:34:49.688025: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1123 06:34:49.689605 1227008 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1123 06:34:49.689617 1227008 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1123 06:34:49.689619 1227008 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1123 06:34:49.689621 1227008 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1123 06:34:49.689624 1227008 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1123 06:34:49.689626 1227008 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1123 06:34:49.689717 1227008 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1123 06:34:49.689721 1227008 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1123 06:34:49.689723 1227008 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1123 06:34:49.689725 1227008 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-23 06:34:49.689729: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax (1, 16, 4128, 80) [[[[-0.0110474 0.0098877 -0.00263977 ... 0.00250244 0.00494385\n",
      "    0.00921631]\n",
      "   [-0.00952148 0.00546265 -0.00234985 ... 0.00576782 0.00382996\n",
      "    0.00604248]\n",
      "   [-0.00306702 0.00518799 -0.00273132 ... 0.00534058 0.00494385\n",
      "    0.00442505]\n",
      "   ...\n",
      "   [-0.00772095 0.00759888 -0.00427246 ... 0.00408936 0.00500488\n",
      "    0.00619507]\n",
      "   [-0.00772095 0.00759888 -0.00427246 ... 0.00408936 0.00500488\n",
      "    0.00619507]\n",
      "   [-0.00772095 0.00759888 -0.00427246 ... 0.00408936 0.00500488\n",
      "    0.00619507]]\n",
      "\n",
      "  [[-0.00238037 -0.00210571 -0.00146484 ... -0.00537109 0.000759125\n",
      "    -0.00976562]\n",
      "   [-0.00270081 -0.00331116 0.000123024 ... -0.00650024 0.00189972\n",
      "    -0.00939941]\n",
      "   [-0.00314331 0.00108337 -0.00338745 ... -0.00836182 0.000213623\n",
      "    -0.00836182]\n",
      "   ...\n",
      "   [-0.00332642 -6.58035e-05 -0.00148773 ... -0.00549316 0.000720978\n",
      "    -0.00720215]\n",
      "   [-0.00332642 -6.58035e-05 -0.00148773 ... -0.00549316 0.000720978\n",
      "    -0.00720215]\n",
      "   [-0.00332642 -6.58035e-05 -0.00148773 ... -0.00549316 0.000720978\n",
      "    -0.00720215]]\n",
      "\n",
      "  [[0.00482178 -0.0123901 -0.00830078 ... -0.00778198 -0.00741577\n",
      "    0.00430298]\n",
      "   [0.00570679 -0.00994873 -0.00254822 ... -0.00683594 -0.0144653\n",
      "    0.0057373]\n",
      "   [0.00579834 -0.0111694 -0.00512695 ... -0.0065918 -0.00939941\n",
      "    -0.000823975]\n",
      "   ...\n",
      "   [0.00512695 -0.0113525 -0.00585938 ... -0.00628662 -0.00994873\n",
      "    0.00209045]\n",
      "   [0.00512695 -0.0113525 -0.00585938 ... -0.00628662 -0.00994873\n",
      "    0.00209045]\n",
      "   [0.00512695 -0.0113525 -0.00585938 ... -0.00628662 -0.00994873\n",
      "    0.00209045]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00119019 -0.0039978 -0.00408936 ... -0.00769043 -0.0105591\n",
      "    -0.0065918]\n",
      "   [0.00201416 -0.00367737 -0.00163269 ... -0.00830078 -0.0172119\n",
      "    -0.00205994]\n",
      "   [0.0065918 -0.00195312 -0.00683594 ... -0.00297546 -0.0148926\n",
      "    -0.00585938]\n",
      "   ...\n",
      "   [0.00192261 -0.00411987 -0.00604248 ... -0.00604248 -0.0119629\n",
      "    -0.00497437]\n",
      "   [0.00192261 -0.00411987 -0.00604248 ... -0.00604248 -0.0119629\n",
      "    -0.00497437]\n",
      "   [0.00192261 -0.00411987 -0.00604248 ... -0.00604248 -0.0119629\n",
      "    -0.00497437]]\n",
      "\n",
      "  [[-0.00271606 0.00692749 0.00457764 ... 0.0112305 0.00245667\n",
      "    -0.00811768]\n",
      "   [-0.00283813 0.00343323 -0.00494385 ... 0.00866699 0.0072937\n",
      "    -0.00567627]\n",
      "   [-0.0010376 0.00227356 0.00415039 ... 0.0110474 0.00637817\n",
      "    -0.00087738]\n",
      "   ...\n",
      "   [-0.00104523 0.00494385 0.00131226 ... 0.00772095 0.0062561\n",
      "    -0.00390625]\n",
      "   [-0.00104523 0.00494385 0.00131226 ... 0.00772095 0.0062561\n",
      "    -0.00390625]\n",
      "   [-0.00104523 0.00494385 0.00131226 ... 0.00772095 0.0062561\n",
      "    -0.00390625]]\n",
      "\n",
      "  [[0.00248718 -0.00430298 0.00151825 ... 0.00288391 0.0055542\n",
      "    0.000499725]\n",
      "   [0.0045166 -0.00473022 0.00332642 ... 0.00250244 0.00204468\n",
      "    0.000953674]\n",
      "   [0.00613403 -0.00337219 0.00531006 ... 0.00537109 0.00389099\n",
      "    0.00466919]\n",
      "   ...\n",
      "   [0.00245667 -0.00387573 0.00337219 ... 0.0032959 0.00306702\n",
      "    0.00309753]\n",
      "   [0.00245667 -0.00387573 0.00337219 ... 0.0032959 0.00306702\n",
      "    0.00309753]\n",
      "   [0.00245667 -0.00387573 0.00337219 ... 0.0032959 0.00306702\n",
      "    0.00309753]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0153809 0.0071106 -0.00370789 ... -0.0174561 0.0336914\n",
      "    0.00842285]\n",
      "   [-0.0147095 0.00701904 -0.00196838 ... -0.0200195 0.0334473\n",
      "    0.0124512]\n",
      "   [-0.0140381 0.00370789 0.00866699 ... -0.015564 0.0314941 0.0136108]\n",
      "   ...\n",
      "   [-0.0145264 0.00653076 -0.000457764 ... -0.0157471 0.0296631\n",
      "    0.0112305]\n",
      "   [-0.0145264 0.00653076 -0.000457764 ... -0.0157471 0.0296631\n",
      "    0.0112305]\n",
      "   [-0.0145264 0.00653076 -0.000457764 ... -0.0157471 0.0296631\n",
      "    0.0112305]]\n",
      "\n",
      "  [[-0.00344849 0.00436401 0.0122681 ... 0.00314331 0.00341797\n",
      "    0.00034523]\n",
      "   [-0.00323486 0.0022583 0.0137939 ... -0.00314331 0.00318909\n",
      "    0.00025177]\n",
      "   [-0.00411987 0.00427246 0.0114136 ... 0.000919342 0.0019455\n",
      "    0.00282288]\n",
      "   ...\n",
      "   [-0.00408936 0.00704956 0.0136108 ... 0.00182343 0.00601196\n",
      "    -0.00205994]\n",
      "   [-0.00408936 0.00704956 0.0136108 ... 0.00182343 0.00601196\n",
      "    -0.00205994]\n",
      "   [-0.00408936 0.00704956 0.0136108 ... 0.00182343 0.00601196\n",
      "    -0.00205994]]\n",
      "\n",
      "  [[-0.0197754 0.0185547 0.00234985 ... -0.0235596 0.00695801\n",
      "    -0.00619507]\n",
      "   [-0.0196533 0.015564 0.00579834 ... -0.0246582 0.00331116\n",
      "    0.000545502]\n",
      "   [-0.0209961 0.0151367 0.00570679 ... -0.0233154 0.00921631\n",
      "    -0.00531006]\n",
      "   ...\n",
      "   [-0.0166016 0.0169678 0.00787354 ... -0.022583 0.00576782\n",
      "    -0.00209045]\n",
      "   [-0.0166016 0.0169678 0.00787354 ... -0.022583 0.00576782\n",
      "    -0.00209045]\n",
      "   [-0.0166016 0.0169678 0.00787354 ... -0.022583 0.00576782\n",
      "    -0.00209045]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.001091 0.000720978 -0.00720215 ... 0.0192871 0.0120239\n",
      "    -0.00564575]\n",
      "   [0.00726318 0.00154114 -0.00939941 ... 0.0189209 0.00823975\n",
      "    -0.00717163]\n",
      "   [0.00442505 0.00317383 -0.00909424 ... 0.0205078 0.0055542\n",
      "    -0.00637817]\n",
      "   ...\n",
      "   [0.00463867 0.0018692 -0.00952148 ... 0.0167236 0.00689697\n",
      "    -0.0106201]\n",
      "   [0.00463867 0.0018692 -0.00952148 ... 0.0167236 0.00689697\n",
      "    -0.0106201]\n",
      "   [0.00463867 0.0018692 -0.00952148 ... 0.0167236 0.00689697\n",
      "    -0.0106201]]\n",
      "\n",
      "  [[0.0159912 -0.0125122 0.0109253 ... -0.0196533 -0.00637817\n",
      "    -0.0027771]\n",
      "   [0.0129395 -0.00878906 0.00337219 ... -0.0224609 -0.00595093\n",
      "    -0.00335693]\n",
      "   [0.0119629 -0.00939941 0.00125885 ... -0.022583 -0.00744629\n",
      "    0.000164986]\n",
      "   ...\n",
      "   [0.00717163 -0.00958252 0.00445557 ... -0.0239258 -0.0120239\n",
      "    -0.00457764]\n",
      "   [0.00717163 -0.00958252 0.00445557 ... -0.0239258 -0.0120239\n",
      "    -0.00457764]\n",
      "   [0.00717163 -0.00958252 0.00445557 ... -0.0239258 -0.0120239\n",
      "    -0.00457764]]\n",
      "\n",
      "  [[0.0147705 -0.0126343 -0.0327148 ... -0.0137939 -0.00136566\n",
      "    0.0266113]\n",
      "   [0.015564 -0.0134277 -0.0241699 ... -0.00668335 -0.00491333\n",
      "    0.0344238]\n",
      "   [0.0186768 -0.0108032 -0.0263672 ... -0.0136108 -0.00210571\n",
      "    0.0294189]\n",
      "   ...\n",
      "   [0.0100098 -0.0170898 -0.0314941 ... -0.0108032 0.00193787 0.0289307]\n",
      "   [0.0100098 -0.0170898 -0.0314941 ... -0.0108032 0.00193787 0.0289307]\n",
      "   [0.0100098 -0.0170898 -0.0314941 ... -0.0108032 0.00193787 0.0289307]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.00778198 0.0119629 -0.0235596 ... -0.0163574 0.0213623 0.0229492]\n",
      "   [0.00759888 0.0112305 -0.0268555 ... -0.019165 0.0185547 0.0245361]\n",
      "   [0.00830078 0.0106201 -0.0229492 ... -0.0134888 0.0203857 0.0219727]\n",
      "   ...\n",
      "   [0.00601196 0.00723267 -0.0263672 ... -0.0163574 0.0196533 0.0236816]\n",
      "   [0.00601196 0.00723267 -0.0263672 ... -0.0163574 0.0196533 0.0236816]\n",
      "   [0.00601196 0.00723267 -0.0263672 ... -0.0163574 0.0196533 0.0236816]]\n",
      "\n",
      "  [[-0.00210571 0.0146484 -0.0088501 ... -0.0527344 0.0125122 0.0062561]\n",
      "   [-0.000331879 0.0150146 -0.00665283 ... -0.052002 0.0115356\n",
      "    0.00793457]\n",
      "   [0.00312805 0.0167236 -0.00756836 ... -0.0544434 0.0111084\n",
      "    0.00337219]\n",
      "   ...\n",
      "   [-0.00140381 0.0135498 -0.0038147 ... -0.0544434 0.0123901 0.010498]\n",
      "   [-0.00140381 0.0135498 -0.0038147 ... -0.0544434 0.0123901 0.010498]\n",
      "   [-0.00140381 0.0135498 -0.0038147 ... -0.0544434 0.0123901 0.010498]]\n",
      "\n",
      "  [[-0.00909424 0.0055542 -0.0106201 ... 0.000495911 0.00650024\n",
      "    0.0137939]\n",
      "   [-0.0185547 0.00708008 -0.00952148 ... -0.000358582 0.0038147\n",
      "    0.0103149]\n",
      "   [-0.0157471 0.00558472 -0.0088501 ... -0.000391006 0.00476074\n",
      "    0.0118408]\n",
      "   ...\n",
      "   [-0.0128174 0.00165558 -0.00976562 ... 0.000236511 0.00427246\n",
      "    0.015564]\n",
      "   [-0.0128174 0.00165558 -0.00976562 ... 0.000236511 0.00427246\n",
      "    0.015564]\n",
      "   [-0.0128174 0.00165558 -0.00976562 ... 0.000236511 0.00427246\n",
      "    0.015564]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0178223 -0.00358582 0.00279236 ... 0.00897217 0.0142822\n",
      "    -0.0393066]\n",
      "   [-0.0202637 -0.00656128 0.00570679 ... 0.00491333 0.0146484\n",
      "    -0.0422363]\n",
      "   [-0.0186768 -0.00418091 0.00628662 ... 0.00689697 0.0141602\n",
      "    -0.043457]\n",
      "   ...\n",
      "   [-0.0179443 -0.00300598 0.00631714 ... 0.00190735 0.0155029\n",
      "    -0.0449219]\n",
      "   [-0.0179443 -0.00300598 0.00631714 ... 0.00190735 0.0155029\n",
      "    -0.0449219]\n",
      "   [-0.0179443 -0.00300598 0.00631714 ... 0.00190735 0.0155029\n",
      "    -0.0449219]]\n",
      "\n",
      "  [[0.0133667 -0.00344849 0.010437 ... -0.00756836 0.0228271 -0.0130615]\n",
      "   [0.010437 0.0012207 0.00683594 ... -0.00646973 0.0195312 -0.0117188]\n",
      "   [0.0119019 -0.00396729 0.0137939 ... -0.00778198 0.0214844\n",
      "    -0.0067749]\n",
      "   ...\n",
      "   [0.0148926 -0.00215149 0.0110474 ... -0.00376892 0.020874 -0.0136108]\n",
      "   [0.0148926 -0.00215149 0.0110474 ... -0.00376892 0.020874 -0.0136108]\n",
      "   [0.0148926 -0.00215149 0.0110474 ... -0.00376892 0.020874 -0.0136108]]\n",
      "\n",
      "  [[0.0197754 0.0216064 -0.019165 ... -0.00817871 0.00823975\n",
      "    -0.00524902]\n",
      "   [0.0180664 0.0209961 -0.019043 ... -0.00518799 0.0151367 -0.00653076]\n",
      "   [0.0213623 0.0244141 -0.013855 ... -0.006073 0.0137939 -0.00558472]\n",
      "   ...\n",
      "   [0.0213623 0.0196533 -0.0127563 ... -0.00231934 0.0117188\n",
      "    -0.00665283]\n",
      "   [0.0213623 0.0196533 -0.0127563 ... -0.00231934 0.0117188\n",
      "    -0.00665283]\n",
      "   [0.0213623 0.0196533 -0.0127563 ... -0.00231934 0.0117188\n",
      "    -0.00665283]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.034668 0.00370789 -0.0344238 ... -0.0181885 -0.0344238\n",
      "    -0.0280762]\n",
      "   [-0.0322266 0.00326538 -0.0356445 ... -0.0233154 -0.0336914\n",
      "    -0.0262451]\n",
      "   [-0.0378418 0.000579834 -0.032959 ... -0.0235596 -0.0314941\n",
      "    -0.0201416]\n",
      "   ...\n",
      "   [-0.0366211 -0.000976562 -0.0390625 ... -0.0228271 -0.0339355\n",
      "    -0.0235596]\n",
      "   [-0.0366211 -0.000976562 -0.0390625 ... -0.0228271 -0.0339355\n",
      "    -0.0235596]\n",
      "   [-0.0366211 -0.000976562 -0.0390625 ... -0.0228271 -0.0339355\n",
      "    -0.0235596]]\n",
      "\n",
      "  [[-0.0223389 -0.0150146 0.00247192 ... 0.0119019 0.0250244 -0.029541]\n",
      "   [-0.0195312 -0.012207 0.00292969 ... 0.0153809 0.0255127 -0.0319824]\n",
      "   [-0.0172119 -0.0146484 0.00247192 ... 0.013855 0.026123 -0.0292969]\n",
      "   ...\n",
      "   [-0.0142212 -0.00970459 0.00273132 ... 0.0123901 0.0228271\n",
      "    -0.0349121]\n",
      "   [-0.0142212 -0.00970459 0.00273132 ... 0.0123901 0.0228271\n",
      "    -0.0349121]\n",
      "   [-0.0142212 -0.00970459 0.00273132 ... 0.0123901 0.0228271\n",
      "    -0.0349121]]\n",
      "\n",
      "  [[0.00656128 0.00622559 -0.00157928 ... 0.0683594 -0.0201416\n",
      "    0.0159912]\n",
      "   [0.00521851 0.0105591 -0.00259399 ... 0.0654297 -0.0192871 0.0157471]\n",
      "   [0.00854492 0.00921631 0.000694275 ... 0.0664062 -0.0201416\n",
      "    0.00817871]\n",
      "   ...\n",
      "   [0.00878906 0.00646973 0.000425339 ... 0.0644531 -0.0163574 0.012146]\n",
      "   [0.00878906 0.00646973 0.000425339 ... 0.0644531 -0.0163574 0.012146]\n",
      "   [0.00878906 0.00646973 0.000425339 ... 0.0644531 -0.0163574 0.012146]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00656128 0.0217285 0.0446777 ... 0.00326538 0.0239258 0.0303955]\n",
      "   [0.00756836 0.0187988 0.0429688 ... -0.000614166 0.0185547 0.0302734]\n",
      "   [0.00473022 0.0108032 0.048584 ... 0.00154114 0.0157471 0.0250244]\n",
      "   ...\n",
      "   [0.0088501 0.0167236 0.0476074 ... 0.00282288 0.0195312 0.0279541]\n",
      "   [0.0088501 0.0167236 0.0476074 ... 0.00282288 0.0195312 0.0279541]\n",
      "   [0.0088501 0.0167236 0.0476074 ... 0.00282288 0.0195312 0.0279541]]\n",
      "\n",
      "  [[0.00686646 -0.0192871 -0.0253906 ... 0.0189209 0.0281982 0.0123901]\n",
      "   [0.0115967 -0.019165 -0.0266113 ... 0.0181885 0.0281982 0.0209961]\n",
      "   [0.00769043 -0.020752 -0.024292 ... 0.0233154 0.0319824 0.0147095]\n",
      "   ...\n",
      "   [0.00750732 -0.0185547 -0.0303955 ... 0.0158691 0.0314941 0.0142212]\n",
      "   [0.00750732 -0.0185547 -0.0303955 ... 0.0158691 0.0314941 0.0142212]\n",
      "   [0.00750732 -0.0185547 -0.0303955 ... 0.0158691 0.0314941 0.0142212]]\n",
      "\n",
      "  [[0.0209961 0.0223389 -0.00144196 ... -0.00878906 0.015625 -0.010437]\n",
      "   [0.0217285 0.0251465 -0.00227356 ... -0.0127563 0.0203857\n",
      "    -0.00476074]\n",
      "   [0.0258789 0.0258789 -0.00234985 ... -0.0107422 0.010376 -0.00860596]\n",
      "   ...\n",
      "   [0.0185547 0.0236816 -0.00245667 ... -0.0124512 0.017334 -0.0140381]\n",
      "   [0.0185547 0.0236816 -0.00245667 ... -0.0124512 0.017334 -0.0140381]\n",
      "   [0.0185547 0.0236816 -0.00245667 ... -0.0124512 0.017334 -0.0140381]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.00994873 0.00793457 0.0065918 ... -0.012085 -0.019043 -0.0149536]\n",
      "   [0.0105591 0.010437 0.0057373 ... -0.0162354 -0.0213623 -0.0164795]\n",
      "   [0.0112305 0.00994873 0.00921631 ... -0.0133667 -0.0158691\n",
      "    -0.0179443]\n",
      "   ...\n",
      "   [0.00958252 0.00958252 0.00970459 ... -0.012207 -0.0205078\n",
      "    -0.0168457]\n",
      "   [0.00958252 0.00958252 0.00970459 ... -0.012207 -0.0205078\n",
      "    -0.0168457]\n",
      "   [0.00958252 0.00958252 0.00970459 ... -0.012207 -0.0205078\n",
      "    -0.0168457]]\n",
      "\n",
      "  [[0.0336914 0.0112915 -0.00415039 ... 0.0152588 -0.00695801\n",
      "    -0.00787354]\n",
      "   [0.0354004 0.0146484 -0.00830078 ... 0.0157471 -0.00921631\n",
      "    -0.00723267]\n",
      "   [0.0368652 0.010498 -0.00915527 ... 0.0167236 -0.0067749 -0.00582886]\n",
      "   ...\n",
      "   [0.0378418 0.0125732 -0.0057373 ... 0.0157471 -0.0107422 -0.00222778]\n",
      "   [0.0378418 0.0125732 -0.0057373 ... 0.0157471 -0.0107422 -0.00222778]\n",
      "   [0.0378418 0.0125732 -0.0057373 ... 0.0157471 -0.0107422 -0.00222778]]\n",
      "\n",
      "  [[-0.0127563 0.0286865 0.0231934 ... -0.0245361 -0.00946045\n",
      "    -0.0140991]\n",
      "   [-0.0126343 0.0205078 0.0247803 ... -0.0212402 -0.0131836 -0.0116577]\n",
      "   [-0.00976562 0.0212402 0.0194092 ... -0.0294189 -0.00830078\n",
      "    -0.0123901]\n",
      "   ...\n",
      "   [-0.00982666 0.0230713 0.022583 ... -0.0236816 -0.00866699\n",
      "    -0.0170898]\n",
      "   [-0.00982666 0.0230713 0.022583 ... -0.0236816 -0.00866699\n",
      "    -0.0170898]\n",
      "   [-0.00982666 0.0230713 0.022583 ... -0.0236816 -0.00866699\n",
      "    -0.0170898]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00352478 0.0292969 -0.00653076 ... 0.0256348 -0.0217285\n",
      "    -0.0264893]\n",
      "   [-0.00296021 0.0289307 -0.00543213 ... 0.0245361 -0.0222168\n",
      "    -0.0239258]\n",
      "   [-0.00537109 0.0322266 -0.000858307 ... 0.0213623 -0.024292\n",
      "    -0.0236816]\n",
      "   ...\n",
      "   [-0.00228882 0.02771 -0.00646973 ... 0.02771 -0.0264893 -0.0209961]\n",
      "   [-0.00228882 0.02771 -0.00646973 ... 0.02771 -0.0264893 -0.0209961]\n",
      "   [-0.00228882 0.02771 -0.00646973 ... 0.02771 -0.0264893 -0.0209961]]\n",
      "\n",
      "  [[-0.0246582 -0.0209961 -0.0258789 ... 0.00823975 -0.0126953\n",
      "    0.0195312]\n",
      "   [-0.0245361 -0.0220947 -0.0273438 ... 0.00787354 -0.00946045\n",
      "    0.0150146]\n",
      "   [-0.0264893 -0.0201416 -0.0291748 ... 0.0108643 -0.0098877 0.019043]\n",
      "   ...\n",
      "   [-0.0229492 -0.0197754 -0.0256348 ... 0.00634766 -0.0128784\n",
      "    0.00970459]\n",
      "   [-0.0229492 -0.0197754 -0.0256348 ... 0.00634766 -0.0128784\n",
      "    0.00970459]\n",
      "   [-0.0229492 -0.0197754 -0.0256348 ... 0.00634766 -0.0128784\n",
      "    0.00970459]]\n",
      "\n",
      "  [[-0.00744629 0.0219727 -0.00772095 ... 0.0272217 -0.00439453\n",
      "    0.0314941]\n",
      "   [-0.00234985 0.0228271 -0.00527954 ... 0.03125 -0.00485229 0.03125]\n",
      "   [-0.00314331 0.0209961 -0.00588989 ... 0.0334473 -0.00717163\n",
      "    0.0291748]\n",
      "   ...\n",
      "   [-0.00521851 0.0227051 -0.00994873 ... 0.0351562 -0.000724792\n",
      "    0.0317383]\n",
      "   [-0.00521851 0.0227051 -0.00994873 ... 0.0351562 -0.000724792\n",
      "    0.0317383]\n",
      "   [-0.00521851 0.0227051 -0.00994873 ... 0.0351562 -0.000724792\n",
      "    0.0317383]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.00299072 -0.0218506 0.046875 ... 0.0224609 -0.0198975 -0.0128784]\n",
      "   [0.00300598 -0.0209961 0.0441895 ... 0.0177002 -0.0205078 -0.0128174]\n",
      "   [0.00466919 -0.0213623 0.0483398 ... 0.0197754 -0.0236816 -0.013855]\n",
      "   ...\n",
      "   [0.00701904 -0.0211182 0.0402832 ... 0.0213623 -0.0224609 -0.0136108]\n",
      "   [0.00701904 -0.0211182 0.0402832 ... 0.0213623 -0.0224609 -0.0136108]\n",
      "   [0.00701904 -0.0211182 0.0402832 ... 0.0213623 -0.0224609 -0.0136108]]\n",
      "\n",
      "  [[0.0388184 0.0358887 -0.00631714 ... 0.00518799 0.00994873\n",
      "    -0.0373535]\n",
      "   [0.0361328 0.0385742 -0.00256348 ... 0.00830078 0.00982666\n",
      "    -0.0371094]\n",
      "   [0.0361328 0.0351562 -0.00430298 ... 0.00830078 0.0154419 -0.0371094]\n",
      "   ...\n",
      "   [0.0380859 0.0361328 -0.00518799 ... 0.00692749 0.00933838\n",
      "    -0.0356445]\n",
      "   [0.0380859 0.0361328 -0.00518799 ... 0.00692749 0.00933838\n",
      "    -0.0356445]\n",
      "   [0.0380859 0.0361328 -0.00518799 ... 0.00692749 0.00933838\n",
      "    -0.0356445]]\n",
      "\n",
      "  [[0.00180054 0.0393066 -0.00897217 ... 0.00512695 -0.0187988\n",
      "    0.0427246]\n",
      "   [0.00159454 0.0344238 -0.00778198 ... -0.00378418 -0.0234375\n",
      "    0.034668]\n",
      "   [0.00564575 0.0378418 -0.0072937 ... 0.00268555 -0.0216064 0.0375977]\n",
      "   ...\n",
      "   [0.00396729 0.0429688 -0.0112305 ... 0.00390625 -0.0240479 0.0378418]\n",
      "   [0.00396729 0.0429688 -0.0112305 ... 0.00390625 -0.0240479 0.0378418]\n",
      "   [0.00396729 0.0429688 -0.0112305 ... 0.00390625 -0.0240479 0.0378418]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0170898 -0.0488281 0.0130615 ... 0.0583496 -0.0288086 0.000770569]\n",
      "   [0.0117798 -0.0463867 0.0203857 ... 0.0561523 -0.0272217 0.00361633]\n",
      "   [0.00811768 -0.0483398 0.0148315 ... 0.0556641 -0.0252686 0.00463867]\n",
      "   ...\n",
      "   [0.0166016 -0.0515137 0.0175781 ... 0.060791 -0.027832 0.00445557]\n",
      "   [0.0166016 -0.0515137 0.0175781 ... 0.060791 -0.027832 0.00445557]\n",
      "   [0.0166016 -0.0515137 0.0175781 ... 0.060791 -0.027832 0.00445557]]\n",
      "\n",
      "  [[0.00653076 -0.000179291 0.0187988 ... 0.000553131 -0.019165\n",
      "    0.0373535]\n",
      "   [0.0133667 0.00662231 0.0150757 ... 0.0035553 -0.0178223 0.0375977]\n",
      "   [0.0115356 0.0102539 0.0127563 ... -0.000892639 -0.0198975 0.0319824]\n",
      "   ...\n",
      "   [0.00778198 0.00176239 0.0183105 ... -0.00150299 -0.0197754\n",
      "    0.0366211]\n",
      "   [0.00778198 0.00176239 0.0183105 ... -0.00150299 -0.0197754\n",
      "    0.0366211]\n",
      "   [0.00778198 0.00176239 0.0183105 ... -0.00150299 -0.0197754\n",
      "    0.0366211]]\n",
      "\n",
      "  [[-0.0114136 0.0378418 0.0119019 ... 0.0192871 -0.0159912\n",
      "    -0.000900269]\n",
      "   [-0.0106201 0.0405273 0.0137329 ... 0.0187988 -0.0111694 0.00891113]\n",
      "   [-0.0118408 0.0383301 0.00933838 ... 0.0257568 -0.0109863 0.00714111]\n",
      "   ...\n",
      "   [-0.0111084 0.0393066 0.0119629 ... 0.0251465 -0.012146 0.00230408]\n",
      "   [-0.0111084 0.0393066 0.0119629 ... 0.0251465 -0.012146 0.00230408]\n",
      "   [-0.0111084 0.0393066 0.0119629 ... 0.0251465 -0.012146 0.00230408]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.015625 0.0168457 -0.0515137 ... -3.31402e-05 -0.00294495\n",
      "    -0.0126343]\n",
      "   [0.0153809 0.0174561 -0.0549316 ... -0.00448608 -0.000274658\n",
      "    -0.0118408]\n",
      "   [0.0149536 0.0186768 -0.0524902 ... -0.00402832 -0.00137329\n",
      "    -0.0123291]\n",
      "   ...\n",
      "   [0.0159912 0.0136108 -0.0541992 ... -0.0012207 0.00288391 -0.0115356]\n",
      "   [0.0159912 0.0136108 -0.0541992 ... -0.0012207 0.00288391 -0.0115356]\n",
      "   [0.0159912 0.0136108 -0.0541992 ... -0.0012207 0.00288391 -0.0115356]]\n",
      "\n",
      "  [[-0.00138855 -0.0368652 -0.0112305 ... -0.0546875 -0.0163574\n",
      "    0.0341797]\n",
      "   [0.00106049 -0.0351562 -0.0135498 ... -0.0561523 -0.0162354\n",
      "    0.0311279]\n",
      "   [-0.00442505 -0.0349121 -0.0130615 ... -0.0529785 -0.0201416\n",
      "    0.034668]\n",
      "   ...\n",
      "   [-0.00674438 -0.0412598 -0.0119629 ... -0.0546875 -0.0179443\n",
      "    0.0322266]\n",
      "   [-0.00674438 -0.0412598 -0.0119629 ... -0.0546875 -0.0179443\n",
      "    0.0322266]\n",
      "   [-0.00674438 -0.0412598 -0.0119629 ... -0.0546875 -0.0179443\n",
      "    0.0322266]]\n",
      "\n",
      "  [[-0.0197754 0.0185547 0.0169678 ... -0.00860596 0.0634766 0.0150757]\n",
      "   [-0.019043 0.0174561 0.0175781 ... -0.0043335 0.0566406 0.0139771]\n",
      "   [-0.0132446 0.0153198 0.0195312 ... -0.00442505 0.0598145 0.0158691]\n",
      "   ...\n",
      "   [-0.0128174 0.0183105 0.0158691 ... -0.00376892 0.0617676 0.0122681]\n",
      "   [-0.0128174 0.0183105 0.0158691 ... -0.00376892 0.0617676 0.0122681]\n",
      "   [-0.0128174 0.0183105 0.0158691 ... -0.00376892 0.0617676 0.0122681]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00817871 -0.0246582 -0.0334473 ... -0.0383301 -0.00521851\n",
      "    -0.0181885]\n",
      "   [0.00482178 -0.0252686 -0.0286865 ... -0.0322266 -0.00402832\n",
      "    -0.0131226]\n",
      "   [0.00512695 -0.0272217 -0.0307617 ... -0.034668 -0.00297546\n",
      "    -0.0170898]\n",
      "   ...\n",
      "   [0.00411987 -0.0238037 -0.0334473 ... -0.0390625 -0.00231934\n",
      "    -0.0170898]\n",
      "   [0.00411987 -0.0238037 -0.0334473 ... -0.0390625 -0.00231934\n",
      "    -0.0170898]\n",
      "   [0.00411987 -0.0238037 -0.0334473 ... -0.0390625 -0.00231934\n",
      "    -0.0170898]]\n",
      "\n",
      "  [[0.00244141 -0.0088501 0.00135803 ... 0.000576019 -0.00878906\n",
      "    -0.0162354]\n",
      "   [0.00338745 -0.00680542 0.00153351 ... 0.00271606 -0.010498\n",
      "    -0.0161133]\n",
      "   [0.00411987 -0.0134888 0.00389099 ... 0.00372314 -0.0126953\n",
      "    -0.0203857]\n",
      "   ...\n",
      "   [-0.000166893 -0.00976562 0.00531006 ... 0.00567627 -0.0100708\n",
      "    -0.0202637]\n",
      "   [-0.000166893 -0.00976562 0.00531006 ... 0.00567627 -0.0100708\n",
      "    -0.0202637]\n",
      "   [-0.000166893 -0.00976562 0.00531006 ... 0.00567627 -0.0100708\n",
      "    -0.0202637]]\n",
      "\n",
      "  [[-0.0200195 0.00396729 -0.0203857 ... 0.0522461 -0.0078125 0.0241699]\n",
      "   [-0.0180664 0.0062561 -0.0255127 ... 0.059082 -0.0102539 0.0223389]\n",
      "   [-0.019165 0.00170135 -0.0233154 ... 0.0510254 -0.0112305 0.0247803]\n",
      "   ...\n",
      "   [-0.0203857 0.00775146 -0.0219727 ... 0.0561523 -0.0135498 0.0267334]\n",
      "   [-0.0203857 0.00775146 -0.0219727 ... 0.0561523 -0.0135498 0.0267334]\n",
      "   [-0.0203857 0.00775146 -0.0219727 ... 0.0561523 -0.0135498 0.0267334]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0115967 -0.0334473 0.00335693 ... -0.0241699 0.0126953\n",
      "    0.000984192]\n",
      "   [0.0144043 -0.032959 0.00506592 ... -0.0216064 0.0145874 -0.00228882]\n",
      "   [0.0150146 -0.0336914 0.00527954 ... -0.0240479 0.0126953 0.00192261]\n",
      "   ...\n",
      "   [0.0164795 -0.0319824 0.00421143 ... -0.0220947 0.0123901 0.00469971]\n",
      "   [0.0164795 -0.0319824 0.00421143 ... -0.0220947 0.0123901 0.00469971]\n",
      "   [0.0164795 -0.0319824 0.00421143 ... -0.0220947 0.0123901 0.00469971]]\n",
      "\n",
      "  [[0.0183105 -0.0231934 -0.0065918 ... -0.0314941 0.0179443\n",
      "    -0.00830078]\n",
      "   [0.0218506 -0.0240479 -0.00460815 ... -0.0291748 0.0152588\n",
      "    -0.00775146]\n",
      "   [0.0230713 -0.0280762 -0.0039978 ... -0.0327148 0.0169678\n",
      "    -0.00646973]\n",
      "   ...\n",
      "   [0.0197754 -0.0214844 -0.00485229 ... -0.0279541 0.0123291\n",
      "    -0.00799561]\n",
      "   [0.0197754 -0.0214844 -0.00485229 ... -0.0279541 0.0123291\n",
      "    -0.00799561]\n",
      "   [0.0197754 -0.0214844 -0.00485229 ... -0.0279541 0.0123291\n",
      "    -0.00799561]]\n",
      "\n",
      "  [[0.0101318 0.0446777 0.0500488 ... 0.00830078 -0.0400391 -0.0197754]\n",
      "   [0.00402832 0.0441895 0.0541992 ... 0.0112915 -0.0415039 -0.0214844]\n",
      "   [0.0114136 0.0495605 0.0449219 ... 0.0113525 -0.045166 -0.0246582]\n",
      "   ...\n",
      "   [0.0150757 0.0480957 0.0510254 ... 0.00787354 -0.043457 -0.0203857]\n",
      "   [0.0150757 0.0480957 0.0510254 ... 0.00787354 -0.043457 -0.0203857]\n",
      "   [0.0150757 0.0480957 0.0510254 ... 0.00787354 -0.043457 -0.0203857]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0405273 0.0308838 0.0356445 ... 0.00958252 0.0322266 0.0654297]\n",
      "   [-0.0368652 0.0317383 0.0341797 ... 0.0157471 0.0371094 0.0664062]\n",
      "   [-0.0402832 0.0253906 0.032959 ... 0.0125122 0.0366211 0.0708008]\n",
      "   ...\n",
      "   [-0.0388184 0.0327148 0.0383301 ... 0.00238037 0.0368652 0.0654297]\n",
      "   [-0.0388184 0.0327148 0.0383301 ... 0.00238037 0.0368652 0.0654297]\n",
      "   [-0.0388184 0.0327148 0.0383301 ... 0.00238037 0.0368652 0.0654297]]\n",
      "\n",
      "  [[0.0227051 -0.0283203 0.00915527 ... 0.0018158 0.000270844 -0.036377]\n",
      "   [0.0230713 -0.0281982 0.00222778 ... 0.000766754 -0.000347137\n",
      "    -0.0380859]\n",
      "   [0.0178223 -0.0223389 0.00294495 ... 0.00126648 0.00262451\n",
      "    -0.0371094]\n",
      "   ...\n",
      "   [0.0200195 -0.0305176 0.00549316 ... 0.00604248 -0.00170898\n",
      "    -0.0383301]\n",
      "   [0.0200195 -0.0305176 0.00549316 ... 0.00604248 -0.00170898\n",
      "    -0.0383301]\n",
      "   [0.0200195 -0.0305176 0.00549316 ... 0.00604248 -0.00170898\n",
      "    -0.0383301]]\n",
      "\n",
      "  [[-0.00765991 0.0466309 0.00665283 ... 0.0419922 0.0429688 0.0639648]\n",
      "   [-0.00787354 0.0483398 0.00204468 ... 0.0493164 0.0390625 0.0603027]\n",
      "   [-0.00772095 0.0493164 0.00311279 ... 0.0461426 0.0437012 0.0644531]\n",
      "   ...\n",
      "   [-0.0145264 0.048584 0.0013504 ... 0.0437012 0.0437012 0.0593262]\n",
      "   [-0.0145264 0.048584 0.0013504 ... 0.0437012 0.0437012 0.0593262]\n",
      "   [-0.0145264 0.048584 0.0013504 ... 0.0437012 0.0437012 0.0593262]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0688477 -0.0197754 0.000244141 ... 0.0466309 0.0192871 -0.0088501]\n",
      "   [0.0708008 -0.0174561 -0.00230408 ... 0.0512695 0.0195312\n",
      "    -0.00518799]\n",
      "   [0.0698242 -0.0172119 -0.00485229 ... 0.0478516 0.0214844 -0.010376]\n",
      "   ...\n",
      "   [0.0668945 -0.0163574 -0.000195503 ... 0.0419922 0.0213623\n",
      "    -0.00933838]\n",
      "   [0.0668945 -0.0163574 -0.000195503 ... 0.0419922 0.0213623\n",
      "    -0.00933838]\n",
      "   [0.0668945 -0.0163574 -0.000195503 ... 0.0419922 0.0213623\n",
      "    -0.00933838]]\n",
      "\n",
      "  [[-0.0132446 0.0169678 0.00204468 ... 0.0136719 0.0380859 -0.0233154]\n",
      "   [-0.0140381 0.019043 0.00198364 ... 0.0152588 0.0305176 -0.0264893]\n",
      "   [-0.0149536 0.0149536 0.00466919 ... 0.0164795 0.0390625 -0.0268555]\n",
      "   ...\n",
      "   [-0.0159912 0.0200195 0.00402832 ... 0.0123291 0.032959 -0.0263672]\n",
      "   [-0.0159912 0.0200195 0.00402832 ... 0.0123291 0.032959 -0.0263672]\n",
      "   [-0.0159912 0.0200195 0.00402832 ... 0.0123291 0.032959 -0.0263672]]\n",
      "\n",
      "  [[0.060791 0.0449219 0.0373535 ... -0.0437012 -0.0551758 0.0283203]\n",
      "   [0.0568848 0.052002 0.0279541 ... -0.0473633 -0.0615234 0.024292]\n",
      "   [0.0588379 0.0461426 0.036377 ... -0.0449219 -0.0576172 0.0264893]\n",
      "   ...\n",
      "   [0.0588379 0.0495605 0.0296631 ... -0.046875 -0.060791 0.022583]\n",
      "   [0.0588379 0.0495605 0.0296631 ... -0.046875 -0.060791 0.022583]\n",
      "   [0.0588379 0.0495605 0.0296631 ... -0.046875 -0.060791 0.022583]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.052002 0.012085 -0.00927734 ... -0.0078125 -0.0110474 0.0303955]\n",
      "   [-0.0559082 0.00830078 -0.000507355 ... -0.00744629 -0.0134277\n",
      "    0.0288086]\n",
      "   [-0.0541992 0.0148926 -0.00195312 ... -0.0098877 -0.00927734\n",
      "    0.0227051]\n",
      "   ...\n",
      "   [-0.0532227 0.0164795 0.00352478 ... -0.0090332 -0.0195312 0.0296631]\n",
      "   [-0.0532227 0.0164795 0.00352478 ... -0.0090332 -0.0195312 0.0296631]\n",
      "   [-0.0532227 0.0164795 0.00352478 ... -0.0090332 -0.0195312 0.0296631]]\n",
      "\n",
      "  [[-0.0559082 -0.0158691 -0.0146484 ... 0.017334 0.0288086 0.000423431]\n",
      "   [-0.0563965 -0.0126343 -0.00741577 ... 0.0238037 0.0358887\n",
      "    0.000265121]\n",
      "   [-0.059082 -0.00836182 -0.0113525 ... 0.0146484 0.0344238 0.00218201]\n",
      "   ...\n",
      "   [-0.0561523 -0.0141602 -0.00915527 ... 0.0196533 0.0375977\n",
      "    0.00552368]\n",
      "   [-0.0561523 -0.0141602 -0.00915527 ... 0.0196533 0.0375977\n",
      "    0.00552368]\n",
      "   [-0.0561523 -0.0141602 -0.00915527 ... 0.0196533 0.0375977\n",
      "    0.00552368]]\n",
      "\n",
      "  [[0.0522461 0.0532227 -0.020874 ... -0.0559082 0.0546875 0.00411987]\n",
      "   [0.0563965 0.0559082 -0.0244141 ... -0.0595703 0.0549316 0.00442505]\n",
      "   [0.0559082 0.0571289 -0.0280762 ... -0.059082 0.0532227 0.00570679]\n",
      "   ...\n",
      "   [0.0559082 0.0546875 -0.0230713 ... -0.0605469 0.0541992 0.00750732]\n",
      "   [0.0559082 0.0546875 -0.0230713 ... -0.0605469 0.0541992 0.00750732]\n",
      "   [0.0559082 0.0546875 -0.0230713 ... -0.0605469 0.0541992 0.00750732]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.00101471 -0.012146 0.0419922 ... 0.00424194 -0.0117798 0.0170898]\n",
      "   [0.00476074 -0.00640869 0.0419922 ... 0.00318909 -0.0143433 0.022583]\n",
      "   [0.00151825 -0.00515747 0.0415039 ... 0.00473022 -0.0114136\n",
      "    0.0151978]\n",
      "   ...\n",
      "   [7.39098e-06 -0.0123291 0.0422363 ... 0.0057373 -0.0135498 0.0145264]\n",
      "   [7.39098e-06 -0.0123291 0.0422363 ... 0.0057373 -0.0135498 0.0145264]\n",
      "   [7.39098e-06 -0.0123291 0.0422363 ... 0.0057373 -0.0135498 0.0145264]]\n",
      "\n",
      "  [[-0.0308838 0.0303955 0.0415039 ... 0.00628662 0.0124512 0.0668945]\n",
      "   [-0.0339355 0.0317383 0.0458984 ... 0.00357056 0.0229492 0.0678711]\n",
      "   [-0.032959 0.0307617 0.0397949 ... 0.00540161 0.019043 0.0708008]\n",
      "   ...\n",
      "   [-0.0332031 0.0336914 0.0385742 ... 0.00482178 0.0163574 0.0644531]\n",
      "   [-0.0332031 0.0336914 0.0385742 ... 0.00482178 0.0163574 0.0644531]\n",
      "   [-0.0332031 0.0336914 0.0385742 ... 0.00482178 0.0163574 0.0644531]]\n",
      "\n",
      "  [[0.0432129 0.0405273 0.0150146 ... -0.0393066 -0.010498 -0.034668]\n",
      "   [0.046875 0.0373535 0.0212402 ... -0.0407715 -0.0125122 -0.0292969]\n",
      "   [0.0393066 0.0366211 0.0167236 ... -0.0368652 -0.0124512 -0.0344238]\n",
      "   ...\n",
      "   [0.0454102 0.0407715 0.0202637 ... -0.0410156 -0.0117188 -0.0351562]\n",
      "   [0.0454102 0.0407715 0.0202637 ... -0.0410156 -0.0117188 -0.0351562]\n",
      "   [0.0454102 0.0407715 0.0202637 ... -0.0410156 -0.0117188 -0.0351562]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0184326 0.0361328 0.0290527 ... -0.027832 -0.012085 -0.0132446]\n",
      "   [-0.0194092 0.0380859 0.0281982 ... -0.0290527 -0.00933838\n",
      "    -0.0106812]\n",
      "   [-0.0216064 0.0341797 0.0253906 ... -0.0322266 -0.0166016\n",
      "    -0.00970459]\n",
      "   ...\n",
      "   [-0.0185547 0.0390625 0.0285645 ... -0.0373535 -0.0103149 -0.0125122]\n",
      "   [-0.0185547 0.0390625 0.0285645 ... -0.0373535 -0.0103149 -0.0125122]\n",
      "   [-0.0185547 0.0390625 0.0285645 ... -0.0373535 -0.0103149 -0.0125122]]\n",
      "\n",
      "  [[0.0612793 0.0255127 0.0490723 ... -0.0332031 0.0115967 0.0554199]\n",
      "   [0.0588379 0.0198975 0.045166 ... -0.0336914 0.0166016 0.0600586]\n",
      "   [0.0629883 0.0212402 0.045166 ... -0.0314941 0.0137939 0.0541992]\n",
      "   ...\n",
      "   [0.0620117 0.0245361 0.0495605 ... -0.032959 0.0107422 0.0554199]\n",
      "   [0.0620117 0.0245361 0.0495605 ... -0.032959 0.0107422 0.0554199]\n",
      "   [0.0620117 0.0245361 0.0495605 ... -0.032959 0.0107422 0.0554199]]\n",
      "\n",
      "  [[-0.00326538 -0.000709534 -0.0253906 ... -0.026123 0.0410156\n",
      "    -0.0148315]\n",
      "   [-0.00300598 -0.00476074 -0.0296631 ... -0.020752 0.0380859\n",
      "    -0.019043]\n",
      "   [0.000881195 -0.00128174 -0.0290527 ... -0.0250244 0.0307617\n",
      "    -0.0158691]\n",
      "   ...\n",
      "   [-0.0035553 0.00102997 -0.0314941 ... -0.0195312 0.0385742\n",
      "    -0.0206299]\n",
      "   [-0.0035553 0.00102997 -0.0314941 ... -0.0195312 0.0385742\n",
      "    -0.0206299]\n",
      "   [-0.0035553 0.00102997 -0.0314941 ... -0.0195312 0.0385742\n",
      "    -0.0206299]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0144653 0.012085 0.0339355 ... -0.0534668 0.00337219 0.0488281]\n",
      "   [-0.0177002 0.0163574 0.0354004 ... -0.050293 0.000522614 0.0483398]\n",
      "   [-0.0172119 0.0148926 0.0354004 ... -0.0488281 0.00430298 0.0432129]\n",
      "   ...\n",
      "   [-0.0177002 0.0167236 0.0307617 ... -0.0500488 0.00107574 0.0463867]\n",
      "   [-0.0177002 0.0167236 0.0307617 ... -0.0500488 0.00107574 0.0463867]\n",
      "   [-0.0177002 0.0167236 0.0307617 ... -0.0500488 0.00107574 0.0463867]]\n",
      "\n",
      "  [[0.0131836 0.0187988 0.00939941 ... 0.0683594 -0.0339355 0.0654297]\n",
      "   [0.0163574 0.0150757 0.00756836 ... 0.0678711 -0.0349121 0.0664062]\n",
      "   [0.0100098 0.0194092 0.0122681 ... 0.0629883 -0.0378418 0.0698242]\n",
      "   ...\n",
      "   [0.0146484 0.0137329 0.00909424 ... 0.0717773 -0.0375977 0.0693359]\n",
      "   [0.0146484 0.0137329 0.00909424 ... 0.0717773 -0.0375977 0.0693359]\n",
      "   [0.0146484 0.0137329 0.00909424 ... 0.0717773 -0.0375977 0.0693359]]\n",
      "\n",
      "  [[0.00288391 -0.00390625 -0.0303955 ... 0.0322266 -0.00386047\n",
      "    -0.0480957]\n",
      "   [0.00787354 -0.00273132 -0.0274658 ... 0.0233154 -0.00479126\n",
      "    -0.0498047]\n",
      "   [0.00531006 -0.00665283 -0.0273438 ... 0.0336914 -0.00250244\n",
      "    -0.0498047]\n",
      "   ...\n",
      "   [0.000284195 -0.00408936 -0.0296631 ... 0.0334473 -0.00244141\n",
      "    -0.0507812]\n",
      "   [0.000284195 -0.00408936 -0.0296631 ... 0.0334473 -0.00244141\n",
      "    -0.0507812]\n",
      "   [0.000284195 -0.00408936 -0.0296631 ... 0.0334473 -0.00244141\n",
      "    -0.0507812]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00601196 0.0187988 -0.0336914 ... 0.00701904 0.0341797 0.0712891]\n",
      "   [0.00473022 0.0228271 -0.0344238 ... 0.00473022 0.0317383 0.0673828]\n",
      "   [0.00521851 0.0194092 -0.0361328 ... 0.00640869 0.0314941 0.0688477]\n",
      "   ...\n",
      "   [0.0038147 0.0192871 -0.0366211 ... 0.00933838 0.0296631 0.0688477]\n",
      "   [0.0038147 0.0192871 -0.0366211 ... 0.00933838 0.0296631 0.0688477]\n",
      "   [0.0038147 0.0192871 -0.0366211 ... 0.00933838 0.0296631 0.0688477]]\n",
      "\n",
      "  [[0.0180664 -0.00424194 -0.0317383 ... 0.0107422 -0.0634766 0.0415039]\n",
      "   [0.0195312 -0.00273132 -0.0332031 ... 0.0105591 -0.057373 0.0422363]\n",
      "   [0.0213623 -0.00524902 -0.0268555 ... 0.00640869 -0.0551758 0.043457]\n",
      "   ...\n",
      "   [0.0244141 -0.00363159 -0.0302734 ... 0.00540161 -0.0578613\n",
      "    0.0444336]\n",
      "   [0.0244141 -0.00363159 -0.0302734 ... 0.00540161 -0.0578613\n",
      "    0.0444336]\n",
      "   [0.0244141 -0.00363159 -0.0302734 ... 0.00540161 -0.0578613\n",
      "    0.0444336]]\n",
      "\n",
      "  [[0.0893555 0.0152588 -0.0957031 ... 0.02771 -0.0288086 0.00209045]\n",
      "   [0.0947266 0.0238037 -0.100586 ... 0.0216064 -0.0286865 0.00119019]\n",
      "   [0.0952148 0.0178223 -0.0952148 ... 0.0263672 -0.0272217 -0.00352478]\n",
      "   ...\n",
      "   [0.0922852 0.0180664 -0.0942383 ... 0.0273438 -0.0269775 0.000656128]\n",
      "   [0.0922852 0.0180664 -0.0942383 ... 0.0273438 -0.0269775 0.000656128]\n",
      "   [0.0922852 0.0180664 -0.0942383 ... 0.0273438 -0.0269775 0.000656128]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0294189 0.0202637 0.0286865 ... 0.00183868 0.0290527 -0.0189209]\n",
      "   [0.029541 0.0185547 0.0303955 ... 0.00482178 0.0319824 -0.0167236]\n",
      "   [0.0275879 0.0192871 0.0253906 ... 0.00209045 0.0270996 -0.0167236]\n",
      "   ...\n",
      "   [0.0322266 0.0224609 0.0217285 ... 0.00393677 0.0266113 -0.0213623]\n",
      "   [0.0322266 0.0224609 0.0217285 ... 0.00393677 0.0266113 -0.0213623]\n",
      "   [0.0322266 0.0224609 0.0217285 ... 0.00393677 0.0266113 -0.0213623]]\n",
      "\n",
      "  [[-0.0354004 -0.057373 -0.0341797 ... 0.0142212 -0.0153198\n",
      "    -0.00112915]\n",
      "   [-0.0322266 -0.0595703 -0.0322266 ... 0.0161133 -0.0147705\n",
      "    -0.00286865]\n",
      "   [-0.03125 -0.0588379 -0.0317383 ... 0.0123901 -0.015564 -0.00445557]\n",
      "   ...\n",
      "   [-0.03125 -0.0595703 -0.0319824 ... 0.0134888 -0.0151978 -0.00805664]\n",
      "   [-0.03125 -0.0595703 -0.0319824 ... 0.0134888 -0.0151978 -0.00805664]\n",
      "   [-0.03125 -0.0595703 -0.0319824 ... 0.0134888 -0.0151978 -0.00805664]]\n",
      "\n",
      "  [[0.0368652 0.0184326 -0.0281982 ... 0.00540161 0.0402832 -0.00970459]\n",
      "   [0.0393066 0.0218506 -0.0327148 ... 0.00787354 0.0375977 -0.00695801]\n",
      "   [0.0402832 0.0209961 -0.0308838 ... 0.013916 0.0356445 -0.00909424]\n",
      "   ...\n",
      "   [0.0385742 0.019165 -0.0306396 ... 0.00698853 0.0400391 -0.0110474]\n",
      "   [0.0385742 0.019165 -0.0306396 ... 0.00698853 0.0400391 -0.0110474]\n",
      "   [0.0385742 0.019165 -0.0306396 ... 0.00698853 0.0400391 -0.0110474]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.048584 0.0098877 -0.00735474 ... 0.0761719 -0.0196533 -0.0067749]\n",
      "   [-0.0463867 0.0129395 -0.0132446 ... 0.0766602 -0.0196533\n",
      "    -0.00518799]\n",
      "   [-0.0500488 0.00817871 -0.010437 ... 0.0717773 -0.0194092\n",
      "    -0.00842285]\n",
      "   ...\n",
      "   [-0.0490723 0.0088501 -0.010376 ... 0.0732422 -0.0194092 -0.010437]\n",
      "   [-0.0490723 0.0088501 -0.010376 ... 0.0732422 -0.0194092 -0.010437]\n",
      "   [-0.0490723 0.0088501 -0.010376 ... 0.0732422 -0.0194092 -0.010437]]\n",
      "\n",
      "  [[0.0585938 -0.0439453 0.0854492 ... -0.00524902 -0.0446777 0.0527344]\n",
      "   [0.0578613 -0.0402832 0.0854492 ... -0.00570679 -0.0444336 0.0534668]\n",
      "   [0.0622559 -0.0449219 0.0844727 ... -0.00405884 -0.0478516 0.0507812]\n",
      "   ...\n",
      "   [0.0554199 -0.0380859 0.0854492 ... -0.0027771 -0.0498047 0.0512695]\n",
      "   [0.0554199 -0.0380859 0.0854492 ... -0.0027771 -0.0498047 0.0512695]\n",
      "   [0.0554199 -0.0380859 0.0854492 ... -0.0027771 -0.0498047 0.0512695]]\n",
      "\n",
      "  [[0.046875 -0.0654297 0.015625 ... -0.0229492 0.0354004 -0.0184326]\n",
      "   [0.0449219 -0.0629883 0.0162354 ... -0.0301514 0.0378418 -0.019043]\n",
      "   [0.0427246 -0.0673828 0.0166016 ... -0.0283203 0.0361328 -0.0153809]\n",
      "   ...\n",
      "   [0.0429688 -0.0644531 0.0155029 ... -0.0272217 0.0322266 -0.0167236]\n",
      "   [0.0429688 -0.0644531 0.0155029 ... -0.0272217 0.0322266 -0.0167236]\n",
      "   [0.0429688 -0.0644531 0.0155029 ... -0.0272217 0.0322266 -0.0167236]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0966797 -0.0133057 -0.0274658 ... 0.0373535 -0.059082 0.0218506]\n",
      "   [-0.09375 -0.0147705 -0.0205078 ... 0.0366211 -0.0541992 0.0217285]\n",
      "   [-0.097168 -0.0144653 -0.0240479 ... 0.0380859 -0.0578613 0.022583]\n",
      "   ...\n",
      "   [-0.0966797 -0.0143433 -0.0223389 ... 0.0366211 -0.057373 0.0241699]\n",
      "   [-0.0966797 -0.0143433 -0.0223389 ... 0.0366211 -0.057373 0.0241699]\n",
      "   [-0.0966797 -0.0143433 -0.0223389 ... 0.0366211 -0.057373 0.0241699]]\n",
      "\n",
      "  [[-0.0179443 0.012146 -0.0402832 ... -0.000389099 -0.0478516\n",
      "    -0.0184326]\n",
      "   [-0.012207 0.0177002 -0.0366211 ... 0.00150299 -0.0490723 -0.0220947]\n",
      "   [-0.0167236 0.0170898 -0.0422363 ... -0.00121307 -0.0515137\n",
      "    -0.0201416]\n",
      "   ...\n",
      "   [-0.0158691 0.0134888 -0.0368652 ... 0.00248718 -0.0546875\n",
      "    -0.0187988]\n",
      "   [-0.0158691 0.0134888 -0.0368652 ... 0.00248718 -0.0546875\n",
      "    -0.0187988]\n",
      "   [-0.0158691 0.0134888 -0.0368652 ... 0.00248718 -0.0546875\n",
      "    -0.0187988]]\n",
      "\n",
      "  [[0.00610352 0.0344238 -0.0229492 ... -0.00561523 0.0356445 0.026123]\n",
      "   [0.0016098 0.0267334 -0.0209961 ... -0.00506592 0.0349121 0.0275879]\n",
      "   [-0.00323486 0.0291748 -0.0213623 ... -0.00521851 0.0358887\n",
      "    0.0283203]\n",
      "   ...\n",
      "   [-0.00062561 0.0319824 -0.022583 ... -0.00854492 0.0354004 0.02771]\n",
      "   [-0.00062561 0.0319824 -0.022583 ... -0.00854492 0.0354004 0.02771]\n",
      "   [-0.00062561 0.0319824 -0.022583 ... -0.00854492 0.0354004 0.02771]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0712891 0.0354004 -0.0100098 ... 0.0952148 0.09375 -0.0839844]\n",
      "   [0.0722656 0.0356445 -0.00866699 ... 0.0957031 0.0952148 -0.0849609]\n",
      "   [0.0708008 0.0383301 -0.0118408 ... 0.097168 0.0913086 -0.0888672]\n",
      "   ...\n",
      "   [0.0693359 0.0366211 -0.00595093 ... 0.0917969 0.0947266 -0.0869141]\n",
      "   [0.0693359 0.0366211 -0.00595093 ... 0.0917969 0.0947266 -0.0869141]\n",
      "   [0.0693359 0.0366211 -0.00595093 ... 0.0917969 0.0947266 -0.0869141]]\n",
      "\n",
      "  [[-0.00463867 0.0515137 -0.0952148 ... -0.0498047 -0.0761719 0.104004]\n",
      "   [0.000640869 0.0488281 -0.09375 ... -0.0429688 -0.0727539 0.104004]\n",
      "   [-0.00131226 0.0493164 -0.0927734 ... -0.0483398 -0.0712891 0.105469]\n",
      "   ...\n",
      "   [-0.00202942 0.0541992 -0.0913086 ... -0.0471191 -0.0722656 0.106934]\n",
      "   [-0.00202942 0.0541992 -0.0913086 ... -0.0471191 -0.0722656 0.106934]\n",
      "   [-0.00202942 0.0541992 -0.0913086 ... -0.0471191 -0.0722656 0.106934]]\n",
      "\n",
      "  [[0.0192871 -0.00543213 0.0649414 ... 0.0227051 -0.0112915 -0.0151978]\n",
      "   [0.0164795 -0.00466919 0.0654297 ... 0.0159912 -0.0131226 -0.0143433]\n",
      "   [0.0186768 -0.00570679 0.0644531 ... 0.0198975 -0.0157471 -0.0159912]\n",
      "   ...\n",
      "   [0.022583 -0.00328064 0.065918 ... 0.0198975 -0.0144653 -0.0177002]\n",
      "   [0.022583 -0.00328064 0.065918 ... 0.0198975 -0.0144653 -0.0177002]\n",
      "   [0.022583 -0.00328064 0.065918 ... 0.0198975 -0.0144653 -0.0177002]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0284424 -0.032959 -0.0371094 ... 0.00619507 0.0185547 -0.00891113]\n",
      "   [0.03125 -0.0288086 -0.0351562 ... 0.00500488 0.0213623 -0.00549316]\n",
      "   [0.0280762 -0.0317383 -0.0400391 ... 0.00817871 0.0180664\n",
      "    -0.00509644]\n",
      "   ...\n",
      "   [0.0285645 -0.03125 -0.0366211 ... 0.0019455 0.0195312 -0.00521851]\n",
      "   [0.0285645 -0.03125 -0.0366211 ... 0.0019455 0.0195312 -0.00521851]\n",
      "   [0.0285645 -0.03125 -0.0366211 ... 0.0019455 0.0195312 -0.00521851]]\n",
      "\n",
      "  [[0.123047 -0.0546875 0.0169678 ... -0.0820312 0.0311279 -0.0258789]\n",
      "   [0.122559 -0.0537109 0.0229492 ... -0.0825195 0.0306396 -0.0251465]\n",
      "   [0.123047 -0.0581055 0.0203857 ... -0.0830078 0.0344238 -0.0262451]\n",
      "   ...\n",
      "   [0.118164 -0.0551758 0.0194092 ... -0.0869141 0.0289307 -0.03125]\n",
      "   [0.118164 -0.0551758 0.0194092 ... -0.0869141 0.0289307 -0.03125]\n",
      "   [0.118164 -0.0551758 0.0194092 ... -0.0869141 0.0289307 -0.03125]]\n",
      "\n",
      "  [[-0.0566406 0.0722656 -0.0390625 ... -0.0213623 -0.000659943\n",
      "    0.0869141]\n",
      "   [-0.0688477 0.0800781 -0.041748 ... -0.0213623 -0.0108643 0.0854492]\n",
      "   [-0.060791 0.0771484 -0.0388184 ... -0.0198975 -0.0072937 0.0888672]\n",
      "   ...\n",
      "   [-0.0563965 0.0742188 -0.0463867 ... -0.0201416 -0.000850677\n",
      "    0.0878906]\n",
      "   [-0.0563965 0.0742188 -0.0463867 ... -0.0201416 -0.000850677\n",
      "    0.0878906]\n",
      "   [-0.0563965 0.0742188 -0.0463867 ... -0.0201416 -0.000850677\n",
      "    0.0878906]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.105469 0.00765991 0.0185547 ... 0.0378418 -0.048584 -0.0216064]\n",
      "   [-0.10498 0.00805664 0.0172119 ... 0.0405273 -0.0517578 -0.0228271]\n",
      "   [-0.0981445 0.00915527 0.0233154 ... 0.0356445 -0.0537109 -0.0209961]\n",
      "   ...\n",
      "   [-0.108398 0.00680542 0.0179443 ... 0.0383301 -0.0473633 -0.0198975]\n",
      "   [-0.108398 0.00680542 0.0179443 ... 0.0383301 -0.0473633 -0.0198975]\n",
      "   [-0.108398 0.00680542 0.0179443 ... 0.0383301 -0.0473633 -0.0198975]]\n",
      "\n",
      "  [[0.0179443 0.020752 0.0437012 ... -0.0397949 -0.0255127 -0.0524902]\n",
      "   [0.0203857 0.0185547 0.0456543 ... -0.0444336 -0.0230713 -0.0539551]\n",
      "   [0.0211182 0.0162354 0.0458984 ... -0.0419922 -0.0187988 -0.0554199]\n",
      "   ...\n",
      "   [0.0213623 0.0189209 0.0490723 ... -0.041748 -0.0258789 -0.0537109]\n",
      "   [0.0213623 0.0189209 0.0490723 ... -0.041748 -0.0258789 -0.0537109]\n",
      "   [0.0213623 0.0189209 0.0490723 ... -0.041748 -0.0258789 -0.0537109]]\n",
      "\n",
      "  [[0.0137939 0.115234 0.0605469 ... -0.0390625 0.0302734 0.0158691]\n",
      "   [0.0111084 0.111816 0.0585938 ... -0.0397949 0.027832 0.0155029]\n",
      "   [0.0137329 0.11084 0.0615234 ... -0.041748 0.029541 0.0136108]\n",
      "   ...\n",
      "   [0.00515747 0.115723 0.0612793 ... -0.0444336 0.0319824 0.0172119]\n",
      "   [0.00515747 0.115723 0.0612793 ... -0.0444336 0.0319824 0.0172119]\n",
      "   [0.00515747 0.115723 0.0612793 ... -0.0444336 0.0319824 0.0172119]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.00823975 -0.0600586 -0.0230713 ... -0.0549316 -0.052002 -0.052002]\n",
      "   [0.00830078 -0.0529785 -0.020752 ... -0.052002 -0.0551758 -0.0522461]\n",
      "   [0.00769043 -0.0625 -0.0231934 ... -0.0495605 -0.0515137 -0.0515137]\n",
      "   ...\n",
      "   [0.00402832 -0.0585938 -0.0211182 ... -0.0541992 -0.0524902\n",
      "    -0.0524902]\n",
      "   [0.00402832 -0.0585938 -0.0211182 ... -0.0541992 -0.0524902\n",
      "    -0.0524902]\n",
      "   [0.00402832 -0.0585938 -0.0211182 ... -0.0541992 -0.0524902\n",
      "    -0.0524902]]\n",
      "\n",
      "  [[0.115234 -0.00671387 -0.0373535 ... -0.0324707 0.00769043\n",
      "    -0.0395508]\n",
      "   [0.124512 -0.00695801 -0.0375977 ... -0.0317383 0.00683594\n",
      "    -0.0385742]\n",
      "   [0.128906 -0.00692749 -0.0380859 ... -0.0324707 0.00509644\n",
      "    -0.0412598]\n",
      "   ...\n",
      "   [0.128906 -0.00418091 -0.0395508 ... -0.0349121 0.00674438\n",
      "    -0.0437012]\n",
      "   [0.128906 -0.00418091 -0.0395508 ... -0.0349121 0.00674438\n",
      "    -0.0437012]\n",
      "   [0.128906 -0.00418091 -0.0395508 ... -0.0349121 0.00674438\n",
      "    -0.0437012]]\n",
      "\n",
      "  [[0.0500488 0.0917969 -0.0776367 ... 0.0109253 0.0505371 0.0463867]\n",
      "   [0.0473633 0.0932617 -0.0703125 ... 0.00964355 0.0517578 0.0446777]\n",
      "   [0.0461426 0.0859375 -0.0727539 ... 0.00823975 0.0476074 0.0493164]\n",
      "   ...\n",
      "   [0.0471191 0.0888672 -0.0771484 ... 0.0107422 0.0539551 0.0488281]\n",
      "   [0.0471191 0.0888672 -0.0771484 ... 0.0107422 0.0539551 0.0488281]\n",
      "   [0.0471191 0.0888672 -0.0771484 ... 0.0107422 0.0539551 0.0488281]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0213623 0.0444336 0.0495605 ... 0.0727539 -0.0529785 0.101074]\n",
      "   [-0.0213623 0.0439453 0.0488281 ... 0.0751953 -0.052002 0.0996094]\n",
      "   [-0.0197754 0.046875 0.0449219 ... 0.0712891 -0.0476074 0.0966797]\n",
      "   ...\n",
      "   [-0.0213623 0.0441895 0.0505371 ... 0.0708008 -0.0527344 0.0991211]\n",
      "   [-0.0213623 0.0441895 0.0505371 ... 0.0708008 -0.0527344 0.0991211]\n",
      "   [-0.0213623 0.0441895 0.0505371 ... 0.0708008 -0.0527344 0.0991211]]\n",
      "\n",
      "  [[-0.00552368 0.104004 -0.0395508 ... -0.0224609 0.0625 -0.0284424]\n",
      "   [-0.00216675 0.10791 -0.0327148 ... -0.0212402 0.0644531 -0.0274658]\n",
      "   [-0.00248718 0.105469 -0.0300293 ... -0.0181885 0.0683594 -0.027832]\n",
      "   ...\n",
      "   [-0.00952148 0.10791 -0.0296631 ... -0.0239258 0.0617676 -0.0336914]\n",
      "   [-0.00952148 0.10791 -0.0296631 ... -0.0239258 0.0617676 -0.0336914]\n",
      "   [-0.00952148 0.10791 -0.0296631 ... -0.0239258 0.0617676 -0.0336914]]\n",
      "\n",
      "  [[-0.0922852 0.00686646 -0.0164795 ... -0.0515137 0.00154877\n",
      "    0.0301514]\n",
      "   [-0.0981445 0.00958252 -0.0175781 ... -0.0493164 0.00108337\n",
      "    0.0349121]\n",
      "   [-0.0966797 0.00698853 -0.0150146 ... -0.046875 0.00254822 0.0306396]\n",
      "   ...\n",
      "   [-0.100586 0.0125122 -0.0172119 ... -0.0458984 0.00166321 0.0327148]\n",
      "   [-0.100586 0.0125122 -0.0172119 ... -0.0458984 0.00166321 0.0327148]\n",
      "   [-0.100586 0.0125122 -0.0172119 ... -0.0458984 0.00166321 0.0327148]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0410156 -0.0922852 -0.0164795 ... -0.0310059 -0.0157471\n",
      "    0.0402832]\n",
      "   [-0.0429688 -0.0883789 -0.0200195 ... -0.0336914 -0.017334 0.0383301]\n",
      "   [-0.0432129 -0.0942383 -0.0168457 ... -0.0314941 -0.0158691\n",
      "    0.0383301]\n",
      "   ...\n",
      "   [-0.0444336 -0.09375 -0.0158691 ... -0.0358887 -0.015564 0.0358887]\n",
      "   [-0.0444336 -0.09375 -0.0158691 ... -0.0358887 -0.015564 0.0358887]\n",
      "   [-0.0444336 -0.09375 -0.0158691 ... -0.0358887 -0.015564 0.0358887]]\n",
      "\n",
      "  [[-0.00958252 0.0144653 -0.010437 ... -0.00946045 -0.0219727\n",
      "    0.0251465]\n",
      "   [-0.0147095 0.0167236 -0.0126343 ... -0.0136108 -0.0241699 0.0263672]\n",
      "   [-0.00891113 0.0108643 -0.0139771 ... -0.00964355 -0.020874\n",
      "    0.0245361]\n",
      "   ...\n",
      "   [-0.00866699 0.0107422 -0.0107422 ... -0.00872803 -0.020874\n",
      "    0.0257568]\n",
      "   [-0.00866699 0.0107422 -0.0107422 ... -0.00872803 -0.020874\n",
      "    0.0257568]\n",
      "   [-0.00866699 0.0107422 -0.0107422 ... -0.00872803 -0.020874\n",
      "    0.0257568]]\n",
      "\n",
      "  [[-0.0174561 -0.0303955 -0.0529785 ... 0.0495605 0.00204468 0.0825195]\n",
      "   [-0.0164795 -0.0324707 -0.0566406 ... 0.0493164 -0.001297 0.0839844]\n",
      "   [-0.0203857 -0.0286865 -0.0549316 ... 0.0515137 0.000289917\n",
      "    0.0839844]\n",
      "   ...\n",
      "   [-0.0135498 -0.0262451 -0.0495605 ... 0.0534668 -0.00112152\n",
      "    0.0839844]\n",
      "   [-0.0135498 -0.0262451 -0.0495605 ... 0.0534668 -0.00112152\n",
      "    0.0839844]\n",
      "   [-0.0135498 -0.0262451 -0.0495605 ... 0.0534668 -0.00112152\n",
      "    0.0839844]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.019165 -0.0180664 -0.0537109 ... 0.032959 -0.03125 -0.00720215]\n",
      "   [-0.0115967 -0.0167236 -0.0546875 ... 0.0349121 -0.0375977 -0.010376]\n",
      "   [-0.0147705 -0.0220947 -0.0556641 ... 0.0292969 -0.0371094\n",
      "    -0.0088501]\n",
      "   ...\n",
      "   [-0.0157471 -0.0209961 -0.0541992 ... 0.0351562 -0.034668 -0.0100708]\n",
      "   [-0.0157471 -0.0209961 -0.0541992 ... 0.0351562 -0.034668 -0.0100708]\n",
      "   [-0.0157471 -0.0209961 -0.0541992 ... 0.0351562 -0.034668 -0.0100708]]\n",
      "\n",
      "  [[0.036377 0.03125 0.134766 ... 0.0917969 0.0119629 -0.034668]\n",
      "   [0.03125 0.0299072 0.133789 ... 0.0927734 0.0100098 -0.036377]\n",
      "   [0.0366211 0.0332031 0.142578 ... 0.090332 0.0102539 -0.0332031]\n",
      "   ...\n",
      "   [0.0378418 0.0349121 0.132812 ... 0.0952148 0.0078125 -0.036377]\n",
      "   [0.0378418 0.0349121 0.132812 ... 0.0952148 0.0078125 -0.036377]\n",
      "   [0.0378418 0.0349121 0.132812 ... 0.0952148 0.0078125 -0.036377]]\n",
      "\n",
      "  [[0.00692749 -0.00476074 0.0294189 ... 0.00318909 -0.0112305\n",
      "    0.0610352]\n",
      "   [0.0101929 -0.0133667 0.0275879 ... 0.00102997 -0.00601196 0.0654297]\n",
      "   [0.00933838 -0.00738525 0.03125 ... 0.00256348 -0.00793457 0.0610352]\n",
      "   ...\n",
      "   [0.00897217 -0.00457764 0.0253906 ... 0.00204468 -0.0071106\n",
      "    0.0610352]\n",
      "   [0.00897217 -0.00457764 0.0253906 ... 0.00204468 -0.0071106\n",
      "    0.0610352]\n",
      "   [0.00897217 -0.00457764 0.0253906 ... 0.00204468 -0.0071106\n",
      "    0.0610352]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0202637 0.0500488 -0.148438 ... 0.0488281 -0.0252686 0.00469971]\n",
      "   [0.017334 0.0473633 -0.141602 ... 0.0522461 -0.0300293 0.000530243]\n",
      "   [0.0220947 0.0512695 -0.147461 ... 0.0524902 -0.0223389 0.000835419]\n",
      "   ...\n",
      "   [0.0220947 0.0534668 -0.148438 ... 0.0527344 -0.022583 0.00358582]\n",
      "   [0.0220947 0.0534668 -0.148438 ... 0.0527344 -0.022583 0.00358582]\n",
      "   [0.0220947 0.0534668 -0.148438 ... 0.0527344 -0.022583 0.00358582]]\n",
      "\n",
      "  [[-0.0498047 -0.0157471 0.0712891 ... 0.00405884 -0.0239258 -0.097168]\n",
      "   [-0.0483398 -0.0177002 0.0712891 ... 0.00119781 -0.0227051\n",
      "    -0.0976562]\n",
      "   [-0.0493164 -0.0181885 0.0732422 ... 0.00299072 -0.0220947\n",
      "    -0.0913086]\n",
      "   ...\n",
      "   [-0.0505371 -0.0147095 0.0703125 ... 0.00296021 -0.0257568\n",
      "    -0.0961914]\n",
      "   [-0.0505371 -0.0147095 0.0703125 ... 0.00296021 -0.0257568\n",
      "    -0.0961914]\n",
      "   [-0.0505371 -0.0147095 0.0703125 ... 0.00296021 -0.0257568\n",
      "    -0.0961914]]\n",
      "\n",
      "  [[0.0458984 0.0119019 0.0238037 ... 0.00860596 -0.0412598 -0.0603027]\n",
      "   [0.0388184 0.0148926 0.0233154 ... 0.0114746 -0.0402832 -0.0588379]\n",
      "   [0.0456543 0.0147705 0.0203857 ... 0.0128174 -0.0375977 -0.0605469]\n",
      "   ...\n",
      "   [0.0488281 0.0137329 0.0197754 ... 0.0100708 -0.0354004 -0.0566406]\n",
      "   [0.0488281 0.0137329 0.0197754 ... 0.0100708 -0.0354004 -0.0566406]\n",
      "   [0.0488281 0.0137329 0.0197754 ... 0.0100708 -0.0354004 -0.0566406]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0634766 0.103516 0.0274658 ... 0.0388184 0.0805664 -0.046875]\n",
      "   [0.0634766 0.101562 0.019043 ... 0.045166 0.0839844 -0.0493164]\n",
      "   [0.0644531 0.105957 0.0267334 ... 0.0385742 0.078125 -0.0410156]\n",
      "   ...\n",
      "   [0.0563965 0.102051 0.0289307 ... 0.0449219 0.0805664 -0.0498047]\n",
      "   [0.0563965 0.102051 0.0289307 ... 0.0449219 0.0805664 -0.0498047]\n",
      "   [0.0563965 0.102051 0.0289307 ... 0.0449219 0.0805664 -0.0498047]]\n",
      "\n",
      "  [[-0.050293 -0.0130005 0.0045166 ... 0.0395508 -0.0224609 -0.0319824]\n",
      "   [-0.0544434 -0.00778198 0.00772095 ... 0.0397949 -0.0247803\n",
      "    -0.0358887]\n",
      "   [-0.0490723 -0.0150146 0.00686646 ... 0.0383301 -0.0245361\n",
      "    -0.0366211]\n",
      "   ...\n",
      "   [-0.0478516 -0.0111694 0.00927734 ... 0.0334473 -0.0213623\n",
      "    -0.0324707]\n",
      "   [-0.0478516 -0.0111694 0.00927734 ... 0.0334473 -0.0213623\n",
      "    -0.0324707]\n",
      "   [-0.0478516 -0.0111694 0.00927734 ... 0.0334473 -0.0213623\n",
      "    -0.0324707]]\n",
      "\n",
      "  [[-0.0354004 -0.0032959 0.0184326 ... 0.0114746 -0.0299072 -0.0147095]\n",
      "   [-0.0297852 -0.00442505 0.0184326 ... 0.00994873 -0.0373535\n",
      "    -0.00408936]\n",
      "   [-0.0341797 -0.000488281 0.0155029 ... 0.0114746 -0.0356445\n",
      "    -0.0090332]\n",
      "   ...\n",
      "   [-0.034668 -0.00236511 0.020752 ... 0.0105591 -0.0373535 -0.00753784]\n",
      "   [-0.034668 -0.00236511 0.020752 ... 0.0105591 -0.0373535 -0.00753784]\n",
      "   [-0.034668 -0.00236511 0.020752 ... 0.0105591 -0.0373535 -0.00753784]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0140381 -0.0732422 0.0174561 ... 0.0361328 -0.0800781 -0.0159912]\n",
      "   [0.0184326 -0.0795898 0.022583 ... 0.036377 -0.0878906 -0.0161133]\n",
      "   [0.0180664 -0.0834961 0.0213623 ... 0.0390625 -0.0874023 -0.0152588]\n",
      "   ...\n",
      "   [0.0192871 -0.081543 0.0206299 ... 0.0361328 -0.090332 -0.0152588]\n",
      "   [0.0192871 -0.081543 0.0206299 ... 0.0361328 -0.090332 -0.0152588]\n",
      "   [0.0192871 -0.081543 0.0206299 ... 0.0361328 -0.090332 -0.0152588]]\n",
      "\n",
      "  [[-0.0668945 -0.00720215 -0.0179443 ... -0.0100708 -0.000370026\n",
      "    -0.00306702]\n",
      "   [-0.0678711 -0.00946045 -0.0213623 ... -0.00866699 -0.00126648\n",
      "    -0.00170898]\n",
      "   [-0.0649414 -0.00933838 -0.0224609 ... -0.0111084 0.00337219\n",
      "    -0.00132751]\n",
      "   ...\n",
      "   [-0.0678711 -0.00994873 -0.0258789 ... -0.0120239 -0.000284195\n",
      "    -0.00376892]\n",
      "   [-0.0678711 -0.00994873 -0.0258789 ... -0.0120239 -0.000284195\n",
      "    -0.00376892]\n",
      "   [-0.0678711 -0.00994873 -0.0258789 ... -0.0120239 -0.000284195\n",
      "    -0.00376892]]\n",
      "\n",
      "  [[-0.0742188 -0.0495605 -0.0612793 ... 0.0776367 -0.00933838\n",
      "    -0.0756836]\n",
      "   [-0.0771484 -0.0446777 -0.0534668 ... 0.0800781 -0.00982666\n",
      "    -0.0810547]\n",
      "   [-0.0761719 -0.0456543 -0.0581055 ... 0.074707 -0.00909424\n",
      "    -0.0854492]\n",
      "   ...\n",
      "   [-0.0732422 -0.0449219 -0.059082 ... 0.0756836 -0.00860596\n",
      "    -0.0776367]\n",
      "   [-0.0732422 -0.0449219 -0.059082 ... 0.0756836 -0.00860596\n",
      "    -0.0776367]\n",
      "   [-0.0732422 -0.0449219 -0.059082 ... 0.0756836 -0.00860596\n",
      "    -0.0776367]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0922852 0.0751953 -0.0153198 ... 0.0166016 0.0218506 -0.0266113]\n",
      "   [-0.0932617 0.0771484 -0.0172119 ... 0.0172119 0.0185547 -0.0296631]\n",
      "   [-0.0947266 0.0761719 -0.0205078 ... 0.0198975 0.0148315 -0.0334473]\n",
      "   ...\n",
      "   [-0.0961914 0.0786133 -0.0187988 ... 0.0187988 0.017334 -0.0250244]\n",
      "   [-0.0961914 0.0786133 -0.0187988 ... 0.0187988 0.017334 -0.0250244]\n",
      "   [-0.0961914 0.0786133 -0.0187988 ... 0.0187988 0.017334 -0.0250244]]\n",
      "\n",
      "  [[0.0233154 0.0102539 -0.0578613 ... -0.000808716 0.00192261\n",
      "    -0.0722656]\n",
      "   [0.0241699 0.0132446 -0.0554199 ... -0.0057373 0.00153351 -0.0776367]\n",
      "   [0.0224609 0.0143433 -0.0522461 ... -0.00101471 0.00292969\n",
      "    -0.0751953]\n",
      "   ...\n",
      "   [0.0255127 0.0109863 -0.0551758 ... -0.00300598 -0.00236511\n",
      "    -0.074707]\n",
      "   [0.0255127 0.0109863 -0.0551758 ... -0.00300598 -0.00236511\n",
      "    -0.074707]\n",
      "   [0.0255127 0.0109863 -0.0551758 ... -0.00300598 -0.00236511\n",
      "    -0.074707]]\n",
      "\n",
      "  [[-0.0136108 0.0507812 -0.013855 ... -0.0361328 -0.00769043\n",
      "    -0.0390625]\n",
      "   [-0.017334 0.0478516 -0.00762939 ... -0.0373535 -0.00564575\n",
      "    -0.0407715]\n",
      "   [-0.015625 0.0510254 -0.0133667 ... -0.0308838 -0.00860596\n",
      "    -0.0412598]\n",
      "   ...\n",
      "   [-0.0196533 0.0515137 -0.0155029 ... -0.0305176 -0.000759125\n",
      "    -0.0383301]\n",
      "   [-0.0196533 0.0515137 -0.0155029 ... -0.0305176 -0.000759125\n",
      "    -0.0383301]\n",
      "   [-0.0196533 0.0515137 -0.0155029 ... -0.0305176 -0.000759125\n",
      "    -0.0383301]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.020752 0.0169678 0.0629883 ... 0.019043 0.0106812 -0.0128174]\n",
      "   [-0.0185547 0.0131836 0.0612793 ... 0.0163574 0.0100098 -0.0140991]\n",
      "   [-0.0177002 0.0137939 0.0649414 ... 0.0157471 0.00964355 -0.0109863]\n",
      "   ...\n",
      "   [-0.019043 0.0158691 0.0593262 ... 0.0144653 0.012146 -0.0127563]\n",
      "   [-0.019043 0.0158691 0.0593262 ... 0.0144653 0.012146 -0.0127563]\n",
      "   [-0.019043 0.0158691 0.0593262 ... 0.0144653 0.012146 -0.0127563]]\n",
      "\n",
      "  [[0.00518799 -0.0246582 -0.0498047 ... 0.0144653 -0.0805664 0.0351562]\n",
      "   [0.00708008 -0.0289307 -0.050293 ... 0.0149536 -0.0761719 0.0339355]\n",
      "   [0.0039978 -0.024292 -0.0512695 ... 0.0126343 -0.0800781 0.0322266]\n",
      "   ...\n",
      "   [0.00372314 -0.0236816 -0.050293 ... 0.0131226 -0.0834961 0.032959]\n",
      "   [0.00372314 -0.0236816 -0.050293 ... 0.0131226 -0.0834961 0.032959]\n",
      "   [0.00372314 -0.0236816 -0.050293 ... 0.0131226 -0.0834961 0.032959]]\n",
      "\n",
      "  [[-0.0169678 -0.0288086 0.0250244 ... 0.0617676 0.0776367 -0.0463867]\n",
      "   [-0.0159912 -0.0230713 0.0228271 ... 0.0620117 0.0756836 -0.052002]\n",
      "   [-0.0184326 -0.0264893 0.020752 ... 0.0612793 0.0756836 -0.0495605]\n",
      "   ...\n",
      "   [-0.0205078 -0.0252686 0.0267334 ... 0.0612793 0.0727539 -0.0480957]\n",
      "   [-0.0205078 -0.0252686 0.0267334 ... 0.0612793 0.0727539 -0.0480957]\n",
      "   [-0.0205078 -0.0252686 0.0267334 ... 0.0612793 0.0727539 -0.0480957]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00119019 0.0957031 -0.0373535 ... -0.0424805 0.026123 -0.0123291]\n",
      "   [-0.000131607 0.0957031 -0.0373535 ... -0.0439453 0.0332031\n",
      "    -0.00994873]\n",
      "   [-0.0013504 0.0981445 -0.0354004 ... -0.0402832 0.0281982\n",
      "    -0.00576782]\n",
      "   ...\n",
      "   [0.0010376 0.097168 -0.036377 ... -0.0424805 0.0244141 -0.00878906]\n",
      "   [0.0010376 0.097168 -0.036377 ... -0.0424805 0.0244141 -0.00878906]\n",
      "   [0.0010376 0.097168 -0.036377 ... -0.0424805 0.0244141 -0.00878906]]\n",
      "\n",
      "  [[-0.0175781 0.0534668 0.0673828 ... -0.0771484 -0.0108032 0.0437012]\n",
      "   [-0.0153809 0.0583496 0.0708008 ... -0.0717773 -0.00297546 0.0395508]\n",
      "   [-0.0148315 0.0571289 0.0673828 ... -0.0678711 -0.00176239 0.0388184]\n",
      "   ...\n",
      "   [-0.0161133 0.0544434 0.0649414 ... -0.0693359 -0.00231934 0.0334473]\n",
      "   [-0.0161133 0.0544434 0.0649414 ... -0.0693359 -0.00231934 0.0334473]\n",
      "   [-0.0161133 0.0544434 0.0649414 ... -0.0693359 -0.00231934 0.0334473]]\n",
      "\n",
      "  [[0.0505371 0.0991211 0.0541992 ... -0.0505371 -0.00778198 -0.0162354]\n",
      "   [0.045166 0.097168 0.0554199 ... -0.0498047 -0.00775146 -0.0177002]\n",
      "   [0.0490723 0.0947266 0.0571289 ... -0.050293 -0.0111084 -0.0166016]\n",
      "   ...\n",
      "   [0.0495605 0.0986328 0.0581055 ... -0.0498047 -0.00897217 -0.0127563]\n",
      "   [0.0495605 0.0986328 0.0581055 ... -0.0498047 -0.00897217 -0.0127563]\n",
      "   [0.0495605 0.0986328 0.0581055 ... -0.0498047 -0.00897217 -0.0127563]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0290527 0.00726318 -0.0317383 ... 0.0825195 0.0534668 -0.0717773]\n",
      "   [-0.0255127 0.0146484 -0.0380859 ... 0.0795898 0.0529785 -0.074707]\n",
      "   [-0.0281982 0.0112305 -0.0317383 ... 0.0805664 0.0544434 -0.0766602]\n",
      "   ...\n",
      "   [-0.0284424 0.0100708 -0.0303955 ... 0.0756836 0.0551758 -0.0732422]\n",
      "   [-0.0284424 0.0100708 -0.0303955 ... 0.0756836 0.0551758 -0.0732422]\n",
      "   [-0.0284424 0.0100708 -0.0303955 ... 0.0756836 0.0551758 -0.0732422]]\n",
      "\n",
      "  [[-0.0327148 -0.0581055 -0.024292 ... -0.0668945 0.027832 0.0913086]\n",
      "   [-0.0286865 -0.0566406 -0.0249023 ... -0.0664062 0.019043 0.0966797]\n",
      "   [-0.0300293 -0.0595703 -0.02771 ... -0.0649414 0.0186768 0.0961914]\n",
      "   ...\n",
      "   [-0.0302734 -0.0588379 -0.0268555 ... -0.0649414 0.020874 0.0922852]\n",
      "   [-0.0302734 -0.0588379 -0.0268555 ... -0.0649414 0.020874 0.0922852]\n",
      "   [-0.0302734 -0.0588379 -0.0268555 ... -0.0649414 0.020874 0.0922852]]\n",
      "\n",
      "  [[-0.0212402 0.0311279 -0.0673828 ... 0.0368652 -0.0588379 0.0424805]\n",
      "   [-0.0194092 0.0314941 -0.0693359 ... 0.0385742 -0.0568848 0.0415039]\n",
      "   [-0.0224609 0.03125 -0.0683594 ... 0.0393066 -0.0505371 0.0410156]\n",
      "   ...\n",
      "   [-0.0198975 0.0375977 -0.0708008 ... 0.0371094 -0.0554199 0.0458984]\n",
      "   [-0.0198975 0.0375977 -0.0708008 ... 0.0371094 -0.0554199 0.0458984]\n",
      "   [-0.0198975 0.0375977 -0.0708008 ... 0.0371094 -0.0554199 0.0458984]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0429688 -0.00854492 0.0230713 ... 0.03125 0.111328 0.0456543]\n",
      "   [-0.0412598 -0.00698853 0.0233154 ... 0.0341797 0.116699 0.0463867]\n",
      "   [-0.036377 -0.00613403 0.0180664 ... 0.0294189 0.110352 0.0429688]\n",
      "   ...\n",
      "   [-0.045166 -0.00601196 0.0184326 ... 0.0332031 0.107422 0.0500488]\n",
      "   [-0.045166 -0.00601196 0.0184326 ... 0.0332031 0.107422 0.0500488]\n",
      "   [-0.045166 -0.00601196 0.0184326 ... 0.0332031 0.107422 0.0500488]]\n",
      "\n",
      "  [[-0.0405273 -0.000724792 -0.0263672 ... -0.0228271 -0.0458984\n",
      "    0.0151978]\n",
      "   [-0.0424805 -0.000923157 -0.0245361 ... -0.0249023 -0.0466309\n",
      "    0.0175781]\n",
      "   [-0.045166 0.00167847 -0.0238037 ... -0.0247803 -0.0454102 0.019043]\n",
      "   ...\n",
      "   [-0.0402832 -0.00166321 -0.0266113 ... -0.0292969 -0.0476074\n",
      "    0.0216064]\n",
      "   [-0.0402832 -0.00166321 -0.0266113 ... -0.0292969 -0.0476074\n",
      "    0.0216064]\n",
      "   [-0.0402832 -0.00166321 -0.0266113 ... -0.0292969 -0.0476074\n",
      "    0.0216064]]\n",
      "\n",
      "  [[-0.00927734 -0.032959 0.0449219 ... 0.0883789 -0.0197754 -0.027832]\n",
      "   [-0.00860596 -0.0284424 0.0488281 ... 0.0859375 -0.019043 -0.0308838]\n",
      "   [-0.012085 -0.0283203 0.0466309 ... 0.0839844 -0.0185547 -0.0288086]\n",
      "   ...\n",
      "   [-0.0144653 -0.0303955 0.0439453 ... 0.0893555 -0.0185547 -0.0267334]\n",
      "   [-0.0144653 -0.0303955 0.0439453 ... 0.0893555 -0.0185547 -0.0267334]\n",
      "   [-0.0144653 -0.0303955 0.0439453 ... 0.0893555 -0.0185547 -0.0267334]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0197754 -0.0220947 0.0410156 ... -0.0742188 -0.0159912 0.0264893]\n",
      "   [0.0166016 -0.0220947 0.0349121 ... -0.0786133 -0.0157471 0.0249023]\n",
      "   [0.0236816 -0.0197754 0.0383301 ... -0.0805664 -0.0166016 0.0218506]\n",
      "   ...\n",
      "   [0.0153198 -0.0168457 0.0378418 ... -0.0742188 -0.0161133 0.0238037]\n",
      "   [0.0153198 -0.0168457 0.0378418 ... -0.0742188 -0.0161133 0.0238037]\n",
      "   [0.0153198 -0.0168457 0.0378418 ... -0.0742188 -0.0161133 0.0238037]]\n",
      "\n",
      "  [[-0.0424805 0.0162354 0.0688477 ... 0.0571289 -0.0148315 0.00735474]\n",
      "   [-0.0422363 0.0164795 0.0693359 ... 0.0634766 -0.0170898 0.00534058]\n",
      "   [-0.0422363 0.0136108 0.0683594 ... 0.0559082 -0.015564 0.00494385]\n",
      "   ...\n",
      "   [-0.0446777 0.0106812 0.0688477 ... 0.0556641 -0.0136108 0.00485229]\n",
      "   [-0.0446777 0.0106812 0.0688477 ... 0.0556641 -0.0136108 0.00485229]\n",
      "   [-0.0446777 0.0106812 0.0688477 ... 0.0556641 -0.0136108 0.00485229]]\n",
      "\n",
      "  [[0.0327148 -0.0554199 0.010437 ... 0.0375977 -0.0136108 0.0351562]\n",
      "   [0.0349121 -0.0507812 0.0100098 ... 0.034668 -0.0115356 0.0319824]\n",
      "   [0.0301514 -0.0549316 0.0109863 ... 0.041748 -0.00909424 0.0294189]\n",
      "   ...\n",
      "   [0.0290527 -0.0559082 0.00488281 ... 0.0351562 -0.0100708 0.0332031]\n",
      "   [0.0290527 -0.0559082 0.00488281 ... 0.0351562 -0.0100708 0.0332031]\n",
      "   [0.0290527 -0.0559082 0.00488281 ... 0.0351562 -0.0100708 0.0332031]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0280762 0.0454102 -0.0578613 ... 0.00860596 -0.0385742\n",
      "    -0.0297852]\n",
      "   [-0.0275879 0.0385742 -0.0541992 ... 0.00878906 -0.0368652\n",
      "    -0.0301514]\n",
      "   [-0.027832 0.0380859 -0.0554199 ... 0.0101318 -0.0383301 -0.0270996]\n",
      "   ...\n",
      "   [-0.0279541 0.0427246 -0.0563965 ... 0.00866699 -0.0402832\n",
      "    -0.0294189]\n",
      "   [-0.0279541 0.0427246 -0.0563965 ... 0.00866699 -0.0402832\n",
      "    -0.0294189]\n",
      "   [-0.0279541 0.0427246 -0.0563965 ... 0.00866699 -0.0402832\n",
      "    -0.0294189]]\n",
      "\n",
      "  [[-0.0883789 0.0116577 0.0233154 ... -0.0957031 0.0693359 -0.0296631]\n",
      "   [-0.0883789 0.0116577 0.0267334 ... -0.0917969 0.0727539 -0.02771]\n",
      "   [-0.0834961 0.0123291 0.0291748 ... -0.0947266 0.0722656 -0.0269775]\n",
      "   ...\n",
      "   [-0.0849609 0.0114136 0.0266113 ... -0.0917969 0.0737305 -0.0284424]\n",
      "   [-0.0849609 0.0114136 0.0266113 ... -0.0917969 0.0737305 -0.0284424]\n",
      "   [-0.0849609 0.0114136 0.0266113 ... -0.0917969 0.0737305 -0.0284424]]\n",
      "\n",
      "  [[-0.00384521 0.0522461 -0.0246582 ... -0.0605469 0.0454102 0.0439453]\n",
      "   [-0.00567627 0.0522461 -0.027832 ... -0.0578613 0.0439453 0.045166]\n",
      "   [-0.00823975 0.0583496 -0.02771 ... -0.0568848 0.045166 0.0505371]\n",
      "   ...\n",
      "   [-0.00570679 0.0549316 -0.0268555 ... -0.0610352 0.0395508 0.046875]\n",
      "   [-0.00570679 0.0549316 -0.0268555 ... -0.0610352 0.0395508 0.046875]\n",
      "   [-0.00570679 0.0549316 -0.0268555 ... -0.0610352 0.0395508 0.046875]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0250244 -0.0727539 -0.00411987 ... 0.00454712 -0.0493164\n",
      "    0.0869141]\n",
      "   [0.0263672 -0.0722656 -0.00228882 ... 0.00823975 -0.0407715\n",
      "    0.0869141]\n",
      "   [0.0280762 -0.0727539 -0.00585938 ... 0.00634766 -0.0456543\n",
      "    0.0893555]\n",
      "   ...\n",
      "   [0.0291748 -0.0722656 -0.00291443 ... 0.00445557 -0.0429688\n",
      "    0.0869141]\n",
      "   [0.0291748 -0.0722656 -0.00291443 ... 0.00445557 -0.0429688\n",
      "    0.0869141]\n",
      "   [0.0291748 -0.0722656 -0.00291443 ... 0.00445557 -0.0429688\n",
      "    0.0869141]]\n",
      "\n",
      "  [[-0.101074 0.0292969 0.0688477 ... -0.0981445 0.0262451 -0.0456543]\n",
      "   [-0.104492 0.0267334 0.0712891 ... -0.105469 0.0219727 -0.0466309]\n",
      "   [-0.0986328 0.0279541 0.0678711 ... -0.103516 0.026001 -0.0488281]\n",
      "   ...\n",
      "   [-0.100586 0.0267334 0.0678711 ... -0.100586 0.0214844 -0.050293]\n",
      "   [-0.100586 0.0267334 0.0678711 ... -0.100586 0.0214844 -0.050293]\n",
      "   [-0.100586 0.0267334 0.0678711 ... -0.100586 0.0214844 -0.050293]]\n",
      "\n",
      "  [[-0.0332031 -0.132812 0.0184326 ... 0.0869141 -0.059082 -0.050293]\n",
      "   [-0.0319824 -0.134766 0.0172119 ... 0.0864258 -0.0571289 -0.0527344]\n",
      "   [-0.0305176 -0.134766 0.0201416 ... 0.0834961 -0.0566406 -0.0500488]\n",
      "   ...\n",
      "   [-0.0289307 -0.130859 0.0174561 ... 0.0874023 -0.0634766 -0.0532227]\n",
      "   [-0.0289307 -0.130859 0.0174561 ... 0.0874023 -0.0634766 -0.0532227]\n",
      "   [-0.0289307 -0.130859 0.0174561 ... 0.0874023 -0.0634766 -0.0532227]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0708008 0.0405273 -0.0888672 ... -0.0476074 0.0649414 0.0332031]\n",
      "   [0.0693359 0.0405273 -0.0913086 ... -0.048584 0.0654297 0.0344238]\n",
      "   [0.0668945 0.0393066 -0.0913086 ... -0.043457 0.0664062 0.0341797]\n",
      "   ...\n",
      "   [0.0668945 0.0400391 -0.0908203 ... -0.0466309 0.0668945 0.0317383]\n",
      "   [0.0668945 0.0400391 -0.0908203 ... -0.0466309 0.0668945 0.0317383]\n",
      "   [0.0668945 0.0400391 -0.0908203 ... -0.0466309 0.0668945 0.0317383]]\n",
      "\n",
      "  [[-0.130859 0.0544434 -0.0106812 ... 0.0771484 0.041748 0.0126343]\n",
      "   [-0.129883 0.0551758 -0.0118408 ... 0.0795898 0.0371094 0.0145874]\n",
      "   [-0.126953 0.0578613 -0.0101929 ... 0.0761719 0.0356445 0.0145874]\n",
      "   ...\n",
      "   [-0.133789 0.0578613 -0.0140991 ... 0.0810547 0.0354004 0.0140381]\n",
      "   [-0.133789 0.0578613 -0.0140991 ... 0.0810547 0.0354004 0.0140381]\n",
      "   [-0.133789 0.0578613 -0.0140991 ... 0.0810547 0.0354004 0.0140381]]\n",
      "\n",
      "  [[0.0203857 -0.0264893 -0.0427246 ... 0.0668945 -0.0664062 -0.0153198]\n",
      "   [0.0157471 -0.0239258 -0.0458984 ... 0.0664062 -0.0683594 -0.0136719]\n",
      "   [0.0187988 -0.0286865 -0.0476074 ... 0.0629883 -0.0654297 -0.0144043]\n",
      "   ...\n",
      "   [0.0189209 -0.0299072 -0.0415039 ... 0.0654297 -0.0654297 -0.0181885]\n",
      "   [0.0189209 -0.0299072 -0.0415039 ... 0.0654297 -0.0654297 -0.0181885]\n",
      "   [0.0189209 -0.0299072 -0.0415039 ... 0.0654297 -0.0654297 -0.0181885]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0427246 0.0888672 0.0625 ... 0.0578613 0.090332 0.074707]\n",
      "   [-0.0512695 0.0820312 0.0561523 ... 0.0563965 0.0864258 0.0732422]\n",
      "   [-0.0461426 0.0864258 0.0559082 ... 0.0561523 0.0913086 0.0717773]\n",
      "   ...\n",
      "   [-0.0444336 0.0849609 0.0585938 ... 0.0556641 0.0898438 0.0722656]\n",
      "   [-0.0444336 0.0849609 0.0585938 ... 0.0556641 0.0898438 0.0722656]\n",
      "   [-0.0444336 0.0849609 0.0585938 ... 0.0556641 0.0898438 0.0722656]]\n",
      "\n",
      "  [[0.0683594 -0.0314941 -0.019043 ... 0.0737305 0.0185547 -0.0654297]\n",
      "   [0.0742188 -0.0324707 -0.0206299 ... 0.0756836 0.0177002 -0.0708008]\n",
      "   [0.0732422 -0.0286865 -0.0231934 ... 0.0722656 0.0164795 -0.0673828]\n",
      "   ...\n",
      "   [0.0639648 -0.0378418 -0.0228271 ... 0.0727539 0.0163574 -0.0654297]\n",
      "   [0.0639648 -0.0378418 -0.0228271 ... 0.0727539 0.0163574 -0.0654297]\n",
      "   [0.0639648 -0.0378418 -0.0228271 ... 0.0727539 0.0163574 -0.0654297]]\n",
      "\n",
      "  [[0.0119629 -0.0252686 0.00491333 ... 0.0125732 -0.0109863 -0.0241699]\n",
      "   [0.0150146 -0.026001 0.00509644 ... 0.00848389 -0.00393677\n",
      "    -0.0216064]\n",
      "   [0.0119629 -0.024292 0.00558472 ... 0.00714111 -0.00585938\n",
      "    -0.0235596]\n",
      "   ...\n",
      "   [0.0140991 -0.0203857 0.0130615 ... 0.0141602 -0.0090332 -0.0233154]\n",
      "   [0.0140991 -0.0203857 0.0130615 ... 0.0141602 -0.0090332 -0.0233154]\n",
      "   [0.0140991 -0.0203857 0.0130615 ... 0.0141602 -0.0090332 -0.0233154]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0712891 0.0270996 -0.0305176 ... 0.125977 0.0356445 0.0305176]\n",
      "   [0.0683594 0.0266113 -0.0230713 ... 0.126953 0.036377 0.0307617]\n",
      "   [0.0751953 0.0283203 -0.0228271 ... 0.131836 0.0407715 0.0305176]\n",
      "   ...\n",
      "   [0.0717773 0.0253906 -0.0246582 ... 0.126953 0.0385742 0.0371094]\n",
      "   [0.0717773 0.0253906 -0.0246582 ... 0.126953 0.0385742 0.0371094]\n",
      "   [0.0717773 0.0253906 -0.0246582 ... 0.126953 0.0385742 0.0371094]]\n",
      "\n",
      "  [[0.00994873 0.0166016 0.0478516 ... 0.0942383 0.107422 0.0332031]\n",
      "   [0.010437 0.0229492 0.0488281 ... 0.0966797 0.106934 0.034668]\n",
      "   [0.00671387 0.0170898 0.0461426 ... 0.0947266 0.109375 0.0270996]\n",
      "   ...\n",
      "   [0.00372314 0.0189209 0.0454102 ... 0.09375 0.11084 0.0324707]\n",
      "   [0.00372314 0.0189209 0.0454102 ... 0.09375 0.11084 0.0324707]\n",
      "   [0.00372314 0.0189209 0.0454102 ... 0.09375 0.11084 0.0324707]]\n",
      "\n",
      "  [[-0.194336 -0.00811768 -0.0444336 ... -0.00118256 -0.0737305\n",
      "    0.0478516]\n",
      "   [-0.19043 -0.00112915 -0.0471191 ... 0.00144958 -0.0722656 0.0478516]\n",
      "   [-0.191406 -0.000218391 -0.0422363 ... -0.00167847 -0.0712891\n",
      "    0.0466309]\n",
      "   ...\n",
      "   [-0.193359 0.0037384 -0.0493164 ... 0.000463486 -0.0717773 0.0512695]\n",
      "   [-0.193359 0.0037384 -0.0493164 ... 0.000463486 -0.0717773 0.0512695]\n",
      "   [-0.193359 0.0037384 -0.0493164 ... 0.000463486 -0.0717773 0.0512695]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.057373 0.0383301 -0.0351562 ... -0.0412598 -0.0554199 -0.0952148]\n",
      "   [0.0571289 0.0407715 -0.0332031 ... -0.0405273 -0.059082 -0.0932617]\n",
      "   [0.0556641 0.0400391 -0.0383301 ... -0.0354004 -0.0600586 -0.0961914]\n",
      "   ...\n",
      "   [0.0534668 0.0407715 -0.0405273 ... -0.0390625 -0.0622559 -0.0981445]\n",
      "   [0.0534668 0.0407715 -0.0405273 ... -0.0390625 -0.0622559 -0.0981445]\n",
      "   [0.0534668 0.0407715 -0.0405273 ... -0.0390625 -0.0622559 -0.0981445]]\n",
      "\n",
      "  [[0.0751953 -0.0125732 -0.0281982 ... 0.00494385 -0.0673828 0.0593262]\n",
      "   [0.078125 -0.0125122 -0.0296631 ... 0.0043335 -0.0639648 0.0612793]\n",
      "   [0.0751953 -0.015625 -0.0246582 ... -0.000237465 -0.065918 0.0532227]\n",
      "   ...\n",
      "   [0.0786133 -0.0158691 -0.0244141 ... 0.00224304 -0.0673828 0.0639648]\n",
      "   [0.0786133 -0.0158691 -0.0244141 ... 0.00224304 -0.0673828 0.0639648]\n",
      "   [0.0786133 -0.0158691 -0.0244141 ... 0.00224304 -0.0673828 0.0639648]]\n",
      "\n",
      "  [[-0.0305176 0.00656128 -0.0118408 ... 0.0874023 -0.0136719\n",
      "    -0.0488281]\n",
      "   [-0.0269775 0.00537109 -0.00775146 ... 0.090332 -0.0119629\n",
      "    -0.0505371]\n",
      "   [-0.0283203 0.00128937 -0.0090332 ... 0.0893555 -0.0101929 -0.050293]\n",
      "   ...\n",
      "   [-0.0253906 0.00640869 -0.00891113 ... 0.0898438 -0.0134888\n",
      "    -0.0493164]\n",
      "   [-0.0253906 0.00640869 -0.00891113 ... 0.0898438 -0.0134888\n",
      "    -0.0493164]\n",
      "   [-0.0253906 0.00640869 -0.00891113 ... 0.0898438 -0.0134888\n",
      "    -0.0493164]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0098877 0.141602 -0.0402832 ... -0.09375 0.0341797 -0.0634766]\n",
      "   [-0.00332642 0.138672 -0.0407715 ... -0.0922852 0.034668 -0.0703125]\n",
      "   [-0.0112305 0.131836 -0.0385742 ... -0.0981445 0.0415039 -0.0712891]\n",
      "   ...\n",
      "   [-0.00598145 0.138672 -0.0393066 ... -0.0952148 0.0385742 -0.0678711]\n",
      "   [-0.00598145 0.138672 -0.0393066 ... -0.0952148 0.0385742 -0.0678711]\n",
      "   [-0.00598145 0.138672 -0.0393066 ... -0.0952148 0.0385742 -0.0678711]]\n",
      "\n",
      "  [[-0.0593262 0.0722656 0.0148926 ... -0.00558472 -0.032959 0.0246582]\n",
      "   [-0.0593262 0.0722656 0.0130005 ... 0.000965118 -0.0314941 0.0253906]\n",
      "   [-0.0600586 0.074707 0.0139771 ... -0.00653076 -0.0371094 0.0234375]\n",
      "   ...\n",
      "   [-0.0629883 0.0683594 0.0155029 ... 4.52995e-05 -0.0339355 0.0238037]\n",
      "   [-0.0629883 0.0683594 0.0155029 ... 4.52995e-05 -0.0339355 0.0238037]\n",
      "   [-0.0629883 0.0683594 0.0155029 ... 4.52995e-05 -0.0339355 0.0238037]]\n",
      "\n",
      "  [[-0.0090332 0.103027 0.0385742 ... -0.0275879 0.0603027 -0.027832]\n",
      "   [-0.010498 0.103027 0.0449219 ... -0.0279541 0.0556641 -0.0327148]\n",
      "   [-0.00726318 0.103027 0.0419922 ... -0.0334473 0.057373 -0.0284424]\n",
      "   ...\n",
      "   [-0.0115356 0.103027 0.0429688 ... -0.0358887 0.0568848 -0.0336914]\n",
      "   [-0.0115356 0.103027 0.0429688 ... -0.0358887 0.0568848 -0.0336914]\n",
      "   [-0.0115356 0.103027 0.0429688 ... -0.0358887 0.0568848 -0.0336914]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0551758 -0.059082 -0.0544434 ... -0.0310059 -0.111816 -0.00976562]\n",
      "   [0.0561523 -0.0551758 -0.0537109 ... -0.026001 -0.110352 -0.0135498]\n",
      "   [0.0605469 -0.0512695 -0.0529785 ... -0.0275879 -0.110352 -0.0114746]\n",
      "   ...\n",
      "   [0.0563965 -0.0507812 -0.0478516 ... -0.0205078 -0.11084 -0.0088501]\n",
      "   [0.0563965 -0.0507812 -0.0478516 ... -0.0205078 -0.11084 -0.0088501]\n",
      "   [0.0563965 -0.0507812 -0.0478516 ... -0.0205078 -0.11084 -0.0088501]]\n",
      "\n",
      "  [[-0.0595703 0.0844727 0.0227051 ... -0.060791 -0.0162354 0.0253906]\n",
      "   [-0.0581055 0.0839844 0.0229492 ... -0.0603027 -0.0130615 0.03125]\n",
      "   [-0.0605469 0.0820312 0.0236816 ... -0.0600586 -0.0181885 0.0327148]\n",
      "   ...\n",
      "   [-0.0588379 0.0864258 0.0214844 ... -0.0598145 -0.0216064 0.0311279]\n",
      "   [-0.0588379 0.0864258 0.0214844 ... -0.0598145 -0.0216064 0.0311279]\n",
      "   [-0.0588379 0.0864258 0.0214844 ... -0.0598145 -0.0216064 0.0311279]]\n",
      "\n",
      "  [[-0.0164795 -0.0200195 0.012085 ... -0.0109863 -0.0235596 -0.0349121]\n",
      "   [-0.0202637 -0.0241699 0.00686646 ... -0.00408936 -0.026123\n",
      "    -0.0314941]\n",
      "   [-0.0194092 -0.0231934 0.00860596 ... -0.00811768 -0.02771\n",
      "    -0.0307617]\n",
      "   ...\n",
      "   [-0.013916 -0.0212402 0.0110474 ... -0.0119629 -0.0238037 -0.0303955]\n",
      "   [-0.013916 -0.0212402 0.0110474 ... -0.0119629 -0.0238037 -0.0303955]\n",
      "   [-0.013916 -0.0212402 0.0110474 ... -0.0119629 -0.0238037 -0.0303955]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.109863 -0.0111694 -0.0673828 ... -0.0546875 -0.00775146\n",
      "    -0.00109863]\n",
      "   [-0.109863 -0.00909424 -0.0634766 ... -0.0563965 -0.00500488\n",
      "    0.000220299]\n",
      "   [-0.115234 -0.0153198 -0.0629883 ... -0.0546875 0.00180817\n",
      "    -0.000705719]\n",
      "   ...\n",
      "   [-0.111816 -0.0158691 -0.060791 ... -0.0551758 -0.00744629\n",
      "    -0.0043335]\n",
      "   [-0.111816 -0.0158691 -0.060791 ... -0.0551758 -0.00744629\n",
      "    -0.0043335]\n",
      "   [-0.111816 -0.0158691 -0.060791 ... -0.0551758 -0.00744629\n",
      "    -0.0043335]]\n",
      "\n",
      "  [[-0.0113525 0.00244141 -0.0527344 ... 0.0598145 -0.0344238\n",
      "    -0.0500488]\n",
      "   [-0.0071106 0.00473022 -0.0517578 ... 0.0605469 -0.0341797\n",
      "    -0.0498047]\n",
      "   [-0.0105591 0.00842285 -0.0515137 ... 0.0593262 -0.0334473\n",
      "    -0.0478516]\n",
      "   ...\n",
      "   [-0.0136108 0.00500488 -0.0517578 ... 0.060791 -0.0339355 -0.0524902]\n",
      "   [-0.0136108 0.00500488 -0.0517578 ... 0.060791 -0.0339355 -0.0524902]\n",
      "   [-0.0136108 0.00500488 -0.0517578 ... 0.060791 -0.0339355 -0.0524902]]\n",
      "\n",
      "  [[-0.0878906 -0.0544434 0.0498047 ... -0.0407715 0.0664062\n",
      "    -0.00309753]\n",
      "   [-0.0854492 -0.0498047 0.0478516 ... -0.0400391 0.0654297\n",
      "    -6.67572e-05]\n",
      "   [-0.0830078 -0.0498047 0.0517578 ... -0.0439453 0.0664062\n",
      "    -0.00127411]\n",
      "   ...\n",
      "   [-0.0869141 -0.0539551 0.0563965 ... -0.045166 0.0644531 0.000423431]\n",
      "   [-0.0869141 -0.0539551 0.0563965 ... -0.045166 0.0644531 0.000423431]\n",
      "   [-0.0869141 -0.0539551 0.0563965 ... -0.045166 0.0644531 0.000423431]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0664062 0.0864258 0.0236816 ... -0.0153198 -0.0568848 -0.0065918]\n",
      "   [0.0673828 0.0888672 0.0180664 ... -0.0179443 -0.0612793 -0.00349426]\n",
      "   [0.0629883 0.0874023 0.0235596 ... -0.0152588 -0.0620117 -0.00482178]\n",
      "   ...\n",
      "   [0.0664062 0.0883789 0.0213623 ... -0.0183105 -0.0610352 -0.00811768]\n",
      "   [0.0664062 0.0883789 0.0213623 ... -0.0183105 -0.0610352 -0.00811768]\n",
      "   [0.0664062 0.0883789 0.0213623 ... -0.0183105 -0.0610352 -0.00811768]]\n",
      "\n",
      "  [[-0.0756836 0.0341797 -0.0303955 ... 0.00576782 0.133789 -0.0449219]\n",
      "   [-0.0751953 0.0356445 -0.0339355 ... 0.00340271 0.129883 -0.0400391]\n",
      "   [-0.0703125 0.0368652 -0.034668 ... 0.00180054 0.129883 -0.041748]\n",
      "   ...\n",
      "   [-0.074707 0.0361328 -0.032959 ... 0.00213623 0.129883 -0.043457]\n",
      "   [-0.074707 0.0361328 -0.032959 ... 0.00213623 0.129883 -0.043457]\n",
      "   [-0.074707 0.0361328 -0.032959 ... 0.00213623 0.129883 -0.043457]]\n",
      "\n",
      "  [[0.022583 0.0187988 0.0766602 ... -0.0524902 0.0581055 0.0292969]\n",
      "   [0.0212402 0.0179443 0.0810547 ... -0.048584 0.0527344 0.0332031]\n",
      "   [0.019165 0.0136719 0.0776367 ... -0.052002 0.0493164 0.0327148]\n",
      "   ...\n",
      "   [0.0223389 0.0153198 0.0751953 ... -0.050293 0.0480957 0.0303955]\n",
      "   [0.0223389 0.0153198 0.0751953 ... -0.050293 0.0480957 0.0303955]\n",
      "   [0.0223389 0.0153198 0.0751953 ... -0.050293 0.0480957 0.0303955]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00494385 0.0223389 0.0227051 ... 0.0437012 -0.0561523 0.0180664]\n",
      "   [0.00311279 0.0240479 0.0157471 ... 0.0441895 -0.0556641 0.0183105]\n",
      "   [0.00830078 0.0170898 0.022583 ... 0.0473633 -0.050293 0.0224609]\n",
      "   ...\n",
      "   [0.00546265 0.0233154 0.0170898 ... 0.0439453 -0.052002 0.0189209]\n",
      "   [0.00546265 0.0233154 0.0170898 ... 0.0439453 -0.052002 0.0189209]\n",
      "   [0.00546265 0.0233154 0.0170898 ... 0.0439453 -0.052002 0.0189209]]\n",
      "\n",
      "  [[-0.0175781 -0.0437012 0.0179443 ... -0.0162354 -0.0561523\n",
      "    -0.00726318]\n",
      "   [-0.0195312 -0.043457 0.0168457 ... -0.015625 -0.0559082 -0.0050354]\n",
      "   [-0.022583 -0.043457 0.017334 ... -0.0153809 -0.0598145 -0.00830078]\n",
      "   ...\n",
      "   [-0.0197754 -0.0427246 0.0203857 ... -0.019165 -0.0566406 -0.0078125]\n",
      "   [-0.0197754 -0.0427246 0.0203857 ... -0.019165 -0.0566406 -0.0078125]\n",
      "   [-0.0197754 -0.0427246 0.0203857 ... -0.019165 -0.0566406 -0.0078125]]\n",
      "\n",
      "  [[-0.0800781 -0.0407715 -0.00604248 ... 0.111328 -0.00337219\n",
      "    -0.0634766]\n",
      "   [-0.0771484 -0.048584 -0.00126648 ... 0.114258 0.00165558 -0.0673828]\n",
      "   [-0.0776367 -0.0439453 -0.000888824 ... 0.115723 -0.00411987\n",
      "    -0.0678711]\n",
      "   ...\n",
      "   [-0.0776367 -0.0410156 0.000220299 ... 0.11084 1.32918e-05\n",
      "    -0.0698242]\n",
      "   [-0.0776367 -0.0410156 0.000220299 ... 0.11084 1.32918e-05\n",
      "    -0.0698242]\n",
      "   [-0.0776367 -0.0410156 0.000220299 ... 0.11084 1.32918e-05\n",
      "    -0.0698242]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0603027 -0.0830078 -0.022583 ... -0.0228271 -0.045166 -0.0290527]\n",
      "   [0.059082 -0.0849609 -0.0262451 ... -0.0145264 -0.0412598 -0.0344238]\n",
      "   [0.0529785 -0.0869141 -0.0275879 ... -0.015564 -0.0449219 -0.0356445]\n",
      "   ...\n",
      "   [0.0571289 -0.0869141 -0.0251465 ... -0.015625 -0.0446777 -0.0332031]\n",
      "   [0.0571289 -0.0869141 -0.0251465 ... -0.015625 -0.0446777 -0.0332031]\n",
      "   [0.0571289 -0.0869141 -0.0251465 ... -0.015625 -0.0446777 -0.0332031]]\n",
      "\n",
      "  [[0.0737305 -0.100098 0.110352 ... 0.0957031 -0.0424805 -0.112305]\n",
      "   [0.0732422 -0.0952148 0.10791 ... 0.0981445 -0.0415039 -0.112305]\n",
      "   [0.0727539 -0.0942383 0.108887 ... 0.101074 -0.0471191 -0.111328]\n",
      "   ...\n",
      "   [0.0708008 -0.0991211 0.107422 ... 0.0942383 -0.0461426 -0.118652]\n",
      "   [0.0708008 -0.0991211 0.107422 ... 0.0942383 -0.0461426 -0.118652]\n",
      "   [0.0708008 -0.0991211 0.107422 ... 0.0942383 -0.0461426 -0.118652]]\n",
      "\n",
      "  [[-0.0302734 0.0522461 -0.0466309 ... -0.00982666 0.022583 -0.050293]\n",
      "   [-0.0341797 0.0463867 -0.046875 ... -0.0109253 0.0144043 -0.0461426]\n",
      "   [-0.0290527 0.0500488 -0.0463867 ... -0.0119019 0.0169678 -0.041748]\n",
      "   ...\n",
      "   [-0.0351562 0.0476074 -0.048584 ... -0.00836182 0.022583 -0.0488281]\n",
      "   [-0.0351562 0.0476074 -0.048584 ... -0.00836182 0.022583 -0.0488281]\n",
      "   [-0.0351562 0.0476074 -0.048584 ... -0.00836182 0.022583 -0.0488281]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00799561 0.0202637 -0.103027 ... 0.0727539 0.00753784 -0.0375977]\n",
      "   [0.00732422 0.0234375 -0.106445 ... 0.0766602 0.00592041 -0.0393066]\n",
      "   [0.0098877 0.0240479 -0.102051 ... 0.0771484 0.00595093 -0.0439453]\n",
      "   ...\n",
      "   [0.00878906 0.0211182 -0.100586 ... 0.0766602 0.0088501 -0.0400391]\n",
      "   [0.00878906 0.0211182 -0.100586 ... 0.0766602 0.0088501 -0.0400391]\n",
      "   [0.00878906 0.0211182 -0.100586 ... 0.0766602 0.0088501 -0.0400391]]\n",
      "\n",
      "  [[0.0154419 -0.0791016 -0.0771484 ... 0.109375 0.0356445 -0.0149536]\n",
      "   [0.0174561 -0.0795898 -0.0795898 ... 0.105469 0.0336914 -0.0146484]\n",
      "   [0.0177002 -0.0810547 -0.0786133 ... 0.106934 0.0327148 -0.0174561]\n",
      "   ...\n",
      "   [0.0159912 -0.0825195 -0.0800781 ... 0.106934 0.0339355 -0.0205078]\n",
      "   [0.0159912 -0.0825195 -0.0800781 ... 0.106934 0.0339355 -0.0205078]\n",
      "   [0.0159912 -0.0825195 -0.0800781 ... 0.106934 0.0339355 -0.0205078]]\n",
      "\n",
      "  [[0.0209961 0.0500488 -0.0285645 ... 0.121094 0.0454102 0.0605469]\n",
      "   [0.0203857 0.0458984 -0.0181885 ... 0.120605 0.0432129 0.0678711]\n",
      "   [0.0212402 0.0490723 -0.0206299 ... 0.125977 0.0424805 0.0634766]\n",
      "   ...\n",
      "   [0.0258789 0.0515137 -0.0275879 ... 0.124023 0.0446777 0.0598145]\n",
      "   [0.0258789 0.0515137 -0.0275879 ... 0.124023 0.0446777 0.0598145]\n",
      "   [0.0258789 0.0515137 -0.0275879 ... 0.124023 0.0446777 0.0598145]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0236816 -0.0380859 0.0854492 ... -0.0593262 0.0893555 0.0422363]\n",
      "   [0.0228271 -0.0378418 0.0849609 ... -0.0581055 0.0834961 0.0454102]\n",
      "   [0.022583 -0.0358887 0.0820312 ... -0.0559082 0.0898438 0.0407715]\n",
      "   ...\n",
      "   [0.0220947 -0.0366211 0.0913086 ... -0.0571289 0.0864258 0.0390625]\n",
      "   [0.0220947 -0.0366211 0.0913086 ... -0.0571289 0.0864258 0.0390625]\n",
      "   [0.0220947 -0.0366211 0.0913086 ... -0.0571289 0.0864258 0.0390625]]\n",
      "\n",
      "  [[0.0327148 -0.112305 0.0170898 ... -0.0981445 -0.112305 0.0515137]\n",
      "   [0.0308838 -0.111816 0.0170898 ... -0.0981445 -0.11084 0.0461426]\n",
      "   [0.0354004 -0.11084 0.0130615 ... -0.101074 -0.111328 0.0463867]\n",
      "   ...\n",
      "   [0.0358887 -0.109375 0.0152588 ... -0.100098 -0.110352 0.0471191]\n",
      "   [0.0358887 -0.109375 0.0152588 ... -0.100098 -0.110352 0.0471191]\n",
      "   [0.0358887 -0.109375 0.0152588 ... -0.100098 -0.110352 0.0471191]]\n",
      "\n",
      "  [[0.0168457 -0.00288391 -0.00720215 ... -0.0393066 -0.0617676\n",
      "    0.0766602]\n",
      "   [0.0177002 -0.00842285 -0.00750732 ... -0.0385742 -0.0610352\n",
      "    0.0756836]\n",
      "   [0.0167236 -0.00854492 -0.0116577 ... -0.0429688 -0.0605469\n",
      "    0.0810547]\n",
      "   ...\n",
      "   [0.0211182 -0.0100708 -0.00805664 ... -0.0332031 -0.0649414\n",
      "    0.0756836]\n",
      "   [0.0211182 -0.0100708 -0.00805664 ... -0.0332031 -0.0649414\n",
      "    0.0756836]\n",
      "   [0.0211182 -0.0100708 -0.00805664 ... -0.0332031 -0.0649414\n",
      "    0.0756836]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0849609 -0.0090332 0.0319824 ... -0.0981445 0.0220947 0.0515137]\n",
      "   [0.0825195 -0.0108643 0.0354004 ... -0.102051 0.0209961 0.0527344]\n",
      "   [0.0810547 -0.0114746 0.0336914 ... -0.106445 0.0228271 0.0527344]\n",
      "   ...\n",
      "   [0.0839844 -0.00741577 0.0299072 ... -0.103027 0.0236816 0.0532227]\n",
      "   [0.0839844 -0.00741577 0.0299072 ... -0.103027 0.0236816 0.0532227]\n",
      "   [0.0839844 -0.00741577 0.0299072 ... -0.103027 0.0236816 0.0532227]]\n",
      "\n",
      "  [[0.090332 0.0441895 -0.0668945 ... -0.0703125 -0.0947266 -0.0241699]\n",
      "   [0.0844727 0.043457 -0.0654297 ... -0.0712891 -0.0927734 -0.020752]\n",
      "   [0.0864258 0.0439453 -0.0664062 ... -0.0673828 -0.0932617 -0.0179443]\n",
      "   ...\n",
      "   [0.0908203 0.0444336 -0.0639648 ... -0.0693359 -0.0888672 -0.0200195]\n",
      "   [0.0908203 0.0444336 -0.0639648 ... -0.0693359 -0.0888672 -0.0200195]\n",
      "   [0.0908203 0.0444336 -0.0639648 ... -0.0693359 -0.0888672 -0.0200195]]\n",
      "\n",
      "  [[0.0495605 0.0639648 -0.0598145 ... 0.00799561 0.0148926 0.115723]\n",
      "   [0.0505371 0.0603027 -0.057373 ... 0.00524902 0.0181885 0.112305]\n",
      "   [0.0517578 0.0649414 -0.0544434 ... 0.0136108 0.0112305 0.112793]\n",
      "   ...\n",
      "   [0.0512695 0.0617676 -0.0568848 ... 0.0108032 0.019043 0.112305]\n",
      "   [0.0512695 0.0617676 -0.0568848 ... 0.0108032 0.019043 0.112305]\n",
      "   [0.0512695 0.0617676 -0.0568848 ... 0.0108032 0.019043 0.112305]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.145508 -0.0634766 -0.00457764 ... 0.132812 -0.0336914 -0.00714111]\n",
      "   [0.141602 -0.0668945 -0.0071106 ... 0.130859 -0.0314941 -0.00744629]\n",
      "   [0.138672 -0.0644531 -0.00491333 ... 0.129883 -0.0305176 -0.0090332]\n",
      "   ...\n",
      "   [0.142578 -0.0654297 -0.00668335 ... 0.128906 -0.0300293 -0.0119019]\n",
      "   [0.142578 -0.0654297 -0.00668335 ... 0.128906 -0.0300293 -0.0119019]\n",
      "   [0.142578 -0.0654297 -0.00668335 ... 0.128906 -0.0300293 -0.0119019]]\n",
      "\n",
      "  [[-0.0349121 -0.0214844 0.0258789 ... -0.0228271 0.0668945 -0.0132446]\n",
      "   [-0.0410156 -0.0218506 0.0228271 ... -0.0214844 0.0654297 -0.0107422]\n",
      "   [-0.0349121 -0.0253906 0.0203857 ... -0.0146484 0.0649414\n",
      "    -0.00860596]\n",
      "   ...\n",
      "   [-0.0356445 -0.0255127 0.0214844 ... -0.0195312 0.0683594 -0.0108643]\n",
      "   [-0.0356445 -0.0255127 0.0214844 ... -0.0195312 0.0683594 -0.0108643]\n",
      "   [-0.0356445 -0.0255127 0.0214844 ... -0.0195312 0.0683594 -0.0108643]]\n",
      "\n",
      "  [[0.0174561 -0.115723 0.0844727 ... -0.00588989 -0.0317383 -0.0122681]\n",
      "   [0.0179443 -0.120117 0.0883789 ... 0.000782013 -0.0314941 -0.0170898]\n",
      "   [0.0212402 -0.116699 0.0854492 ... -0.00386047 -0.0344238 -0.0170898]\n",
      "   ...\n",
      "   [0.0150146 -0.115723 0.0864258 ... -0.00671387 -0.0311279 -0.0132446]\n",
      "   [0.0150146 -0.115723 0.0864258 ... -0.00671387 -0.0311279 -0.0132446]\n",
      "   [0.0150146 -0.115723 0.0864258 ... -0.00671387 -0.0311279 -0.0132446]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0245361 0.0234375 -0.0771484 ... -0.0893555 0.140625 0.0422363]\n",
      "   [-0.0251465 0.0222168 -0.0727539 ... -0.0898438 0.137695 0.0441895]\n",
      "   [-0.0233154 0.0203857 -0.078125 ... -0.0844727 0.138672 0.0449219]\n",
      "   ...\n",
      "   [-0.0194092 0.0240479 -0.0771484 ... -0.0893555 0.134766 0.0427246]\n",
      "   [-0.0194092 0.0240479 -0.0771484 ... -0.0893555 0.134766 0.0427246]\n",
      "   [-0.0194092 0.0240479 -0.0771484 ... -0.0893555 0.134766 0.0427246]]\n",
      "\n",
      "  [[0.0563965 -0.0349121 0.0349121 ... 0.0322266 -0.0830078 -0.0556641]\n",
      "   [0.0554199 -0.036377 0.0332031 ... 0.0296631 -0.0791016 -0.0563965]\n",
      "   [0.0561523 -0.0339355 0.0327148 ... 0.02771 -0.081543 -0.0507812]\n",
      "   ...\n",
      "   [0.0588379 -0.0407715 0.0308838 ... 0.0336914 -0.0795898 -0.0546875]\n",
      "   [0.0588379 -0.0407715 0.0308838 ... 0.0336914 -0.0795898 -0.0546875]\n",
      "   [0.0588379 -0.0407715 0.0308838 ... 0.0336914 -0.0795898 -0.0546875]]\n",
      "\n",
      "  [[0.0368652 -0.0227051 -0.0045166 ... -0.00775146 -0.074707 -0.048584]\n",
      "   [0.0412598 -0.0255127 -0.000549316 ... -0.00245667 -0.0683594\n",
      "    -0.0444336]\n",
      "   [0.0368652 -0.0227051 -0.00259399 ... -0.00531006 -0.0751953\n",
      "    -0.0422363]\n",
      "   ...\n",
      "   [0.0375977 -0.0249023 0.00124359 ... -0.00369263 -0.0737305\n",
      "    -0.0432129]\n",
      "   [0.0375977 -0.0249023 0.00124359 ... -0.00369263 -0.0737305\n",
      "    -0.0432129]\n",
      "   [0.0375977 -0.0249023 0.00124359 ... -0.00369263 -0.0737305\n",
      "    -0.0432129]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0128174 -0.0262451 0.0703125 ... -0.132812 -0.0231934 0.0898438]\n",
      "   [0.0139771 -0.0256348 0.0698242 ... -0.12793 -0.0180664 0.0888672]\n",
      "   [0.0168457 -0.0213623 0.0678711 ... -0.126953 -0.0179443 0.0917969]\n",
      "   ...\n",
      "   [0.0162354 -0.0214844 0.0712891 ... -0.131836 -0.0159912 0.0908203]\n",
      "   [0.0162354 -0.0214844 0.0712891 ... -0.131836 -0.0159912 0.0908203]\n",
      "   [0.0162354 -0.0214844 0.0712891 ... -0.131836 -0.0159912 0.0908203]]\n",
      "\n",
      "  [[-0.0114746 0.0534668 -0.0683594 ... -0.0415039 0.0415039\n",
      "    -0.00897217]\n",
      "   [-0.013916 0.0549316 -0.0698242 ... -0.043457 0.0429688 -0.00521851]\n",
      "   [-0.0136719 0.0529785 -0.0698242 ... -0.0373535 0.0432129\n",
      "    -0.00668335]\n",
      "   ...\n",
      "   [-0.012085 0.048584 -0.0708008 ... -0.0395508 0.0415039 -0.00390625]\n",
      "   [-0.012085 0.048584 -0.0708008 ... -0.0395508 0.0415039 -0.00390625]\n",
      "   [-0.012085 0.048584 -0.0708008 ... -0.0395508 0.0415039 -0.00390625]]\n",
      "\n",
      "  [[-0.0683594 -0.0234375 0.111816 ... 0.00494385 -0.0354004 -0.0244141]\n",
      "   [-0.0664062 -0.0273438 0.10791 ... 0.0045166 -0.0412598 -0.0285645]\n",
      "   [-0.0688477 -0.0317383 0.108398 ... 0.00442505 -0.0415039 -0.0228271]\n",
      "   ...\n",
      "   [-0.0668945 -0.022583 0.104492 ... 0.00698853 -0.0375977 -0.0307617]\n",
      "   [-0.0668945 -0.022583 0.104492 ... 0.00698853 -0.0375977 -0.0307617]\n",
      "   [-0.0668945 -0.022583 0.104492 ... 0.00698853 -0.0375977 -0.0307617]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.060791 -0.0334473 0.0205078 ... -0.0732422 0.0134888 -0.0241699]\n",
      "   [-0.0598145 -0.0344238 0.0197754 ... -0.0737305 0.0150757 -0.0256348]\n",
      "   [-0.0603027 -0.0341797 0.0177002 ... -0.0703125 0.0145264 -0.026001]\n",
      "   ...\n",
      "   [-0.0593262 -0.0327148 0.0236816 ... -0.0703125 0.0150146 -0.0244141]\n",
      "   [-0.0593262 -0.0327148 0.0236816 ... -0.0703125 0.0150146 -0.0244141]\n",
      "   [-0.0593262 -0.0327148 0.0236816 ... -0.0703125 0.0150146 -0.0244141]]\n",
      "\n",
      "  [[0.121582 -0.137695 0.00408936 ... 0.0256348 0.00106049 0.111328]\n",
      "   [0.124512 -0.138672 0.00842285 ... 0.0186768 -0.00509644 0.11377]\n",
      "   [0.121582 -0.135742 0.00204468 ... 0.0250244 -0.000991821 0.106934]\n",
      "   ...\n",
      "   [0.121094 -0.139648 -0.000621796 ... 0.0241699 -0.00317383 0.111328]\n",
      "   [0.121094 -0.139648 -0.000621796 ... 0.0241699 -0.00317383 0.111328]\n",
      "   [0.121094 -0.139648 -0.000621796 ... 0.0241699 -0.00317383 0.111328]]\n",
      "\n",
      "  [[0.0218506 -0.0125122 0.102539 ... 0.078125 0.0927734 0.0284424]\n",
      "   [0.0301514 -0.0192871 0.0932617 ... 0.0869141 0.0966797 0.032959]\n",
      "   [0.0285645 -0.0170898 0.0908203 ... 0.0839844 0.0913086 0.029541]\n",
      "   ...\n",
      "   [0.0314941 -0.0144653 0.0932617 ... 0.0834961 0.0869141 0.0336914]\n",
      "   [0.0314941 -0.0144653 0.0932617 ... 0.0834961 0.0869141 0.0336914]\n",
      "   [0.0314941 -0.0144653 0.0932617 ... 0.0834961 0.0869141 0.0336914]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0498047 0.0214844 0.0412598 ... -0.0546875 0.118652 0.0126953]\n",
      "   [-0.0527344 0.0234375 0.0397949 ... -0.0598145 0.117676 0.0168457]\n",
      "   [-0.0495605 0.0192871 0.0441895 ... -0.0546875 0.117676 0.0228271]\n",
      "   ...\n",
      "   [-0.050293 0.0240479 0.0407715 ... -0.0610352 0.120605 0.0149536]\n",
      "   [-0.050293 0.0240479 0.0407715 ... -0.0610352 0.120605 0.0149536]\n",
      "   [-0.050293 0.0240479 0.0407715 ... -0.0610352 0.120605 0.0149536]]\n",
      "\n",
      "  [[-0.0203857 -0.157227 0.00643921 ... -0.0454102 0.00300598\n",
      "    -0.0256348]\n",
      "   [-0.0172119 -0.160156 0.0134888 ... -0.0454102 0.00515747 -0.0275879]\n",
      "   [-0.0183105 -0.161133 0.015564 ... -0.0463867 0.00631714 -0.0230713]\n",
      "   ...\n",
      "   [-0.0170898 -0.15918 0.0111084 ... -0.0419922 0.00854492 -0.0255127]\n",
      "   [-0.0170898 -0.15918 0.0111084 ... -0.0419922 0.00854492 -0.0255127]\n",
      "   [-0.0170898 -0.15918 0.0111084 ... -0.0419922 0.00854492 -0.0255127]]\n",
      "\n",
      "  [[0.041748 0.0859375 0.0556641 ... -0.0294189 -0.015564 0.0668945]\n",
      "   [0.0395508 0.090332 0.0568848 ... -0.0322266 -0.013855 0.065918]\n",
      "   [0.0437012 0.090332 0.0588379 ... -0.0324707 -0.0168457 0.0654297]\n",
      "   ...\n",
      "   [0.0446777 0.0849609 0.0617676 ... -0.0341797 -0.0214844 0.0698242]\n",
      "   [0.0446777 0.0849609 0.0617676 ... -0.0341797 -0.0214844 0.0698242]\n",
      "   [0.0446777 0.0849609 0.0617676 ... -0.0341797 -0.0214844 0.0698242]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0164795 -0.0571289 0.0761719 ... -0.0654297 0.0289307 0.0500488]\n",
      "   [0.0128784 -0.0537109 0.078125 ... -0.0683594 0.0270996 0.0473633]\n",
      "   [0.0134277 -0.0524902 0.0732422 ... -0.0664062 0.0336914 0.0510254]\n",
      "   ...\n",
      "   [0.0164795 -0.0522461 0.0742188 ... -0.0654297 0.0319824 0.0495605]\n",
      "   [0.0164795 -0.0522461 0.0742188 ... -0.0654297 0.0319824 0.0495605]\n",
      "   [0.0164795 -0.0522461 0.0742188 ... -0.0654297 0.0319824 0.0495605]]\n",
      "\n",
      "  [[-0.0883789 -0.0419922 0.121094 ... -0.0189209 -0.134766 -0.0639648]\n",
      "   [-0.090332 -0.043457 0.121094 ... -0.0169678 -0.135742 -0.0634766]\n",
      "   [-0.0913086 -0.0415039 0.116699 ... -0.0228271 -0.132812 -0.0649414]\n",
      "   ...\n",
      "   [-0.0898438 -0.0471191 0.116699 ... -0.0214844 -0.135742 -0.0644531]\n",
      "   [-0.0898438 -0.0471191 0.116699 ... -0.0214844 -0.135742 -0.0644531]\n",
      "   [-0.0898438 -0.0471191 0.116699 ... -0.0214844 -0.135742 -0.0644531]]\n",
      "\n",
      "  [[-0.0179443 -0.0703125 -0.0405273 ... 0.0732422 0.105469 0.0722656]\n",
      "   [-0.0158691 -0.0649414 -0.0400391 ... 0.0751953 0.105957 0.0737305]\n",
      "   [-0.0166016 -0.0703125 -0.0407715 ... 0.0693359 0.113281 0.0766602]\n",
      "   ...\n",
      "   [-0.0154419 -0.0683594 -0.0393066 ... 0.0727539 0.109375 0.0708008]\n",
      "   [-0.0154419 -0.0683594 -0.0393066 ... 0.0727539 0.109375 0.0708008]\n",
      "   [-0.0154419 -0.0683594 -0.0393066 ... 0.0727539 0.109375 0.0708008]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0317383 0.0339355 -0.0500488 ... -0.0407715 -0.0561523 -0.0756836]\n",
      "   [0.0324707 0.0336914 -0.0544434 ... -0.0383301 -0.0532227 -0.0756836]\n",
      "   [0.0311279 0.0324707 -0.0539551 ... -0.041748 -0.0549316 -0.0805664]\n",
      "   ...\n",
      "   [0.0289307 0.029541 -0.0510254 ... -0.0410156 -0.0539551 -0.0800781]\n",
      "   [0.0289307 0.029541 -0.0510254 ... -0.0410156 -0.0539551 -0.0800781]\n",
      "   [0.0289307 0.029541 -0.0510254 ... -0.0410156 -0.0539551 -0.0800781]]\n",
      "\n",
      "  [[0.00253296 -0.0917969 0.0268555 ... 0.0476074 -0.0539551 -0.0283203]\n",
      "   [0.00408936 -0.0849609 0.0297852 ... 0.0510254 -0.0529785 -0.0270996]\n",
      "   [0.00325012 -0.0888672 0.020874 ... 0.048584 -0.0529785 -0.0253906]\n",
      "   ...\n",
      "   [0.00579834 -0.0874023 0.0297852 ... 0.0483398 -0.0527344 -0.027832]\n",
      "   [0.00579834 -0.0874023 0.0297852 ... 0.0483398 -0.0527344 -0.027832]\n",
      "   [0.00579834 -0.0874023 0.0297852 ... 0.0483398 -0.0527344 -0.027832]]\n",
      "\n",
      "  [[0.034668 -0.0241699 -0.0161133 ... -0.00964355 -0.0864258\n",
      "    -0.0322266]\n",
      "   [0.0361328 -0.0283203 -0.0175781 ... -0.0178223 -0.0834961\n",
      "    -0.0300293]\n",
      "   [0.0375977 -0.0341797 -0.0143433 ... -0.0166016 -0.0800781\n",
      "    -0.0281982]\n",
      "   ...\n",
      "   [0.0341797 -0.0299072 -0.0198975 ... -0.0180664 -0.0825195\n",
      "    -0.0297852]\n",
      "   [0.0341797 -0.0299072 -0.0198975 ... -0.0180664 -0.0825195\n",
      "    -0.0297852]\n",
      "   [0.0341797 -0.0299072 -0.0198975 ... -0.0180664 -0.0825195\n",
      "    -0.0297852]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.019043 0.131836 0.0134888 ... -0.0266113 0.0164795 -0.0341797]\n",
      "   [0.0164795 0.131836 0.0117798 ... -0.0245361 0.00558472 -0.0300293]\n",
      "   [0.0128174 0.130859 0.00701904 ... -0.0251465 0.00927734 -0.0336914]\n",
      "   ...\n",
      "   [0.013916 0.130859 0.0109863 ... -0.0229492 0.00909424 -0.036377]\n",
      "   [0.013916 0.130859 0.0109863 ... -0.0229492 0.00909424 -0.036377]\n",
      "   [0.013916 0.130859 0.0109863 ... -0.0229492 0.00909424 -0.036377]]\n",
      "\n",
      "  [[0.0247803 -0.0595703 -0.110352 ... -0.132812 0.140625 -0.100098]\n",
      "   [0.0303955 -0.0593262 -0.108887 ... -0.136719 0.140625 -0.104004]\n",
      "   [0.0297852 -0.0544434 -0.115234 ... -0.131836 0.135742 -0.101562]\n",
      "   ...\n",
      "   [0.0274658 -0.0544434 -0.112793 ... -0.132812 0.137695 -0.102539]\n",
      "   [0.0274658 -0.0544434 -0.112793 ... -0.132812 0.137695 -0.102539]\n",
      "   [0.0274658 -0.0544434 -0.112793 ... -0.132812 0.137695 -0.102539]]\n",
      "\n",
      "  [[-0.00570679 0.00543213 0.0559082 ... 0.0461426 0.065918 0.0534668]\n",
      "   [-0.00582886 0.00787354 0.0549316 ... 0.0473633 0.065918 0.0532227]\n",
      "   [-0.0090332 0.0105591 0.0537109 ... 0.0493164 0.0634766 0.0495605]\n",
      "   ...\n",
      "   [-0.00817871 0.00315857 0.0549316 ... 0.046875 0.0664062 0.057373]\n",
      "   [-0.00817871 0.00315857 0.0549316 ... 0.046875 0.0664062 0.057373]\n",
      "   [-0.00817871 0.00315857 0.0549316 ... 0.046875 0.0664062 0.057373]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.12793 0.0644531 0.0429688 ... -0.0274658 -0.010376 0.048584]\n",
      "   [-0.12793 0.0639648 0.046875 ... -0.034668 -0.0131226 0.0495605]\n",
      "   [-0.132812 0.0688477 0.0437012 ... -0.0296631 -0.0158691 0.050293]\n",
      "   ...\n",
      "   [-0.12793 0.0634766 0.0388184 ... -0.0319824 -0.00946045 0.0483398]\n",
      "   [-0.12793 0.0634766 0.0388184 ... -0.0319824 -0.00946045 0.0483398]\n",
      "   [-0.12793 0.0634766 0.0388184 ... -0.0319824 -0.00946045 0.0483398]]\n",
      "\n",
      "  [[0.0732422 -0.110352 -0.0800781 ... -0.108398 0.0216064 -0.100586]\n",
      "   [0.0708008 -0.109863 -0.078125 ... -0.111328 0.0185547 -0.100586]\n",
      "   [0.0742188 -0.109375 -0.0776367 ... -0.109863 0.0168457 -0.102539]\n",
      "   ...\n",
      "   [0.0766602 -0.110352 -0.0766602 ... -0.109375 0.0194092 -0.101074]\n",
      "   [0.0766602 -0.110352 -0.0766602 ... -0.109375 0.0194092 -0.101074]\n",
      "   [0.0766602 -0.110352 -0.0766602 ... -0.109375 0.0194092 -0.101074]]\n",
      "\n",
      "  [[0.144531 -0.0698242 -0.0137329 ... 0.0324707 0.00720215\n",
      "    -0.000736237]\n",
      "   [0.143555 -0.0693359 -0.0134277 ... 0.0255127 0.0055542 -0.000444412]\n",
      "   [0.142578 -0.0693359 -0.0101929 ... 0.0285645 0.013855 -0.000333786]\n",
      "   ...\n",
      "   [0.142578 -0.0722656 -0.0150146 ... 0.0332031 0.00848389 0.00408936]\n",
      "   [0.142578 -0.0722656 -0.0150146 ... 0.0332031 0.00848389 0.00408936]\n",
      "   [0.142578 -0.0722656 -0.0150146 ... 0.0332031 0.00848389 0.00408936]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0727539 0.00325012 -0.144531 ... -0.041748 0.113281 0.0314941]\n",
      "   [0.0712891 0.00704956 -0.142578 ... -0.0444336 0.11084 0.0273438]\n",
      "   [0.0727539 0.000946045 -0.148438 ... -0.0427246 0.108887 0.034668]\n",
      "   ...\n",
      "   [0.0722656 0.00263977 -0.148438 ... -0.0419922 0.112305 0.0292969]\n",
      "   [0.0722656 0.00263977 -0.148438 ... -0.0419922 0.112305 0.0292969]\n",
      "   [0.0722656 0.00263977 -0.148438 ... -0.0419922 0.112305 0.0292969]]\n",
      "\n",
      "  [[0.0593262 -0.00595093 -0.0463867 ... 0.165039 0.149414 0.0141602]\n",
      "   [0.052002 -0.0108032 -0.045166 ... 0.163086 0.148438 0.0103149]\n",
      "   [0.057373 -0.00921631 -0.0488281 ... 0.166016 0.150391 0.0157471]\n",
      "   ...\n",
      "   [0.0603027 -0.00521851 -0.043457 ... 0.167969 0.149414 0.0135498]\n",
      "   [0.0603027 -0.00521851 -0.043457 ... 0.167969 0.149414 0.0135498]\n",
      "   [0.0603027 -0.00521851 -0.043457 ... 0.167969 0.149414 0.0135498]]\n",
      "\n",
      "  [[-0.0864258 -0.0742188 -0.0581055 ... 0.0488281 0.0283203\n",
      "    -0.00698853]\n",
      "   [-0.0791016 -0.078125 -0.0522461 ... 0.048584 0.026001 -0.00408936]\n",
      "   [-0.0810547 -0.0727539 -0.057373 ... 0.046875 0.0285645 -0.00704956]\n",
      "   ...\n",
      "   [-0.0874023 -0.0771484 -0.0583496 ... 0.048584 0.0251465 -0.0125732]\n",
      "   [-0.0874023 -0.0771484 -0.0583496 ... 0.048584 0.0251465 -0.0125732]\n",
      "   [-0.0874023 -0.0771484 -0.0583496 ... 0.048584 0.0251465 -0.0125732]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.00701904 0.0238037 -0.15625 ... -0.00830078 -0.0820312 0.105957]\n",
      "   [0.00585938 0.0194092 -0.160156 ... -0.00521851 -0.0874023 0.109375]\n",
      "   [0.00970459 0.0219727 -0.163086 ... -0.00509644 -0.0888672 0.10498]\n",
      "   ...\n",
      "   [0.00878906 0.0219727 -0.161133 ... -0.00604248 -0.0888672 0.102539]\n",
      "   [0.00878906 0.0219727 -0.161133 ... -0.00604248 -0.0888672 0.102539]\n",
      "   [0.00878906 0.0219727 -0.161133 ... -0.00604248 -0.0888672 0.102539]]\n",
      "\n",
      "  [[-0.0761719 -0.010498 -0.0722656 ... 0.0830078 -0.0559082 -0.0500488]\n",
      "   [-0.0727539 -0.00878906 -0.0673828 ... 0.0839844 -0.0551758\n",
      "    -0.0478516]\n",
      "   [-0.0786133 -0.0119019 -0.0693359 ... 0.0878906 -0.0546875\n",
      "    -0.0490723]\n",
      "   ...\n",
      "   [-0.0742188 -0.00692749 -0.0654297 ... 0.0834961 -0.057373\n",
      "    -0.0527344]\n",
      "   [-0.0742188 -0.00692749 -0.0654297 ... 0.0834961 -0.057373\n",
      "    -0.0527344]\n",
      "   [-0.0742188 -0.00692749 -0.0654297 ... 0.0834961 -0.057373\n",
      "    -0.0527344]]\n",
      "\n",
      "  [[0.0917969 0.0344238 0.0186768 ... 0.0449219 -0.0275879 0.00411987]\n",
      "   [0.0883789 0.0344238 0.0174561 ... 0.043457 -0.0258789 0.00209045]\n",
      "   [0.0878906 0.0339355 0.0184326 ... 0.0466309 -0.0231934 -0.000104904]\n",
      "   ...\n",
      "   [0.0883789 0.0383301 0.0179443 ... 0.0419922 -0.0275879 -0.00157928]\n",
      "   [0.0883789 0.0383301 0.0179443 ... 0.0419922 -0.0275879 -0.00157928]\n",
      "   [0.0883789 0.0383301 0.0179443 ... 0.0419922 -0.0275879 -0.00157928]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.131836 0.0678711 0.019165 ... -0.130859 -0.0412598 -0.0334473]\n",
      "   [0.135742 0.0703125 0.0174561 ... -0.125977 -0.041748 -0.0358887]\n",
      "   [0.135742 0.0751953 0.0175781 ... -0.128906 -0.0446777 -0.0371094]\n",
      "   ...\n",
      "   [0.128906 0.0693359 0.0131836 ... -0.128906 -0.0405273 -0.0339355]\n",
      "   [0.128906 0.0693359 0.0131836 ... -0.128906 -0.0405273 -0.0339355]\n",
      "   [0.128906 0.0693359 0.0131836 ... -0.128906 -0.0405273 -0.0339355]]\n",
      "\n",
      "  [[0.0476074 0.090332 0.0756836 ... -0.0683594 -0.0795898 0.0202637]\n",
      "   [0.052002 0.0854492 0.0737305 ... -0.0698242 -0.0844727 0.0240479]\n",
      "   [0.0488281 0.0913086 0.0737305 ... -0.0703125 -0.0756836 0.0202637]\n",
      "   ...\n",
      "   [0.0505371 0.0922852 0.074707 ... -0.0727539 -0.0825195 0.0234375]\n",
      "   [0.0505371 0.0922852 0.074707 ... -0.0727539 -0.0825195 0.0234375]\n",
      "   [0.0505371 0.0922852 0.074707 ... -0.0727539 -0.0825195 0.0234375]]\n",
      "\n",
      "  [[0.0761719 0.0529785 0.0349121 ... -0.0203857 0.0766602 0.0141602]\n",
      "   [0.0737305 0.0534668 0.0366211 ... -0.0175781 0.0698242 0.0114746]\n",
      "   [0.0727539 0.0522461 0.0332031 ... -0.0167236 0.0683594 0.00823975]\n",
      "   ...\n",
      "   [0.0751953 0.0541992 0.0269775 ... -0.019043 0.074707 0.0132446]\n",
      "   [0.0751953 0.0541992 0.0269775 ... -0.019043 0.074707 0.0132446]\n",
      "   [0.0751953 0.0541992 0.0269775 ... -0.019043 0.074707 0.0132446]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.124023 0.078125 -0.050293 ... -0.0432129 -0.0864258 -0.0524902]\n",
      "   [-0.123535 0.0771484 -0.0568848 ... -0.0375977 -0.0893555 -0.0515137]\n",
      "   [-0.121094 0.0795898 -0.0566406 ... -0.0385742 -0.0893555 -0.0493164]\n",
      "   ...\n",
      "   [-0.123047 0.074707 -0.0588379 ... -0.0397949 -0.0864258 -0.0515137]\n",
      "   [-0.123047 0.074707 -0.0588379 ... -0.0397949 -0.0864258 -0.0515137]\n",
      "   [-0.123047 0.074707 -0.0588379 ... -0.0397949 -0.0864258 -0.0515137]]\n",
      "\n",
      "  [[0.0883789 0.0368652 0.017334 ... -0.0583496 0.0402832 0.00787354]\n",
      "   [0.0947266 0.0366211 0.0198975 ... -0.0593262 0.041748 0.0109863]\n",
      "   [0.0908203 0.0310059 0.0219727 ... -0.0617676 0.0437012 0.00805664]\n",
      "   ...\n",
      "   [0.0913086 0.0358887 0.019165 ... -0.0625 0.0441895 0.00753784]\n",
      "   [0.0913086 0.0358887 0.019165 ... -0.0625 0.0441895 0.00753784]\n",
      "   [0.0913086 0.0358887 0.019165 ... -0.0625 0.0441895 0.00753784]]\n",
      "\n",
      "  [[0.00069046 0.0272217 0.0512695 ... -0.0244141 0.100586 -0.0148926]\n",
      "   [0.00695801 0.0279541 0.0483398 ... -0.0246582 0.100586 -0.017334]\n",
      "   [0.0050354 0.0249023 0.0480957 ... -0.022583 0.101562 -0.0150146]\n",
      "   ...\n",
      "   [0.00537109 0.0267334 0.0515137 ... -0.0244141 0.102051 -0.0158691]\n",
      "   [0.00537109 0.0267334 0.0515137 ... -0.0244141 0.102051 -0.0158691]\n",
      "   [0.00537109 0.0267334 0.0515137 ... -0.0244141 0.102051 -0.0158691]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.134766 0.0732422 0.0227051 ... -0.090332 0.0375977 -0.0198975]\n",
      "   [-0.135742 0.0786133 0.0187988 ... -0.0834961 0.0302734 -0.0269775]\n",
      "   [-0.133789 0.074707 0.0167236 ... -0.0810547 0.0375977 -0.0224609]\n",
      "   ...\n",
      "   [-0.136719 0.0756836 0.0209961 ... -0.0883789 0.0366211 -0.0175781]\n",
      "   [-0.136719 0.0756836 0.0209961 ... -0.0883789 0.0366211 -0.0175781]\n",
      "   [-0.136719 0.0756836 0.0209961 ... -0.0883789 0.0366211 -0.0175781]]\n",
      "\n",
      "  [[0.0109863 -0.0566406 0.0795898 ... 0.0444336 -0.0786133 0.017334]\n",
      "   [0.00704956 -0.0534668 0.0800781 ... 0.0449219 -0.0776367 0.0177002]\n",
      "   [0.00976562 -0.0563965 0.0756836 ... 0.041748 -0.0844727 0.0189209]\n",
      "   ...\n",
      "   [0.0098877 -0.0563965 0.0820312 ... 0.0466309 -0.0795898 0.0213623]\n",
      "   [0.0098877 -0.0563965 0.0820312 ... 0.0466309 -0.0795898 0.0213623]\n",
      "   [0.0098877 -0.0563965 0.0820312 ... 0.0466309 -0.0795898 0.0213623]]\n",
      "\n",
      "  [[0.0065918 -0.166992 -0.0529785 ... 0.0620117 0.0495605 0.139648]\n",
      "   [0.00964355 -0.168945 -0.0471191 ... 0.0688477 0.0495605 0.142578]\n",
      "   [0.0140991 -0.171875 -0.0441895 ... 0.0683594 0.046875 0.141602]\n",
      "   ...\n",
      "   [0.00598145 -0.171875 -0.0534668 ... 0.0688477 0.052002 0.144531]\n",
      "   [0.00598145 -0.171875 -0.0534668 ... 0.0688477 0.052002 0.144531]\n",
      "   [0.00598145 -0.171875 -0.0534668 ... 0.0688477 0.052002 0.144531]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0617676 -0.0307617 -0.0214844 ... -0.10498 0.0400391 -0.0461426]\n",
      "   [-0.0595703 -0.0250244 -0.0249023 ... -0.106934 0.0393066 -0.0441895]\n",
      "   [-0.0566406 -0.0294189 -0.0152588 ... -0.103027 0.0400391 -0.0498047]\n",
      "   ...\n",
      "   [-0.0546875 -0.0267334 -0.0198975 ... -0.103027 0.034668 -0.0446777]\n",
      "   [-0.0546875 -0.0267334 -0.0198975 ... -0.103027 0.034668 -0.0446777]\n",
      "   [-0.0546875 -0.0267334 -0.0198975 ... -0.103027 0.034668 -0.0446777]]\n",
      "\n",
      "  [[-0.0493164 0.0388184 0.109863 ... 0.0810547 -0.0407715 0.0327148]\n",
      "   [-0.0510254 0.0437012 0.109863 ... 0.0786133 -0.041748 0.0311279]\n",
      "   [-0.0498047 0.0419922 0.112305 ... 0.0751953 -0.0444336 0.0314941]\n",
      "   ...\n",
      "   [-0.0510254 0.0432129 0.112305 ... 0.0761719 -0.0446777 0.0303955]\n",
      "   [-0.0510254 0.0432129 0.112305 ... 0.0761719 -0.0446777 0.0303955]\n",
      "   [-0.0510254 0.0432129 0.112305 ... 0.0761719 -0.0446777 0.0303955]]\n",
      "\n",
      "  [[0.00741577 -0.128906 -0.0296631 ... 0.10791 -0.0235596 -0.0209961]\n",
      "   [0.00927734 -0.131836 -0.0284424 ... 0.108398 -0.0230713 -0.019043]\n",
      "   [0.00854492 -0.12793 -0.0267334 ... 0.108398 -0.0255127 -0.019043]\n",
      "   ...\n",
      "   [0.00744629 -0.126953 -0.0257568 ... 0.107422 -0.0235596 -0.0187988]\n",
      "   [0.00744629 -0.126953 -0.0257568 ... 0.107422 -0.0235596 -0.0187988]\n",
      "   [0.00744629 -0.126953 -0.0257568 ... 0.107422 -0.0235596 -0.0187988]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00276184 0.171875 -0.097168 ... 0.0786133 -0.0549316 0.0211182]\n",
      "   [0.000770569 0.171875 -0.0957031 ... 0.0810547 -0.0517578 0.0241699]\n",
      "   [-0.00427246 0.168945 -0.0981445 ... 0.0761719 -0.0578613 0.026123]\n",
      "   ...\n",
      "   [-0.00280762 0.168945 -0.0991211 ... 0.0795898 -0.0559082 0.0267334]\n",
      "   [-0.00280762 0.168945 -0.0991211 ... 0.0795898 -0.0559082 0.0267334]\n",
      "   [-0.00280762 0.168945 -0.0991211 ... 0.0795898 -0.0559082 0.0267334]]\n",
      "\n",
      "  [[-0.0366211 0.0600586 -0.0541992 ... -0.0737305 -0.0149536 0.0100098]\n",
      "   [-0.0375977 0.0568848 -0.0576172 ... -0.0771484 -0.0144043\n",
      "    0.00946045]\n",
      "   [-0.0424805 0.0617676 -0.0529785 ... -0.0751953 -0.0140381 0.0072937]\n",
      "   ...\n",
      "   [-0.0358887 0.0625 -0.0566406 ... -0.0717773 -0.0136719 0.00616455]\n",
      "   [-0.0358887 0.0625 -0.0566406 ... -0.0717773 -0.0136719 0.00616455]\n",
      "   [-0.0358887 0.0625 -0.0566406 ... -0.0717773 -0.0136719 0.00616455]]\n",
      "\n",
      "  [[-0.0197754 0.00653076 0.026001 ... -0.00708008 0.101562 -0.130859]\n",
      "   [-0.0117188 0.00424194 0.022583 ... -0.00683594 0.101562 -0.129883]\n",
      "   [-0.0164795 -0.00075531 0.0281982 ... -0.00921631 0.103027 -0.133789]\n",
      "   ...\n",
      "   [-0.0150757 0.00665283 0.0247803 ... -0.00305176 0.0991211 -0.129883]\n",
      "   [-0.0150757 0.00665283 0.0247803 ... -0.00305176 0.0991211 -0.129883]\n",
      "   [-0.0150757 0.00665283 0.0247803 ... -0.00305176 0.0991211 -0.129883]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0795898 0.0751953 -0.0612793 ... -0.017334 0.145508 -0.15332]\n",
      "   [0.0800781 0.0732422 -0.065918 ... -0.0198975 0.143555 -0.155273]\n",
      "   [0.0849609 0.074707 -0.0693359 ... -0.0161133 0.140625 -0.152344]\n",
      "   ...\n",
      "   [0.0820312 0.0727539 -0.0620117 ... -0.0102539 0.145508 -0.150391]\n",
      "   [0.0820312 0.0727539 -0.0620117 ... -0.0102539 0.145508 -0.150391]\n",
      "   [0.0820312 0.0727539 -0.0620117 ... -0.0102539 0.145508 -0.150391]]\n",
      "\n",
      "  [[-0.0280762 -0.0830078 -0.0751953 ... -0.00283813 0.132812 0.0515137]\n",
      "   [-0.0305176 -0.0800781 -0.0742188 ... -0.00196838 0.137695 0.0480957]\n",
      "   [-0.0339355 -0.0776367 -0.0742188 ... -0.0013504 0.131836 0.0490723]\n",
      "   ...\n",
      "   [-0.0327148 -0.081543 -0.0712891 ... -0.00497437 0.135742 0.0480957]\n",
      "   [-0.0327148 -0.081543 -0.0712891 ... -0.00497437 0.135742 0.0480957]\n",
      "   [-0.0327148 -0.081543 -0.0712891 ... -0.00497437 0.135742 0.0480957]]\n",
      "\n",
      "  [[-0.0245361 -0.0522461 0.0976562 ... 0.000728607 0.0673828\n",
      "    -0.0113525]\n",
      "   [-0.02771 -0.0505371 0.0991211 ... 0.00390625 0.0644531 -0.012207]\n",
      "   [-0.0302734 -0.0532227 0.0961914 ... 0.000220299 0.0588379\n",
      "    -0.0115967]\n",
      "   ...\n",
      "   [-0.0269775 -0.0515137 0.0996094 ... 0.00198364 0.0605469 -0.0102539]\n",
      "   [-0.0269775 -0.0515137 0.0996094 ... 0.00198364 0.0605469 -0.0102539]\n",
      "   [-0.0269775 -0.0515137 0.0996094 ... 0.00198364 0.0605469 -0.0102539]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0664062 -0.0341797 -0.148438 ... 0.117676 -0.0322266 0.0466309]\n",
      "   [-0.0698242 -0.0395508 -0.143555 ... 0.111816 -0.0395508 0.0454102]\n",
      "   [-0.0703125 -0.0388184 -0.146484 ... 0.117188 -0.0314941 0.0495605]\n",
      "   ...\n",
      "   [-0.0693359 -0.0339355 -0.154297 ... 0.115234 -0.0361328 0.0488281]\n",
      "   [-0.0693359 -0.0339355 -0.154297 ... 0.115234 -0.0361328 0.0488281]\n",
      "   [-0.0693359 -0.0339355 -0.154297 ... 0.115234 -0.0361328 0.0488281]]\n",
      "\n",
      "  [[-0.120605 0.00421143 0.0698242 ... 0.0458984 -0.0202637 0.10498]\n",
      "   [-0.122559 0.00921631 0.0693359 ... 0.0437012 -0.0196533 0.106934]\n",
      "   [-0.117188 0.00588989 0.0664062 ... 0.0480957 -0.0153198 0.109375]\n",
      "   ...\n",
      "   [-0.126953 0.00921631 0.0678711 ... 0.041748 -0.0185547 0.108887]\n",
      "   [-0.126953 0.00921631 0.0678711 ... 0.041748 -0.0185547 0.108887]\n",
      "   [-0.126953 0.00921631 0.0678711 ... 0.041748 -0.0185547 0.108887]]\n",
      "\n",
      "  [[0.105469 0.00793457 -0.114746 ... 0.0405273 -0.208008 -0.00958252]\n",
      "   [0.106934 0.0126343 -0.118652 ... 0.0446777 -0.209961 -0.00946045]\n",
      "   [0.10498 0.0106812 -0.114746 ... 0.0444336 -0.210938 -0.0133667]\n",
      "   ...\n",
      "   [0.105469 0.0140381 -0.116211 ... 0.0422363 -0.211914 -0.0117798]\n",
      "   [0.105469 0.0140381 -0.116211 ... 0.0422363 -0.211914 -0.0117798]\n",
      "   [0.105469 0.0140381 -0.116211 ... 0.0422363 -0.211914 -0.0117798]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0859375 -0.0241699 0.0961914 ... 0.0888672 0.0478516 -0.0301514]\n",
      "   [-0.0869141 -0.020752 0.0913086 ... 0.0864258 0.0500488 -0.0375977]\n",
      "   [-0.0893555 -0.0213623 0.09375 ... 0.0834961 0.0527344 -0.0327148]\n",
      "   ...\n",
      "   [-0.0908203 -0.0274658 0.0913086 ... 0.0898438 0.0476074 -0.0310059]\n",
      "   [-0.0908203 -0.0274658 0.0913086 ... 0.0898438 0.0476074 -0.0310059]\n",
      "   [-0.0908203 -0.0274658 0.0913086 ... 0.0898438 0.0476074 -0.0310059]]\n",
      "\n",
      "  [[-0.00637817 0.00686646 0.0554199 ... 0.078125 -0.129883 0.0825195]\n",
      "   [-0.00043869 0.00411987 0.0554199 ... 0.0712891 -0.136719 0.0830078]\n",
      "   [0.00396729 0.00689697 0.0539551 ... 0.0742188 -0.131836 0.0825195]\n",
      "   ...\n",
      "   [-0.00149536 0.00848389 0.0532227 ... 0.0698242 -0.129883 0.0800781]\n",
      "   [-0.00149536 0.00848389 0.0532227 ... 0.0698242 -0.129883 0.0800781]\n",
      "   [-0.00149536 0.00848389 0.0532227 ... 0.0698242 -0.129883 0.0800781]]\n",
      "\n",
      "  [[0.0251465 0.0135498 0.0507812 ... 0.143555 0.045166 0.0737305]\n",
      "   [0.0229492 0.0144043 0.0522461 ... 0.143555 0.0473633 0.0756836]\n",
      "   [0.0249023 0.0122681 0.0495605 ... 0.147461 0.048584 0.074707]\n",
      "   ...\n",
      "   [0.0269775 0.0137329 0.0563965 ... 0.145508 0.0422363 0.0761719]\n",
      "   [0.0269775 0.0137329 0.0563965 ... 0.145508 0.0422363 0.0761719]\n",
      "   [0.0269775 0.0137329 0.0563965 ... 0.145508 0.0422363 0.0761719]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0400391 0.0549316 -0.0683594 ... 0.0230713 0.0693359 0.0722656]\n",
      "   [-0.0380859 0.0566406 -0.0703125 ... 0.0217285 0.0673828 0.0732422]\n",
      "   [-0.0383301 0.0541992 -0.0664062 ... 0.0213623 0.0703125 0.0737305]\n",
      "   ...\n",
      "   [-0.0385742 0.059082 -0.0703125 ... 0.0186768 0.0698242 0.0717773]\n",
      "   [-0.0385742 0.059082 -0.0703125 ... 0.0186768 0.0698242 0.0717773]\n",
      "   [-0.0385742 0.059082 -0.0703125 ... 0.0186768 0.0698242 0.0717773]]\n",
      "\n",
      "  [[0.0198975 -0.0898438 0.0368652 ... 0.0419922 0.00665283 -0.0507812]\n",
      "   [0.0196533 -0.0908203 0.0393066 ... 0.0463867 0.00189972 -0.0517578]\n",
      "   [0.0212402 -0.0878906 0.0422363 ... 0.0400391 0.00491333 -0.0507812]\n",
      "   ...\n",
      "   [0.0214844 -0.0913086 0.0410156 ... 0.0378418 0.00732422 -0.0510254]\n",
      "   [0.0214844 -0.0913086 0.0410156 ... 0.0378418 0.00732422 -0.0510254]\n",
      "   [0.0214844 -0.0913086 0.0410156 ... 0.0378418 0.00732422 -0.0510254]]\n",
      "\n",
      "  [[0.0240479 -0.0124512 -0.0456543 ... -0.00662231 0.046875 0.026123]\n",
      "   [0.0249023 -0.0108032 -0.0458984 ... -0.00805664 0.0512695 0.0250244]\n",
      "   [0.0264893 -0.0078125 -0.0488281 ... -0.00497437 0.0544434 0.0288086]\n",
      "   ...\n",
      "   [0.0234375 -0.00463867 -0.0483398 ... -0.00366211 0.0539551\n",
      "    0.0269775]\n",
      "   [0.0234375 -0.00463867 -0.0483398 ... -0.00366211 0.0539551\n",
      "    0.0269775]\n",
      "   [0.0234375 -0.00463867 -0.0483398 ... -0.00366211 0.0539551\n",
      "    0.0269775]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0515137 0.00872803 0.0568848 ... -0.0157471 0.0500488 0.0610352]\n",
      "   [0.0483398 0.00744629 0.0524902 ... -0.0150757 0.0419922 0.060791]\n",
      "   [0.0476074 0.00732422 0.0510254 ... -0.0133057 0.036377 0.0581055]\n",
      "   ...\n",
      "   [0.0493164 0.00775146 0.0529785 ... -0.0148926 0.0444336 0.0610352]\n",
      "   [0.0493164 0.00775146 0.0529785 ... -0.0148926 0.0444336 0.0610352]\n",
      "   [0.0493164 0.00775146 0.0529785 ... -0.0148926 0.0444336 0.0610352]]\n",
      "\n",
      "  [[0.0324707 0.0290527 -0.0500488 ... 0.0563965 0.00254822 -0.00805664]\n",
      "   [0.0397949 0.0305176 -0.0517578 ... 0.0576172 0.00393677 -0.0103149]\n",
      "   [0.0373535 0.0314941 -0.0534668 ... 0.059082 0.006073 -0.00488281]\n",
      "   ...\n",
      "   [0.0393066 0.0317383 -0.0561523 ... 0.0578613 0.00701904 -0.00491333]\n",
      "   [0.0393066 0.0317383 -0.0561523 ... 0.0578613 0.00701904 -0.00491333]\n",
      "   [0.0393066 0.0317383 -0.0561523 ... 0.0578613 0.00701904 -0.00491333]]\n",
      "\n",
      "  [[-0.0507812 0.0373535 -0.027832 ... -0.107422 -0.00210571 -0.0111694]\n",
      "   [-0.0529785 0.034668 -0.0279541 ... -0.101562 0.0050354 -0.0101318]\n",
      "   [-0.0549316 0.0339355 -0.0279541 ... -0.10498 0.00253296 -0.00686646]\n",
      "   ...\n",
      "   [-0.0610352 0.0371094 -0.0314941 ... -0.102539 0.00260925 -0.0149536]\n",
      "   [-0.0610352 0.0371094 -0.0314941 ... -0.102539 0.00260925 -0.0149536]\n",
      "   [-0.0610352 0.0371094 -0.0314941 ... -0.102539 0.00260925 -0.0149536]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0189209 0.078125 0.102539 ... 0.00253296 -0.0908203 0.0378418]\n",
      "   [0.0201416 0.0844727 0.0996094 ... -0.00219727 -0.0917969 0.0344238]\n",
      "   [0.0195312 0.0791016 0.100098 ... -0.000667572 -0.0908203 0.0407715]\n",
      "   ...\n",
      "   [0.0154419 0.0844727 0.103516 ... 0.00105286 -0.0874023 0.0380859]\n",
      "   [0.0154419 0.0844727 0.103516 ... 0.00105286 -0.0874023 0.0380859]\n",
      "   [0.0154419 0.0844727 0.103516 ... 0.00105286 -0.0874023 0.0380859]]\n",
      "\n",
      "  [[-0.0527344 0.0220947 0.00241089 ... -0.0429688 -0.0233154 0.0181885]\n",
      "   [-0.0522461 0.0150757 0.00178528 ... -0.0427246 -0.0192871 0.0187988]\n",
      "   [-0.0473633 0.0217285 0.00268555 ... -0.043457 -0.0219727 0.0240479]\n",
      "   ...\n",
      "   [-0.0541992 0.0218506 -0.000488281 ... -0.0463867 -0.0201416\n",
      "    0.0147095]\n",
      "   [-0.0541992 0.0218506 -0.000488281 ... -0.0463867 -0.0201416\n",
      "    0.0147095]\n",
      "   [-0.0541992 0.0218506 -0.000488281 ... -0.0463867 -0.0201416\n",
      "    0.0147095]]\n",
      "\n",
      "  [[-0.0913086 0.0258789 0.0344238 ... 0.0300293 0.0634766 -0.015564]\n",
      "   [-0.0932617 0.0236816 0.0319824 ... 0.0280762 0.0668945 -0.0129395]\n",
      "   [-0.0947266 0.0247803 0.0281982 ... 0.0302734 0.0722656 -0.0163574]\n",
      "   ...\n",
      "   [-0.0893555 0.0262451 0.0334473 ... 0.032959 0.0712891 -0.0157471]\n",
      "   [-0.0893555 0.0262451 0.0334473 ... 0.032959 0.0712891 -0.0157471]\n",
      "   [-0.0893555 0.0262451 0.0334473 ... 0.032959 0.0712891 -0.0157471]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0991211 0.0578613 0.131836 ... -0.0231934 0.0223389 0.0957031]\n",
      "   [0.0996094 0.0566406 0.126953 ... -0.0239258 0.0195312 0.0927734]\n",
      "   [0.0991211 0.0578613 0.130859 ... -0.0227051 0.0212402 0.0917969]\n",
      "   ...\n",
      "   [0.0961914 0.0546875 0.134766 ... -0.0240479 0.0202637 0.0913086]\n",
      "   [0.0961914 0.0546875 0.134766 ... -0.0240479 0.0202637 0.0913086]\n",
      "   [0.0961914 0.0546875 0.134766 ... -0.0240479 0.0202637 0.0913086]]\n",
      "\n",
      "  [[-0.0908203 -0.0136719 0.0898438 ... 0.15332 -0.00445557 -0.0189209]\n",
      "   [-0.0957031 -0.015564 0.0913086 ... 0.154297 -0.00741577 -0.019165]\n",
      "   [-0.0922852 -0.0154419 0.0878906 ... 0.152344 -0.00653076 -0.0247803]\n",
      "   ...\n",
      "   [-0.0913086 -0.0151978 0.0864258 ... 0.151367 -0.00241089 -0.0178223]\n",
      "   [-0.0913086 -0.0151978 0.0864258 ... 0.151367 -0.00241089 -0.0178223]\n",
      "   [-0.0913086 -0.0151978 0.0864258 ... 0.151367 -0.00241089 -0.0178223]]\n",
      "\n",
      "  [[0.0284424 0.146484 -0.074707 ... 0.000299454 0.0649414 0.0385742]\n",
      "   [0.0306396 0.142578 -0.0717773 ... -0.00692749 0.0688477 0.0437012]\n",
      "   [0.0322266 0.142578 -0.0751953 ... -0.00509644 0.0678711 0.0405273]\n",
      "   ...\n",
      "   [0.0291748 0.144531 -0.0751953 ... -6.4671e-06 0.065918 0.036377]\n",
      "   [0.0291748 0.144531 -0.0751953 ... -6.4671e-06 0.065918 0.036377]\n",
      "   [0.0291748 0.144531 -0.0751953 ... -6.4671e-06 0.065918 0.036377]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0179443 0.0683594 0.0727539 ... -0.0371094 0.00653076 0.00386047]\n",
      "   [0.0161133 0.0673828 0.0717773 ... -0.0441895 0.00686646 0.00350952]\n",
      "   [0.015564 0.0703125 0.0708008 ... -0.0351562 0.00933838 0.00915527]\n",
      "   ...\n",
      "   [0.0214844 0.0668945 0.0722656 ... -0.0361328 0.00408936 0.00872803]\n",
      "   [0.0214844 0.0668945 0.0722656 ... -0.0361328 0.00408936 0.00872803]\n",
      "   [0.0214844 0.0668945 0.0722656 ... -0.0361328 0.00408936 0.00872803]]\n",
      "\n",
      "  [[0.0110474 -0.0133057 0.0233154 ... -0.128906 0.136719 0.0446777]\n",
      "   [0.0119019 -0.0180664 0.0274658 ... -0.133789 0.138672 0.043457]\n",
      "   [0.0122681 -0.0205078 0.0244141 ... -0.125 0.134766 0.0444336]\n",
      "   ...\n",
      "   [0.0126953 -0.0158691 0.0251465 ... -0.125977 0.138672 0.0490723]\n",
      "   [0.0126953 -0.0158691 0.0251465 ... -0.125977 0.138672 0.0490723]\n",
      "   [0.0126953 -0.0158691 0.0251465 ... -0.125977 0.138672 0.0490723]]\n",
      "\n",
      "  [[0.034668 -0.0419922 0.0493164 ... -0.0529785 -0.142578 0.0197754]\n",
      "   [0.0290527 -0.0437012 0.0498047 ... -0.0524902 -0.139648 0.0236816]\n",
      "   [0.0336914 -0.0466309 0.0473633 ... -0.0488281 -0.137695 0.0189209]\n",
      "   ...\n",
      "   [0.0339355 -0.045166 0.0507812 ... -0.052002 -0.141602 0.0194092]\n",
      "   [0.0339355 -0.045166 0.0507812 ... -0.052002 -0.141602 0.0194092]\n",
      "   [0.0339355 -0.045166 0.0507812 ... -0.052002 -0.141602 0.0194092]]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/amd/model/hub/models--meta-llama--Llama-3.2-11B-Vision/pytorch were not used when initializing FlaxMllamaVisionModel: {('language_model', 'model', 'layers.3', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.37', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.9', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.16', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.14', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.16', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.17', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'embed_tokens', 'kernel'), ('language_model', 'model', 'layers.29', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.33', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.29', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.38', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'mlp', 'down_proj', 'kernel'), ('multi_modal_projector', 'bias'), ('language_model', 'model', 'layers.0', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.15', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.36', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.34', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.24', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.3', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'norm', 'kernel'), ('language_model', 'model', 'layers.6', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.17', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.0', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.15', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.36', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.25', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.27', 'input_layernorm', 'kernel'), ('language_model', 'lm_head', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.37', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.30', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.31', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.20', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.39', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.9', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.26', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.30', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.21', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.24', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.37', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.29', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.3', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.6', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.19', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.1', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.7', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.9', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.30', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.36', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.15', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.28', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.12', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.12', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.0', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.12', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'input_layernorm', 'kernel'), ('multi_modal_projector', 'kernel'), ('language_model', 'model', 'layers.24', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.26', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.8', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.5', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.9', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.23', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.0', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.31', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.20', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.31', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.37', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.11', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.6', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.31', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.6', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.32', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'q_proj', 'kernel')}\n",
      "- This IS expected if you are initializing FlaxMllamaVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxMllamaVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some of the weights of FlaxMllamaVisionModel were initialized in bfloat16 precision from the model checkpoint at /home/amd/model/hub/models--meta-llama--Llama-3.2-11B-Vision/pytorch:\n",
      "[('vision_model', 'class_embedding'), ('vision_model', 'gated_positional_embedding', 'embedding'), ('vision_model', 'gated_positional_embedding', 'gate'), ('vision_model', 'gated_positional_embedding', 'tile_embedding', 'embedding'), ('vision_model', 'global_transformer', 'layers.0', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.0', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.0', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.1', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.1', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.2', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.2', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.3', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.3', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.4', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.4', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.5', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.5', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.6', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.6', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.7', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.7', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'layernorm_post', 'bias'), ('vision_model', 'layernorm_post', 'scale'), ('vision_model', 'layernorm_pre', 'bias'), ('vision_model', 'layernorm_pre', 'scale'), ('vision_model', 'patch_embedding', 'kernel'), ('vision_model', 'post_tile_positional_embedding', 'embedding', 'embedding'), ('vision_model', 'post_tile_positional_embedding', 'gate'), ('vision_model', 'pre_tile_positional_embedding', 'embedding', 'embedding'), ('vision_model', 'pre_tile_positional_embedding', 'gate'), ('vision_model', 'transformer', 'layers.0', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.0', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.0', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.1', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.1', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.10', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.10', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.11', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.11', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.12', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.12', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.13', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.13', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.14', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.14', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.15', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.15', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.16', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.16', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.17', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.17', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.18', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.18', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.19', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.19', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.2', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.2', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.20', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.20', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.21', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.21', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.22', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.22', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.23', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.23', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.24', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.24', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.25', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.25', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.26', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.26', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.27', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.27', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.28', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.28', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.29', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.29', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.3', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.3', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.30', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.30', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.31', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.31', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.4', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.4', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.5', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.5', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.6', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.6', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.7', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.7', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.8', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.8', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.9', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.9', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'v_proj', 'kernel')]\n",
      "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MllamaVisionModel, FlaxMllamaVisionModel\n",
    "from transformers import AutoProcessor, MllamaTextModel\n",
    "import requests\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image\n",
    "from huggingface_hub import login\n",
    "torch.set_printoptions(precision=8)\n",
    "jax.numpy.set_printoptions(precision=10)\n",
    "\n",
    "hf_token = \"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\"\n",
    "login(hf_token)\n",
    "checkpoint = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "model_torch = MllamaVisionModel.from_pretrained(checkpoint, torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "\n",
    "model = FlaxMllamaVisionModel.from_pretrained(\"/home/amd/model/hub/models--meta-llama--Llama-3.2-11B-Vision/pytorch\", from_pt=True, dtype=jnp.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-0.01129150,  0.20898438, -0.00903320,  ...,  0.02868652,\n",
      "            0.01806641, -0.01214600],\n",
      "          [ 0.00625610, -0.13867188, -0.14453125,  ..., -0.03320312,\n",
      "            0.05004883, -0.03344727],\n",
      "          [ 0.01037598, -0.17968750, -0.16015625,  ..., -0.05517578,\n",
      "            0.05029297, -0.02600098],\n",
      "          ...,\n",
      "          [ 0.06591797,  0.39843750,  0.00059128,  ..., -0.02258301,\n",
      "            0.03051758,  0.05908203],\n",
      "          [ 0.06591797,  0.39843750,  0.00059128,  ..., -0.02258301,\n",
      "            0.03051758,  0.05908203],\n",
      "          [ 0.06591797,  0.39843750,  0.00059128,  ..., -0.02258301,\n",
      "            0.03051758,  0.05908203]],\n",
      "\n",
      "         [[-0.00714111,  0.04467773,  0.02416992,  ..., -0.01525879,\n",
      "           -0.00212097,  0.03271484],\n",
      "          [ 0.00133514,  0.05395508,  0.03759766,  ..., -0.00503540,\n",
      "           -0.12011719,  0.06152344],\n",
      "          [ 0.00354004,  0.05493164,  0.03759766,  ..., -0.00285339,\n",
      "           -0.12792969,  0.06445312],\n",
      "          ...,\n",
      "          [ 0.00364685,  0.03417969,  0.02502441,  ..., -0.01818848,\n",
      "            0.10302734,  0.00823975],\n",
      "          [ 0.00364685,  0.03417969,  0.02502441,  ..., -0.01818848,\n",
      "            0.10302734,  0.00823975],\n",
      "          [ 0.00364685,  0.03417969,  0.02502441,  ..., -0.01818848,\n",
      "            0.10302734,  0.00823975]],\n",
      "\n",
      "         [[-0.13769531,  0.01324463,  0.02343750,  ..., -0.01562500,\n",
      "           -0.01599121, -0.10742188],\n",
      "          [-0.13964844,  0.00704956,  0.01721191,  ..., -0.02697754,\n",
      "           -0.01586914, -0.08398438],\n",
      "          [-0.13867188,  0.00686646,  0.01416016,  ..., -0.02661133,\n",
      "           -0.01513672, -0.08984375],\n",
      "          ...,\n",
      "          [-0.14160156,  0.01031494,  0.02966309,  ..., -0.02722168,\n",
      "           -0.01855469, -0.06445312],\n",
      "          [-0.14160156,  0.01031494,  0.02966309,  ..., -0.02722168,\n",
      "           -0.01855469, -0.06445312],\n",
      "          [-0.14160156,  0.01031494,  0.02966309,  ..., -0.02722168,\n",
      "           -0.01855469, -0.06445312]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.04736328, -0.07324219,  0.00518799,  ...,  0.01080322,\n",
      "            0.03442383,  0.04125977],\n",
      "          [ 0.01428223, -0.14746094, -0.20117188,  ..., -0.35546875,\n",
      "           -0.29687500, -0.14257812],\n",
      "          [ 0.01916504, -0.15820312, -0.21386719,  ..., -0.35937500,\n",
      "           -0.30078125, -0.15136719],\n",
      "          ...,\n",
      "          [-0.09960938,  0.01965332, -0.12353516,  ..., -0.02111816,\n",
      "            0.09814453, -0.04077148],\n",
      "          [-0.09960938,  0.01965332, -0.12353516,  ..., -0.02111816,\n",
      "            0.09814453, -0.04077148],\n",
      "          [-0.09960938,  0.01965332, -0.12353516,  ..., -0.02111816,\n",
      "            0.09814453, -0.04077148]],\n",
      "\n",
      "         [[-0.08105469, -0.09326172,  0.00698853,  ..., -0.00543213,\n",
      "           -0.04467773,  0.01257324],\n",
      "          [-0.05712891, -0.02429199,  0.05151367,  ..., -0.02880859,\n",
      "           -0.02258301,  0.02868652],\n",
      "          [-0.05810547, -0.02783203,  0.05151367,  ..., -0.02783203,\n",
      "           -0.02233887,  0.03222656],\n",
      "          ...,\n",
      "          [-0.06835938, -0.08935547,  0.00218201,  ..., -0.00781250,\n",
      "           -0.04614258,  0.00946045],\n",
      "          [-0.06835938, -0.08935547,  0.00218201,  ..., -0.00781250,\n",
      "           -0.04614258,  0.00946045],\n",
      "          [-0.06835938, -0.08935547,  0.00218201,  ..., -0.00781250,\n",
      "           -0.04614258,  0.00946045]],\n",
      "\n",
      "         [[ 0.02661133, -0.01989746, -0.04907227,  ...,  0.01782227,\n",
      "           -0.02978516,  0.01867676],\n",
      "          [-0.08935547, -0.11035156,  0.21191406,  ...,  0.13671875,\n",
      "            0.06542969, -0.11523438],\n",
      "          [-0.13769531, -0.11328125,  0.26171875,  ...,  0.11279297,\n",
      "            0.13476562, -0.14062500],\n",
      "          ...,\n",
      "          [-0.00823975, -0.00952148, -0.00448608,  ..., -0.04687500,\n",
      "            0.04858398,  0.00303650],\n",
      "          [-0.00823975, -0.00952148, -0.00448608,  ..., -0.04687500,\n",
      "            0.04858398,  0.00303650],\n",
      "          [-0.00823975, -0.00952148, -0.00448608,  ..., -0.04687500,\n",
      "            0.04858398,  0.00303650]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 2.47802734e-02,  6.88476562e-02, -4.95605469e-02,  ...,\n",
      "            7.93457031e-03,  2.78320312e-02, -7.76367188e-02],\n",
      "          [ 3.19824219e-02,  5.88378906e-02, -2.47802734e-02,  ...,\n",
      "           -1.06201172e-02,  1.94091797e-02, -1.14257812e-01],\n",
      "          [ 3.12500000e-02,  5.93261719e-02, -2.25830078e-02,  ...,\n",
      "           -1.20544434e-03,  1.12915039e-02, -1.11816406e-01],\n",
      "          ...,\n",
      "          [ 2.51464844e-02,  8.25195312e-02, -4.73632812e-02,  ...,\n",
      "           -9.70458984e-03,  1.55639648e-02, -9.42382812e-02],\n",
      "          [ 2.51464844e-02,  8.25195312e-02, -4.73632812e-02,  ...,\n",
      "           -9.70458984e-03,  1.55639648e-02, -9.42382812e-02],\n",
      "          [ 2.51464844e-02,  8.25195312e-02, -4.73632812e-02,  ...,\n",
      "           -9.70458984e-03,  1.55639648e-02, -9.42382812e-02]],\n",
      "\n",
      "         [[-2.62451172e-02,  1.62353516e-02, -9.17968750e-02,  ...,\n",
      "           -2.81982422e-02, -5.39550781e-02, -5.20019531e-02],\n",
      "          [-2.73437500e-02,  1.60156250e-01, -5.88378906e-02,  ...,\n",
      "           -4.17709351e-04, -1.35742188e-01,  2.72216797e-02],\n",
      "          [-2.18505859e-02,  1.86523438e-01, -5.93261719e-02,  ...,\n",
      "            3.29971313e-04, -1.51367188e-01,  3.27148438e-02],\n",
      "          ...,\n",
      "          [ 1.63574219e-02,  2.83203125e-02, -1.02539062e-01,  ...,\n",
      "            1.63085938e-01, -1.63085938e-01, -3.93066406e-02],\n",
      "          [ 1.63574219e-02,  2.83203125e-02, -1.02539062e-01,  ...,\n",
      "            1.63085938e-01, -1.63085938e-01, -3.93066406e-02],\n",
      "          [ 1.63574219e-02,  2.83203125e-02, -1.02539062e-01,  ...,\n",
      "            1.63085938e-01, -1.63085938e-01, -3.93066406e-02]],\n",
      "\n",
      "         [[-4.02832031e-02, -1.29882812e-01, -3.82812500e-01,  ...,\n",
      "            6.77490234e-03,  4.15039062e-03, -7.56835938e-02],\n",
      "          [ 2.11715698e-04, -1.42822266e-02,  2.21679688e-01,  ...,\n",
      "            1.50390625e-01,  9.33837891e-03, -3.93066406e-02],\n",
      "          [ 6.28662109e-03, -1.35803223e-03,  3.39843750e-01,  ...,\n",
      "            1.59179688e-01,  3.00598145e-03, -4.24804688e-02],\n",
      "          ...,\n",
      "          [ 5.68847656e-02, -1.46484375e-01,  5.74218750e-01,  ...,\n",
      "            5.98144531e-02, -5.00488281e-03, -1.70898438e-01],\n",
      "          [ 5.68847656e-02, -1.46484375e-01,  5.74218750e-01,  ...,\n",
      "            5.98144531e-02, -5.00488281e-03, -1.70898438e-01],\n",
      "          [ 5.68847656e-02, -1.46484375e-01,  5.74218750e-01,  ...,\n",
      "            5.98144531e-02, -5.00488281e-03, -1.70898438e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.53808594e-02,  3.17382812e-02,  1.14746094e-02,  ...,\n",
      "           -9.39941406e-03, -1.28906250e-01,  7.11059570e-03],\n",
      "          [ 1.68457031e-02,  3.49121094e-02,  8.85009766e-03,  ...,\n",
      "           -1.05590820e-02, -1.45507812e-01,  9.46044922e-03],\n",
      "          [ 1.70898438e-02,  3.46679688e-02,  9.03320312e-03,  ...,\n",
      "           -1.06811523e-02, -1.44531250e-01,  9.03320312e-03],\n",
      "          ...,\n",
      "          [ 4.39453125e-02,  1.06811523e-02, -2.27050781e-02,  ...,\n",
      "           -1.96533203e-02, -4.02832031e-02,  7.42187500e-02],\n",
      "          [ 4.39453125e-02,  1.06811523e-02, -2.27050781e-02,  ...,\n",
      "           -1.96533203e-02, -4.02832031e-02,  7.42187500e-02],\n",
      "          [ 4.39453125e-02,  1.06811523e-02, -2.27050781e-02,  ...,\n",
      "           -1.96533203e-02, -4.02832031e-02,  7.42187500e-02]],\n",
      "\n",
      "         [[-5.44433594e-02, -4.97436523e-03,  5.41992188e-02,  ...,\n",
      "           -2.02941895e-03, -3.14941406e-02, -1.06811523e-03],\n",
      "          [-5.17578125e-02,  1.39160156e-02,  1.35498047e-02,  ...,\n",
      "           -1.81884766e-02, -4.49218750e-02, -1.02539062e-02],\n",
      "          [-4.37011719e-02,  2.12097168e-03,  2.31933594e-02,  ...,\n",
      "           -2.57873535e-03, -6.64062500e-02, -5.52368164e-03],\n",
      "          ...,\n",
      "          [-1.01562500e-01,  4.08935547e-03,  8.17871094e-03,  ...,\n",
      "           -4.05273438e-02, -1.83105469e-02, -3.03955078e-02],\n",
      "          [-1.01562500e-01,  4.08935547e-03,  8.17871094e-03,  ...,\n",
      "           -4.05273438e-02, -1.83105469e-02, -3.03955078e-02],\n",
      "          [-1.01562500e-01,  4.08935547e-03,  8.17871094e-03,  ...,\n",
      "           -4.05273438e-02, -1.83105469e-02, -3.03955078e-02]],\n",
      "\n",
      "         [[ 5.00488281e-02,  6.49414062e-02,  8.97216797e-03,  ...,\n",
      "           -6.07910156e-02,  5.49316406e-02,  3.22265625e-02],\n",
      "          [ 1.04492188e-01, -1.00585938e-01, -5.59082031e-02,  ...,\n",
      "            1.38671875e-01,  5.85937500e-02, -6.88476562e-02],\n",
      "          [ 1.07421875e-01, -1.45507812e-01, -5.83496094e-02,  ...,\n",
      "            1.45507812e-01,  9.96093750e-02, -6.88476562e-02],\n",
      "          ...,\n",
      "          [ 5.63964844e-02, -1.17675781e-01, -6.25000000e-02,  ...,\n",
      "            7.42187500e-02,  6.59179688e-02, -3.54003906e-02],\n",
      "          [ 5.63964844e-02, -1.17675781e-01, -6.25000000e-02,  ...,\n",
      "            7.42187500e-02,  6.59179688e-02, -3.54003906e-02],\n",
      "          [ 5.63964844e-02, -1.17675781e-01, -6.25000000e-02,  ...,\n",
      "            7.42187500e-02,  6.59179688e-02, -3.54003906e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 2.90527344e-02,  1.22070312e-02,  8.97216797e-03,  ...,\n",
      "            2.00195312e-02,  5.34667969e-02, -3.34472656e-02],\n",
      "          [ 1.62353516e-02,  1.77001953e-02,  2.41699219e-02,  ...,\n",
      "            4.15039062e-02,  6.31713867e-03, -4.32128906e-02],\n",
      "          [-9.82284546e-05,  3.83300781e-02,  3.00292969e-02,  ...,\n",
      "            6.78710938e-02, -7.08007812e-02, -8.78906250e-02],\n",
      "          ...,\n",
      "          [-9.81445312e-02,  2.68554688e-02,  2.56347656e-02,  ...,\n",
      "           -6.05468750e-02, -1.45507812e-01, -5.78613281e-02],\n",
      "          [-9.81445312e-02,  2.68554688e-02,  2.56347656e-02,  ...,\n",
      "           -6.05468750e-02, -1.45507812e-01, -5.78613281e-02],\n",
      "          [-9.81445312e-02,  2.68554688e-02,  2.56347656e-02,  ...,\n",
      "           -6.05468750e-02, -1.45507812e-01, -5.78613281e-02]],\n",
      "\n",
      "         [[-7.20214844e-03, -5.10253906e-02,  8.85009766e-03,  ...,\n",
      "            7.22656250e-02, -7.47070312e-02, -1.97753906e-02],\n",
      "          [ 2.52685547e-02, -1.05468750e-01,  6.29882812e-02,  ...,\n",
      "            8.98437500e-02, -2.16064453e-02,  8.97216797e-03],\n",
      "          [ 3.32031250e-02, -9.81445312e-02,  6.29882812e-02,  ...,\n",
      "            8.69140625e-02, -2.33154297e-02,  1.44042969e-02],\n",
      "          ...,\n",
      "          [ 3.32031250e-02, -4.24804688e-02, -1.47705078e-02,  ...,\n",
      "            8.83789062e-02, -3.93066406e-02, -8.44726562e-02],\n",
      "          [ 3.32031250e-02, -4.24804688e-02, -1.47705078e-02,  ...,\n",
      "            8.83789062e-02, -3.93066406e-02, -8.44726562e-02],\n",
      "          [ 3.32031250e-02, -4.24804688e-02, -1.47705078e-02,  ...,\n",
      "            8.83789062e-02, -3.93066406e-02, -8.44726562e-02]],\n",
      "\n",
      "         [[ 6.78710938e-02,  7.78198242e-03, -1.74804688e-01,  ...,\n",
      "           -4.98046875e-02,  8.78906250e-02, -4.68750000e-02],\n",
      "          [ 5.85937500e-02, -1.62506104e-03, -1.59179688e-01,  ...,\n",
      "           -5.93261719e-02,  8.10546875e-02, -4.88281250e-02],\n",
      "          [ 5.34667969e-02, -2.30407715e-03, -1.54296875e-01,  ...,\n",
      "           -5.85937500e-02,  8.05664062e-02, -4.46777344e-02],\n",
      "          ...,\n",
      "          [ 2.35595703e-02,  8.49609375e-02, -7.56835938e-02,  ...,\n",
      "            1.72851562e-01,  7.61718750e-02,  7.23266602e-03],\n",
      "          [ 2.35595703e-02,  8.49609375e-02, -7.56835938e-02,  ...,\n",
      "            1.72851562e-01,  7.61718750e-02,  7.23266602e-03],\n",
      "          [ 2.35595703e-02,  8.49609375e-02, -7.56835938e-02,  ...,\n",
      "            1.72851562e-01,  7.61718750e-02,  7.23266602e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.00598145e-03,  7.71484375e-02, -3.07617188e-02,  ...,\n",
      "           -1.22680664e-02, -6.98852539e-03,  7.01904297e-03],\n",
      "          [ 6.59179688e-02,  1.90429688e-01, -1.71875000e-01,  ...,\n",
      "           -9.82666016e-03, -1.36718750e-01,  1.68945312e-01],\n",
      "          [ 6.98242188e-02,  2.35351562e-01, -1.66992188e-01,  ...,\n",
      "           -1.26342773e-02, -1.28906250e-01,  1.68945312e-01],\n",
      "          ...,\n",
      "          [ 2.99072266e-02,  4.29687500e-02, -3.36914062e-02,  ...,\n",
      "           -5.64575195e-03, -1.82617188e-01,  3.71093750e-02],\n",
      "          [ 2.99072266e-02,  4.29687500e-02, -3.36914062e-02,  ...,\n",
      "           -5.64575195e-03, -1.82617188e-01,  3.71093750e-02],\n",
      "          [ 2.99072266e-02,  4.29687500e-02, -3.36914062e-02,  ...,\n",
      "           -5.64575195e-03, -1.82617188e-01,  3.71093750e-02]],\n",
      "\n",
      "         [[-6.78710938e-02,  3.09753418e-03, -3.06396484e-02,  ...,\n",
      "           -1.81884766e-02, -6.98242188e-02,  1.66015625e-02],\n",
      "          [ 3.02734375e-01, -2.28271484e-02, -1.01562500e-01,  ...,\n",
      "            1.46484375e-01, -8.98437500e-02,  8.00781250e-02],\n",
      "          [ 4.82421875e-01, -3.19824219e-02, -1.49414062e-01,  ...,\n",
      "            2.19726562e-01, -8.78906250e-02,  1.23535156e-01],\n",
      "          ...,\n",
      "          [ 2.38037109e-02, -1.04492188e-01, -1.71875000e-01,  ...,\n",
      "            6.29882812e-02, -3.06396484e-02,  7.61718750e-02],\n",
      "          [ 2.38037109e-02, -1.04492188e-01, -1.71875000e-01,  ...,\n",
      "            6.29882812e-02, -3.06396484e-02,  7.61718750e-02],\n",
      "          [ 2.38037109e-02, -1.04492188e-01, -1.71875000e-01,  ...,\n",
      "            6.29882812e-02, -3.06396484e-02,  7.61718750e-02]],\n",
      "\n",
      "         [[ 1.73339844e-02, -3.85742188e-02, -1.52587891e-02,  ...,\n",
      "           -2.30712891e-02, -3.14941406e-02,  4.93164062e-02],\n",
      "          [ 1.70898438e-02, -3.83300781e-02, -1.53808594e-02,  ...,\n",
      "           -2.35595703e-02, -3.14941406e-02,  4.85839844e-02],\n",
      "          [ 1.72119141e-02, -3.90625000e-02, -1.54418945e-02,  ...,\n",
      "           -2.41699219e-02, -3.27148438e-02,  4.83398438e-02],\n",
      "          ...,\n",
      "          [ 3.31115723e-03,  2.00195312e-02, -3.70788574e-03,  ...,\n",
      "            8.60595703e-03, -7.22656250e-02, -6.83593750e-02],\n",
      "          [ 3.31115723e-03,  2.00195312e-02, -3.70788574e-03,  ...,\n",
      "            8.60595703e-03, -7.22656250e-02, -6.83593750e-02],\n",
      "          [ 3.31115723e-03,  2.00195312e-02, -3.70788574e-03,  ...,\n",
      "            8.60595703e-03, -7.22656250e-02, -6.83593750e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 2.05078125e-02, -4.63867188e-02,  8.23974609e-03,  ...,\n",
      "           -3.66210938e-02,  5.71289062e-02, -2.06298828e-02],\n",
      "          [ 4.34570312e-02, -4.78515625e-02, -1.26953125e-02,  ...,\n",
      "           -4.78515625e-02,  8.30078125e-02,  1.18164062e-01],\n",
      "          [ 4.49218750e-02, -4.95605469e-02, -7.75146484e-03,  ...,\n",
      "           -3.51562500e-02,  7.71484375e-02,  6.07910156e-02],\n",
      "          ...,\n",
      "          [ 1.57470703e-02,  6.44531250e-02, -9.58251953e-03,  ...,\n",
      "            4.44335938e-02,  1.45507812e-01, -3.73046875e-01],\n",
      "          [ 1.57470703e-02,  6.44531250e-02, -9.58251953e-03,  ...,\n",
      "            4.44335938e-02,  1.45507812e-01, -3.73046875e-01],\n",
      "          [ 1.57470703e-02,  6.44531250e-02, -9.58251953e-03,  ...,\n",
      "            4.44335938e-02,  1.45507812e-01, -3.73046875e-01]],\n",
      "\n",
      "         [[-7.47680664e-03,  1.91650391e-02,  8.88671875e-02,  ...,\n",
      "            6.68945312e-02, -6.54296875e-02,  4.74609375e-01],\n",
      "          [-1.09252930e-02,  7.22656250e-02, -2.89916992e-03,  ...,\n",
      "           -1.26953125e-01,  9.81445312e-02,  3.92578125e-01],\n",
      "          [-1.24359131e-03,  7.03125000e-02,  1.04980469e-02,  ...,\n",
      "           -1.12792969e-01,  8.98437500e-02,  3.98437500e-01],\n",
      "          ...,\n",
      "          [-3.38745117e-03, -6.88476562e-02,  2.15820312e-01,  ...,\n",
      "            3.35937500e-01, -2.59765625e-01,  5.97656250e-01],\n",
      "          [-3.38745117e-03, -6.88476562e-02,  2.15820312e-01,  ...,\n",
      "            3.35937500e-01, -2.59765625e-01,  5.97656250e-01],\n",
      "          [-3.38745117e-03, -6.88476562e-02,  2.15820312e-01,  ...,\n",
      "            3.35937500e-01, -2.59765625e-01,  5.97656250e-01]],\n",
      "\n",
      "         [[-1.64794922e-02, -1.96533203e-02,  3.39355469e-02,  ...,\n",
      "            1.00708008e-02,  4.95605469e-02, -3.75976562e-02],\n",
      "          [ 2.19726562e-03, -2.56347656e-02, -3.90625000e-02,  ...,\n",
      "            2.75878906e-02,  4.98046875e-02,  3.96728516e-03],\n",
      "          [-1.54113770e-03, -2.44140625e-02, -3.58886719e-02,  ...,\n",
      "            3.24707031e-02,  5.32226562e-02,  4.42504883e-03],\n",
      "          ...,\n",
      "          [ 9.86328125e-02, -2.56347656e-02, -1.86523438e-01,  ...,\n",
      "           -9.22851562e-02, -5.78613281e-02,  1.31835938e-01],\n",
      "          [ 9.86328125e-02, -2.56347656e-02, -1.86523438e-01,  ...,\n",
      "           -9.22851562e-02, -5.78613281e-02,  1.31835938e-01],\n",
      "          [ 9.86328125e-02, -2.56347656e-02, -1.86523438e-01,  ...,\n",
      "           -9.22851562e-02, -5.78613281e-02,  1.31835938e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.27734375e-03, -7.44628906e-03, -2.70080566e-03,  ...,\n",
      "            7.32421875e-02,  2.31933594e-02, -4.85839844e-02],\n",
      "          [-4.91333008e-03, -6.65283203e-03, -5.95092773e-03,  ...,\n",
      "            7.17773438e-02,  2.68554688e-02, -5.73730469e-02],\n",
      "          [-1.20849609e-02, -8.30078125e-03, -2.34985352e-03,  ...,\n",
      "            7.32421875e-02,  2.40478516e-02, -4.41894531e-02],\n",
      "          ...,\n",
      "          [-2.47070312e-01,  2.42919922e-02, -9.22851562e-02,  ...,\n",
      "            1.77734375e-01,  1.19628906e-02, -2.29492188e-01],\n",
      "          [-2.47070312e-01,  2.42919922e-02, -9.22851562e-02,  ...,\n",
      "            1.77734375e-01,  1.19628906e-02, -2.29492188e-01],\n",
      "          [-2.47070312e-01,  2.42919922e-02, -9.22851562e-02,  ...,\n",
      "            1.77734375e-01,  1.19628906e-02, -2.29492188e-01]],\n",
      "\n",
      "         [[ 1.06201172e-02, -1.76757812e-01, -3.32031250e-02,  ...,\n",
      "           -8.17871094e-03,  2.07519531e-03, -2.88085938e-02],\n",
      "          [ 6.44531250e-02, -4.98046875e-02,  4.19921875e-02,  ...,\n",
      "           -4.10156250e-02, -3.40270996e-03, -1.70898438e-02],\n",
      "          [ 1.81884766e-02, -1.61132812e-01,  9.52148438e-03,  ...,\n",
      "           -2.81982422e-02, -8.86917114e-05, -2.38037109e-02],\n",
      "          ...,\n",
      "          [ 6.68945312e-02, -3.55468750e-01,  4.46777344e-02,  ...,\n",
      "           -1.41601562e-02,  8.69140625e-02,  5.00488281e-02],\n",
      "          [ 6.68945312e-02, -3.55468750e-01,  4.46777344e-02,  ...,\n",
      "           -1.41601562e-02,  8.69140625e-02,  5.00488281e-02],\n",
      "          [ 6.68945312e-02, -3.55468750e-01,  4.46777344e-02,  ...,\n",
      "           -1.41601562e-02,  8.69140625e-02,  5.00488281e-02]],\n",
      "\n",
      "         [[-6.00585938e-02,  5.32226562e-02,  4.90722656e-02,  ...,\n",
      "           -1.28784180e-02, -6.54296875e-02,  1.62109375e-01],\n",
      "          [-5.02929688e-02,  6.39648438e-02,  5.66406250e-02,  ...,\n",
      "           -1.74560547e-02, -6.34765625e-02,  1.64062500e-01],\n",
      "          [-4.73632812e-02,  6.68945312e-02,  5.90820312e-02,  ...,\n",
      "           -1.92871094e-02, -6.17675781e-02,  1.64062500e-01],\n",
      "          ...,\n",
      "          [ 5.29785156e-02, -1.00708008e-02,  1.95312500e-01,  ...,\n",
      "            4.98046875e-02, -2.50000000e-01,  1.35742188e-01],\n",
      "          [ 5.29785156e-02, -1.00708008e-02,  1.95312500e-01,  ...,\n",
      "            4.98046875e-02, -2.50000000e-01,  1.35742188e-01],\n",
      "          [ 5.29785156e-02, -1.00708008e-02,  1.95312500e-01,  ...,\n",
      "            4.98046875e-02, -2.50000000e-01,  1.35742188e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 5.00488281e-02,  8.97216797e-03,  5.58471680e-03,  ...,\n",
      "           -4.80957031e-02, -1.63574219e-02,  3.11279297e-02],\n",
      "          [ 4.63867188e-02,  1.68457031e-02,  8.66699219e-03,  ...,\n",
      "           -4.22363281e-02, -2.22167969e-02,  4.12597656e-02],\n",
      "          [ 4.61425781e-02,  1.75781250e-02,  8.97216797e-03,  ...,\n",
      "           -4.19921875e-02, -2.27050781e-02,  4.22363281e-02],\n",
      "          ...,\n",
      "          [-2.41210938e-01, -1.30859375e-01,  1.01074219e-01,  ...,\n",
      "            3.06701660e-03,  1.37695312e-01, -1.74804688e-01],\n",
      "          [-2.41210938e-01, -1.30859375e-01,  1.01074219e-01,  ...,\n",
      "            3.06701660e-03,  1.37695312e-01, -1.74804688e-01],\n",
      "          [-2.41210938e-01, -1.30859375e-01,  1.01074219e-01,  ...,\n",
      "            3.06701660e-03,  1.37695312e-01, -1.74804688e-01]],\n",
      "\n",
      "         [[-2.99072266e-02, -1.61132812e-02, -1.14135742e-02,  ...,\n",
      "           -5.54199219e-02,  5.11169434e-04, -7.47070312e-02],\n",
      "          [-2.68554688e-02, -1.58691406e-02, -1.09252930e-02,  ...,\n",
      "           -5.83496094e-02,  6.14166260e-04, -7.27539062e-02],\n",
      "          [-2.99072266e-02, -1.64794922e-02, -1.12304688e-02,  ...,\n",
      "           -5.56640625e-02,  2.61306763e-04, -7.51953125e-02],\n",
      "          ...,\n",
      "          [-1.74560547e-02, -2.03857422e-02, -3.11279297e-02,  ...,\n",
      "           -4.10156250e-02, -2.22167969e-02, -3.22265625e-02],\n",
      "          [-1.74560547e-02, -2.03857422e-02, -3.11279297e-02,  ...,\n",
      "           -4.10156250e-02, -2.22167969e-02, -3.22265625e-02],\n",
      "          [-1.74560547e-02, -2.03857422e-02, -3.11279297e-02,  ...,\n",
      "           -4.10156250e-02, -2.22167969e-02, -3.22265625e-02]],\n",
      "\n",
      "         [[-1.01562500e-01, -4.12597656e-02, -1.59912109e-02,  ...,\n",
      "           -9.86328125e-02, -5.92041016e-03,  1.56250000e-02],\n",
      "          [-1.00097656e-01, -4.22363281e-02, -1.44653320e-02,  ...,\n",
      "           -9.76562500e-02, -5.43212891e-03,  1.50146484e-02],\n",
      "          [-9.27734375e-02, -4.34570312e-02, -1.36108398e-02,  ...,\n",
      "           -9.71679688e-02, -5.15747070e-03,  1.49536133e-02],\n",
      "          ...,\n",
      "          [ 1.04687500e+00, -3.36914062e-02,  6.40869141e-03,  ...,\n",
      "           -6.93359375e-02, -3.75976562e-02,  2.20703125e-01],\n",
      "          [ 1.04687500e+00, -3.36914062e-02,  6.40869141e-03,  ...,\n",
      "           -6.93359375e-02, -3.75976562e-02,  2.20703125e-01],\n",
      "          [ 1.04687500e+00, -3.36914062e-02,  6.40869141e-03,  ...,\n",
      "           -6.93359375e-02, -3.75976562e-02,  2.20703125e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.15136719e-02,  2.89306641e-02,  6.22558594e-03,  ...,\n",
      "            5.73730469e-02, -4.12597656e-02,  1.62353516e-02],\n",
      "          [ 2.11181641e-02,  5.07812500e-02, -2.34985352e-03,  ...,\n",
      "            5.49316406e-02, -4.02832031e-03,  1.96533203e-02],\n",
      "          [ 2.53906250e-02,  4.49218750e-02, -1.00708008e-02,  ...,\n",
      "            4.46777344e-02, -2.18200684e-03,  1.33056641e-02],\n",
      "          ...,\n",
      "          [ 3.56445312e-02,  8.44726562e-02,  6.10351562e-02,  ...,\n",
      "            6.34765625e-02, -3.29589844e-02,  7.51953125e-02],\n",
      "          [ 3.56445312e-02,  8.44726562e-02,  6.10351562e-02,  ...,\n",
      "            6.34765625e-02, -3.29589844e-02,  7.51953125e-02],\n",
      "          [ 3.56445312e-02,  8.44726562e-02,  6.10351562e-02,  ...,\n",
      "            6.34765625e-02, -3.29589844e-02,  7.51953125e-02]],\n",
      "\n",
      "         [[-2.22656250e-01, -3.32031250e-02, -4.21875000e-01,  ...,\n",
      "            5.00488281e-02,  2.92968750e-02, -1.24511719e-02],\n",
      "          [-1.38281250e+00,  2.92968750e-01,  2.08007812e-01,  ...,\n",
      "            9.25781250e-01, -1.07910156e-01,  5.78125000e-01],\n",
      "          [-1.38281250e+00,  7.17773438e-02,  3.96484375e-01,  ...,\n",
      "            2.21875000e+00,  1.43554688e-01,  7.22656250e-01],\n",
      "          ...,\n",
      "          [ 2.24609375e-01,  4.29687500e-02, -4.37500000e-01,  ...,\n",
      "           -8.04687500e-01,  1.46484375e-01,  8.54492188e-02],\n",
      "          [ 2.24609375e-01,  4.29687500e-02, -4.37500000e-01,  ...,\n",
      "           -8.04687500e-01,  1.46484375e-01,  8.54492188e-02],\n",
      "          [ 2.24609375e-01,  4.29687500e-02, -4.37500000e-01,  ...,\n",
      "           -8.04687500e-01,  1.46484375e-01,  8.54492188e-02]],\n",
      "\n",
      "         [[-1.83105469e-02,  8.05664062e-02,  7.95898438e-02,  ...,\n",
      "            8.30078125e-02, -6.88476562e-02, -1.14257812e-01],\n",
      "          [-2.11181641e-02,  7.61718750e-02,  7.71484375e-02,  ...,\n",
      "            8.05664062e-02, -6.78710938e-02, -1.04492188e-01],\n",
      "          [-2.01416016e-02,  7.66601562e-02,  7.66601562e-02,  ...,\n",
      "            7.91015625e-02, -6.54296875e-02, -1.01562500e-01],\n",
      "          ...,\n",
      "          [ 6.73828125e-02,  2.07031250e-01,  9.88769531e-03,  ...,\n",
      "            1.39648438e-01, -4.78515625e-02, -1.10839844e-01],\n",
      "          [ 6.73828125e-02,  2.07031250e-01,  9.88769531e-03,  ...,\n",
      "            1.39648438e-01, -4.78515625e-02, -1.10839844e-01],\n",
      "          [ 6.73828125e-02,  2.07031250e-01,  9.88769531e-03,  ...,\n",
      "            1.39648438e-01, -4.78515625e-02, -1.10839844e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.08398438,  0.02514648,  0.02221680,  ...,  0.02062988,\n",
      "           -0.02258301,  0.01409912],\n",
      "          [ 0.08496094,  0.02526855,  0.02246094,  ...,  0.01721191,\n",
      "           -0.02465820,  0.01452637],\n",
      "          [ 0.08496094,  0.02600098,  0.02258301,  ...,  0.01635742,\n",
      "           -0.02600098,  0.01440430],\n",
      "          ...,\n",
      "          [ 0.00891113,  0.12597656, -0.02001953,  ..., -0.05444336,\n",
      "           -0.21679688,  0.07226562],\n",
      "          [ 0.00891113,  0.12597656, -0.02001953,  ..., -0.05444336,\n",
      "           -0.21679688,  0.07226562],\n",
      "          [ 0.00891113,  0.12597656, -0.02001953,  ..., -0.05444336,\n",
      "           -0.21679688,  0.07226562]],\n",
      "\n",
      "         [[ 0.00662231, -0.00188446,  0.05957031,  ..., -0.02368164,\n",
      "           -0.08593750,  0.11230469],\n",
      "          [-0.02880859,  0.02990723, -0.11523438,  ..., -0.09765625,\n",
      "           -0.06689453,  0.05859375],\n",
      "          [-0.07470703,  0.05566406, -0.24218750,  ..., -0.15625000,\n",
      "           -0.16210938,  0.01397705],\n",
      "          ...,\n",
      "          [-0.03686523,  0.01440430,  0.00457764,  ..., -0.08349609,\n",
      "           -0.05371094,  0.13476562],\n",
      "          [-0.03686523,  0.01440430,  0.00457764,  ..., -0.08349609,\n",
      "           -0.05371094,  0.13476562],\n",
      "          [-0.03686523,  0.01440430,  0.00457764,  ..., -0.08349609,\n",
      "           -0.05371094,  0.13476562]],\n",
      "\n",
      "         [[ 0.04150391,  0.02294922, -0.01831055,  ..., -0.01599121,\n",
      "           -0.04663086, -0.04174805],\n",
      "          [-0.05761719,  0.01300049, -0.03393555,  ..., -0.03686523,\n",
      "            0.04907227,  0.01525879],\n",
      "          [-0.01220703,  0.03515625, -0.00506592,  ..., -0.03784180,\n",
      "            0.05932617, -0.01348877],\n",
      "          ...,\n",
      "          [-0.11230469, -0.05566406, -0.00102234,  ..., -0.05102539,\n",
      "            0.01544189, -0.03808594],\n",
      "          [-0.11230469, -0.05566406, -0.00102234,  ..., -0.05102539,\n",
      "            0.01544189, -0.03808594],\n",
      "          [-0.11230469, -0.05566406, -0.00102234,  ..., -0.05102539,\n",
      "            0.01544189, -0.03808594]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.04638672, -0.04223633,  0.19042969,  ..., -0.22167969,\n",
      "            0.04589844, -0.20214844],\n",
      "          [-0.20507812, -0.14746094, -0.36523438,  ..., -0.11083984,\n",
      "           -0.03051758, -0.08544922],\n",
      "          [-0.43164062, -0.14746094, -0.44531250,  ..., -0.10253906,\n",
      "           -0.02197266, -0.09716797],\n",
      "          ...,\n",
      "          [ 0.00372314, -0.03833008,  0.13085938,  ..., -0.22851562,\n",
      "            0.05615234, -0.14453125],\n",
      "          [ 0.00372314, -0.03833008,  0.13085938,  ..., -0.22851562,\n",
      "            0.05615234, -0.14453125],\n",
      "          [ 0.00372314, -0.03833008,  0.13085938,  ..., -0.22851562,\n",
      "            0.05615234, -0.14453125]],\n",
      "\n",
      "         [[-0.08398438, -0.10253906, -0.06982422,  ..., -0.05249023,\n",
      "           -0.23242188,  0.04125977],\n",
      "          [-0.21875000, -0.00328064,  0.10791016,  ..., -0.01446533,\n",
      "           -0.03491211, -0.06079102],\n",
      "          [-0.21875000,  0.00891113,  0.05615234,  ...,  0.01446533,\n",
      "           -0.06298828, -0.16113281],\n",
      "          ...,\n",
      "          [ 0.04785156,  0.17089844, -0.07080078,  ...,  0.00347900,\n",
      "           -0.13867188, -0.16601562],\n",
      "          [ 0.04785156,  0.17089844, -0.07080078,  ...,  0.00347900,\n",
      "           -0.13867188, -0.16601562],\n",
      "          [ 0.04785156,  0.17089844, -0.07080078,  ...,  0.00347900,\n",
      "           -0.13867188, -0.16601562]],\n",
      "\n",
      "         [[ 0.02050781, -0.06201172,  0.06933594,  ...,  0.08300781,\n",
      "            0.06982422, -0.00622559],\n",
      "          [ 0.01977539, -0.06396484,  0.07177734,  ...,  0.08544922,\n",
      "            0.06982422, -0.00585938],\n",
      "          [ 0.01916504, -0.06445312,  0.07324219,  ...,  0.08642578,\n",
      "            0.06884766, -0.00598145],\n",
      "          ...,\n",
      "          [ 0.02905273,  0.18164062,  0.05078125,  ..., -0.03442383,\n",
      "            0.02612305,  0.03076172],\n",
      "          [ 0.02905273,  0.18164062,  0.05078125,  ..., -0.03442383,\n",
      "            0.02612305,  0.03076172],\n",
      "          [ 0.02905273,  0.18164062,  0.05078125,  ..., -0.03442383,\n",
      "            0.02612305,  0.03076172]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-8.34960938e-02, -1.11816406e-01,  2.06054688e-01,  ...,\n",
      "           -7.81250000e-02,  1.54876709e-03, -2.96630859e-02],\n",
      "          [-1.17187500e-01, -6.44531250e-02,  1.33789062e-01,  ...,\n",
      "           -1.01074219e-01,  9.27734375e-02, -5.93261719e-02],\n",
      "          [-8.49609375e-02, -4.68750000e-02,  1.24511719e-01,  ...,\n",
      "           -1.15722656e-01,  1.29882812e-01, -4.61425781e-02],\n",
      "          ...,\n",
      "          [-3.73535156e-02, -9.57031250e-02,  1.72851562e-01,  ...,\n",
      "           -9.42382812e-02,  2.80761719e-02, -4.73022461e-04],\n",
      "          [-3.73535156e-02, -9.57031250e-02,  1.72851562e-01,  ...,\n",
      "           -9.42382812e-02,  2.80761719e-02, -4.73022461e-04],\n",
      "          [-3.73535156e-02, -9.57031250e-02,  1.72851562e-01,  ...,\n",
      "           -9.42382812e-02,  2.80761719e-02, -4.73022461e-04]],\n",
      "\n",
      "         [[ 4.17968750e-01,  3.33984375e-01,  1.67968750e-01,  ...,\n",
      "           -1.05468750e-01,  3.45703125e-01,  1.83593750e-01],\n",
      "          [ 8.47656250e-01,  1.02343750e+00,  2.96875000e-01,  ...,\n",
      "           -1.17187500e-02, -9.27734375e-02,  1.02539062e-01],\n",
      "          [ 1.48437500e+00,  8.32031250e-01,  7.22656250e-01,  ...,\n",
      "           -4.93164062e-02,  3.30078125e-01,  2.77343750e-01],\n",
      "          ...,\n",
      "          [-1.09375000e-01,  1.06933594e-01,  2.40234375e-01,  ...,\n",
      "           -7.56835938e-02,  3.18359375e-01,  3.24218750e-01],\n",
      "          [-1.09375000e-01,  1.06933594e-01,  2.40234375e-01,  ...,\n",
      "           -7.56835938e-02,  3.18359375e-01,  3.24218750e-01],\n",
      "          [-1.09375000e-01,  1.06933594e-01,  2.40234375e-01,  ...,\n",
      "           -7.56835938e-02,  3.18359375e-01,  3.24218750e-01]],\n",
      "\n",
      "         [[-1.46484375e-01,  1.62353516e-02,  9.52148438e-02,  ...,\n",
      "            6.88476562e-02, -3.95507812e-02, -3.51562500e-02],\n",
      "          [-1.33789062e-01, -3.11279297e-03,  1.14257812e-01,  ...,\n",
      "            1.01074219e-01, -6.83593750e-02, -3.06396484e-02],\n",
      "          [-1.35742188e-01, -3.03649902e-03,  1.15234375e-01,  ...,\n",
      "            1.03027344e-01, -7.08007812e-02, -3.14941406e-02],\n",
      "          ...,\n",
      "          [-1.68945312e-01,  4.73632812e-02, -1.75781250e-02,  ...,\n",
      "           -1.33056641e-02,  4.46777344e-02, -1.70898438e-01],\n",
      "          [-1.68945312e-01,  4.73632812e-02, -1.75781250e-02,  ...,\n",
      "           -1.33056641e-02,  4.46777344e-02, -1.70898438e-01],\n",
      "          [-1.68945312e-01,  4.73632812e-02, -1.75781250e-02,  ...,\n",
      "           -1.33056641e-02,  4.46777344e-02, -1.70898438e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.90722656e-02, -1.07421875e-01, -4.39453125e-02,  ...,\n",
      "           -1.50146484e-02,  1.86523438e-01, -2.57812500e-01],\n",
      "          [-2.02148438e-01, -4.14062500e-01,  2.69531250e-01,  ...,\n",
      "           -1.41601562e-01,  2.59765625e-01, -2.30468750e-01],\n",
      "          [-3.51562500e-01, -2.85156250e-01,  1.16210938e-01,  ...,\n",
      "           -4.12597656e-02,  1.90429688e-01, -3.32031250e-01],\n",
      "          ...,\n",
      "          [-1.96289062e-01, -8.49609375e-02,  3.32031250e-02,  ...,\n",
      "           -1.69921875e-01,  1.14257812e-01, -2.59765625e-01],\n",
      "          [-1.96289062e-01, -8.49609375e-02,  3.32031250e-02,  ...,\n",
      "           -1.69921875e-01,  1.14257812e-01, -2.59765625e-01],\n",
      "          [-1.96289062e-01, -8.49609375e-02,  3.32031250e-02,  ...,\n",
      "           -1.69921875e-01,  1.14257812e-01, -2.59765625e-01]],\n",
      "\n",
      "         [[ 9.61914062e-02,  7.08007812e-02,  5.56640625e-02,  ...,\n",
      "           -1.04003906e-01,  4.22363281e-02, -7.03125000e-02],\n",
      "          [ 9.47265625e-02,  7.12890625e-02,  5.20019531e-02,  ...,\n",
      "           -1.03515625e-01,  4.39453125e-02, -6.88476562e-02],\n",
      "          [ 9.47265625e-02,  7.08007812e-02,  5.29785156e-02,  ...,\n",
      "           -1.03515625e-01,  4.46777344e-02, -6.93359375e-02],\n",
      "          ...,\n",
      "          [ 2.28515625e-01, -8.10546875e-02, -5.67626953e-03,  ...,\n",
      "           -1.68457031e-02, -1.34765625e-01, -2.23388672e-02],\n",
      "          [ 2.28515625e-01, -8.10546875e-02, -5.67626953e-03,  ...,\n",
      "           -1.68457031e-02, -1.34765625e-01, -2.23388672e-02],\n",
      "          [ 2.28515625e-01, -8.10546875e-02, -5.67626953e-03,  ...,\n",
      "           -1.68457031e-02, -1.34765625e-01, -2.23388672e-02]],\n",
      "\n",
      "         [[-5.39550781e-02,  2.45361328e-02, -1.95312500e-01,  ...,\n",
      "           -1.90429688e-01,  2.63671875e-02, -2.67578125e-01],\n",
      "          [-3.63281250e-01, -6.10351562e-02, -7.69531250e-01,  ...,\n",
      "           -6.83593750e-02,  1.51367188e-01, -7.77343750e-01],\n",
      "          [ 7.59887695e-03,  3.96484375e-01, -4.33593750e-01,  ...,\n",
      "            8.20312500e-02,  8.49609375e-02, -5.66406250e-01],\n",
      "          ...,\n",
      "          [-6.98242188e-02,  8.15429688e-02, -1.37695312e-01,  ...,\n",
      "           -1.46484375e-01, -8.48388672e-03, -4.08203125e-01],\n",
      "          [-6.98242188e-02,  8.15429688e-02, -1.37695312e-01,  ...,\n",
      "           -1.46484375e-01, -8.48388672e-03, -4.08203125e-01],\n",
      "          [-6.98242188e-02,  8.15429688e-02, -1.37695312e-01,  ...,\n",
      "           -1.46484375e-01, -8.48388672e-03, -4.08203125e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-1.01562500e-01, -1.40625000e-01, -1.46484375e-01,  ...,\n",
      "           -2.33398438e-01,  4.39453125e-02,  5.90820312e-02],\n",
      "          [-6.29882812e-02, -6.44531250e-02, -1.22558594e-01,  ...,\n",
      "           -1.46484375e-01,  1.04980469e-02, -2.86865234e-02],\n",
      "          [-6.15234375e-02, -8.98437500e-02, -1.26953125e-01,  ...,\n",
      "           -1.58203125e-01,  6.04248047e-03, -1.66015625e-02],\n",
      "          ...,\n",
      "          [-1.68945312e-01,  7.12890625e-02, -1.74804688e-01,  ...,\n",
      "           -3.14453125e-01,  2.34375000e-01,  3.68652344e-02],\n",
      "          [-1.68945312e-01,  7.12890625e-02, -1.74804688e-01,  ...,\n",
      "           -3.14453125e-01,  2.34375000e-01,  3.68652344e-02],\n",
      "          [-1.68945312e-01,  7.12890625e-02, -1.74804688e-01,  ...,\n",
      "           -3.14453125e-01,  2.34375000e-01,  3.68652344e-02]],\n",
      "\n",
      "         [[ 5.58471680e-03, -1.20605469e-01,  2.11181641e-02,  ...,\n",
      "           -1.16210938e-01, -1.47460938e-01, -1.39648438e-01],\n",
      "          [ 1.66015625e-02, -1.81640625e-01,  6.10351562e-02,  ...,\n",
      "           -1.05468750e-01, -5.02929688e-02, -1.21093750e-01],\n",
      "          [ 1.62353516e-02, -1.81640625e-01,  5.44433594e-02,  ...,\n",
      "           -1.11328125e-01, -5.61523438e-02, -1.28906250e-01],\n",
      "          ...,\n",
      "          [ 1.05468750e-01,  5.85937500e-02,  2.13867188e-01,  ...,\n",
      "           -1.95503235e-04, -2.87109375e-01, -1.33789062e-01],\n",
      "          [ 1.05468750e-01,  5.85937500e-02,  2.13867188e-01,  ...,\n",
      "           -1.95503235e-04, -2.87109375e-01, -1.33789062e-01],\n",
      "          [ 1.05468750e-01,  5.85937500e-02,  2.13867188e-01,  ...,\n",
      "           -1.95503235e-04, -2.87109375e-01, -1.33789062e-01]],\n",
      "\n",
      "         [[ 6.98242188e-02,  8.10546875e-02,  5.85937500e-02,  ...,\n",
      "            6.59179688e-02, -1.29882812e-01, -9.86328125e-02],\n",
      "          [ 7.76367188e-02,  4.83398438e-02,  5.22460938e-02,  ...,\n",
      "            6.88476562e-02, -1.00585938e-01, -7.95898438e-02],\n",
      "          [ 8.15429688e-02,  4.10156250e-02,  5.32226562e-02,  ...,\n",
      "            6.59179688e-02, -8.54492188e-02, -8.15429688e-02],\n",
      "          ...,\n",
      "          [ 1.71875000e-01,  1.77734375e-01,  1.16210938e-01,  ...,\n",
      "            4.22363281e-02, -4.02832031e-02, -3.28125000e-01],\n",
      "          [ 1.71875000e-01,  1.77734375e-01,  1.16210938e-01,  ...,\n",
      "            4.22363281e-02, -4.02832031e-02, -3.28125000e-01],\n",
      "          [ 1.71875000e-01,  1.77734375e-01,  1.16210938e-01,  ...,\n",
      "            4.22363281e-02, -4.02832031e-02, -3.28125000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.45507812e-01,  1.73828125e-01,  1.76757812e-01,  ...,\n",
      "            6.44531250e-02,  5.07812500e-02, -6.83593750e-02],\n",
      "          [-1.44531250e-01,  6.29882812e-02,  3.06396484e-02,  ...,\n",
      "            6.68334961e-03,  7.12890625e-02, -3.17382812e-02],\n",
      "          [-4.56542969e-02,  1.23046875e-01,  9.91210938e-02,  ...,\n",
      "            4.12597656e-02,  8.34960938e-02, -1.66015625e-02],\n",
      "          ...,\n",
      "          [ 2.00195312e-01,  1.97265625e-01,  1.41601562e-01,  ...,\n",
      "            4.88281250e-02,  4.83398438e-02, -8.93554688e-02],\n",
      "          [ 2.00195312e-01,  1.97265625e-01,  1.41601562e-01,  ...,\n",
      "            4.88281250e-02,  4.83398438e-02, -8.93554688e-02],\n",
      "          [ 2.00195312e-01,  1.97265625e-01,  1.41601562e-01,  ...,\n",
      "            4.88281250e-02,  4.83398438e-02, -8.93554688e-02]],\n",
      "\n",
      "         [[ 9.32617188e-02,  2.30468750e-01,  7.66601562e-02,  ...,\n",
      "            1.44531250e-01, -5.32226562e-02,  6.78710938e-02],\n",
      "          [ 1.00097656e-01,  1.87500000e-01, -1.62109375e-01,  ...,\n",
      "            1.38671875e-01,  3.19824219e-02,  1.17187500e-01],\n",
      "          [ 9.61914062e-02,  1.67968750e-01, -1.14746094e-01,  ...,\n",
      "            1.66015625e-01,  4.37011719e-02,  8.59375000e-02],\n",
      "          ...,\n",
      "          [ 1.65039062e-01,  1.86523438e-01,  1.73339844e-02,  ...,\n",
      "            1.37695312e-01, -7.56835938e-02,  8.74023438e-02],\n",
      "          [ 1.65039062e-01,  1.86523438e-01,  1.73339844e-02,  ...,\n",
      "            1.37695312e-01, -7.56835938e-02,  8.74023438e-02],\n",
      "          [ 1.65039062e-01,  1.86523438e-01,  1.73339844e-02,  ...,\n",
      "            1.37695312e-01, -7.56835938e-02,  8.74023438e-02]],\n",
      "\n",
      "         [[ 1.12792969e-01,  2.62451172e-03, -3.65234375e-01,  ...,\n",
      "           -1.06933594e-01, -1.45874023e-02, -4.66308594e-02],\n",
      "          [ 7.95898438e-02,  3.17382812e-02, -3.69140625e-01,  ...,\n",
      "           -1.29882812e-01, -2.23388672e-02, -7.76367188e-02],\n",
      "          [ 1.10351562e-01,  4.73022461e-03, -3.63281250e-01,  ...,\n",
      "           -1.08398438e-01, -1.50756836e-02, -4.83398438e-02],\n",
      "          ...,\n",
      "          [-4.58984375e-02,  1.04492188e-01, -4.10156250e-01,  ...,\n",
      "           -1.20605469e-01, -9.57031250e-02, -4.41894531e-02],\n",
      "          [-4.58984375e-02,  1.04492188e-01, -4.10156250e-01,  ...,\n",
      "           -1.20605469e-01, -9.57031250e-02, -4.41894531e-02],\n",
      "          [-4.58984375e-02,  1.04492188e-01, -4.10156250e-01,  ...,\n",
      "           -1.20605469e-01, -9.57031250e-02, -4.41894531e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.17187500,  0.05151367,  0.10693359,  ...,  0.15234375,\n",
      "           -0.31054688,  0.04101562],\n",
      "          [-0.20703125,  0.10205078, -0.14648438,  ...,  0.08056641,\n",
      "           -0.02832031,  0.16894531],\n",
      "          [-0.30468750,  0.12402344, -0.12597656,  ...,  0.05468750,\n",
      "           -0.25390625,  0.14746094],\n",
      "          ...,\n",
      "          [ 0.08544922,  0.08642578,  0.07617188,  ...,  0.06225586,\n",
      "            0.28710938,  0.07910156],\n",
      "          [ 0.08544922,  0.08642578,  0.07617188,  ...,  0.06225586,\n",
      "            0.28710938,  0.07910156],\n",
      "          [ 0.08544922,  0.08642578,  0.07617188,  ...,  0.06225586,\n",
      "            0.28710938,  0.07910156]],\n",
      "\n",
      "         [[-0.05981445, -0.14941406, -0.13281250,  ..., -0.10400391,\n",
      "           -0.07958984, -0.03466797],\n",
      "          [-0.97656250,  0.28515625, -0.12158203,  ...,  0.23535156,\n",
      "           -0.17480469,  0.17382812],\n",
      "          [-0.67578125,  0.09179688, -0.05932617,  ..., -0.10595703,\n",
      "           -0.32031250, -0.03588867],\n",
      "          ...,\n",
      "          [-0.14550781, -0.13671875, -0.02490234,  ..., -0.12402344,\n",
      "           -0.18164062, -0.02343750],\n",
      "          [-0.14550781, -0.13671875, -0.02490234,  ..., -0.12402344,\n",
      "           -0.18164062, -0.02343750],\n",
      "          [-0.14550781, -0.13671875, -0.02490234,  ..., -0.12402344,\n",
      "           -0.18164062, -0.02343750]],\n",
      "\n",
      "         [[ 0.03906250,  0.05419922,  0.32031250,  ..., -0.17968750,\n",
      "            0.12060547,  0.08203125],\n",
      "          [-0.21582031,  0.33984375,  0.26953125,  ...,  0.00927734,\n",
      "           -0.04907227,  0.19921875],\n",
      "          [-0.12695312,  0.24316406,  0.17968750,  ...,  0.14746094,\n",
      "           -0.17578125,  0.10937500],\n",
      "          ...,\n",
      "          [-0.04760742,  0.02355957,  0.36132812,  ..., -0.11621094,\n",
      "            0.09716797,  0.08935547],\n",
      "          [-0.04760742,  0.02355957,  0.36132812,  ..., -0.11621094,\n",
      "            0.09716797,  0.08935547],\n",
      "          [-0.04760742,  0.02355957,  0.36132812,  ..., -0.11621094,\n",
      "            0.09716797,  0.08935547]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.17382812, -0.00567627,  0.07812500,  ..., -0.06054688,\n",
      "           -0.11865234,  0.08007812],\n",
      "          [-0.14160156, -0.78906250,  0.46679688,  ..., -0.57421875,\n",
      "           -0.21289062, -0.37109375],\n",
      "          [-0.30468750, -0.49609375,  0.48437500,  ..., -0.59765625,\n",
      "           -0.10205078, -0.26171875],\n",
      "          ...,\n",
      "          [-0.02612305, -0.05053711,  0.00344849,  ...,  0.05346680,\n",
      "           -0.13964844,  0.00726318],\n",
      "          [-0.02612305, -0.05053711,  0.00344849,  ...,  0.05346680,\n",
      "           -0.13964844,  0.00726318],\n",
      "          [-0.02612305, -0.05053711,  0.00344849,  ...,  0.05346680,\n",
      "           -0.13964844,  0.00726318]],\n",
      "\n",
      "         [[-0.08789062, -0.21875000,  0.28710938,  ...,  0.02075195,\n",
      "            0.00637817, -0.18359375],\n",
      "          [-0.16992188, -0.06640625,  0.21679688,  ...,  0.03344727,\n",
      "           -0.05957031, -0.25976562],\n",
      "          [-0.18945312, -0.08593750,  0.10693359,  ...,  0.08203125,\n",
      "           -0.05981445, -0.26953125],\n",
      "          ...,\n",
      "          [-0.16503906, -0.14160156,  0.37500000,  ..., -0.07080078,\n",
      "           -0.06176758, -0.22460938],\n",
      "          [-0.16503906, -0.14160156,  0.37500000,  ..., -0.07080078,\n",
      "           -0.06176758, -0.22460938],\n",
      "          [-0.16503906, -0.14160156,  0.37500000,  ..., -0.07080078,\n",
      "           -0.06176758, -0.22460938]],\n",
      "\n",
      "         [[ 0.10400391,  0.16406250, -0.30468750,  ..., -0.38867188,\n",
      "           -0.11279297,  0.21777344],\n",
      "          [ 0.08203125,  0.23144531, -0.39062500,  ..., -0.39062500,\n",
      "           -0.15917969,  0.22363281],\n",
      "          [ 0.11621094,  0.25390625, -0.47656250,  ..., -0.33203125,\n",
      "           -0.16699219,  0.23828125],\n",
      "          ...,\n",
      "          [ 0.02624512,  0.20898438, -0.28125000,  ..., -0.37109375,\n",
      "           -0.13476562,  0.10351562],\n",
      "          [ 0.02624512,  0.20898438, -0.28125000,  ..., -0.37109375,\n",
      "           -0.13476562,  0.10351562],\n",
      "          [ 0.02624512,  0.20898438, -0.28125000,  ..., -0.37109375,\n",
      "           -0.13476562,  0.10351562]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 2.31445312e-01,  6.07910156e-02,  4.05273438e-02,  ...,\n",
      "           -4.24804688e-02, -1.91406250e-01,  1.83105469e-02],\n",
      "          [-2.12890625e-01,  2.53906250e-01,  8.88671875e-02,  ...,\n",
      "            2.27050781e-02, -2.77343750e-01, -7.66601562e-02],\n",
      "          [-3.92578125e-01,  3.06640625e-01,  9.52148438e-03,  ...,\n",
      "           -1.01562500e-01, -1.54296875e-01, -1.49414062e-01],\n",
      "          ...,\n",
      "          [ 8.39843750e-02,  4.76074219e-02,  8.78906250e-02,  ...,\n",
      "            6.44531250e-02, -1.04492188e-01, -8.44726562e-02],\n",
      "          [ 8.39843750e-02,  4.76074219e-02,  8.78906250e-02,  ...,\n",
      "            6.44531250e-02, -1.04492188e-01, -8.44726562e-02],\n",
      "          [ 8.39843750e-02,  4.76074219e-02,  8.78906250e-02,  ...,\n",
      "            6.44531250e-02, -1.04492188e-01, -8.44726562e-02]],\n",
      "\n",
      "         [[ 4.66308594e-02,  7.47070312e-02, -1.46484375e-01,  ...,\n",
      "           -1.39770508e-02, -1.05468750e-01,  8.39843750e-01],\n",
      "          [-2.39257812e-02,  9.57031250e-02, -1.32812500e-01,  ...,\n",
      "           -9.86328125e-02, -2.33398438e-01,  3.02734375e-01],\n",
      "          [-3.27148438e-02,  1.35742188e-01, -6.68334961e-03,  ...,\n",
      "           -1.56250000e-02, -2.14843750e-01,  2.09960938e-01],\n",
      "          ...,\n",
      "          [ 2.12097168e-03,  7.66601562e-02, -2.81250000e-01,  ...,\n",
      "            5.22613525e-04, -1.77734375e-01,  6.40625000e-01],\n",
      "          [ 2.12097168e-03,  7.66601562e-02, -2.81250000e-01,  ...,\n",
      "            5.22613525e-04, -1.77734375e-01,  6.40625000e-01],\n",
      "          [ 2.12097168e-03,  7.66601562e-02, -2.81250000e-01,  ...,\n",
      "            5.22613525e-04, -1.77734375e-01,  6.40625000e-01]],\n",
      "\n",
      "         [[ 8.93554688e-02, -1.87500000e-01, -1.68945312e-01,  ...,\n",
      "            2.51953125e-01, -5.37109375e-02, -2.34375000e-01],\n",
      "          [-3.10546875e-01,  2.18750000e-01,  6.48437500e-01,  ...,\n",
      "            3.73046875e-01, -4.41406250e-01,  3.00781250e-01],\n",
      "          [-1.95312500e-01,  6.44531250e-02,  6.56250000e-01,  ...,\n",
      "            2.87109375e-01, -4.10156250e-01,  3.75000000e-01],\n",
      "          ...,\n",
      "          [ 2.19726562e-02, -1.64062500e-01, -1.55273438e-01,  ...,\n",
      "            2.17773438e-01, -1.31835938e-01, -1.01562500e-01],\n",
      "          [ 2.19726562e-02, -1.64062500e-01, -1.55273438e-01,  ...,\n",
      "            2.17773438e-01, -1.31835938e-01, -1.01562500e-01],\n",
      "          [ 2.19726562e-02, -1.64062500e-01, -1.55273438e-01,  ...,\n",
      "            2.17773438e-01, -1.31835938e-01, -1.01562500e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.34375000e-02, -7.08007812e-02, -6.68334961e-03,  ...,\n",
      "           -1.30859375e-01,  9.32617188e-02,  3.41796875e-02],\n",
      "          [ 2.94921875e-01,  8.15429688e-02, -8.49609375e-02,  ...,\n",
      "           -3.18359375e-01,  2.08007812e-01,  4.25781250e-01],\n",
      "          [ 2.87109375e-01, -2.81982422e-02, -8.30078125e-02,  ...,\n",
      "           -2.33398438e-01,  2.13867188e-01,  4.29687500e-01],\n",
      "          ...,\n",
      "          [ 5.02929688e-02, -7.81250000e-02, -7.12890625e-02,  ...,\n",
      "           -2.73437500e-01,  9.22851562e-02,  2.69531250e-01],\n",
      "          [ 5.02929688e-02, -7.81250000e-02, -7.12890625e-02,  ...,\n",
      "           -2.73437500e-01,  9.22851562e-02,  2.69531250e-01],\n",
      "          [ 5.02929688e-02, -7.81250000e-02, -7.12890625e-02,  ...,\n",
      "           -2.73437500e-01,  9.22851562e-02,  2.69531250e-01]],\n",
      "\n",
      "         [[ 1.46484375e-01, -3.39355469e-02, -2.20703125e-01,  ...,\n",
      "            8.25195312e-02,  2.73437500e-01, -2.02148438e-01],\n",
      "          [-7.22656250e-02,  1.06933594e-01,  4.80468750e-01,  ...,\n",
      "           -5.54687500e-01,  4.39453125e-01, -3.43750000e-01],\n",
      "          [-2.27539062e-01,  1.58203125e-01,  4.88281250e-01,  ...,\n",
      "           -3.84765625e-01,  4.72656250e-01, -4.47265625e-01],\n",
      "          ...,\n",
      "          [ 1.48437500e-01,  4.66308594e-02, -1.42578125e-01,  ...,\n",
      "            2.57812500e-01,  1.28906250e-01, -2.53906250e-01],\n",
      "          [ 1.48437500e-01,  4.66308594e-02, -1.42578125e-01,  ...,\n",
      "            2.57812500e-01,  1.28906250e-01, -2.53906250e-01],\n",
      "          [ 1.48437500e-01,  4.66308594e-02, -1.42578125e-01,  ...,\n",
      "            2.57812500e-01,  1.28906250e-01, -2.53906250e-01]],\n",
      "\n",
      "         [[-1.12792969e-01,  7.61718750e-02, -2.13867188e-01,  ...,\n",
      "           -2.25585938e-01, -7.08007812e-02,  9.86328125e-02],\n",
      "          [-1.19628906e-01,  3.30078125e-01,  1.02539062e-01,  ...,\n",
      "            1.36718750e-02,  1.74804688e-01, -5.02929688e-02],\n",
      "          [-2.29492188e-01,  1.49414062e-01,  1.46484375e-01,  ...,\n",
      "           -9.13085938e-02,  7.08007812e-02, -1.77383423e-04],\n",
      "          ...,\n",
      "          [-3.08593750e-01,  2.45361328e-02,  1.85012817e-04,  ...,\n",
      "           -3.80859375e-02,  2.55126953e-02, -2.57568359e-02],\n",
      "          [-3.08593750e-01,  2.45361328e-02,  1.85012817e-04,  ...,\n",
      "           -3.80859375e-02,  2.55126953e-02, -2.57568359e-02],\n",
      "          [-3.08593750e-01,  2.45361328e-02,  1.85012817e-04,  ...,\n",
      "           -3.80859375e-02,  2.55126953e-02, -2.57568359e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 5.34667969e-02, -1.43554688e-01, -8.64257812e-02,  ...,\n",
      "            1.19628906e-01, -2.36328125e-01,  1.24023438e-01],\n",
      "          [ 3.82812500e-01,  8.25195312e-02, -1.08886719e-01,  ...,\n",
      "            2.91015625e-01, -5.68847656e-02, -3.12500000e-01],\n",
      "          [ 4.21875000e-01,  4.19921875e-02, -1.16699219e-01,  ...,\n",
      "            5.27343750e-01,  3.85742188e-02, -7.22656250e-01],\n",
      "          ...,\n",
      "          [ 1.72851562e-01,  5.54199219e-02, -1.48437500e-01,  ...,\n",
      "           -2.35595703e-02, -1.30859375e-01, -1.15722656e-01],\n",
      "          [ 1.72851562e-01,  5.54199219e-02, -1.48437500e-01,  ...,\n",
      "           -2.35595703e-02, -1.30859375e-01, -1.15722656e-01],\n",
      "          [ 1.72851562e-01,  5.54199219e-02, -1.48437500e-01,  ...,\n",
      "           -2.35595703e-02, -1.30859375e-01, -1.15722656e-01]],\n",
      "\n",
      "         [[ 1.15722656e-01,  1.55273438e-01, -7.47070312e-02,  ...,\n",
      "           -1.07421875e-01,  1.91406250e-01, -1.77734375e-01],\n",
      "          [ 2.79296875e-01, -7.18750000e-01, -1.03515625e-01,  ...,\n",
      "            4.76562500e-01, -2.41210938e-01, -3.08593750e-01],\n",
      "          [ 2.81250000e-01, -8.12500000e-01, -8.34960938e-02,  ...,\n",
      "            5.11718750e-01, -2.94921875e-01, -3.76953125e-01],\n",
      "          ...,\n",
      "          [-7.47070312e-02, -1.46484375e-01, -1.02050781e-01,  ...,\n",
      "            6.44531250e-01,  1.40625000e-01, -9.32617188e-02],\n",
      "          [-7.47070312e-02, -1.46484375e-01, -1.02050781e-01,  ...,\n",
      "            6.44531250e-01,  1.40625000e-01, -9.32617188e-02],\n",
      "          [-7.47070312e-02, -1.46484375e-01, -1.02050781e-01,  ...,\n",
      "            6.44531250e-01,  1.40625000e-01, -9.32617188e-02]],\n",
      "\n",
      "         [[ 1.11328125e-01, -5.71289062e-02,  2.89062500e-01,  ...,\n",
      "           -1.76239014e-03, -1.71875000e-01, -2.06054688e-01],\n",
      "          [ 6.05468750e-01,  2.94921875e-01,  4.29687500e-01,  ...,\n",
      "           -1.30859375e-01, -7.30468750e-01, -1.03027344e-01],\n",
      "          [ 4.39453125e-01,  1.33789062e-01,  1.34765625e-01,  ...,\n",
      "           -1.07421875e-01, -4.58984375e-01,  8.17871094e-03],\n",
      "          ...,\n",
      "          [-4.94140625e-01,  2.51953125e-01,  3.69140625e-01,  ...,\n",
      "           -1.79687500e-01, -6.09375000e-01, -4.76562500e-01],\n",
      "          [-4.94140625e-01,  2.51953125e-01,  3.69140625e-01,  ...,\n",
      "           -1.79687500e-01, -6.09375000e-01, -4.76562500e-01],\n",
      "          [-4.94140625e-01,  2.51953125e-01,  3.69140625e-01,  ...,\n",
      "           -1.79687500e-01, -6.09375000e-01, -4.76562500e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.32226562e-02,  3.69140625e-01,  1.42578125e-01,  ...,\n",
      "            1.58203125e-01, -2.53906250e-01, -9.96093750e-02],\n",
      "          [-6.49414062e-02,  1.12792969e-01,  4.45312500e-01,  ...,\n",
      "            6.13281250e-01,  3.01513672e-02, -5.39062500e-01],\n",
      "          [ 1.71875000e-01,  2.27539062e-01,  1.63085938e-01,  ...,\n",
      "            3.02734375e-01, -1.96289062e-01, -9.61914062e-02],\n",
      "          ...,\n",
      "          [-1.19628906e-01,  3.04687500e-01,  1.40625000e-01,  ...,\n",
      "            1.21093750e-01, -2.87109375e-01, -1.16210938e-01],\n",
      "          [-1.19628906e-01,  3.04687500e-01,  1.40625000e-01,  ...,\n",
      "            1.21093750e-01, -2.87109375e-01, -1.16210938e-01],\n",
      "          [-1.19628906e-01,  3.04687500e-01,  1.40625000e-01,  ...,\n",
      "            1.21093750e-01, -2.87109375e-01, -1.16210938e-01]],\n",
      "\n",
      "         [[-2.23632812e-01,  2.01171875e-01,  1.94335938e-01,  ...,\n",
      "           -2.91015625e-01, -3.92578125e-01, -2.77343750e-01],\n",
      "          [-3.57421875e-01, -4.37011719e-02, -3.24218750e-01,  ...,\n",
      "           -2.36328125e-01,  1.52343750e-01,  1.33789062e-01],\n",
      "          [-3.75000000e-01,  8.42285156e-03, -4.23828125e-01,  ...,\n",
      "           -1.73828125e-01,  2.01171875e-01,  1.43554688e-01],\n",
      "          ...,\n",
      "          [-3.86718750e-01,  2.13867188e-01,  3.16406250e-01,  ...,\n",
      "           -1.22070312e-01, -3.57421875e-01, -2.41210938e-01],\n",
      "          [-3.86718750e-01,  2.13867188e-01,  3.16406250e-01,  ...,\n",
      "           -1.22070312e-01, -3.57421875e-01, -2.41210938e-01],\n",
      "          [-3.86718750e-01,  2.13867188e-01,  3.16406250e-01,  ...,\n",
      "           -1.22070312e-01, -3.57421875e-01, -2.41210938e-01]],\n",
      "\n",
      "         [[-1.36718750e-02, -2.30712891e-02, -9.57031250e-02,  ...,\n",
      "            3.68118286e-04, -4.88281250e-01, -4.32128906e-02],\n",
      "          [-1.78710938e-01, -1.06250000e+00, -5.42968750e-01,  ...,\n",
      "            5.82031250e-01,  1.53125000e+00, -2.34375000e-01],\n",
      "          [-1.28906250e-01, -7.61718750e-02, -8.75000000e-01,  ...,\n",
      "            6.64062500e-01,  1.38281250e+00, -1.35742188e-01],\n",
      "          ...,\n",
      "          [ 1.66992188e-01,  1.02050781e-01,  1.69921875e-01,  ...,\n",
      "           -7.14111328e-03,  4.02832031e-02,  2.53906250e-01],\n",
      "          [ 1.66992188e-01,  1.02050781e-01,  1.69921875e-01,  ...,\n",
      "           -7.14111328e-03,  4.02832031e-02,  2.53906250e-01],\n",
      "          [ 1.66992188e-01,  1.02050781e-01,  1.69921875e-01,  ...,\n",
      "           -7.14111328e-03,  4.02832031e-02,  2.53906250e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.01660156, -0.48242188,  0.05957031,  ...,  0.16992188,\n",
      "            0.18066406,  0.09375000],\n",
      "          [-0.06884766,  0.27539062,  0.55468750,  ...,  0.39257812,\n",
      "            0.10742188,  0.07470703],\n",
      "          [-0.02624512,  0.41015625,  0.56640625,  ...,  0.44531250,\n",
      "            0.25195312, -0.18359375],\n",
      "          ...,\n",
      "          [-0.15039062, -0.20019531,  0.12695312,  ...,  0.21484375,\n",
      "            0.21191406,  0.01550293],\n",
      "          [-0.15039062, -0.20019531,  0.12695312,  ...,  0.21484375,\n",
      "            0.21191406,  0.01550293],\n",
      "          [-0.15039062, -0.20019531,  0.12695312,  ...,  0.21484375,\n",
      "            0.21191406,  0.01550293]],\n",
      "\n",
      "         [[-0.34375000,  0.19335938, -0.22460938,  ..., -0.19531250,\n",
      "            0.01373291, -0.37304688],\n",
      "          [-0.91406250,  0.25585938, -1.03125000,  ..., -1.01562500,\n",
      "           -0.34960938, -0.17675781],\n",
      "          [-0.26757812,  0.14746094, -0.52343750,  ..., -0.71093750,\n",
      "           -0.34179688, -0.05615234],\n",
      "          ...,\n",
      "          [-0.18261719,  0.32421875, -0.18945312,  ..., -0.24707031,\n",
      "           -0.04516602, -0.26367188],\n",
      "          [-0.18261719,  0.32421875, -0.18945312,  ..., -0.24707031,\n",
      "           -0.04516602, -0.26367188],\n",
      "          [-0.18261719,  0.32421875, -0.18945312,  ..., -0.24707031,\n",
      "           -0.04516602, -0.26367188]],\n",
      "\n",
      "         [[-0.29687500,  0.17089844,  0.57031250,  ..., -0.30664062,\n",
      "            0.32812500, -0.01306152],\n",
      "          [-0.27539062,  0.23046875,  1.10937500,  ..., -0.12255859,\n",
      "           -0.31054688, -0.16699219],\n",
      "          [-0.41406250,  0.40039062,  0.92187500,  ..., -0.03344727,\n",
      "           -0.13867188, -0.34570312],\n",
      "          ...,\n",
      "          [-0.19335938,  0.20507812,  0.71484375,  ..., -0.30078125,\n",
      "            0.32812500,  0.04980469],\n",
      "          [-0.19335938,  0.20507812,  0.71484375,  ..., -0.30078125,\n",
      "            0.32812500,  0.04980469],\n",
      "          [-0.19335938,  0.20507812,  0.71484375,  ..., -0.30078125,\n",
      "            0.32812500,  0.04980469]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.21777344, -0.02648926,  0.10058594,  ...,  0.21582031,\n",
      "            0.31640625, -0.17675781],\n",
      "          [-0.44140625, -0.26367188,  0.16894531,  ...,  0.42773438,\n",
      "           -0.05175781,  0.10839844],\n",
      "          [-0.44335938, -0.20410156,  0.17968750,  ...,  0.33203125,\n",
      "           -0.08251953, -0.02490234],\n",
      "          ...,\n",
      "          [-0.15527344, -0.19824219,  0.15039062,  ...,  0.13574219,\n",
      "            0.27343750, -0.25390625],\n",
      "          [-0.15527344, -0.19824219,  0.15039062,  ...,  0.13574219,\n",
      "            0.27343750, -0.25390625],\n",
      "          [-0.15527344, -0.19824219,  0.15039062,  ...,  0.13574219,\n",
      "            0.27343750, -0.25390625]],\n",
      "\n",
      "         [[ 0.08300781,  0.10351562, -0.08789062,  ...,  0.31640625,\n",
      "           -0.05517578,  0.13574219],\n",
      "          [ 0.17089844, -0.36132812, -0.04125977,  ...,  0.16796875,\n",
      "            0.57421875,  0.01965332],\n",
      "          [ 0.38671875, -0.50000000,  0.03540039,  ...,  0.06933594,\n",
      "            0.63281250, -0.26757812],\n",
      "          ...,\n",
      "          [ 0.13867188,  0.29101562, -0.23730469,  ...,  0.14648438,\n",
      "           -0.18261719,  0.31054688],\n",
      "          [ 0.13867188,  0.29101562, -0.23730469,  ...,  0.14648438,\n",
      "           -0.18261719,  0.31054688],\n",
      "          [ 0.13867188,  0.29101562, -0.23730469,  ...,  0.14648438,\n",
      "           -0.18261719,  0.31054688]],\n",
      "\n",
      "         [[ 0.10791016,  0.34570312, -0.02770996,  ...,  0.11425781,\n",
      "            0.07226562,  0.00885010],\n",
      "          [ 0.06787109,  0.86328125, -0.11425781,  ...,  0.08105469,\n",
      "            0.18261719,  0.09619141],\n",
      "          [ 0.19335938,  0.02209473, -0.17382812,  ...,  0.08642578,\n",
      "            0.19628906,  0.27539062],\n",
      "          ...,\n",
      "          [ 0.07373047,  0.29492188, -0.04589844,  ...,  0.19433594,\n",
      "            0.11865234,  0.06250000],\n",
      "          [ 0.07373047,  0.29492188, -0.04589844,  ...,  0.19433594,\n",
      "            0.11865234,  0.06250000],\n",
      "          [ 0.07373047,  0.29492188, -0.04589844,  ...,  0.19433594,\n",
      "            0.11865234,  0.06250000]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.24707031,  0.07861328, -0.28515625,  ..., -0.06542969,\n",
      "           -0.03515625, -0.19335938],\n",
      "          [ 0.42382812,  0.24804688, -0.32031250,  ...,  0.33007812,\n",
      "            0.24609375, -0.24902344],\n",
      "          [ 0.28320312, -0.35937500, -0.16796875,  ...,  0.02246094,\n",
      "           -0.03076172,  0.28320312],\n",
      "          ...,\n",
      "          [ 0.15527344, -0.10302734, -0.11132812,  ..., -0.12695312,\n",
      "           -0.06152344,  0.12304688],\n",
      "          [ 0.15527344, -0.10302734, -0.11132812,  ..., -0.12695312,\n",
      "           -0.06152344,  0.12304688],\n",
      "          [ 0.15527344, -0.10302734, -0.11132812,  ..., -0.12695312,\n",
      "           -0.06152344,  0.12304688]],\n",
      "\n",
      "         [[-0.15722656,  0.08203125,  0.20117188,  ...,  0.07373047,\n",
      "           -0.06640625,  0.15234375],\n",
      "          [-0.29882812, -1.01562500,  0.73046875,  ..., -0.19433594,\n",
      "           -0.37695312,  0.35156250],\n",
      "          [-0.35546875, -1.02343750,  0.68359375,  ..., -0.15039062,\n",
      "           -0.37109375,  0.36523438],\n",
      "          ...,\n",
      "          [-0.36523438, -0.19824219,  0.45117188,  ...,  0.14257812,\n",
      "           -0.04980469,  0.27539062],\n",
      "          [-0.36523438, -0.19824219,  0.45117188,  ...,  0.14257812,\n",
      "           -0.04980469,  0.27539062],\n",
      "          [-0.36523438, -0.19824219,  0.45117188,  ...,  0.14257812,\n",
      "           -0.04980469,  0.27539062]],\n",
      "\n",
      "         [[ 0.34570312, -0.08447266,  0.13964844,  ..., -0.14843750,\n",
      "            0.28320312, -0.12792969],\n",
      "          [-0.36132812,  0.37890625, -0.18457031,  ...,  0.23828125,\n",
      "           -0.33203125, -0.52343750],\n",
      "          [-0.28710938,  0.56250000, -0.10839844,  ...,  0.23046875,\n",
      "            0.11914062, -0.46679688],\n",
      "          ...,\n",
      "          [-0.13476562,  0.08740234,  0.02770996,  ..., -0.03759766,\n",
      "            0.07226562, -0.05273438],\n",
      "          [-0.13476562,  0.08740234,  0.02770996,  ..., -0.03759766,\n",
      "            0.07226562, -0.05273438],\n",
      "          [-0.13476562,  0.08740234,  0.02770996,  ..., -0.03759766,\n",
      "            0.07226562, -0.05273438]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.25585938,  0.19824219,  0.05541992,  ..., -0.23242188,\n",
      "           -0.16308594, -0.43750000],\n",
      "          [ 0.19726562,  0.39843750, -0.22363281,  ...,  0.38085938,\n",
      "            0.24511719, -0.36132812],\n",
      "          [ 0.66796875, -0.04467773,  0.39453125,  ..., -0.13183594,\n",
      "           -0.03125000, -0.18359375],\n",
      "          ...,\n",
      "          [-0.06835938,  0.46289062,  0.07714844,  ..., -0.04663086,\n",
      "            0.08203125, -0.41406250],\n",
      "          [-0.06835938,  0.46289062,  0.07714844,  ..., -0.04663086,\n",
      "            0.08203125, -0.41406250],\n",
      "          [-0.06835938,  0.46289062,  0.07714844,  ..., -0.04663086,\n",
      "            0.08203125, -0.41406250]],\n",
      "\n",
      "         [[ 0.31640625,  0.34179688,  0.25000000,  ..., -0.13574219,\n",
      "           -0.03662109,  0.01733398],\n",
      "          [ 0.25976562, -0.11425781,  0.42382812,  ..., -0.41406250,\n",
      "           -0.49218750,  0.66406250],\n",
      "          [ 0.30273438, -0.21972656,  0.38867188,  ..., -0.41992188,\n",
      "           -0.54687500,  0.94140625],\n",
      "          ...,\n",
      "          [ 0.43945312,  0.25390625,  0.25390625,  ..., -0.20996094,\n",
      "           -0.10693359,  0.05810547],\n",
      "          [ 0.43945312,  0.25390625,  0.25390625,  ..., -0.20996094,\n",
      "           -0.10693359,  0.05810547],\n",
      "          [ 0.43945312,  0.25390625,  0.25390625,  ..., -0.20996094,\n",
      "           -0.10693359,  0.05810547]],\n",
      "\n",
      "         [[ 0.02563477, -0.01562500,  0.14453125,  ..., -0.01647949,\n",
      "            0.31054688,  0.00442505],\n",
      "          [-0.05029297,  0.57031250, -1.07031250,  ...,  0.03784180,\n",
      "            0.57031250, -0.94140625],\n",
      "          [ 0.32421875,  0.21289062, -0.06494141,  ..., -0.49414062,\n",
      "            1.01562500, -0.82421875],\n",
      "          ...,\n",
      "          [ 0.06640625, -0.26562500,  0.17871094,  ..., -0.04882812,\n",
      "            0.29687500, -0.01507568],\n",
      "          [ 0.06640625, -0.26562500,  0.17871094,  ..., -0.04882812,\n",
      "            0.29687500, -0.01507568],\n",
      "          [ 0.06640625, -0.26562500,  0.17871094,  ..., -0.04882812,\n",
      "            0.29687500, -0.01507568]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.06347656,  0.02783203, -0.06591797,  ...,  0.11376953,\n",
      "            0.23828125, -0.30468750],\n",
      "          [-0.30468750,  0.14453125,  0.14648438,  ..., -0.14843750,\n",
      "           -0.33789062, -0.17382812],\n",
      "          [-0.35546875, -0.01684570,  0.32812500,  ..., -0.20410156,\n",
      "           -0.25195312, -0.15917969],\n",
      "          ...,\n",
      "          [-0.09765625,  0.17773438,  0.12695312,  ...,  0.01226807,\n",
      "            0.22851562, -0.25390625],\n",
      "          [-0.09765625,  0.17773438,  0.12695312,  ...,  0.01226807,\n",
      "            0.22851562, -0.25390625],\n",
      "          [-0.09765625,  0.17773438,  0.12695312,  ...,  0.01226807,\n",
      "            0.22851562, -0.25390625]],\n",
      "\n",
      "         [[-0.25390625, -0.01464844, -0.20312500,  ..., -0.02917480,\n",
      "            0.42773438, -0.08935547],\n",
      "          [-0.21972656, -0.41992188, -0.26367188,  ..., -0.34179688,\n",
      "            0.12353516,  0.06640625],\n",
      "          [-0.36718750, -0.23730469, -0.10693359,  ..., -0.39062500,\n",
      "            0.07568359,  0.19042969],\n",
      "          ...,\n",
      "          [-0.29492188, -0.02783203, -0.26562500,  ..., -0.11767578,\n",
      "            0.62890625, -0.13964844],\n",
      "          [-0.29492188, -0.02783203, -0.26562500,  ..., -0.11767578,\n",
      "            0.62890625, -0.13964844],\n",
      "          [-0.29492188, -0.02783203, -0.26562500,  ..., -0.11767578,\n",
      "            0.62890625, -0.13964844]],\n",
      "\n",
      "         [[-0.13867188, -0.12695312, -0.09765625,  ...,  0.19335938,\n",
      "            0.53906250, -0.07128906],\n",
      "          [-0.17480469,  0.28710938, -0.02294922,  ...,  0.37304688,\n",
      "            0.83593750, -0.19140625],\n",
      "          [-0.01525879,  0.06933594, -0.19042969,  ...,  0.27734375,\n",
      "            0.66406250, -0.24121094],\n",
      "          ...,\n",
      "          [-0.13085938,  0.01214600,  0.25585938,  ...,  0.10156250,\n",
      "            0.39257812, -0.11523438],\n",
      "          [-0.13085938,  0.01214600,  0.25585938,  ...,  0.10156250,\n",
      "            0.39257812, -0.11523438],\n",
      "          [-0.13085938,  0.01214600,  0.25585938,  ...,  0.10156250,\n",
      "            0.39257812, -0.11523438]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.07177734, -0.32031250,  0.03637695,  ..., -0.39648438,\n",
      "            0.09765625,  0.12988281],\n",
      "          [-0.05004883, -0.16992188,  0.34375000,  ..., -0.15429688,\n",
      "            0.16503906, -0.59765625],\n",
      "          [-0.00878906, -0.01177979,  0.43554688,  ..., -0.19531250,\n",
      "            0.33984375, -0.55078125],\n",
      "          ...,\n",
      "          [-0.26562500,  0.11523438,  0.00175476,  ..., -0.13574219,\n",
      "            0.27148438, -0.06396484],\n",
      "          [-0.26562500,  0.11523438,  0.00175476,  ..., -0.13574219,\n",
      "            0.27148438, -0.06396484],\n",
      "          [-0.26562500,  0.11523438,  0.00175476,  ..., -0.13574219,\n",
      "            0.27148438, -0.06396484]],\n",
      "\n",
      "         [[-0.15820312,  0.49218750,  0.32421875,  ..., -0.19238281,\n",
      "            0.26953125, -0.28125000],\n",
      "          [-0.33398438,  0.58593750, -0.11132812,  ...,  0.12500000,\n",
      "            0.43359375, -0.55078125],\n",
      "          [-0.26757812,  0.53515625, -0.10351562,  ...,  0.13183594,\n",
      "            0.39257812, -0.53125000],\n",
      "          ...,\n",
      "          [-0.00460815,  0.23632812,  0.01855469,  ...,  0.17578125,\n",
      "           -0.18750000, -0.18847656],\n",
      "          [-0.00460815,  0.23632812,  0.01855469,  ...,  0.17578125,\n",
      "           -0.18750000, -0.18847656],\n",
      "          [-0.00460815,  0.23632812,  0.01855469,  ...,  0.17578125,\n",
      "           -0.18750000, -0.18847656]],\n",
      "\n",
      "         [[-0.02038574, -0.23046875,  0.03808594,  ...,  0.25781250,\n",
      "           -0.26171875,  0.12353516],\n",
      "          [ 0.05444336, -0.29296875, -0.35546875,  ..., -0.06347656,\n",
      "            0.05297852,  0.01232910],\n",
      "          [-0.04931641, -0.27539062, -0.36132812,  ..., -0.12792969,\n",
      "            0.03369141, -0.07128906],\n",
      "          ...,\n",
      "          [ 0.21777344, -0.15136719, -0.09814453,  ...,  0.14062500,\n",
      "           -0.28320312,  0.05541992],\n",
      "          [ 0.21777344, -0.15136719, -0.09814453,  ...,  0.14062500,\n",
      "           -0.28320312,  0.05541992],\n",
      "          [ 0.21777344, -0.15136719, -0.09814453,  ...,  0.14062500,\n",
      "           -0.28320312,  0.05541992]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-2.79296875e-01,  4.27734375e-01,  2.34375000e-01,  ...,\n",
      "            7.71484375e-02, -2.53906250e-01,  5.85937500e-01],\n",
      "          [ 1.54296875e-01,  5.07812500e-01,  4.16015625e-01,  ...,\n",
      "            6.56127930e-03,  2.87109375e-01, -1.67187500e+00],\n",
      "          [ 2.08007812e-01,  5.27343750e-01,  3.76953125e-01,  ...,\n",
      "           -2.29492188e-02,  4.21875000e-01, -1.55468750e+00],\n",
      "          ...,\n",
      "          [-8.00781250e-02, -3.80859375e-01,  1.15356445e-02,  ...,\n",
      "            4.63867188e-02,  5.27343750e-01,  3.96484375e-01],\n",
      "          [-8.00781250e-02, -3.80859375e-01,  1.15356445e-02,  ...,\n",
      "            4.63867188e-02,  5.27343750e-01,  3.96484375e-01],\n",
      "          [-8.00781250e-02, -3.80859375e-01,  1.15356445e-02,  ...,\n",
      "            4.63867188e-02,  5.27343750e-01,  3.96484375e-01]],\n",
      "\n",
      "         [[ 2.51953125e-01,  7.66601562e-02,  1.16699219e-01,  ...,\n",
      "            3.61328125e-02, -1.97753906e-02,  1.18164062e-01],\n",
      "          [ 1.34765625e-01, -3.57421875e-01,  6.17675781e-02,  ...,\n",
      "           -4.72656250e-01, -4.90234375e-01,  1.20605469e-01],\n",
      "          [ 2.28515625e-01, -1.28906250e-01, -1.09375000e-01,  ...,\n",
      "           -5.31250000e-01, -3.90625000e-01,  3.93066406e-02],\n",
      "          ...,\n",
      "          [-7.18750000e-01,  1.61132812e-01, -2.08984375e-01,  ...,\n",
      "           -1.90429688e-01,  5.27343750e-01, -4.90234375e-01],\n",
      "          [-7.18750000e-01,  1.61132812e-01, -2.08984375e-01,  ...,\n",
      "           -1.90429688e-01,  5.27343750e-01, -4.90234375e-01],\n",
      "          [-7.18750000e-01,  1.61132812e-01, -2.08984375e-01,  ...,\n",
      "           -1.90429688e-01,  5.27343750e-01, -4.90234375e-01]],\n",
      "\n",
      "         [[ 2.37304688e-01,  9.13085938e-02,  5.17578125e-02,  ...,\n",
      "           -9.66796875e-02,  1.97265625e-01, -2.96875000e-01],\n",
      "          [ 1.73828125e-01, -8.98437500e-01,  1.19140625e-01,  ...,\n",
      "           -3.55468750e-01,  5.82031250e-01, -4.51171875e-01],\n",
      "          [ 1.32812500e-01, -6.52343750e-01,  7.66601562e-02,  ...,\n",
      "           -4.84375000e-01,  6.83593750e-01, -5.19531250e-01],\n",
      "          ...,\n",
      "          [ 1.24023438e-01, -2.22656250e-01, -1.80664062e-02,  ...,\n",
      "           -1.34765625e-01, -1.90734863e-03, -8.00781250e-02],\n",
      "          [ 1.24023438e-01, -2.22656250e-01, -1.80664062e-02,  ...,\n",
      "           -1.34765625e-01, -1.90734863e-03, -8.00781250e-02],\n",
      "          [ 1.24023438e-01, -2.22656250e-01, -1.80664062e-02,  ...,\n",
      "           -1.34765625e-01, -1.90734863e-03, -8.00781250e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.30859375e-01,  1.73828125e-01,  1.87500000e-01,  ...,\n",
      "           -2.12402344e-02, -2.83203125e-01,  8.49609375e-02],\n",
      "          [ 1.15722656e-01,  1.34765625e-01,  7.42187500e-01,  ...,\n",
      "            3.39843750e-01, -2.30468750e-01,  1.08337402e-03],\n",
      "          [ 1.03027344e-01,  2.09960938e-01,  6.25000000e-01,  ...,\n",
      "            4.88281250e-01, -1.86523438e-01,  8.05664062e-02],\n",
      "          ...,\n",
      "          [ 4.83398438e-02,  2.08984375e-01,  2.36328125e-01,  ...,\n",
      "           -1.37939453e-02, -3.43750000e-01, -8.39843750e-02],\n",
      "          [ 4.83398438e-02,  2.08984375e-01,  2.36328125e-01,  ...,\n",
      "           -1.37939453e-02, -3.43750000e-01, -8.39843750e-02],\n",
      "          [ 4.83398438e-02,  2.08984375e-01,  2.36328125e-01,  ...,\n",
      "           -1.37939453e-02, -3.43750000e-01, -8.39843750e-02]],\n",
      "\n",
      "         [[-2.34375000e-01,  4.47265625e-01, -1.87500000e-01,  ...,\n",
      "           -5.73730469e-02,  2.11914062e-01, -2.12890625e-01],\n",
      "          [-1.51367188e-01, -3.78417969e-02,  2.03125000e-01,  ...,\n",
      "           -1.26562500e+00,  7.53906250e-01,  1.74804688e-01],\n",
      "          [-4.15039062e-02, -3.03955078e-02,  3.05175781e-02,  ...,\n",
      "           -5.50781250e-01, -1.90429688e-02,  1.30859375e-01],\n",
      "          ...,\n",
      "          [-1.86523438e-01, -7.66601562e-02,  9.86328125e-02,  ...,\n",
      "           -2.15820312e-01,  6.88476562e-02, -2.89306641e-02],\n",
      "          [-1.86523438e-01, -7.66601562e-02,  9.86328125e-02,  ...,\n",
      "           -2.15820312e-01,  6.88476562e-02, -2.89306641e-02],\n",
      "          [-1.86523438e-01, -7.66601562e-02,  9.86328125e-02,  ...,\n",
      "           -2.15820312e-01,  6.88476562e-02, -2.89306641e-02]],\n",
      "\n",
      "         [[ 5.81054688e-02, -9.27734375e-02, -1.32812500e-01,  ...,\n",
      "           -1.51367188e-01,  1.89453125e-01,  1.05468750e-01],\n",
      "          [-1.49414062e-01, -2.85156250e-01,  1.09375000e+00,  ...,\n",
      "           -6.64062500e-01,  4.53125000e-01, -3.71093750e-02],\n",
      "          [-9.27734375e-02, -2.46093750e-01,  1.14062500e+00,  ...,\n",
      "           -6.79687500e-01,  5.15625000e-01,  7.17773438e-02],\n",
      "          ...,\n",
      "          [ 1.42578125e-01, -2.33154297e-02, -4.37500000e-01,  ...,\n",
      "            8.46862793e-04,  3.02734375e-01, -1.00097656e-01],\n",
      "          [ 1.42578125e-01, -2.33154297e-02, -4.37500000e-01,  ...,\n",
      "            8.46862793e-04,  3.02734375e-01, -1.00097656e-01],\n",
      "          [ 1.42578125e-01, -2.33154297e-02, -4.37500000e-01,  ...,\n",
      "            8.46862793e-04,  3.02734375e-01, -1.00097656e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.45117188, -0.36523438, -0.19531250,  ...,  0.39062500,\n",
      "            0.86718750, -0.47656250],\n",
      "          [-0.10888672, -0.19238281, -0.75390625,  ...,  0.57031250,\n",
      "            1.25000000, -0.42578125],\n",
      "          [-0.13476562, -0.24804688, -0.76562500,  ...,  0.56640625,\n",
      "            1.14062500, -0.19140625],\n",
      "          ...,\n",
      "          [ 0.05029297, -0.04882812, -0.29882812,  ...,  0.16503906,\n",
      "            0.38671875, -0.27148438],\n",
      "          [ 0.05029297, -0.04882812, -0.29882812,  ...,  0.16503906,\n",
      "            0.38671875, -0.27148438],\n",
      "          [ 0.05029297, -0.04882812, -0.29882812,  ...,  0.16503906,\n",
      "            0.38671875, -0.27148438]],\n",
      "\n",
      "         [[ 0.39843750, -0.01336670,  0.16992188,  ..., -0.35937500,\n",
      "           -0.17089844, -0.21972656],\n",
      "          [ 0.13574219,  0.18457031,  0.26953125,  ..., -0.51562500,\n",
      "           -0.29492188, -0.43945312],\n",
      "          [ 0.35742188,  0.01818848,  0.50000000,  ..., -0.47851562,\n",
      "           -0.12011719, -0.28320312],\n",
      "          ...,\n",
      "          [ 0.34960938, -0.04565430,  0.24023438,  ..., -0.00506592,\n",
      "           -0.37109375, -0.33984375],\n",
      "          [ 0.34960938, -0.04565430,  0.24023438,  ..., -0.00506592,\n",
      "           -0.37109375, -0.33984375],\n",
      "          [ 0.34960938, -0.04565430,  0.24023438,  ..., -0.00506592,\n",
      "           -0.37109375, -0.33984375]],\n",
      "\n",
      "         [[ 0.17773438,  0.20214844,  0.22070312,  ...,  0.19433594,\n",
      "           -0.29492188,  0.32812500],\n",
      "          [ 0.19140625,  0.20898438,  0.22558594,  ...,  0.18652344,\n",
      "           -0.28515625,  0.34960938],\n",
      "          [ 0.22265625,  0.21484375,  0.26562500,  ...,  0.15917969,\n",
      "           -0.27539062,  0.32812500],\n",
      "          ...,\n",
      "          [ 0.18652344,  0.20312500,  0.21679688,  ...,  0.19042969,\n",
      "           -0.30273438,  0.32226562],\n",
      "          [ 0.18652344,  0.20312500,  0.21679688,  ...,  0.19042969,\n",
      "           -0.30273438,  0.32226562],\n",
      "          [ 0.18652344,  0.20312500,  0.21679688,  ...,  0.19042969,\n",
      "           -0.30273438,  0.32226562]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.04296875, -0.03247070, -0.32421875,  ..., -0.11132812,\n",
      "            0.04467773, -0.04272461],\n",
      "          [-0.11181641,  0.05493164, -0.24121094,  ...,  0.15722656,\n",
      "           -0.31445312,  0.21875000],\n",
      "          [-0.13867188,  0.06787109, -0.08105469,  ...,  0.00885010,\n",
      "           -0.23437500,  0.46093750],\n",
      "          ...,\n",
      "          [-0.00497437, -0.13769531, -0.27148438,  ..., -0.08740234,\n",
      "            0.08251953,  0.11474609],\n",
      "          [-0.00497437, -0.13769531, -0.27148438,  ..., -0.08740234,\n",
      "            0.08251953,  0.11474609],\n",
      "          [-0.00497437, -0.13769531, -0.27148438,  ..., -0.08740234,\n",
      "            0.08251953,  0.11474609]],\n",
      "\n",
      "         [[ 0.17968750,  0.04394531, -0.14648438,  ...,  0.02661133,\n",
      "           -0.17187500,  0.20996094],\n",
      "          [ 0.27148438,  0.20898438, -0.27148438,  ...,  0.06347656,\n",
      "            0.43164062,  1.17187500],\n",
      "          [ 0.33593750,  0.21582031, -0.26562500,  ..., -0.24804688,\n",
      "            0.46875000,  0.91406250],\n",
      "          ...,\n",
      "          [ 0.31054688,  0.02160645, -0.24414062,  ...,  0.07421875,\n",
      "           -0.33789062,  0.12060547],\n",
      "          [ 0.31054688,  0.02160645, -0.24414062,  ...,  0.07421875,\n",
      "           -0.33789062,  0.12060547],\n",
      "          [ 0.31054688,  0.02160645, -0.24414062,  ...,  0.07421875,\n",
      "           -0.33789062,  0.12060547]],\n",
      "\n",
      "         [[ 0.22460938,  0.00231934,  0.04052734,  ...,  0.16015625,\n",
      "            0.05957031, -0.41210938],\n",
      "          [ 0.13964844, -0.02697754,  0.09716797,  ...,  0.09130859,\n",
      "           -0.06225586, -0.01940918],\n",
      "          [ 0.14746094, -0.13281250,  0.07470703,  ...,  0.12109375,\n",
      "           -0.07275391,  0.04248047],\n",
      "          ...,\n",
      "          [ 0.29101562, -0.14355469, -0.05444336,  ...,  0.03784180,\n",
      "            0.06225586, -0.13867188],\n",
      "          [ 0.29101562, -0.14355469, -0.05444336,  ...,  0.03784180,\n",
      "            0.06225586, -0.13867188],\n",
      "          [ 0.29101562, -0.14355469, -0.05444336,  ...,  0.03784180,\n",
      "            0.06225586, -0.13867188]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-0.45507812, -0.24609375,  0.08837891,  ...,  0.10009766,\n",
      "            0.08056641, -0.25195312],\n",
      "          [-0.55859375, -0.31835938, -0.28125000,  ..., -0.00367737,\n",
      "           -0.01989746, -0.11425781],\n",
      "          [-0.28320312, -0.47070312,  0.03930664,  ..., -0.18359375,\n",
      "           -0.13378906, -0.87500000],\n",
      "          ...,\n",
      "          [ 0.01226807, -0.21484375,  0.08544922,  ...,  0.00286865,\n",
      "            0.10888672, -0.27539062],\n",
      "          [ 0.01226807, -0.21484375,  0.08544922,  ...,  0.00286865,\n",
      "            0.10888672, -0.27539062],\n",
      "          [ 0.01226807, -0.21484375,  0.08544922,  ...,  0.00286865,\n",
      "            0.10888672, -0.27539062]],\n",
      "\n",
      "         [[-0.31835938,  0.30273438,  0.19531250,  ..., -0.32031250,\n",
      "            0.06835938, -0.09130859],\n",
      "          [ 0.22656250,  0.14550781, -0.52734375,  ..., -0.08544922,\n",
      "           -0.02941895,  0.16699219],\n",
      "          [ 0.27539062,  0.13964844, -0.72265625,  ..., -0.06176758,\n",
      "           -0.05151367,  0.19238281],\n",
      "          ...,\n",
      "          [-0.07910156,  0.37500000,  0.09863281,  ..., -0.12792969,\n",
      "            0.05102539,  0.19335938],\n",
      "          [-0.07910156,  0.37500000,  0.09863281,  ..., -0.12792969,\n",
      "            0.05102539,  0.19335938],\n",
      "          [-0.07910156,  0.37500000,  0.09863281,  ..., -0.12792969,\n",
      "            0.05102539,  0.19335938]],\n",
      "\n",
      "         [[ 0.32226562, -0.19726562, -0.25976562,  ..., -0.12109375,\n",
      "            0.12792969, -0.00411987],\n",
      "          [ 0.01525879, -0.53515625,  0.15722656,  ..., -0.25195312,\n",
      "            0.09667969, -0.21972656],\n",
      "          [ 0.06127930, -0.64843750,  0.02319336,  ..., -0.59765625,\n",
      "            0.07373047,  0.05786133],\n",
      "          ...,\n",
      "          [ 0.02661133, -0.17382812, -0.20312500,  ..., -0.27539062,\n",
      "            0.05590820,  0.05200195],\n",
      "          [ 0.02661133, -0.17382812, -0.20312500,  ..., -0.27539062,\n",
      "            0.05590820,  0.05200195],\n",
      "          [ 0.02661133, -0.17382812, -0.20312500,  ..., -0.27539062,\n",
      "            0.05590820,  0.05200195]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.01855469, -0.04394531,  0.05419922,  ..., -0.11132812,\n",
      "            0.10351562, -0.00878906],\n",
      "          [-0.14062500, -0.85546875, -0.59375000,  ..., -0.52343750,\n",
      "           -0.12500000, -0.09716797],\n",
      "          [-0.39453125, -0.95703125, -0.45117188,  ..., -0.36523438,\n",
      "           -0.13281250,  0.25000000],\n",
      "          ...,\n",
      "          [-0.05419922,  0.14941406,  0.02050781,  ..., -0.09912109,\n",
      "            0.07226562,  0.07666016],\n",
      "          [-0.05419922,  0.14941406,  0.02050781,  ..., -0.09912109,\n",
      "            0.07226562,  0.07666016],\n",
      "          [-0.05419922,  0.14941406,  0.02050781,  ..., -0.09912109,\n",
      "            0.07226562,  0.07666016]],\n",
      "\n",
      "         [[-0.13671875,  0.00436401,  0.44726562,  ...,  0.09619141,\n",
      "            0.30859375,  0.24609375],\n",
      "          [-0.49609375, -0.76562500,  0.07275391,  ...,  0.48828125,\n",
      "            0.33789062,  0.07031250],\n",
      "          [-0.64062500, -0.13281250,  0.08740234,  ...,  0.85156250,\n",
      "           -0.33789062, -0.04272461],\n",
      "          ...,\n",
      "          [ 0.22265625,  0.09814453,  0.38085938,  ...,  0.15039062,\n",
      "            0.31445312, -0.19140625],\n",
      "          [ 0.22265625,  0.09814453,  0.38085938,  ...,  0.15039062,\n",
      "            0.31445312, -0.19140625],\n",
      "          [ 0.22265625,  0.09814453,  0.38085938,  ...,  0.15039062,\n",
      "            0.31445312, -0.19140625]],\n",
      "\n",
      "         [[-0.20410156,  0.09423828,  0.20703125,  ...,  0.08105469,\n",
      "            0.11914062, -0.01843262],\n",
      "          [ 0.30664062, -0.42578125,  0.08056641,  ...,  0.28515625,\n",
      "            0.27148438,  0.21582031],\n",
      "          [ 0.30664062, -0.57421875,  0.12158203,  ...,  0.24511719,\n",
      "            0.21679688,  0.52734375],\n",
      "          ...,\n",
      "          [-0.16015625,  0.00518799,  0.10644531,  ...,  0.00433350,\n",
      "            0.36132812, -0.31250000],\n",
      "          [-0.16015625,  0.00518799,  0.10644531,  ...,  0.00433350,\n",
      "            0.36132812, -0.31250000],\n",
      "          [-0.16015625,  0.00518799,  0.10644531,  ...,  0.00433350,\n",
      "            0.36132812, -0.31250000]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 3.41796875e-02,  4.19921875e-01,  4.10156250e-02,  ...,\n",
      "           -1.84326172e-02, -2.01416016e-02,  3.05175781e-02],\n",
      "          [-2.96875000e-01,  3.49609375e-01,  1.94335938e-01,  ...,\n",
      "           -1.71875000e-01,  3.93066406e-02,  1.29882812e-01],\n",
      "          [-3.02734375e-01,  3.08593750e-01,  3.75976562e-02,  ...,\n",
      "           -2.88085938e-02, -3.02734375e-02,  1.04492188e-01],\n",
      "          ...,\n",
      "          [-5.35156250e-01, -3.51562500e-02,  8.78906250e-02,  ...,\n",
      "           -2.52685547e-02, -1.57226562e-01,  2.94921875e-01],\n",
      "          [-5.35156250e-01, -3.51562500e-02,  8.78906250e-02,  ...,\n",
      "           -2.52685547e-02, -1.57226562e-01,  2.94921875e-01],\n",
      "          [-5.35156250e-01, -3.51562500e-02,  8.78906250e-02,  ...,\n",
      "           -2.52685547e-02, -1.57226562e-01,  2.94921875e-01]],\n",
      "\n",
      "         [[-9.02343750e-01,  6.32812500e-01, -2.91748047e-02,  ...,\n",
      "           -5.15625000e-01, -2.51953125e-01, -1.71875000e-01],\n",
      "          [-7.85156250e-01, -4.72656250e-01, -1.10937500e+00,  ...,\n",
      "            6.56250000e-01,  3.75000000e-01, -1.78222656e-02],\n",
      "          [ 2.23632812e-01, -5.05371094e-02,  1.53808594e-02,  ...,\n",
      "            2.87109375e-01, -3.20312500e-01,  4.47265625e-01],\n",
      "          ...,\n",
      "          [ 2.17773438e-01,  2.75390625e-01,  3.45703125e-01,  ...,\n",
      "            2.53906250e-01, -1.93359375e-01,  6.59179688e-02],\n",
      "          [ 2.17773438e-01,  2.75390625e-01,  3.45703125e-01,  ...,\n",
      "            2.53906250e-01, -1.93359375e-01,  6.59179688e-02],\n",
      "          [ 2.17773438e-01,  2.75390625e-01,  3.45703125e-01,  ...,\n",
      "            2.53906250e-01, -1.93359375e-01,  6.59179688e-02]],\n",
      "\n",
      "         [[ 1.97265625e-01,  2.53906250e-01,  1.29882812e-01,  ...,\n",
      "           -2.63671875e-01, -3.26171875e-01, -1.56250000e-01],\n",
      "          [ 7.57812500e-01,  5.93750000e-01,  3.00781250e-01,  ...,\n",
      "           -1.50390625e-01, -1.14062500e+00, -4.23828125e-01],\n",
      "          [ 8.51562500e-01,  5.15625000e-01, -6.10351562e-02,  ...,\n",
      "           -3.00781250e-01, -1.17187500e+00, -7.10937500e-01],\n",
      "          ...,\n",
      "          [ 1.39648438e-01,  9.71679688e-02,  1.61132812e-01,  ...,\n",
      "           -2.28515625e-01, -2.45117188e-01, -4.83398438e-02],\n",
      "          [ 1.39648438e-01,  9.71679688e-02,  1.61132812e-01,  ...,\n",
      "           -2.28515625e-01, -2.45117188e-01, -4.83398438e-02],\n",
      "          [ 1.39648438e-01,  9.71679688e-02,  1.61132812e-01,  ...,\n",
      "           -2.28515625e-01, -2.45117188e-01, -4.83398438e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.53125000e-01,  4.48608398e-03, -1.35742188e-01,  ...,\n",
      "           -2.67578125e-01, -2.96875000e-01,  8.63281250e-01],\n",
      "          [ 1.30859375e-01, -1.25000000e-01, -1.01562500e+00,  ...,\n",
      "           -2.22656250e-01,  1.00781250e+00, -5.97656250e-01],\n",
      "          [ 4.45312500e-01, -5.50781250e-01, -6.67968750e-01,  ...,\n",
      "           -2.79296875e-01,  7.46093750e-01,  8.39843750e-02],\n",
      "          ...,\n",
      "          [-6.05468750e-01, -1.96289062e-01, -1.44653320e-02,  ...,\n",
      "           -1.14257812e-01, -9.22851562e-02,  2.49023438e-01],\n",
      "          [-6.05468750e-01, -1.96289062e-01, -1.44653320e-02,  ...,\n",
      "           -1.14257812e-01, -9.22851562e-02,  2.49023438e-01],\n",
      "          [-6.05468750e-01, -1.96289062e-01, -1.44653320e-02,  ...,\n",
      "           -1.14257812e-01, -9.22851562e-02,  2.49023438e-01]],\n",
      "\n",
      "         [[ 5.02929688e-02, -1.34765625e-01,  6.17675781e-02,  ...,\n",
      "           -1.18408203e-02, -1.84570312e-01, -1.43554688e-01],\n",
      "          [-8.39843750e-02, -9.21630859e-03, -1.37695312e-01,  ...,\n",
      "            2.18750000e-01, -1.57226562e-01,  3.78906250e-01],\n",
      "          [ 1.25976562e-01, -2.42187500e-01, -2.91824341e-04,  ...,\n",
      "            4.66796875e-01, -4.98046875e-01,  8.98437500e-01],\n",
      "          ...,\n",
      "          [-5.41992188e-02, -5.49316406e-02,  6.44531250e-02,  ...,\n",
      "           -6.98242188e-02, -2.67578125e-01, -1.80664062e-01],\n",
      "          [-5.41992188e-02, -5.49316406e-02,  6.44531250e-02,  ...,\n",
      "           -6.98242188e-02, -2.67578125e-01, -1.80664062e-01],\n",
      "          [-5.41992188e-02, -5.49316406e-02,  6.44531250e-02,  ...,\n",
      "           -6.98242188e-02, -2.67578125e-01, -1.80664062e-01]],\n",
      "\n",
      "         [[-4.62890625e-01,  1.03027344e-01,  5.54687500e-01,  ...,\n",
      "            2.24609375e-01, -2.61718750e-01, -1.75781250e-01],\n",
      "          [ 1.84570312e-01,  7.03125000e-01, -2.02148438e-01,  ...,\n",
      "            2.96875000e-01,  1.00781250e+00,  1.10937500e+00],\n",
      "          [ 4.47265625e-01,  4.39453125e-01,  7.66601562e-02,  ...,\n",
      "            3.06640625e-01,  1.96875000e+00,  1.57812500e+00],\n",
      "          ...,\n",
      "          [ 1.85546875e-01, -9.96093750e-02, -3.67187500e-01,  ...,\n",
      "           -3.86718750e-01,  8.00781250e-01,  8.54492188e-02],\n",
      "          [ 1.85546875e-01, -9.96093750e-02, -3.67187500e-01,  ...,\n",
      "           -3.86718750e-01,  8.00781250e-01,  8.54492188e-02],\n",
      "          [ 1.85546875e-01, -9.96093750e-02, -3.67187500e-01,  ...,\n",
      "           -3.86718750e-01,  8.00781250e-01,  8.54492188e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 3.82812500e-01,  3.41796875e-01, -2.83203125e-01,  ...,\n",
      "           -1.82617188e-01,  3.04687500e-01,  5.88378906e-02],\n",
      "          [ 2.65625000e-01, -4.00390625e-01,  8.55468750e-01,  ...,\n",
      "           -8.16406250e-01,  1.89062500e+00, -7.42187500e-02],\n",
      "          [ 1.75781250e-01,  5.54687500e-01, -4.98046875e-02,  ...,\n",
      "           -7.51953125e-02,  2.28125000e+00,  5.54687500e-01],\n",
      "          ...,\n",
      "          [-2.27539062e-01,  1.04003906e-01,  1.18652344e-01,  ...,\n",
      "           -1.01074219e-01,  1.91406250e-01,  6.78710938e-02],\n",
      "          [-2.27539062e-01,  1.04003906e-01,  1.18652344e-01,  ...,\n",
      "           -1.01074219e-01,  1.91406250e-01,  6.78710938e-02],\n",
      "          [-2.27539062e-01,  1.04003906e-01,  1.18652344e-01,  ...,\n",
      "           -1.01074219e-01,  1.91406250e-01,  6.78710938e-02]],\n",
      "\n",
      "         [[ 2.96875000e-01,  8.94531250e-01,  1.63085938e-01,  ...,\n",
      "            2.14843750e-01,  1.11328125e-01, -4.78515625e-01],\n",
      "          [-1.59179688e-01,  5.54687500e-01,  1.78710938e-01,  ...,\n",
      "            2.69531250e-01, -3.88671875e-01,  4.49218750e-01],\n",
      "          [-1.07031250e+00, -3.18359375e-01, -7.12890625e-02,  ...,\n",
      "            2.35351562e-01, -2.55859375e-01, -1.68945312e-01],\n",
      "          ...,\n",
      "          [ 2.88391113e-03,  4.21875000e-01, -1.11694336e-02,  ...,\n",
      "            5.27343750e-02,  8.88671875e-02, -2.27539062e-01],\n",
      "          [ 2.88391113e-03,  4.21875000e-01, -1.11694336e-02,  ...,\n",
      "            5.27343750e-02,  8.88671875e-02, -2.27539062e-01],\n",
      "          [ 2.88391113e-03,  4.21875000e-01, -1.11694336e-02,  ...,\n",
      "            5.27343750e-02,  8.88671875e-02, -2.27539062e-01]],\n",
      "\n",
      "         [[ 2.29492188e-01, -4.85839844e-02,  2.15820312e-01,  ...,\n",
      "            3.00781250e-01,  5.39062500e-01, -1.10351562e-01],\n",
      "          [ 1.60217285e-04, -2.07031250e-01, -3.06640625e-01,  ...,\n",
      "            1.74804688e-01,  8.54492188e-02,  3.76892090e-03],\n",
      "          [-8.83789062e-02, -1.18652344e-01, -3.00781250e-01,  ...,\n",
      "            2.32421875e-01,  1.53320312e-01,  2.01416016e-02],\n",
      "          ...,\n",
      "          [-2.57812500e-01, -1.12304688e-01,  1.86523438e-01,  ...,\n",
      "            2.28515625e-01,  3.57421875e-01, -1.95312500e-01],\n",
      "          [-2.57812500e-01, -1.12304688e-01,  1.86523438e-01,  ...,\n",
      "            2.28515625e-01,  3.57421875e-01, -1.95312500e-01],\n",
      "          [-2.57812500e-01, -1.12304688e-01,  1.86523438e-01,  ...,\n",
      "            2.28515625e-01,  3.57421875e-01, -1.95312500e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.49414062e-01,  8.90625000e-01, -1.66992188e-01,  ...,\n",
      "           -1.20117188e-01,  3.84765625e-01, -4.14062500e-01],\n",
      "          [ 3.50952148e-04,  4.29687500e-01,  1.73828125e-01,  ...,\n",
      "           -2.41210938e-01,  1.06201172e-02,  3.22265625e-01],\n",
      "          [ 4.66308594e-02,  3.12500000e-01,  3.71093750e-01,  ...,\n",
      "            2.50000000e-01,  1.63574219e-02,  4.23828125e-01],\n",
      "          ...,\n",
      "          [ 1.31835938e-01,  1.25976562e-01,  3.85742188e-02,  ...,\n",
      "            7.91015625e-02, -1.20117188e-01,  8.69140625e-02],\n",
      "          [ 1.31835938e-01,  1.25976562e-01,  3.85742188e-02,  ...,\n",
      "            7.91015625e-02, -1.20117188e-01,  8.69140625e-02],\n",
      "          [ 1.31835938e-01,  1.25976562e-01,  3.85742188e-02,  ...,\n",
      "            7.91015625e-02, -1.20117188e-01,  8.69140625e-02]],\n",
      "\n",
      "         [[-1.79687500e-01, -1.95312500e-01,  5.35156250e-01,  ...,\n",
      "           -1.82812500e+00, -2.13867188e-01, -1.03906250e+00],\n",
      "          [ 2.69531250e-01, -3.14453125e-01, -3.02734375e-02,  ...,\n",
      "            2.32421875e-01,  4.78515625e-02, -8.90625000e-01],\n",
      "          [ 3.26171875e-01,  2.79541016e-02,  1.39648438e-01,  ...,\n",
      "            4.27734375e-01, -4.24804688e-02, -6.71875000e-01],\n",
      "          ...,\n",
      "          [-1.90429688e-01, -6.20117188e-02,  3.04687500e-01,  ...,\n",
      "            1.48437500e+00,  2.57812500e-01,  6.25000000e-02],\n",
      "          [-1.90429688e-01, -6.20117188e-02,  3.04687500e-01,  ...,\n",
      "            1.48437500e+00,  2.57812500e-01,  6.25000000e-02],\n",
      "          [-1.90429688e-01, -6.20117188e-02,  3.04687500e-01,  ...,\n",
      "            1.48437500e+00,  2.57812500e-01,  6.25000000e-02]],\n",
      "\n",
      "         [[-2.51953125e-01,  1.88476562e-01,  1.34765625e-01,  ...,\n",
      "           -2.85644531e-02, -2.08007812e-01,  2.44140625e-01],\n",
      "          [-1.60156250e-01,  2.61718750e-01,  1.89453125e-01,  ...,\n",
      "           -4.98046875e-02, -2.03857422e-02,  1.91406250e-01],\n",
      "          [-3.20312500e-01,  4.43359375e-01, -7.59887695e-03,  ...,\n",
      "           -6.44531250e-02,  6.44531250e-02,  3.26171875e-01],\n",
      "          ...,\n",
      "          [-2.75390625e-01,  1.56250000e-01,  2.81250000e-01,  ...,\n",
      "           -3.24707031e-02, -2.37304688e-01,  1.93359375e-01],\n",
      "          [-2.75390625e-01,  1.56250000e-01,  2.81250000e-01,  ...,\n",
      "           -3.24707031e-02, -2.37304688e-01,  1.93359375e-01],\n",
      "          [-2.75390625e-01,  1.56250000e-01,  2.81250000e-01,  ...,\n",
      "           -3.24707031e-02, -2.37304688e-01,  1.93359375e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-6.93359375e-02, -7.42187500e-02, -1.85546875e-01,  ...,\n",
      "           -1.84570312e-01,  4.49218750e-01, -4.14062500e-01],\n",
      "          [ 5.00000000e-01, -6.75781250e-01, -2.38281250e-01,  ...,\n",
      "           -7.17773438e-02, -5.35156250e-01,  2.42919922e-02],\n",
      "          [ 5.19531250e-01, -1.15625000e+00, -5.42968750e-01,  ...,\n",
      "            1.45507812e-01, -5.74218750e-01, -4.57763672e-03],\n",
      "          ...,\n",
      "          [-1.25976562e-01, -1.05957031e-01,  1.14746094e-01,  ...,\n",
      "           -3.73046875e-01,  8.44726562e-02, -2.81250000e-01],\n",
      "          [-1.25976562e-01, -1.05957031e-01,  1.14746094e-01,  ...,\n",
      "           -3.73046875e-01,  8.44726562e-02, -2.81250000e-01],\n",
      "          [-1.25976562e-01, -1.05957031e-01,  1.14746094e-01,  ...,\n",
      "           -3.73046875e-01,  8.44726562e-02, -2.81250000e-01]],\n",
      "\n",
      "         [[ 4.24804688e-02, -2.91442871e-03, -6.88476562e-02,  ...,\n",
      "            2.08740234e-02,  2.85156250e-01,  7.86132812e-02],\n",
      "          [-2.44140625e-04,  1.42578125e-01,  1.18652344e-01,  ...,\n",
      "            2.83203125e-01,  4.71191406e-02,  2.29492188e-01],\n",
      "          [ 8.08593750e-01,  5.19531250e-01,  1.16699219e-01,  ...,\n",
      "            2.47070312e-01,  3.88183594e-02,  1.28906250e-01],\n",
      "          ...,\n",
      "          [ 1.93359375e-01, -2.09960938e-02, -1.37695312e-01,  ...,\n",
      "            7.12890625e-02,  4.27734375e-01,  1.20117188e-01],\n",
      "          [ 1.93359375e-01, -2.09960938e-02, -1.37695312e-01,  ...,\n",
      "            7.12890625e-02,  4.27734375e-01,  1.20117188e-01],\n",
      "          [ 1.93359375e-01, -2.09960938e-02, -1.37695312e-01,  ...,\n",
      "            7.12890625e-02,  4.27734375e-01,  1.20117188e-01]],\n",
      "\n",
      "         [[-1.12304688e-01, -1.82617188e-01,  1.67968750e-01,  ...,\n",
      "            5.44433594e-02, -2.44140625e-01,  3.98437500e-01],\n",
      "          [-2.21679688e-01, -2.04101562e-01, -2.53906250e-01,  ...,\n",
      "            4.86328125e-01, -4.37500000e-01, -6.78710938e-02],\n",
      "          [-8.16406250e-01, -9.02343750e-01, -3.98437500e-01,  ...,\n",
      "            5.82031250e-01, -7.57812500e-01,  8.78906250e-01],\n",
      "          ...,\n",
      "          [-1.30004883e-02, -1.22070312e-01,  5.83496094e-02,  ...,\n",
      "            6.03027344e-02, -4.76837158e-04,  3.16406250e-01],\n",
      "          [-1.30004883e-02, -1.22070312e-01,  5.83496094e-02,  ...,\n",
      "            6.03027344e-02, -4.76837158e-04,  3.16406250e-01],\n",
      "          [-1.30004883e-02, -1.22070312e-01,  5.83496094e-02,  ...,\n",
      "            6.03027344e-02, -4.76837158e-04,  3.16406250e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.08203125e-02, -5.62500000e-01, -2.96875000e-01,  ...,\n",
      "            5.82031250e-01,  9.17968750e-02,  3.66210938e-02],\n",
      "          [ 8.24218750e-01, -1.20312500e+00,  8.71093750e-01,  ...,\n",
      "           -1.32812500e-01,  1.12500000e+00,  2.79687500e+00],\n",
      "          [ 3.53515625e-01, -6.44531250e-01,  1.77734375e-01,  ...,\n",
      "           -1.04370117e-02,  4.23828125e-01,  1.28125000e+00],\n",
      "          ...,\n",
      "          [-3.45703125e-01, -1.74804688e-01, -6.52343750e-01,  ...,\n",
      "            3.16406250e-01, -6.59179688e-02, -2.75390625e-01],\n",
      "          [-3.45703125e-01, -1.74804688e-01, -6.52343750e-01,  ...,\n",
      "            3.16406250e-01, -6.59179688e-02, -2.75390625e-01],\n",
      "          [-3.45703125e-01, -1.74804688e-01, -6.52343750e-01,  ...,\n",
      "            3.16406250e-01, -6.59179688e-02, -2.75390625e-01]],\n",
      "\n",
      "         [[ 1.74560547e-02, -3.14941406e-02, -1.51367188e-02,  ...,\n",
      "            1.10351562e-01,  8.59375000e-02,  2.00195312e-01],\n",
      "          [ 4.57031250e-01,  2.61718750e-01,  8.98437500e-01,  ...,\n",
      "           -2.42187500e-01, -1.00585938e-01, -3.37890625e-01],\n",
      "          [ 2.51953125e-01,  3.51562500e-01,  7.22656250e-01,  ...,\n",
      "           -2.02148438e-01,  7.27539062e-02, -1.88476562e-01],\n",
      "          ...,\n",
      "          [ 1.04492188e-01,  2.46093750e-01,  1.12304688e-01,  ...,\n",
      "           -8.15429688e-02,  1.09375000e-01, -9.13085938e-02],\n",
      "          [ 1.04492188e-01,  2.46093750e-01,  1.12304688e-01,  ...,\n",
      "           -8.15429688e-02,  1.09375000e-01, -9.13085938e-02],\n",
      "          [ 1.04492188e-01,  2.46093750e-01,  1.12304688e-01,  ...,\n",
      "           -8.15429688e-02,  1.09375000e-01, -9.13085938e-02]],\n",
      "\n",
      "         [[ 5.02929688e-02,  4.71191406e-02,  1.97265625e-01,  ...,\n",
      "            1.69921875e-01,  1.76757812e-01,  2.30468750e-01],\n",
      "          [-2.41210938e-01,  1.20605469e-01, -7.76367188e-02,  ...,\n",
      "           -4.61425781e-02, -1.13281250e-01, -5.31250000e-01],\n",
      "          [-4.68750000e-02,  4.56542969e-02, -9.76562500e-02,  ...,\n",
      "           -2.75878906e-02, -1.08886719e-01, -1.25976562e-01],\n",
      "          ...,\n",
      "          [-1.15722656e-01,  6.17675781e-02,  1.28906250e-01,  ...,\n",
      "            1.15722656e-01,  7.76367188e-02,  1.97265625e-01],\n",
      "          [-1.15722656e-01,  6.17675781e-02,  1.28906250e-01,  ...,\n",
      "            1.15722656e-01,  7.76367188e-02,  1.97265625e-01],\n",
      "          [-1.15722656e-01,  6.17675781e-02,  1.28906250e-01,  ...,\n",
      "            1.15722656e-01,  7.76367188e-02,  1.97265625e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-0.06933594, -0.44531250, -0.19921875,  ..., -0.08886719,\n",
      "           -0.22460938, -0.50390625],\n",
      "          [-0.08300781,  0.15722656, -0.37890625,  ...,  0.48437500,\n",
      "            0.26757812, -0.25976562],\n",
      "          [-0.09912109, -0.08691406, -0.42187500,  ...,  0.23242188,\n",
      "            0.64843750,  0.05786133],\n",
      "          ...,\n",
      "          [-0.06250000, -0.08837891, -0.25390625,  ...,  0.23925781,\n",
      "           -0.12402344, -0.35156250],\n",
      "          [-0.06250000, -0.08837891, -0.25390625,  ...,  0.23925781,\n",
      "           -0.12402344, -0.35156250],\n",
      "          [-0.06250000, -0.08837891, -0.25390625,  ...,  0.23925781,\n",
      "           -0.12402344, -0.35156250]],\n",
      "\n",
      "         [[-0.15722656,  0.28515625, -0.16210938,  ..., -0.01611328,\n",
      "            0.03515625,  0.13378906],\n",
      "          [ 0.45703125,  0.47656250,  0.27343750,  ..., -0.23632812,\n",
      "            0.23828125,  0.08544922],\n",
      "          [ 0.82812500,  0.45312500,  1.21875000,  ..., -1.07812500,\n",
      "            0.46093750, -0.49609375],\n",
      "          ...,\n",
      "          [-0.03735352,  0.05053711, -0.24218750,  ..., -0.40234375,\n",
      "           -0.18945312,  0.20996094],\n",
      "          [-0.03735352,  0.05053711, -0.24218750,  ..., -0.40234375,\n",
      "           -0.18945312,  0.20996094],\n",
      "          [-0.03735352,  0.05053711, -0.24218750,  ..., -0.40234375,\n",
      "           -0.18945312,  0.20996094]],\n",
      "\n",
      "         [[ 0.74218750, -0.12597656,  0.31835938,  ..., -0.12304688,\n",
      "            0.41601562,  0.06982422],\n",
      "          [ 0.02563477, -0.74218750, -0.15625000,  ...,  0.41601562,\n",
      "           -0.28320312, -0.11376953],\n",
      "          [-0.05029297, -0.82812500, -0.45507812,  ...,  0.36132812,\n",
      "            0.13964844, -0.23632812],\n",
      "          ...,\n",
      "          [ 0.31640625, -0.31250000, -0.09667969,  ...,  0.05004883,\n",
      "            0.24121094,  0.39453125],\n",
      "          [ 0.31640625, -0.31250000, -0.09667969,  ...,  0.05004883,\n",
      "            0.24121094,  0.39453125],\n",
      "          [ 0.31640625, -0.31250000, -0.09667969,  ...,  0.05004883,\n",
      "            0.24121094,  0.39453125]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.00494385,  0.02429199, -0.02819824,  ...,  0.03247070,\n",
      "            0.01770020, -0.19335938],\n",
      "          [-0.18554688,  0.02880859, -0.20898438,  ...,  0.14257812,\n",
      "           -0.15332031, -0.18750000],\n",
      "          [-0.07177734,  0.05615234, -0.13867188,  ...,  0.12255859,\n",
      "           -0.06176758, -0.20312500],\n",
      "          ...,\n",
      "          [-0.09130859,  0.08154297, -0.33007812,  ..., -0.02001953,\n",
      "           -0.05444336, -0.20898438],\n",
      "          [-0.09130859,  0.08154297, -0.33007812,  ..., -0.02001953,\n",
      "           -0.05444336, -0.20898438],\n",
      "          [-0.09130859,  0.08154297, -0.33007812,  ..., -0.02001953,\n",
      "           -0.05444336, -0.20898438]],\n",
      "\n",
      "         [[-0.38085938, -0.30468750, -0.05517578,  ...,  0.33593750,\n",
      "            0.05004883, -0.19628906],\n",
      "          [ 0.03735352,  0.09912109, -0.39257812,  ..., -0.15625000,\n",
      "           -0.30468750, -0.33007812],\n",
      "          [ 0.00131989, -0.07568359, -0.33593750,  ..., -0.10595703,\n",
      "           -0.10791016, -0.09863281],\n",
      "          ...,\n",
      "          [-0.02490234, -0.21093750, -0.31250000,  ..., -0.04785156,\n",
      "           -0.07519531,  0.16699219],\n",
      "          [-0.02490234, -0.21093750, -0.31250000,  ..., -0.04785156,\n",
      "           -0.07519531,  0.16699219],\n",
      "          [-0.02490234, -0.21093750, -0.31250000,  ..., -0.04785156,\n",
      "           -0.07519531,  0.16699219]],\n",
      "\n",
      "         [[-0.50000000, -0.03833008, -0.42382812,  ...,  0.64843750,\n",
      "            0.88671875,  0.18457031],\n",
      "          [-0.04077148, -0.08203125, -0.15039062,  ..., -0.05224609,\n",
      "           -0.11621094,  0.07617188],\n",
      "          [-0.22265625, -0.13378906, -0.03710938,  ...,  0.25000000,\n",
      "            0.10644531, -0.01177979],\n",
      "          ...,\n",
      "          [-0.05175781,  0.21972656,  0.02856445,  ...,  0.10595703,\n",
      "            0.25976562,  0.02087402],\n",
      "          [-0.05175781,  0.21972656,  0.02856445,  ...,  0.10595703,\n",
      "            0.25976562,  0.02087402],\n",
      "          [-0.05175781,  0.21972656,  0.02856445,  ...,  0.10595703,\n",
      "            0.25976562,  0.02087402]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-0.22949219,  0.11035156,  0.02197266,  ..., -0.41796875,\n",
      "           -0.15136719, -0.31445312],\n",
      "          [-0.17675781,  0.27343750,  0.07031250,  ..., -0.46093750,\n",
      "            0.71875000, -2.51562500],\n",
      "          [-0.06347656,  0.33593750,  0.13964844,  ..., -0.26562500,\n",
      "            0.66406250, -2.29687500],\n",
      "          ...,\n",
      "          [-0.70703125, -0.27734375, -0.32421875,  ...,  0.29687500,\n",
      "           -0.30468750,  0.06054688],\n",
      "          [-0.70703125, -0.27734375, -0.32421875,  ...,  0.29687500,\n",
      "           -0.30468750,  0.06054688],\n",
      "          [-0.70703125, -0.27734375, -0.32421875,  ...,  0.29687500,\n",
      "           -0.30468750,  0.06054688]],\n",
      "\n",
      "         [[-0.22851562,  0.32421875,  0.68359375,  ..., -0.59765625,\n",
      "           -0.28320312, -0.26367188],\n",
      "          [ 0.60156250, -0.06787109, -0.19921875,  ..., -0.30664062,\n",
      "            0.15136719, -0.15722656],\n",
      "          [ 0.59765625, -0.01068115, -0.25585938,  ..., -0.06542969,\n",
      "            0.24218750, -0.39453125],\n",
      "          ...,\n",
      "          [ 0.36132812, -0.09082031, -0.07666016,  ..., -0.20312500,\n",
      "            0.05273438, -0.24804688],\n",
      "          [ 0.36132812, -0.09082031, -0.07666016,  ..., -0.20312500,\n",
      "            0.05273438, -0.24804688],\n",
      "          [ 0.36132812, -0.09082031, -0.07666016,  ..., -0.20312500,\n",
      "            0.05273438, -0.24804688]],\n",
      "\n",
      "         [[-0.02856445,  0.01037598, -0.00567627,  ..., -0.03979492,\n",
      "            0.18847656,  0.15332031],\n",
      "          [-0.35546875,  0.13281250,  0.13574219,  ..., -0.18945312,\n",
      "           -0.29101562, -0.01867676],\n",
      "          [-0.54687500,  0.06591797,  0.06347656,  ..., -0.11376953,\n",
      "           -0.19531250,  0.00643921],\n",
      "          ...,\n",
      "          [-0.18945312, -0.00946045,  0.01904297,  ..., -0.02734375,\n",
      "           -0.08691406, -0.13671875],\n",
      "          [-0.18945312, -0.00946045,  0.01904297,  ..., -0.02734375,\n",
      "           -0.08691406, -0.13671875],\n",
      "          [-0.18945312, -0.00946045,  0.01904297,  ..., -0.02734375,\n",
      "           -0.08691406, -0.13671875]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.02355957, -0.24609375, -0.17089844,  ..., -0.07861328,\n",
      "           -0.05957031, -0.48242188],\n",
      "          [ 0.09277344,  0.13769531, -0.09179688,  ..., -0.11181641,\n",
      "           -0.25390625,  0.02673340],\n",
      "          [ 0.14941406,  0.03686523, -0.07324219,  ..., -0.05322266,\n",
      "           -0.15625000,  0.04150391],\n",
      "          ...,\n",
      "          [-0.04516602,  0.10009766, -0.10009766,  ..., -0.13378906,\n",
      "           -0.26562500, -0.05737305],\n",
      "          [-0.04516602,  0.10009766, -0.10009766,  ..., -0.13378906,\n",
      "           -0.26562500, -0.05737305],\n",
      "          [-0.04516602,  0.10009766, -0.10009766,  ..., -0.13378906,\n",
      "           -0.26562500, -0.05737305]],\n",
      "\n",
      "         [[-0.46679688,  0.06176758, -0.14941406,  ..., -0.03637695,\n",
      "           -0.09521484,  0.15722656],\n",
      "          [-0.06542969, -0.01672363,  0.12597656,  ...,  0.14648438,\n",
      "           -0.06591797,  0.01538086],\n",
      "          [-0.22265625,  0.40820312,  0.43945312,  ...,  0.26562500,\n",
      "            0.03710938,  0.38867188],\n",
      "          ...,\n",
      "          [ 0.03344727, -0.12988281,  0.00732422,  ..., -0.26953125,\n",
      "           -0.01251221, -0.05371094],\n",
      "          [ 0.03344727, -0.12988281,  0.00732422,  ..., -0.26953125,\n",
      "           -0.01251221, -0.05371094],\n",
      "          [ 0.03344727, -0.12988281,  0.00732422,  ..., -0.26953125,\n",
      "           -0.01251221, -0.05371094]],\n",
      "\n",
      "         [[ 0.47265625,  0.34960938, -0.19921875,  ..., -0.18847656,\n",
      "            0.39257812,  0.22265625],\n",
      "          [ 1.08593750,  0.69140625, -0.26757812,  ...,  0.25000000,\n",
      "            0.61328125, -0.03833008],\n",
      "          [ 0.96484375,  0.40039062, -0.41210938,  ...,  0.25390625,\n",
      "            0.34179688, -0.18261719],\n",
      "          ...,\n",
      "          [ 0.02099609,  0.04882812,  0.07861328,  ...,  0.01416016,\n",
      "            0.02136230, -0.03149414],\n",
      "          [ 0.02099609,  0.04882812,  0.07861328,  ...,  0.01416016,\n",
      "            0.02136230, -0.03149414],\n",
      "          [ 0.02099609,  0.04882812,  0.07861328,  ...,  0.01416016,\n",
      "            0.02136230, -0.03149414]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 2.88085938e-02,  7.08007812e-02,  5.59082031e-02,  ...,\n",
      "           -3.97949219e-02,  6.95800781e-03,  7.47070312e-02],\n",
      "          [ 4.88281250e-02, -3.05175781e-02,  5.66406250e-01,  ...,\n",
      "           -1.16210938e-01, -7.66754150e-04,  3.47656250e-01],\n",
      "          [ 8.59375000e-02,  2.10571289e-03,  4.62890625e-01,  ...,\n",
      "           -1.59179688e-01, -5.63964844e-02,  4.23828125e-01],\n",
      "          ...,\n",
      "          [-1.07910156e-01, -2.57812500e-01,  3.55468750e-01,  ...,\n",
      "            6.78710938e-02, -1.02050781e-01,  1.41601562e-01],\n",
      "          [-1.07910156e-01, -2.57812500e-01,  3.55468750e-01,  ...,\n",
      "            6.78710938e-02, -1.02050781e-01,  1.41601562e-01],\n",
      "          [-1.07910156e-01, -2.57812500e-01,  3.55468750e-01,  ...,\n",
      "            6.78710938e-02, -1.02050781e-01,  1.41601562e-01]],\n",
      "\n",
      "         [[-3.10546875e-01,  2.05078125e-01,  1.55468750e+00,  ...,\n",
      "           -8.00781250e-01, -5.27343750e-01, -1.28906250e-01],\n",
      "          [ 1.44531250e-01, -2.89062500e-01,  7.71484375e-02,  ...,\n",
      "           -1.75781250e-01, -2.95410156e-02, -5.22460938e-02],\n",
      "          [ 5.88378906e-02, -2.63671875e-01,  6.16455078e-03,  ...,\n",
      "           -1.73828125e-01, -1.89453125e-01, -5.85937500e-02],\n",
      "          ...,\n",
      "          [ 3.19824219e-02, -1.54296875e-01,  3.51562500e-02,  ...,\n",
      "            1.23901367e-02, -1.21093750e-01, -9.91210938e-02],\n",
      "          [ 3.19824219e-02, -1.54296875e-01,  3.51562500e-02,  ...,\n",
      "            1.23901367e-02, -1.21093750e-01, -9.91210938e-02],\n",
      "          [ 3.19824219e-02, -1.54296875e-01,  3.51562500e-02,  ...,\n",
      "            1.23901367e-02, -1.21093750e-01, -9.91210938e-02]],\n",
      "\n",
      "         [[ 1.42578125e-01,  8.64257812e-02,  7.51953125e-02,  ...,\n",
      "           -1.46484375e-01,  3.37890625e-01, -9.17968750e-02],\n",
      "          [ 5.59082031e-02,  7.12890625e-02,  2.41210938e-01,  ...,\n",
      "           -3.96484375e-01,  1.16699219e-01, -1.14746094e-01],\n",
      "          [ 1.14257812e-01, -1.06933594e-01,  2.37304688e-01,  ...,\n",
      "           -4.39453125e-01,  1.62109375e-01, -2.41210938e-01],\n",
      "          ...,\n",
      "          [-7.81250000e-02, -1.02539062e-01,  8.42285156e-03,  ...,\n",
      "           -3.39843750e-01, -7.51953125e-02, -2.49023438e-01],\n",
      "          [-7.81250000e-02, -1.02539062e-01,  8.42285156e-03,  ...,\n",
      "           -3.39843750e-01, -7.51953125e-02, -2.49023438e-01],\n",
      "          [-7.81250000e-02, -1.02539062e-01,  8.42285156e-03,  ...,\n",
      "           -3.39843750e-01, -7.51953125e-02, -2.49023438e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.78906250e-01, -4.31640625e-01,  9.08203125e-02,  ...,\n",
      "            3.18359375e-01,  5.19531250e-01,  7.03125000e-02],\n",
      "          [-2.57812500e-01,  3.98437500e-01, -1.99218750e-01,  ...,\n",
      "            2.91015625e-01,  6.64062500e-02, -2.15820312e-01],\n",
      "          [-3.10546875e-01,  1.64062500e-01, -2.32421875e-01,  ...,\n",
      "            1.89453125e-01, -1.96533203e-02, -1.07574463e-03],\n",
      "          ...,\n",
      "          [ 2.18750000e-01, -2.63671875e-01, -1.03027344e-01,  ...,\n",
      "           -6.68945312e-02, -1.74804688e-01,  1.46484375e-02],\n",
      "          [ 2.18750000e-01, -2.63671875e-01, -1.03027344e-01,  ...,\n",
      "           -6.68945312e-02, -1.74804688e-01,  1.46484375e-02],\n",
      "          [ 2.18750000e-01, -2.63671875e-01, -1.03027344e-01,  ...,\n",
      "           -6.68945312e-02, -1.74804688e-01,  1.46484375e-02]],\n",
      "\n",
      "         [[-2.27050781e-02, -5.46875000e-02, -2.58789062e-02,  ...,\n",
      "            1.67968750e-01,  5.24902344e-02, -2.11914062e-01],\n",
      "          [ 1.59179688e-01,  6.29882812e-02, -3.14453125e-01,  ...,\n",
      "            2.35351562e-01, -2.32421875e-01,  1.80664062e-01],\n",
      "          [ 3.28125000e-01,  1.71875000e-01, -4.00390625e-01,  ...,\n",
      "            2.92968750e-01, -2.91015625e-01,  4.07714844e-02],\n",
      "          ...,\n",
      "          [-9.27734375e-03,  6.54296875e-02, -5.34667969e-02,  ...,\n",
      "           -2.63671875e-01, -4.37500000e-01, -5.11718750e-01],\n",
      "          [-9.27734375e-03,  6.54296875e-02, -5.34667969e-02,  ...,\n",
      "           -2.63671875e-01, -4.37500000e-01, -5.11718750e-01],\n",
      "          [-9.27734375e-03,  6.54296875e-02, -5.34667969e-02,  ...,\n",
      "           -2.63671875e-01, -4.37500000e-01, -5.11718750e-01]],\n",
      "\n",
      "         [[-5.50781250e-01, -4.39453125e-01, -1.30859375e-01,  ...,\n",
      "            2.55859375e-01, -4.41406250e-01, -2.19726562e-01],\n",
      "          [ 3.26171875e-01, -1.24511719e-01,  1.44531250e-01,  ...,\n",
      "           -2.65625000e-01, -1.10839844e-01, -2.57812500e-01],\n",
      "          [ 3.51562500e-01, -1.85546875e-02,  1.41601562e-01,  ...,\n",
      "           -2.39257812e-01, -9.76562500e-02, -1.61132812e-01],\n",
      "          ...,\n",
      "          [-2.10937500e-01,  1.31835938e-01, -2.50000000e-01,  ...,\n",
      "            9.52148438e-02, -2.79296875e-01, -3.51562500e-02],\n",
      "          [-2.10937500e-01,  1.31835938e-01, -2.50000000e-01,  ...,\n",
      "            9.52148438e-02, -2.79296875e-01, -3.51562500e-02],\n",
      "          [-2.10937500e-01,  1.31835938e-01, -2.50000000e-01,  ...,\n",
      "            9.52148438e-02, -2.79296875e-01, -3.51562500e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.06835938,  0.13281250, -0.07812500,  ...,  0.00430298,\n",
      "            0.12207031,  0.01147461],\n",
      "          [ 0.20800781,  0.45703125, -0.37500000,  ..., -0.12988281,\n",
      "           -0.22070312, -0.05004883],\n",
      "          [ 0.02221680,  0.09863281, -0.12890625,  ..., -0.00793457,\n",
      "           -0.15234375,  0.23828125],\n",
      "          ...,\n",
      "          [-0.05273438, -0.19433594, -0.10498047,  ...,  0.12792969,\n",
      "            0.26953125,  0.24609375],\n",
      "          [-0.05273438, -0.19433594, -0.10498047,  ...,  0.12792969,\n",
      "            0.26953125,  0.24609375],\n",
      "          [-0.05273438, -0.19433594, -0.10498047,  ...,  0.12792969,\n",
      "            0.26953125,  0.24609375]],\n",
      "\n",
      "         [[-0.74218750,  0.50390625, -0.17382812,  ..., -0.36132812,\n",
      "            1.59375000,  0.56640625],\n",
      "          [ 0.20117188,  0.16894531,  0.01867676,  ...,  0.07080078,\n",
      "           -0.00927734,  0.07226562],\n",
      "          [-0.15234375,  0.12255859, -0.04077148,  ...,  0.19531250,\n",
      "            0.19140625,  0.00549316],\n",
      "          ...,\n",
      "          [ 0.21972656,  0.26367188,  0.01416016,  ...,  0.12011719,\n",
      "            0.11230469, -0.07958984],\n",
      "          [ 0.21972656,  0.26367188,  0.01416016,  ...,  0.12011719,\n",
      "            0.11230469, -0.07958984],\n",
      "          [ 0.21972656,  0.26367188,  0.01416016,  ...,  0.12011719,\n",
      "            0.11230469, -0.07958984]],\n",
      "\n",
      "         [[-0.29882812, -0.22949219,  0.03784180,  ...,  0.28515625,\n",
      "            0.07617188,  0.18652344],\n",
      "          [-0.54687500, -0.43359375,  0.21679688,  ..., -0.07519531,\n",
      "           -0.15234375,  0.62109375],\n",
      "          [-0.79296875, -0.42773438, -0.15429688,  ..., -0.06591797,\n",
      "           -0.11816406,  1.25000000],\n",
      "          ...,\n",
      "          [-0.02111816, -0.21386719, -0.03466797,  ..., -0.09765625,\n",
      "            0.27734375, -0.00314331],\n",
      "          [-0.02111816, -0.21386719, -0.03466797,  ..., -0.09765625,\n",
      "            0.27734375, -0.00314331],\n",
      "          [-0.02111816, -0.21386719, -0.03466797,  ..., -0.09765625,\n",
      "            0.27734375, -0.00314331]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.15722656, -0.22363281,  0.12597656,  ...,  0.11816406,\n",
      "            0.07910156, -0.14355469],\n",
      "          [-0.93359375, -0.52734375, -0.12451172,  ..., -0.41796875,\n",
      "           -0.90234375,  0.92578125],\n",
      "          [-1.64062500, -0.76562500, -0.19921875,  ..., -0.40429688,\n",
      "           -0.24804688,  0.82812500],\n",
      "          ...,\n",
      "          [ 0.05810547, -0.26757812,  0.37109375,  ...,  0.25195312,\n",
      "            0.13574219, -0.27148438],\n",
      "          [ 0.05810547, -0.26757812,  0.37109375,  ...,  0.25195312,\n",
      "            0.13574219, -0.27148438],\n",
      "          [ 0.05810547, -0.26757812,  0.37109375,  ...,  0.25195312,\n",
      "            0.13574219, -0.27148438]],\n",
      "\n",
      "         [[-0.70312500, -0.02355957, -0.27929688,  ..., -0.25781250,\n",
      "            0.40234375, -0.28320312],\n",
      "          [ 0.00193024,  0.45703125, -0.42187500,  ..., -0.19824219,\n",
      "            0.64843750,  0.57812500],\n",
      "          [-0.24316406,  0.34179688, -0.55078125,  ..., -0.06835938,\n",
      "            0.78906250,  0.40625000],\n",
      "          ...,\n",
      "          [ 0.05517578,  0.10986328,  0.17285156,  ...,  0.17968750,\n",
      "            0.28710938,  0.01733398],\n",
      "          [ 0.05517578,  0.10986328,  0.17285156,  ...,  0.17968750,\n",
      "            0.28710938,  0.01733398],\n",
      "          [ 0.05517578,  0.10986328,  0.17285156,  ...,  0.17968750,\n",
      "            0.28710938,  0.01733398]],\n",
      "\n",
      "         [[-0.25195312, -0.15917969, -0.11669922,  ...,  0.15722656,\n",
      "           -0.01647949,  0.18457031],\n",
      "          [-0.29882812,  0.31054688,  0.00457764,  ...,  0.33789062,\n",
      "            0.12890625,  0.26367188],\n",
      "          [-0.36718750,  0.30273438, -0.18652344,  ...,  0.42382812,\n",
      "           -0.18261719,  0.37695312],\n",
      "          ...,\n",
      "          [-0.31640625,  0.15039062, -0.15136719,  ...,  0.21386719,\n",
      "           -0.04052734,  0.28710938],\n",
      "          [-0.31640625,  0.15039062, -0.15136719,  ...,  0.21386719,\n",
      "           -0.04052734,  0.28710938],\n",
      "          [-0.31640625,  0.15039062, -0.15136719,  ...,  0.21386719,\n",
      "           -0.04052734,  0.28710938]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 6.93359375e-02, -6.44531250e-02, -4.19921875e-01,  ...,\n",
      "           -2.17773438e-01,  1.31835938e-01,  3.69140625e-01],\n",
      "          [-8.05664062e-02, -4.32128906e-02, -9.70458984e-03,  ...,\n",
      "            1.23535156e-01, -7.91015625e-02, -2.29492188e-02],\n",
      "          [-2.65625000e-01, -3.75000000e-01,  2.98828125e-01,  ...,\n",
      "            4.12109375e-01, -2.67578125e-01, -3.04687500e-01],\n",
      "          ...,\n",
      "          [ 2.47070312e-01, -1.65039062e-01, -5.35156250e-01,  ...,\n",
      "           -2.22656250e-01,  1.16699219e-01,  3.33984375e-01],\n",
      "          [ 2.47070312e-01, -1.65039062e-01, -5.35156250e-01,  ...,\n",
      "           -2.22656250e-01,  1.16699219e-01,  3.33984375e-01],\n",
      "          [ 2.47070312e-01, -1.65039062e-01, -5.35156250e-01,  ...,\n",
      "           -2.22656250e-01,  1.16699219e-01,  3.33984375e-01]],\n",
      "\n",
      "         [[ 2.41210938e-01, -1.13487244e-04,  1.65557861e-03,  ...,\n",
      "           -6.07910156e-02, -1.34765625e-01,  2.11181641e-02],\n",
      "          [ 3.18359375e-01, -3.93066406e-02, -7.12890625e-02,  ...,\n",
      "            1.43554688e-01,  3.01513672e-02,  6.29882812e-02],\n",
      "          [ 1.51367188e-01,  1.45263672e-02,  1.06933594e-01,  ...,\n",
      "            2.57812500e-01,  1.76757812e-01, -1.39648438e-01],\n",
      "          ...,\n",
      "          [ 3.35937500e-01,  2.22167969e-02, -2.57568359e-02,  ...,\n",
      "           -5.15747070e-03, -9.76562500e-02, -1.35742188e-01],\n",
      "          [ 3.35937500e-01,  2.22167969e-02, -2.57568359e-02,  ...,\n",
      "           -5.15747070e-03, -9.76562500e-02, -1.35742188e-01],\n",
      "          [ 3.35937500e-01,  2.22167969e-02, -2.57568359e-02,  ...,\n",
      "           -5.15747070e-03, -9.76562500e-02, -1.35742188e-01]],\n",
      "\n",
      "         [[-2.28271484e-02, -1.04003906e-01, -1.62353516e-02,  ...,\n",
      "           -6.15234375e-02,  8.30078125e-02, -7.51953125e-02],\n",
      "          [ 1.84326172e-02, -7.71484375e-02,  2.33398438e-01,  ...,\n",
      "            1.41601562e-01,  2.02148438e-01, -1.58203125e-01],\n",
      "          [ 1.38671875e-01, -8.34960938e-02,  1.40625000e-01,  ...,\n",
      "            3.20312500e-01,  2.01171875e-01, -1.51367188e-01],\n",
      "          ...,\n",
      "          [-9.46044922e-03,  3.18359375e-01, -2.06054688e-01,  ...,\n",
      "            1.58203125e-01,  8.88671875e-02,  1.15234375e-01],\n",
      "          [-9.46044922e-03,  3.18359375e-01, -2.06054688e-01,  ...,\n",
      "            1.58203125e-01,  8.88671875e-02,  1.15234375e-01],\n",
      "          [-9.46044922e-03,  3.18359375e-01, -2.06054688e-01,  ...,\n",
      "            1.58203125e-01,  8.88671875e-02,  1.15234375e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.17968750e-02,  8.34960938e-02, -1.25976562e-01,  ...,\n",
      "            1.59179688e-01, -9.47265625e-02, -7.08007812e-02],\n",
      "          [-1.78710938e-01, -6.25000000e-01, -2.61718750e-01,  ...,\n",
      "           -1.98242188e-01,  1.98242188e-01,  7.71484375e-02],\n",
      "          [-3.14453125e-01, -1.21875000e+00, -4.27734375e-01,  ...,\n",
      "           -3.35937500e-01,  7.07031250e-01,  6.34765625e-02],\n",
      "          ...,\n",
      "          [ 1.21307373e-03,  2.46093750e-01,  2.13623047e-02,  ...,\n",
      "           -1.25976562e-01, -1.33789062e-01, -1.25976562e-01],\n",
      "          [ 1.21307373e-03,  2.46093750e-01,  2.13623047e-02,  ...,\n",
      "           -1.25976562e-01, -1.33789062e-01, -1.25976562e-01],\n",
      "          [ 1.21307373e-03,  2.46093750e-01,  2.13623047e-02,  ...,\n",
      "           -1.25976562e-01, -1.33789062e-01, -1.25976562e-01]],\n",
      "\n",
      "         [[ 2.75878906e-02,  2.66113281e-02, -7.95898438e-02,  ...,\n",
      "            2.03857422e-02, -1.05468750e-01,  1.15722656e-01],\n",
      "          [-8.08593750e-01, -8.05664062e-02,  4.98046875e-01,  ...,\n",
      "           -2.83203125e-01,  1.81198120e-04,  2.41210938e-01],\n",
      "          [ 7.93457031e-03, -5.19531250e-01,  9.06250000e-01,  ...,\n",
      "            3.43750000e-01,  2.29492188e-01,  6.64062500e-02],\n",
      "          ...,\n",
      "          [-2.33154297e-02,  1.23046875e-01, -1.31835938e-01,  ...,\n",
      "            8.54492188e-02, -9.61914062e-02,  4.02343750e-01],\n",
      "          [-2.33154297e-02,  1.23046875e-01, -1.31835938e-01,  ...,\n",
      "            8.54492188e-02, -9.61914062e-02,  4.02343750e-01],\n",
      "          [-2.33154297e-02,  1.23046875e-01, -1.31835938e-01,  ...,\n",
      "            8.54492188e-02, -9.61914062e-02,  4.02343750e-01]],\n",
      "\n",
      "         [[ 1.79687500e-01,  1.10839844e-01, -9.96093750e-02,  ...,\n",
      "            1.19140625e-01, -1.73339844e-02, -1.20605469e-01],\n",
      "          [-1.15966797e-02, -1.11328125e-01,  4.00390625e-02,  ...,\n",
      "           -1.79443359e-02,  4.22363281e-02, -1.09863281e-01],\n",
      "          [-6.73828125e-02, -2.36816406e-02,  2.28271484e-02,  ...,\n",
      "            2.75878906e-02, -5.95703125e-02, -1.50390625e-01],\n",
      "          ...,\n",
      "          [ 4.02343750e-01,  3.41796875e-02, -1.04003906e-01,  ...,\n",
      "            1.31835938e-01,  9.91210938e-02, -7.32421875e-02],\n",
      "          [ 4.02343750e-01,  3.41796875e-02, -1.04003906e-01,  ...,\n",
      "            1.31835938e-01,  9.91210938e-02, -7.32421875e-02],\n",
      "          [ 4.02343750e-01,  3.41796875e-02, -1.04003906e-01,  ...,\n",
      "            1.31835938e-01,  9.91210938e-02, -7.32421875e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.07031250, -0.10595703,  0.15429688,  ...,  0.14160156,\n",
      "           -0.30859375,  0.08496094],\n",
      "          [-0.11865234, -0.07763672, -0.06225586,  ..., -0.05419922,\n",
      "            0.01544189, -0.02160645],\n",
      "          [-0.06542969, -0.13476562, -0.05957031,  ..., -0.00753784,\n",
      "           -0.02917480, -0.01385498],\n",
      "          ...,\n",
      "          [ 0.11865234,  0.07226562,  0.40820312,  ...,  0.22265625,\n",
      "           -0.39257812,  0.10253906],\n",
      "          [ 0.11865234,  0.07226562,  0.40820312,  ...,  0.22265625,\n",
      "           -0.39257812,  0.10253906],\n",
      "          [ 0.11865234,  0.07226562,  0.40820312,  ...,  0.22265625,\n",
      "           -0.39257812,  0.10253906]],\n",
      "\n",
      "         [[-0.27734375,  0.04907227, -0.14453125,  ..., -0.09521484,\n",
      "           -0.06591797,  0.21972656],\n",
      "          [ 0.66796875, -0.51953125,  0.69531250,  ...,  1.27343750,\n",
      "           -0.40429688, -0.27929688],\n",
      "          [ 0.62890625, -0.49414062,  0.72265625,  ...,  1.13281250,\n",
      "           -0.20117188, -0.17871094],\n",
      "          ...,\n",
      "          [-0.41992188,  0.03784180, -0.15136719,  ..., -0.12988281,\n",
      "            0.00279236, -0.01501465],\n",
      "          [-0.41992188,  0.03784180, -0.15136719,  ..., -0.12988281,\n",
      "            0.00279236, -0.01501465],\n",
      "          [-0.41992188,  0.03784180, -0.15136719,  ..., -0.12988281,\n",
      "            0.00279236, -0.01501465]],\n",
      "\n",
      "         [[ 0.24121094, -0.03979492,  0.07861328,  ..., -0.07275391,\n",
      "            0.39257812, -0.04956055],\n",
      "          [-0.19238281, -0.14062500,  0.39843750,  ..., -0.32031250,\n",
      "            0.09277344,  0.01397705],\n",
      "          [-0.36523438,  0.13769531,  0.34179688,  ..., -0.75781250,\n",
      "            0.07861328,  0.03222656],\n",
      "          ...,\n",
      "          [-0.36132812,  0.08789062,  0.14355469,  ...,  0.15429688,\n",
      "           -0.11230469,  0.10156250],\n",
      "          [-0.36132812,  0.08789062,  0.14355469,  ...,  0.15429688,\n",
      "           -0.11230469,  0.10156250],\n",
      "          [-0.36132812,  0.08789062,  0.14355469,  ...,  0.15429688,\n",
      "           -0.11230469,  0.10156250]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.13378906, -0.43164062,  0.46093750,  ..., -0.43164062,\n",
      "           -0.12158203,  0.14843750],\n",
      "          [-0.13476562,  0.02343750,  0.30664062,  ...,  0.23144531,\n",
      "            0.19238281,  0.10351562],\n",
      "          [-0.01196289, -0.05908203,  0.34765625,  ...,  0.13476562,\n",
      "            0.13281250, -0.02148438],\n",
      "          ...,\n",
      "          [-0.16699219, -0.29492188,  0.08984375,  ..., -0.25976562,\n",
      "            0.17285156,  0.26171875],\n",
      "          [-0.16699219, -0.29492188,  0.08984375,  ..., -0.25976562,\n",
      "            0.17285156,  0.26171875],\n",
      "          [-0.16699219, -0.29492188,  0.08984375,  ..., -0.25976562,\n",
      "            0.17285156,  0.26171875]],\n",
      "\n",
      "         [[-0.09570312, -0.07470703,  0.00518799,  ..., -0.14257812,\n",
      "            0.18359375,  0.15625000],\n",
      "          [ 0.00982666, -0.01019287,  0.00662231,  ..., -0.00436401,\n",
      "           -0.05908203, -0.12304688],\n",
      "          [ 0.05761719,  0.06787109,  0.09082031,  ...,  0.01165771,\n",
      "            0.06079102, -0.03735352],\n",
      "          ...,\n",
      "          [ 0.21191406, -0.28515625,  0.05224609,  ..., -0.06225586,\n",
      "           -0.16503906, -0.19531250],\n",
      "          [ 0.21191406, -0.28515625,  0.05224609,  ..., -0.06225586,\n",
      "           -0.16503906, -0.19531250],\n",
      "          [ 0.21191406, -0.28515625,  0.05224609,  ..., -0.06225586,\n",
      "           -0.16503906, -0.19531250]],\n",
      "\n",
      "         [[ 0.09228516,  0.03198242, -0.08691406,  ..., -0.06640625,\n",
      "           -0.03247070, -0.06445312],\n",
      "          [ 0.29296875,  0.19042969,  0.08496094,  ..., -0.21875000,\n",
      "           -0.11767578, -0.30859375],\n",
      "          [ 0.13964844,  0.36914062, -0.13671875,  ..., -0.06127930,\n",
      "           -0.02319336,  0.18359375],\n",
      "          ...,\n",
      "          [-0.00601196, -0.13671875, -0.24511719,  ..., -0.58593750,\n",
      "           -0.12792969, -0.74609375],\n",
      "          [-0.00601196, -0.13671875, -0.24511719,  ..., -0.58593750,\n",
      "           -0.12792969, -0.74609375],\n",
      "          [-0.00601196, -0.13671875, -0.24511719,  ..., -0.58593750,\n",
      "           -0.12792969, -0.74609375]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 3.44238281e-02, -6.39648438e-02, -1.06933594e-01,  ...,\n",
      "            1.74804688e-01,  3.71093750e-02,  8.00781250e-02],\n",
      "          [ 1.29882812e-01,  1.69921875e-01, -1.87500000e-01,  ...,\n",
      "            2.50000000e-01, -2.19726562e-03,  1.28906250e-01],\n",
      "          [ 1.09375000e-01,  2.69531250e-01, -1.27929688e-01,  ...,\n",
      "            2.11914062e-01, -3.34472656e-02,  8.42285156e-03],\n",
      "          ...,\n",
      "          [ 1.30859375e-01, -1.36718750e-01,  3.00292969e-02,  ...,\n",
      "            2.39257812e-02, -3.73535156e-02,  1.29882812e-01],\n",
      "          [ 1.30859375e-01, -1.36718750e-01,  3.00292969e-02,  ...,\n",
      "            2.39257812e-02, -3.73535156e-02,  1.29882812e-01],\n",
      "          [ 1.30859375e-01, -1.36718750e-01,  3.00292969e-02,  ...,\n",
      "            2.39257812e-02, -3.73535156e-02,  1.29882812e-01]],\n",
      "\n",
      "         [[-1.47460938e-01, -3.61328125e-02, -4.51660156e-02,  ...,\n",
      "            4.78515625e-01,  7.46093750e-01, -4.62890625e-01],\n",
      "          [ 3.66210938e-02, -3.44238281e-02,  9.37500000e-02,  ...,\n",
      "           -2.58789062e-02, -1.80664062e-01,  1.57226562e-01],\n",
      "          [ 6.78710938e-02, -1.03027344e-01, -9.47265625e-02,  ...,\n",
      "            1.14746094e-01, -2.28515625e-01, -3.90625000e-02],\n",
      "          ...,\n",
      "          [-1.92382812e-01, -2.53906250e-01,  1.89453125e-01,  ...,\n",
      "           -6.88476562e-02, -2.17773438e-01,  3.61328125e-01],\n",
      "          [-1.92382812e-01, -2.53906250e-01,  1.89453125e-01,  ...,\n",
      "           -6.88476562e-02, -2.17773438e-01,  3.61328125e-01],\n",
      "          [-1.92382812e-01, -2.53906250e-01,  1.89453125e-01,  ...,\n",
      "           -6.88476562e-02, -2.17773438e-01,  3.61328125e-01]],\n",
      "\n",
      "         [[-7.22656250e-02, -6.98242188e-02, -1.11816406e-01,  ...,\n",
      "           -1.47460938e-01, -2.05078125e-02, -9.81445312e-02],\n",
      "          [ 6.25000000e-02, -5.43212891e-03, -4.10156250e-02,  ...,\n",
      "            2.13623047e-02, -1.03515625e-01, -2.53906250e-02],\n",
      "          [-3.36914062e-02, -1.06933594e-01,  3.36914062e-02,  ...,\n",
      "            7.81250000e-02, -2.86865234e-03, -5.34667969e-02],\n",
      "          ...,\n",
      "          [-1.29882812e-01, -1.52343750e-01, -2.81250000e-01,  ...,\n",
      "           -2.01171875e-01, -1.84570312e-01,  2.42919922e-02],\n",
      "          [-1.29882812e-01, -1.52343750e-01, -2.81250000e-01,  ...,\n",
      "           -2.01171875e-01, -1.84570312e-01,  2.42919922e-02],\n",
      "          [-1.29882812e-01, -1.52343750e-01, -2.81250000e-01,  ...,\n",
      "           -2.01171875e-01, -1.84570312e-01,  2.42919922e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.44335938e-02,  1.14257812e-01,  4.68750000e-02,  ...,\n",
      "            1.29394531e-02, -1.40625000e-01, -1.20849609e-02],\n",
      "          [ 1.98242188e-01,  1.16210938e-01, -3.66210938e-02,  ...,\n",
      "            1.49414062e-01, -1.66015625e-01, -2.01171875e-01],\n",
      "          [ 8.20312500e-02,  1.17675781e-01,  3.54003906e-02,  ...,\n",
      "            1.42578125e-01, -8.74023438e-02, -6.59179688e-02],\n",
      "          ...,\n",
      "          [ 1.68945312e-01,  5.78613281e-02,  1.71875000e-01,  ...,\n",
      "           -1.11328125e-01,  2.18505859e-02, -4.37011719e-02],\n",
      "          [ 1.68945312e-01,  5.78613281e-02,  1.71875000e-01,  ...,\n",
      "           -1.11328125e-01,  2.18505859e-02, -4.37011719e-02],\n",
      "          [ 1.68945312e-01,  5.78613281e-02,  1.71875000e-01,  ...,\n",
      "           -1.11328125e-01,  2.18505859e-02, -4.37011719e-02]],\n",
      "\n",
      "         [[ 7.81250000e-02, -4.32128906e-02, -5.35156250e-01,  ...,\n",
      "            6.48437500e-01,  9.02343750e-01,  1.62109375e-01],\n",
      "          [ 1.29687500e+00,  7.61718750e-01,  2.91748047e-02,  ...,\n",
      "            5.35156250e-01,  1.02343750e+00,  1.05468750e+00],\n",
      "          [ 1.03906250e+00,  3.32031250e-01, -9.94873047e-03,  ...,\n",
      "            1.19628906e-01,  2.57812500e-01,  6.32812500e-01],\n",
      "          ...,\n",
      "          [ 4.10156250e-01, -1.38549805e-02,  4.58984375e-01,  ...,\n",
      "            5.35156250e-01, -2.03125000e-01,  1.65039062e-01],\n",
      "          [ 4.10156250e-01, -1.38549805e-02,  4.58984375e-01,  ...,\n",
      "            5.35156250e-01, -2.03125000e-01,  1.65039062e-01],\n",
      "          [ 4.10156250e-01, -1.38549805e-02,  4.58984375e-01,  ...,\n",
      "            5.35156250e-01, -2.03125000e-01,  1.65039062e-01]],\n",
      "\n",
      "         [[ 1.61132812e-01, -9.13085938e-02,  1.05957031e-01,  ...,\n",
      "           -1.63085938e-01,  1.00097656e-01, -1.72851562e-01],\n",
      "          [ 1.82617188e-01, -7.14843750e-01,  2.36328125e-01,  ...,\n",
      "           -9.49218750e-01, -2.21679688e-01,  4.12597656e-02],\n",
      "          [ 1.90429688e-01, -6.17187500e-01,  2.83203125e-01,  ...,\n",
      "           -7.14843750e-01, -4.21524048e-04,  6.78710938e-02],\n",
      "          ...,\n",
      "          [-3.22265625e-01, -5.58593750e-01, -5.11718750e-01,  ...,\n",
      "           -2.96875000e-01,  1.39648438e-01, -1.32812500e-01],\n",
      "          [-3.22265625e-01, -5.58593750e-01, -5.11718750e-01,  ...,\n",
      "           -2.96875000e-01,  1.39648438e-01, -1.32812500e-01],\n",
      "          [-3.22265625e-01, -5.58593750e-01, -5.11718750e-01,  ...,\n",
      "           -2.96875000e-01,  1.39648438e-01, -1.32812500e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 1.97265625e-01, -9.86328125e-02,  1.20117188e-01,  ...,\n",
      "            1.24511719e-01,  1.67846680e-03, -3.83300781e-02],\n",
      "          [-7.08007812e-02, -7.32421875e-02,  1.39648438e-01,  ...,\n",
      "            6.59179688e-02,  3.56445312e-02, -8.83789062e-02],\n",
      "          [-3.39355469e-02, -1.25976562e-01,  1.63085938e-01,  ...,\n",
      "            9.61914062e-02,  7.86132812e-02, -9.91210938e-02],\n",
      "          ...,\n",
      "          [ 3.45703125e-01,  2.79296875e-01,  1.79687500e-01,  ...,\n",
      "           -2.31933594e-02,  4.17968750e-01,  1.16699219e-01],\n",
      "          [ 3.45703125e-01,  2.79296875e-01,  1.79687500e-01,  ...,\n",
      "           -2.31933594e-02,  4.17968750e-01,  1.16699219e-01],\n",
      "          [ 3.45703125e-01,  2.79296875e-01,  1.79687500e-01,  ...,\n",
      "           -2.31933594e-02,  4.17968750e-01,  1.16699219e-01]],\n",
      "\n",
      "         [[-1.28906250e-01, -4.27246094e-02,  7.51953125e-02,  ...,\n",
      "           -7.95898438e-02, -1.66015625e-01, -1.11816406e-01],\n",
      "          [ 5.63964844e-02, -2.07031250e-01,  1.15356445e-02,  ...,\n",
      "           -1.95312500e-02, -1.05957031e-01,  1.85546875e-02],\n",
      "          [-5.27343750e-02, -1.72851562e-01, -5.85937500e-02,  ...,\n",
      "           -3.41796875e-02, -1.69921875e-01,  1.21459961e-02],\n",
      "          ...,\n",
      "          [-6.25000000e-01,  5.83496094e-02, -4.80957031e-02,  ...,\n",
      "           -4.51660156e-02, -2.11181641e-02, -2.44140625e-01],\n",
      "          [-6.25000000e-01,  5.83496094e-02, -4.80957031e-02,  ...,\n",
      "           -4.51660156e-02, -2.11181641e-02, -2.44140625e-01],\n",
      "          [-6.25000000e-01,  5.83496094e-02, -4.80957031e-02,  ...,\n",
      "           -4.51660156e-02, -2.11181641e-02, -2.44140625e-01]],\n",
      "\n",
      "         [[-1.49414062e-01,  1.09863281e-01,  6.59179688e-02,  ...,\n",
      "            2.91015625e-01, -3.71093750e-01, -1.15966797e-02],\n",
      "          [-2.55126953e-02, -9.57031250e-02,  2.55126953e-02,  ...,\n",
      "           -1.38671875e-01, -1.22558594e-01, -7.51953125e-02],\n",
      "          [ 6.05468750e-02, -4.37011719e-02,  1.40991211e-02,  ...,\n",
      "           -8.00781250e-02, -1.43554688e-01, -3.78417969e-02],\n",
      "          ...,\n",
      "          [-2.63671875e-01,  1.18652344e-01, -1.11328125e-01,  ...,\n",
      "            3.37890625e-01, -1.60156250e-01, -7.10937500e-01],\n",
      "          [-2.63671875e-01,  1.18652344e-01, -1.11328125e-01,  ...,\n",
      "            3.37890625e-01, -1.60156250e-01, -7.10937500e-01],\n",
      "          [-2.63671875e-01,  1.18652344e-01, -1.11328125e-01,  ...,\n",
      "            3.37890625e-01, -1.60156250e-01, -7.10937500e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.33398438e-01,  5.07831573e-05,  3.80859375e-02,  ...,\n",
      "            7.66601562e-02, -6.25000000e-02, -7.61718750e-02],\n",
      "          [ 3.19824219e-02,  1.35498047e-02,  5.61523438e-02,  ...,\n",
      "           -3.68652344e-02, -1.35498047e-02, -1.23046875e-01],\n",
      "          [ 8.54492188e-02, -1.32446289e-02, -4.49218750e-02,  ...,\n",
      "           -6.20117188e-02,  1.15234375e-01, -1.69921875e-01],\n",
      "          ...,\n",
      "          [-6.54296875e-02,  1.39648438e-01,  1.77734375e-01,  ...,\n",
      "            5.81054688e-02, -7.99560547e-03, -1.84570312e-01],\n",
      "          [-6.54296875e-02,  1.39648438e-01,  1.77734375e-01,  ...,\n",
      "            5.81054688e-02, -7.99560547e-03, -1.84570312e-01],\n",
      "          [-6.54296875e-02,  1.39648438e-01,  1.77734375e-01,  ...,\n",
      "            5.81054688e-02, -7.99560547e-03, -1.84570312e-01]],\n",
      "\n",
      "         [[-9.42382812e-02, -6.88476562e-02,  6.39648438e-02,  ...,\n",
      "           -1.77734375e-01, -2.50244141e-02,  3.95507812e-02],\n",
      "          [ 3.14941406e-02, -1.97753906e-02,  2.27050781e-02,  ...,\n",
      "            3.51562500e-02, -3.83300781e-02, -3.02734375e-02],\n",
      "          [ 7.81250000e-02, -1.66015625e-01,  7.47070312e-02,  ...,\n",
      "           -6.22558594e-02,  2.75878906e-02, -1.26953125e-01],\n",
      "          ...,\n",
      "          [ 1.87500000e-01, -4.98046875e-02, -1.60156250e-01,  ...,\n",
      "            2.16064453e-02, -1.76239014e-03, -5.15136719e-02],\n",
      "          [ 1.87500000e-01, -4.98046875e-02, -1.60156250e-01,  ...,\n",
      "            2.16064453e-02, -1.76239014e-03, -5.15136719e-02],\n",
      "          [ 1.87500000e-01, -4.98046875e-02, -1.60156250e-01,  ...,\n",
      "            2.16064453e-02, -1.76239014e-03, -5.15136719e-02]],\n",
      "\n",
      "         [[ 2.92968750e-02, -8.74023438e-02, -1.34765625e-01,  ...,\n",
      "            1.86767578e-02,  3.75976562e-02, -6.15234375e-02],\n",
      "          [-1.07910156e-01, -1.20605469e-01, -1.63085938e-01,  ...,\n",
      "           -6.50024414e-03,  5.17578125e-02, -2.01416016e-02],\n",
      "          [-1.47460938e-01, -8.34960938e-02, -8.69140625e-02,  ...,\n",
      "           -5.61523438e-02,  1.04003906e-01, -1.39770508e-02],\n",
      "          ...,\n",
      "          [-1.12792969e-01, -1.77734375e-01, -5.93750000e-01,  ...,\n",
      "           -1.05957031e-01,  1.05590820e-02,  1.37695312e-01],\n",
      "          [-1.12792969e-01, -1.77734375e-01, -5.93750000e-01,  ...,\n",
      "           -1.05957031e-01,  1.05590820e-02,  1.37695312e-01],\n",
      "          [-1.12792969e-01, -1.77734375e-01, -5.93750000e-01,  ...,\n",
      "           -1.05957031e-01,  1.05590820e-02,  1.37695312e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-7.51953125e-02, -1.21093750e-01, -5.59082031e-02,  ...,\n",
      "           -1.05957031e-01, -1.43432617e-02,  4.76074219e-02],\n",
      "          [ 3.49121094e-02, -4.00390625e-02, -3.39355469e-02,  ...,\n",
      "           -5.61523438e-02, -1.44042969e-02,  1.04003906e-01],\n",
      "          [ 6.68945312e-02, -3.71093750e-02,  6.39648438e-02,  ...,\n",
      "           -6.98242188e-02,  1.06048584e-03,  7.81250000e-02],\n",
      "          ...,\n",
      "          [-3.92578125e-01,  3.92578125e-01,  6.93359375e-02,  ...,\n",
      "           -1.25976562e-01,  4.34570312e-02, -2.95410156e-02],\n",
      "          [-3.92578125e-01,  3.92578125e-01,  6.93359375e-02,  ...,\n",
      "           -1.25976562e-01,  4.34570312e-02, -2.95410156e-02],\n",
      "          [-3.92578125e-01,  3.92578125e-01,  6.93359375e-02,  ...,\n",
      "           -1.25976562e-01,  4.34570312e-02, -2.95410156e-02]],\n",
      "\n",
      "         [[-8.39843750e-01,  6.44531250e-01, -6.32812500e-01,  ...,\n",
      "           -1.80664062e-01,  1.16699219e-01, -1.95312500e-01],\n",
      "          [ 5.49316406e-02, -4.29687500e-01, -2.00195312e-01,  ...,\n",
      "            1.60156250e-01, -1.99218750e-01, -1.02050781e-01],\n",
      "          [ 1.17675781e-01, -4.53125000e-01, -3.00292969e-02,  ...,\n",
      "            3.69140625e-01, -4.15039062e-02, -7.61718750e-02],\n",
      "          ...,\n",
      "          [ 5.07812500e-01,  2.18750000e-01,  5.62500000e-01,  ...,\n",
      "            8.78906250e-02,  2.79296875e-01, -1.36718750e-02],\n",
      "          [ 5.07812500e-01,  2.18750000e-01,  5.62500000e-01,  ...,\n",
      "            8.78906250e-02,  2.79296875e-01, -1.36718750e-02],\n",
      "          [ 5.07812500e-01,  2.18750000e-01,  5.62500000e-01,  ...,\n",
      "            8.78906250e-02,  2.79296875e-01, -1.36718750e-02]],\n",
      "\n",
      "         [[-2.87109375e-01, -7.71484375e-02, -1.45507812e-01,  ...,\n",
      "           -3.00292969e-02, -8.20312500e-02,  1.34765625e-01],\n",
      "          [ 6.83593750e-02, -1.57226562e-01, -8.74023438e-02,  ...,\n",
      "            2.00195312e-02,  1.85546875e-01,  8.66699219e-03],\n",
      "          [-1.75781250e-01, -1.24023438e-01, -7.56835938e-02,  ...,\n",
      "            2.53906250e-02,  2.37304688e-01, -1.04492188e-01],\n",
      "          ...,\n",
      "          [-6.60156250e-01, -1.33789062e-01, -4.80468750e-01,  ...,\n",
      "           -1.01074219e-01,  4.86328125e-01, -1.16699219e-01],\n",
      "          [-6.60156250e-01, -1.33789062e-01, -4.80468750e-01,  ...,\n",
      "           -1.01074219e-01,  4.86328125e-01, -1.16699219e-01],\n",
      "          [-6.60156250e-01, -1.33789062e-01, -4.80468750e-01,  ...,\n",
      "           -1.01074219e-01,  4.86328125e-01, -1.16699219e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.59765625e-01, -4.88281250e-01,  4.33593750e-01,  ...,\n",
      "            4.80957031e-02,  1.07910156e-01,  5.02929688e-02],\n",
      "          [-1.26953125e-01, -1.84570312e-01, -8.69750977e-04,  ...,\n",
      "            9.33593750e-01, -4.12109375e-01, -4.90234375e-01],\n",
      "          [-2.30468750e-01, -1.49414062e-01, -2.45117188e-01,  ...,\n",
      "            1.09375000e+00, -3.34472656e-02, -5.19531250e-01],\n",
      "          ...,\n",
      "          [-1.13281250e-01, -6.48437500e-01, -1.15234375e-01,  ...,\n",
      "           -6.95312500e-01, -2.92968750e-01, -9.37500000e-02],\n",
      "          [-1.13281250e-01, -6.48437500e-01, -1.15234375e-01,  ...,\n",
      "           -6.95312500e-01, -2.92968750e-01, -9.37500000e-02],\n",
      "          [-1.13281250e-01, -6.48437500e-01, -1.15234375e-01,  ...,\n",
      "           -6.95312500e-01, -2.92968750e-01, -9.37500000e-02]],\n",
      "\n",
      "         [[ 1.25976562e-01,  5.71289062e-02, -4.68750000e-02,  ...,\n",
      "           -1.11328125e-01,  1.73828125e-01,  2.81250000e-01],\n",
      "          [ 9.08203125e-02, -2.03857422e-02, -1.36718750e-01,  ...,\n",
      "            4.95605469e-02, -9.32617188e-02,  2.06054688e-01],\n",
      "          [ 5.15136719e-02, -3.90625000e-02, -1.25000000e-01,  ...,\n",
      "            7.56835938e-02, -1.38671875e-01,  2.19726562e-01],\n",
      "          ...,\n",
      "          [ 2.79296875e-01,  5.50781250e-01, -3.18359375e-01,  ...,\n",
      "           -2.22656250e-01, -4.66308594e-02,  2.15820312e-01],\n",
      "          [ 2.79296875e-01,  5.50781250e-01, -3.18359375e-01,  ...,\n",
      "           -2.22656250e-01, -4.66308594e-02,  2.15820312e-01],\n",
      "          [ 2.79296875e-01,  5.50781250e-01, -3.18359375e-01,  ...,\n",
      "           -2.22656250e-01, -4.66308594e-02,  2.15820312e-01]],\n",
      "\n",
      "         [[ 3.95507812e-02, -1.08886719e-01,  3.26171875e-01,  ...,\n",
      "           -1.73828125e-01, -2.14843750e-01,  1.63085938e-01],\n",
      "          [ 5.12695312e-02, -1.72851562e-01, -1.76757812e-01,  ...,\n",
      "           -1.40625000e-01, -6.68945312e-02, -6.64062500e-02],\n",
      "          [-4.51660156e-02, -1.85546875e-01, -2.98828125e-01,  ...,\n",
      "           -1.78710938e-01,  5.32226562e-02, -2.00195312e-01],\n",
      "          ...,\n",
      "          [-1.56250000e-01, -1.77734375e-01, -1.56250000e-01,  ...,\n",
      "            1.26953125e-02,  2.81250000e-01,  4.05273438e-02],\n",
      "          [-1.56250000e-01, -1.77734375e-01, -1.56250000e-01,  ...,\n",
      "            1.26953125e-02,  2.81250000e-01,  4.05273438e-02],\n",
      "          [-1.56250000e-01, -1.77734375e-01, -1.56250000e-01,  ...,\n",
      "            1.26953125e-02,  2.81250000e-01,  4.05273438e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 7.03125000e-02, -7.85156250e-01, -2.83203125e-01,  ...,\n",
      "           -2.96875000e-01, -5.66406250e-01, -2.22656250e-01],\n",
      "          [-3.28125000e-01, -1.80664062e-01,  9.34600830e-04,  ...,\n",
      "            8.72802734e-03, -1.89453125e-01, -3.93066406e-02],\n",
      "          [-8.12500000e-01, -2.47070312e-01,  2.02148438e-01,  ...,\n",
      "            2.01171875e-01, -4.70703125e-01, -1.07910156e-01],\n",
      "          ...,\n",
      "          [-3.12500000e-01, -2.71484375e-01, -1.17675781e-01,  ...,\n",
      "           -3.98437500e-01, -2.18750000e-01,  8.71093750e-01],\n",
      "          [-3.12500000e-01, -2.71484375e-01, -1.17675781e-01,  ...,\n",
      "           -3.98437500e-01, -2.18750000e-01,  8.71093750e-01],\n",
      "          [-3.12500000e-01, -2.71484375e-01, -1.17675781e-01,  ...,\n",
      "           -3.98437500e-01, -2.18750000e-01,  8.71093750e-01]],\n",
      "\n",
      "         [[ 8.98437500e-02, -4.54101562e-02,  1.04003906e-01,  ...,\n",
      "            1.09375000e-01, -3.63769531e-02, -1.57470703e-02],\n",
      "          [-2.91748047e-02,  4.00390625e-02, -1.46484375e-01,  ...,\n",
      "           -3.63769531e-02, -1.95312500e-01,  1.77734375e-01],\n",
      "          [-2.35351562e-01,  7.93457031e-03, -3.08593750e-01,  ...,\n",
      "           -2.34375000e-01, -7.86132812e-02,  7.53906250e-01],\n",
      "          ...,\n",
      "          [-6.32812500e-01,  1.48437500e-01,  2.07031250e-01,  ...,\n",
      "           -4.04296875e-01,  1.57226562e-01,  4.53125000e-01],\n",
      "          [-6.32812500e-01,  1.48437500e-01,  2.07031250e-01,  ...,\n",
      "           -4.04296875e-01,  1.57226562e-01,  4.53125000e-01],\n",
      "          [-6.32812500e-01,  1.48437500e-01,  2.07031250e-01,  ...,\n",
      "           -4.04296875e-01,  1.57226562e-01,  4.53125000e-01]],\n",
      "\n",
      "         [[ 4.14062500e-01,  7.32421875e-02,  3.73046875e-01,  ...,\n",
      "            4.17968750e-01,  3.49609375e-01,  1.25000000e-01],\n",
      "          [ 2.55859375e-01, -8.59375000e-01, -2.72216797e-02,  ...,\n",
      "            3.47656250e-01, -2.55859375e-01,  2.22656250e-01],\n",
      "          [ 4.57031250e-01, -6.05468750e-01, -2.03125000e-01,  ...,\n",
      "            2.05078125e-01, -4.22363281e-02,  1.19140625e-01],\n",
      "          ...,\n",
      "          [ 1.98242188e-01,  1.08886719e-01, -2.94921875e-01,  ...,\n",
      "            1.08886719e-01, -3.51562500e-01,  4.66796875e-01],\n",
      "          [ 1.98242188e-01,  1.08886719e-01, -2.94921875e-01,  ...,\n",
      "            1.08886719e-01, -3.51562500e-01,  4.66796875e-01],\n",
      "          [ 1.98242188e-01,  1.08886719e-01, -2.94921875e-01,  ...,\n",
      "            1.08886719e-01, -3.51562500e-01,  4.66796875e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.87109375e-01, -1.66992188e-01, -1.19140625e-01,  ...,\n",
      "           -8.64257812e-02,  3.00781250e-01,  2.48046875e-01],\n",
      "          [ 1.19628906e-01,  5.42968750e-01,  1.78710938e-01,  ...,\n",
      "           -1.52343750e-01, -1.81640625e-01,  3.61328125e-02],\n",
      "          [ 4.35546875e-01,  8.94531250e-01, -8.20312500e-02,  ...,\n",
      "            5.12695312e-03, -4.37500000e-01, -3.29589844e-02],\n",
      "          ...,\n",
      "          [ 4.16015625e-01, -3.39843750e-01,  1.83593750e-01,  ...,\n",
      "           -3.68652344e-02,  2.29492188e-02,  1.40625000e-01],\n",
      "          [ 4.16015625e-01, -3.39843750e-01,  1.83593750e-01,  ...,\n",
      "           -3.68652344e-02,  2.29492188e-02,  1.40625000e-01],\n",
      "          [ 4.16015625e-01, -3.39843750e-01,  1.83593750e-01,  ...,\n",
      "           -3.68652344e-02,  2.29492188e-02,  1.40625000e-01]],\n",
      "\n",
      "         [[-2.85156250e-01,  4.10156250e-02, -9.25781250e-01,  ...,\n",
      "            7.07031250e-01, -3.98437500e-01, -1.70312500e+00],\n",
      "          [ 7.08007812e-02,  2.71484375e-01,  1.04980469e-01,  ...,\n",
      "            3.66210938e-02, -4.07714844e-02, -6.25000000e-02],\n",
      "          [ 8.78906250e-02,  1.64062500e-01,  7.17773438e-02,  ...,\n",
      "            1.48925781e-02, -1.04980469e-02,  3.79943848e-03],\n",
      "          ...,\n",
      "          [-1.55029297e-02, -3.88671875e-01,  1.71875000e-01,  ...,\n",
      "            2.03125000e-01,  3.67187500e-01,  4.80468750e-01],\n",
      "          [-1.55029297e-02, -3.88671875e-01,  1.71875000e-01,  ...,\n",
      "            2.03125000e-01,  3.67187500e-01,  4.80468750e-01],\n",
      "          [-1.55029297e-02, -3.88671875e-01,  1.71875000e-01,  ...,\n",
      "            2.03125000e-01,  3.67187500e-01,  4.80468750e-01]],\n",
      "\n",
      "         [[ 2.83203125e-01,  3.45703125e-01,  5.54687500e-01,  ...,\n",
      "           -3.43750000e-01, -9.37500000e-02,  2.25585938e-01],\n",
      "          [ 3.71093750e-02,  4.66796875e-01,  2.09960938e-01,  ...,\n",
      "           -3.65234375e-01, -1.14062500e+00,  1.17187500e+00],\n",
      "          [-1.44531250e-01,  8.30078125e-02, -8.83789062e-02,  ...,\n",
      "           -1.76757812e-01, -3.43750000e-01,  4.45312500e-01],\n",
      "          ...,\n",
      "          [ 2.50000000e-01,  5.46875000e-01,  2.81250000e-01,  ...,\n",
      "           -5.66406250e-01,  3.65234375e-01, -2.92968750e-01],\n",
      "          [ 2.50000000e-01,  5.46875000e-01,  2.81250000e-01,  ...,\n",
      "           -5.66406250e-01,  3.65234375e-01, -2.92968750e-01],\n",
      "          [ 2.50000000e-01,  5.46875000e-01,  2.81250000e-01,  ...,\n",
      "           -5.66406250e-01,  3.65234375e-01, -2.92968750e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-1.26953125e-01, -4.23828125e-01,  2.61718750e-01,  ...,\n",
      "            2.91015625e-01,  7.08007812e-02,  4.27734375e-01],\n",
      "          [-1.48437500e-01, -1.92382812e-01,  3.78906250e-01,  ...,\n",
      "           -7.66601562e-02,  3.84765625e-01,  7.46093750e-01],\n",
      "          [-3.57421875e-01, -6.25000000e-02,  3.43750000e-01,  ...,\n",
      "           -6.73828125e-02,  5.78125000e-01,  7.18750000e-01],\n",
      "          ...,\n",
      "          [-3.82812500e-01, -1.87500000e-01,  4.23828125e-01,  ...,\n",
      "            1.92382812e-01,  1.61132812e-01,  1.01562500e+00],\n",
      "          [-3.82812500e-01, -1.87500000e-01,  4.23828125e-01,  ...,\n",
      "            1.92382812e-01,  1.61132812e-01,  1.01562500e+00],\n",
      "          [-3.82812500e-01, -1.87500000e-01,  4.23828125e-01,  ...,\n",
      "            1.92382812e-01,  1.61132812e-01,  1.01562500e+00]],\n",
      "\n",
      "         [[-1.54687500e+00,  4.37500000e-01,  2.12500000e+00,  ...,\n",
      "            2.42187500e+00,  5.46264648e-03,  8.35937500e-01],\n",
      "          [ 2.73437500e-02, -9.66796875e-02, -4.55078125e-01,  ...,\n",
      "            2.10937500e-01,  8.04687500e-01,  1.82617188e-01],\n",
      "          [ 3.63281250e-01, -6.20117188e-02, -3.26171875e-01,  ...,\n",
      "            3.10546875e-01,  5.03906250e-01,  1.07421875e-01],\n",
      "          ...,\n",
      "          [-4.08203125e-01, -3.32031250e-01,  5.41992188e-02,  ...,\n",
      "            8.12500000e-01,  1.69921875e-01,  4.33593750e-01],\n",
      "          [-4.08203125e-01, -3.32031250e-01,  5.41992188e-02,  ...,\n",
      "            8.12500000e-01,  1.69921875e-01,  4.33593750e-01],\n",
      "          [-4.08203125e-01, -3.32031250e-01,  5.41992188e-02,  ...,\n",
      "            8.12500000e-01,  1.69921875e-01,  4.33593750e-01]],\n",
      "\n",
      "         [[-3.68652344e-02,  5.83496094e-02, -3.92578125e-01,  ...,\n",
      "           -6.73828125e-02, -2.81250000e-01,  1.35742188e-01],\n",
      "          [-1.82617188e-01,  4.00390625e-02, -4.04296875e-01,  ...,\n",
      "            1.40625000e-01,  3.14453125e-01, -6.54296875e-02],\n",
      "          [-3.02734375e-01,  4.48608398e-03, -4.76562500e-01,  ...,\n",
      "            1.05957031e-01,  3.28125000e-01, -1.58203125e-01],\n",
      "          ...,\n",
      "          [ 9.52148438e-02, -6.13281250e-01,  9.13085938e-02,  ...,\n",
      "           -9.17968750e-01, -6.13281250e-01, -1.17187500e-01],\n",
      "          [ 9.52148438e-02, -6.13281250e-01,  9.13085938e-02,  ...,\n",
      "           -9.17968750e-01, -6.13281250e-01, -1.17187500e-01],\n",
      "          [ 9.52148438e-02, -6.13281250e-01,  9.13085938e-02,  ...,\n",
      "           -9.17968750e-01, -6.13281250e-01, -1.17187500e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.60937500e-01,  1.90429688e-01, -2.83203125e-01,  ...,\n",
      "            1.33789062e-01, -2.61718750e-01,  2.59765625e-01],\n",
      "          [ 2.11914062e-01,  1.58203125e-01, -4.19921875e-01,  ...,\n",
      "           -5.34667969e-02,  1.53320312e-01,  1.25000000e-01],\n",
      "          [ 2.22656250e-01,  2.07031250e-01, -4.39453125e-01,  ...,\n",
      "           -9.86328125e-02,  1.90429688e-01,  1.77734375e-01],\n",
      "          ...,\n",
      "          [ 7.85156250e-01,  1.03515625e-01,  1.21093750e-01,  ...,\n",
      "            4.78515625e-01, -9.25781250e-01,  6.78710938e-02],\n",
      "          [ 7.85156250e-01,  1.03515625e-01,  1.21093750e-01,  ...,\n",
      "            4.78515625e-01, -9.25781250e-01,  6.78710938e-02],\n",
      "          [ 7.85156250e-01,  1.03515625e-01,  1.21093750e-01,  ...,\n",
      "            4.78515625e-01, -9.25781250e-01,  6.78710938e-02]],\n",
      "\n",
      "         [[-1.32812500e-01, -3.05175781e-02,  1.86920166e-03,  ...,\n",
      "           -1.78710938e-01,  1.62353516e-02, -5.00000000e-01],\n",
      "          [ 7.66601562e-02, -1.00708008e-02,  6.88476562e-02,  ...,\n",
      "           -6.54296875e-02,  8.74023438e-02, -5.85937500e-01],\n",
      "          [-1.09252930e-02, -2.75390625e-01,  5.61523438e-02,  ...,\n",
      "            1.94091797e-02,  2.05078125e-01, -9.41406250e-01],\n",
      "          ...,\n",
      "          [-5.97656250e-01,  2.81250000e-01, -2.02148438e-01,  ...,\n",
      "            4.39453125e-01, -5.27343750e-01, -2.79296875e-01],\n",
      "          [-5.97656250e-01,  2.81250000e-01, -2.02148438e-01,  ...,\n",
      "            4.39453125e-01, -5.27343750e-01, -2.79296875e-01],\n",
      "          [-5.97656250e-01,  2.81250000e-01, -2.02148438e-01,  ...,\n",
      "            4.39453125e-01, -5.27343750e-01, -2.79296875e-01]],\n",
      "\n",
      "         [[-2.71484375e-01,  2.01171875e-01, -1.82617188e-01,  ...,\n",
      "           -3.65234375e-01,  1.00097656e-01, -2.24609375e-01],\n",
      "          [-1.90429688e-01,  1.75781250e-01, -1.28906250e-01,  ...,\n",
      "           -2.98828125e-01,  6.25000000e-02, -2.05078125e-01],\n",
      "          [-2.27539062e-01,  1.58203125e-01, -7.71484375e-02,  ...,\n",
      "           -4.21875000e-01,  1.16699219e-01, -3.04687500e-01],\n",
      "          ...,\n",
      "          [ 7.86132812e-02,  3.84765625e-01,  3.71093750e-01,  ...,\n",
      "            1.62109375e-01,  5.93750000e-01, -6.64062500e-02],\n",
      "          [ 7.86132812e-02,  3.84765625e-01,  3.71093750e-01,  ...,\n",
      "            1.62109375e-01,  5.93750000e-01, -6.64062500e-02],\n",
      "          [ 7.86132812e-02,  3.84765625e-01,  3.71093750e-01,  ...,\n",
      "            1.62109375e-01,  5.93750000e-01, -6.64062500e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.01129150,  0.44335938, -0.60546875,  ...,  0.20605469,\n",
      "           -0.46484375, -0.62500000],\n",
      "          [-0.20605469, -0.19531250,  0.27343750,  ...,  0.47851562,\n",
      "           -0.07763672,  0.31250000],\n",
      "          [ 0.17968750, -0.13183594,  0.19335938,  ...,  0.21484375,\n",
      "            0.06494141,  0.26757812],\n",
      "          ...,\n",
      "          [ 0.17773438, -0.02453613, -0.76953125,  ...,  0.72265625,\n",
      "            0.93750000, -0.48828125],\n",
      "          [ 0.17773438, -0.02453613, -0.76953125,  ...,  0.72265625,\n",
      "            0.93750000, -0.48828125],\n",
      "          [ 0.17773438, -0.02453613, -0.76953125,  ...,  0.72265625,\n",
      "            0.93750000, -0.48828125]],\n",
      "\n",
      "         [[-0.03369141,  0.27343750,  0.10644531,  ..., -0.27343750,\n",
      "            0.05590820,  0.25000000],\n",
      "          [-0.82031250, -0.36523438,  0.48632812,  ...,  0.00891113,\n",
      "           -1.62500000,  1.76562500],\n",
      "          [-0.51562500,  0.04101562,  0.67187500,  ..., -0.15820312,\n",
      "           -1.67187500,  2.03125000],\n",
      "          ...,\n",
      "          [-0.11669922,  0.14257812,  0.28710938,  ..., -0.25390625,\n",
      "            0.00933838,  0.39453125],\n",
      "          [-0.11669922,  0.14257812,  0.28710938,  ..., -0.25390625,\n",
      "            0.00933838,  0.39453125],\n",
      "          [-0.11669922,  0.14257812,  0.28710938,  ..., -0.25390625,\n",
      "            0.00933838,  0.39453125]],\n",
      "\n",
      "         [[ 0.12304688,  0.25195312,  0.02502441,  ...,  0.25195312,\n",
      "           -0.20703125,  0.13183594],\n",
      "          [ 1.22656250,  0.37890625,  0.18554688,  ..., -0.68359375,\n",
      "           -0.91015625,  0.17871094],\n",
      "          [ 0.61328125,  0.40820312,  0.10644531,  ..., -0.35937500,\n",
      "           -0.71875000,  0.13574219],\n",
      "          ...,\n",
      "          [-0.05102539,  0.07324219,  0.17871094,  ...,  0.09863281,\n",
      "           -0.71484375,  0.18652344],\n",
      "          [-0.05102539,  0.07324219,  0.17871094,  ...,  0.09863281,\n",
      "           -0.71484375,  0.18652344],\n",
      "          [-0.05102539,  0.07324219,  0.17871094,  ...,  0.09863281,\n",
      "           -0.71484375,  0.18652344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.03613281, -0.08105469, -0.09619141,  ..., -0.22265625,\n",
      "            0.48632812,  0.10595703],\n",
      "          [ 0.22363281, -0.07226562,  0.24902344,  ..., -0.23828125,\n",
      "            0.01458740,  0.07275391],\n",
      "          [ 0.32031250,  0.09667969,  0.43359375,  ..., -0.20312500,\n",
      "           -0.20703125,  0.03564453],\n",
      "          ...,\n",
      "          [ 0.03173828,  0.32421875,  0.30273438,  ..., -0.39843750,\n",
      "            0.64843750,  0.25976562],\n",
      "          [ 0.03173828,  0.32421875,  0.30273438,  ..., -0.39843750,\n",
      "            0.64843750,  0.25976562],\n",
      "          [ 0.03173828,  0.32421875,  0.30273438,  ..., -0.39843750,\n",
      "            0.64843750,  0.25976562]],\n",
      "\n",
      "         [[-0.22265625, -0.11865234,  0.16308594,  ...,  0.25390625,\n",
      "            0.04809570, -0.30468750],\n",
      "          [ 0.25390625, -0.18652344, -0.09912109,  ...,  0.80078125,\n",
      "            1.02343750,  0.30078125],\n",
      "          [ 0.38085938, -0.29687500, -0.37304688,  ...,  1.07812500,\n",
      "            1.45312500,  0.82031250],\n",
      "          ...,\n",
      "          [ 1.02343750,  0.00799561,  0.07226562,  ..., -0.52734375,\n",
      "            0.02416992, -0.71093750],\n",
      "          [ 1.02343750,  0.00799561,  0.07226562,  ..., -0.52734375,\n",
      "            0.02416992, -0.71093750],\n",
      "          [ 1.02343750,  0.00799561,  0.07226562,  ..., -0.52734375,\n",
      "            0.02416992, -0.71093750]],\n",
      "\n",
      "         [[ 0.98046875, -1.05468750,  1.53906250,  ..., -1.87500000,\n",
      "            0.15332031,  1.46875000],\n",
      "          [-0.00946045, -0.21093750,  0.20214844,  ..., -0.15429688,\n",
      "           -0.13085938,  0.51171875],\n",
      "          [ 0.23046875, -0.48046875,  0.49023438,  ..., -0.46679688,\n",
      "            0.23730469,  0.30664062],\n",
      "          ...,\n",
      "          [ 0.26953125, -0.04882812, -0.33984375,  ...,  0.14160156,\n",
      "           -0.57031250, -0.25390625],\n",
      "          [ 0.26953125, -0.04882812, -0.33984375,  ...,  0.14160156,\n",
      "           -0.57031250, -0.25390625],\n",
      "          [ 0.26953125, -0.04882812, -0.33984375,  ...,  0.14160156,\n",
      "           -0.57031250, -0.25390625]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.06542969, -0.28515625, -0.11914062,  ...,  0.26953125,\n",
      "            0.07177734,  0.17968750],\n",
      "          [-0.14550781, -0.04541016, -0.05712891,  ...,  0.01123047,\n",
      "           -0.51953125,  0.10546875],\n",
      "          [-0.26953125,  0.20703125, -0.00653076,  ..., -0.13769531,\n",
      "           -0.39648438, -0.03784180],\n",
      "          ...,\n",
      "          [-0.17187500, -0.21777344, -0.14453125,  ...,  0.01141357,\n",
      "            0.20019531, -0.27539062],\n",
      "          [-0.17187500, -0.21777344, -0.14453125,  ...,  0.01141357,\n",
      "            0.20019531, -0.27539062],\n",
      "          [-0.17187500, -0.21777344, -0.14453125,  ...,  0.01141357,\n",
      "            0.20019531, -0.27539062]],\n",
      "\n",
      "         [[ 0.13281250, -0.30273438, -0.11132812,  ...,  0.11230469,\n",
      "           -0.16699219, -0.38476562],\n",
      "          [ 0.48632812,  0.00402832,  0.53125000,  ...,  0.01007080,\n",
      "           -0.14453125, -0.77734375],\n",
      "          [ 0.41406250, -0.01916504,  0.61718750,  ..., -0.10888672,\n",
      "           -0.13183594, -0.74609375],\n",
      "          ...,\n",
      "          [-0.14062500,  0.17773438, -0.21679688,  ..., -0.41992188,\n",
      "            0.59765625, -0.64843750],\n",
      "          [-0.14062500,  0.17773438, -0.21679688,  ..., -0.41992188,\n",
      "            0.59765625, -0.64843750],\n",
      "          [-0.14062500,  0.17773438, -0.21679688,  ..., -0.41992188,\n",
      "            0.59765625, -0.64843750]],\n",
      "\n",
      "         [[ 0.23144531,  0.03015137, -0.31835938,  ..., -0.03027344,\n",
      "            0.17089844,  0.02185059],\n",
      "          [-0.71484375,  0.48632812, -0.22558594,  ..., -0.91015625,\n",
      "            0.51953125, -0.43164062],\n",
      "          [-0.71484375,  0.38671875,  0.07958984,  ..., -1.10156250,\n",
      "            0.42187500, -0.37304688],\n",
      "          ...,\n",
      "          [-0.20507812,  0.12988281, -0.04223633,  ...,  0.20312500,\n",
      "            0.32617188,  0.27734375],\n",
      "          [-0.20507812,  0.12988281, -0.04223633,  ...,  0.20312500,\n",
      "            0.32617188,  0.27734375],\n",
      "          [-0.20507812,  0.12988281, -0.04223633,  ...,  0.20312500,\n",
      "            0.32617188,  0.27734375]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.23046875, -0.47460938, -0.77734375,  ..., -0.67968750,\n",
      "           -0.50000000, -0.15234375],\n",
      "          [ 0.01586914, -0.31250000, -0.74609375,  ..., -0.45898438,\n",
      "           -0.21093750,  0.00836182],\n",
      "          [ 0.20312500, -0.26171875, -0.52343750,  ..., -0.34960938,\n",
      "           -0.34375000, -0.24218750],\n",
      "          ...,\n",
      "          [ 0.09179688, -0.35937500, -0.58203125,  ..., -0.45312500,\n",
      "           -0.34570312, -0.40039062],\n",
      "          [ 0.09179688, -0.35937500, -0.58203125,  ..., -0.45312500,\n",
      "           -0.34570312, -0.40039062],\n",
      "          [ 0.09179688, -0.35937500, -0.58203125,  ..., -0.45312500,\n",
      "           -0.34570312, -0.40039062]],\n",
      "\n",
      "         [[ 0.25000000, -0.12353516,  0.12109375,  ..., -0.13476562,\n",
      "           -0.14746094, -0.11621094],\n",
      "          [ 0.09863281, -0.23437500, -0.06127930,  ...,  0.20996094,\n",
      "           -0.48046875,  0.31054688],\n",
      "          [ 0.14453125,  0.17382812,  0.05102539,  ..., -0.03222656,\n",
      "           -0.32617188,  0.43945312],\n",
      "          ...,\n",
      "          [ 0.19531250, -0.11035156,  0.13867188,  ..., -0.05810547,\n",
      "           -0.28710938, -0.08593750],\n",
      "          [ 0.19531250, -0.11035156,  0.13867188,  ..., -0.05810547,\n",
      "           -0.28710938, -0.08593750],\n",
      "          [ 0.19531250, -0.11035156,  0.13867188,  ..., -0.05810547,\n",
      "           -0.28710938, -0.08593750]],\n",
      "\n",
      "         [[ 0.18554688, -0.07812500, -0.55078125,  ...,  0.02722168,\n",
      "           -0.45703125,  0.43359375],\n",
      "          [ 0.20996094,  0.20800781, -0.64453125,  ...,  0.67968750,\n",
      "            0.08691406,  0.82031250],\n",
      "          [ 0.10351562,  0.14648438, -0.63281250,  ...,  0.51953125,\n",
      "           -0.04785156,  0.70703125],\n",
      "          ...,\n",
      "          [ 0.22265625, -0.09228516, -0.52343750,  ...,  0.11083984,\n",
      "           -0.33203125,  0.47851562],\n",
      "          [ 0.22265625, -0.09228516, -0.52343750,  ...,  0.11083984,\n",
      "           -0.33203125,  0.47851562],\n",
      "          [ 0.22265625, -0.09228516, -0.52343750,  ...,  0.11083984,\n",
      "           -0.33203125,  0.47851562]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-1.54296875e-01, -3.95507812e-02,  1.17675781e-01,  ...,\n",
      "            7.47680664e-03,  2.73437500e-01, -5.71289062e-02],\n",
      "          [-4.33593750e-01,  3.66210938e-04,  5.03906250e-01,  ...,\n",
      "            2.28515625e-01,  2.75390625e-01, -2.84423828e-02],\n",
      "          [-1.66015625e-01, -6.73828125e-02,  2.27539062e-01,  ...,\n",
      "            2.13867188e-01,  2.67578125e-01, -1.02050781e-01],\n",
      "          ...,\n",
      "          [-1.27929688e-01,  9.47265625e-02,  4.55078125e-01,  ...,\n",
      "           -1.15234375e-01,  5.31250000e-01,  4.16015625e-01],\n",
      "          [-1.27929688e-01,  9.47265625e-02,  4.55078125e-01,  ...,\n",
      "           -1.15234375e-01,  5.31250000e-01,  4.16015625e-01],\n",
      "          [-1.27929688e-01,  9.47265625e-02,  4.55078125e-01,  ...,\n",
      "           -1.15234375e-01,  5.31250000e-01,  4.16015625e-01]],\n",
      "\n",
      "         [[-2.44140625e-01,  3.67187500e-01, -2.47070312e-01,  ...,\n",
      "            5.39550781e-02,  1.13769531e-01,  2.50000000e-01],\n",
      "          [-1.40625000e-01, -3.96484375e-01,  9.15527344e-03,  ...,\n",
      "            1.44531250e-01,  2.38281250e-01,  2.08007812e-01],\n",
      "          [-1.92382812e-01, -6.87500000e-01, -1.38671875e-01,  ...,\n",
      "            5.71289062e-02,  1.70898438e-01,  5.62500000e-01],\n",
      "          ...,\n",
      "          [-2.14843750e-01, -1.86523438e-01, -2.75390625e-01,  ...,\n",
      "            2.80761719e-03,  1.64062500e-01,  2.53906250e-01],\n",
      "          [-2.14843750e-01, -1.86523438e-01, -2.75390625e-01,  ...,\n",
      "            2.80761719e-03,  1.64062500e-01,  2.53906250e-01],\n",
      "          [-2.14843750e-01, -1.86523438e-01, -2.75390625e-01,  ...,\n",
      "            2.80761719e-03,  1.64062500e-01,  2.53906250e-01]],\n",
      "\n",
      "         [[ 3.10546875e-01, -1.77734375e-01, -3.53515625e-01,  ...,\n",
      "            2.48046875e-01,  2.51953125e-01,  2.34375000e-01],\n",
      "          [-5.10253906e-02, -1.44531250e-01, -6.93359375e-02,  ...,\n",
      "           -5.39550781e-02,  6.83593750e-02, -1.19140625e-01],\n",
      "          [ 5.73730469e-02, -1.18652344e-01,  7.32421875e-02,  ...,\n",
      "           -1.43554688e-01,  6.59179688e-02,  7.66601562e-02],\n",
      "          ...,\n",
      "          [-3.00781250e-01,  3.93676758e-03, -1.17187500e-01,  ...,\n",
      "           -1.89453125e-01, -1.02050781e-01, -6.25000000e-01],\n",
      "          [-3.00781250e-01,  3.93676758e-03, -1.17187500e-01,  ...,\n",
      "           -1.89453125e-01, -1.02050781e-01, -6.25000000e-01],\n",
      "          [-3.00781250e-01,  3.93676758e-03, -1.17187500e-01,  ...,\n",
      "           -1.89453125e-01, -1.02050781e-01, -6.25000000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.53320312e-01,  1.72851562e-01,  3.08593750e-01,  ...,\n",
      "           -1.76757812e-01, -1.63085938e-01, -1.87683105e-03],\n",
      "          [ 1.47460938e-01, -4.97436523e-03,  2.87109375e-01,  ...,\n",
      "           -3.94531250e-01,  1.55273438e-01,  9.47265625e-02],\n",
      "          [-6.49414062e-02, -1.57226562e-01,  1.28906250e-01,  ...,\n",
      "           -4.14062500e-01, -3.71093750e-02,  3.37890625e-01],\n",
      "          ...,\n",
      "          [ 2.17285156e-02, -8.98437500e-02,  1.59179688e-01,  ...,\n",
      "            5.15625000e-01,  2.19726562e-02,  2.61718750e-01],\n",
      "          [ 2.17285156e-02, -8.98437500e-02,  1.59179688e-01,  ...,\n",
      "            5.15625000e-01,  2.19726562e-02,  2.61718750e-01],\n",
      "          [ 2.17285156e-02, -8.98437500e-02,  1.59179688e-01,  ...,\n",
      "            5.15625000e-01,  2.19726562e-02,  2.61718750e-01]],\n",
      "\n",
      "         [[ 1.43554688e-01, -4.35546875e-01, -2.63671875e-01,  ...,\n",
      "            1.19140625e-01, -1.04980469e-01,  2.69531250e-01],\n",
      "          [ 2.05078125e-01, -5.31250000e-01,  1.30615234e-02,  ...,\n",
      "            1.98242188e-01, -4.62890625e-01,  7.12890625e-02],\n",
      "          [-1.32446289e-02, -4.60937500e-01,  1.53808594e-02,  ...,\n",
      "            1.22680664e-02, -4.96093750e-01, -3.44238281e-02],\n",
      "          ...,\n",
      "          [-8.88671875e-02, -2.63671875e-01, -5.03906250e-01,  ...,\n",
      "           -7.91015625e-02, -2.71484375e-01, -3.90625000e-01],\n",
      "          [-8.88671875e-02, -2.63671875e-01, -5.03906250e-01,  ...,\n",
      "           -7.91015625e-02, -2.71484375e-01, -3.90625000e-01],\n",
      "          [-8.88671875e-02, -2.63671875e-01, -5.03906250e-01,  ...,\n",
      "           -7.91015625e-02, -2.71484375e-01, -3.90625000e-01]],\n",
      "\n",
      "         [[ 4.45312500e-01,  3.76953125e-01,  2.37304688e-01,  ...,\n",
      "            1.02050781e-01, -5.54199219e-02,  1.86767578e-02],\n",
      "          [ 1.07812500e+00, -2.11914062e-01, -1.30468750e+00,  ...,\n",
      "            6.25000000e-01, -9.41406250e-01,  1.87500000e-01],\n",
      "          [ 9.37500000e-01, -6.25000000e-01, -1.98437500e+00,  ...,\n",
      "            3.39843750e-01, -7.89062500e-01, -1.04980469e-02],\n",
      "          ...,\n",
      "          [ 2.87109375e-01,  3.20312500e-01,  1.66015625e-01,  ...,\n",
      "            2.05078125e-01, -1.45507812e-01, -4.49218750e-01],\n",
      "          [ 2.87109375e-01,  3.20312500e-01,  1.66015625e-01,  ...,\n",
      "            2.05078125e-01, -1.45507812e-01, -4.49218750e-01],\n",
      "          [ 2.87109375e-01,  3.20312500e-01,  1.66015625e-01,  ...,\n",
      "            2.05078125e-01, -1.45507812e-01, -4.49218750e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 6.67968750e-01,  4.23828125e-01, -1.24511719e-01,  ...,\n",
      "            1.90429688e-01,  1.84375000e+00,  3.57421875e-01],\n",
      "          [ 3.43750000e+00,  4.75000000e+00, -7.96875000e-01,  ...,\n",
      "           -4.31640625e-01,  6.18750000e+00,  2.14843750e-01],\n",
      "          [ 2.25000000e+00,  3.26562500e+00, -5.19531250e-01,  ...,\n",
      "           -1.54296875e-01,  4.43750000e+00,  3.28125000e-01],\n",
      "          ...,\n",
      "          [-4.00390625e-01, -3.02734375e-01,  4.00390625e-01,  ...,\n",
      "            1.07910156e-01,  5.11718750e-01,  7.03125000e-01],\n",
      "          [-4.00390625e-01, -3.02734375e-01,  4.00390625e-01,  ...,\n",
      "            1.07910156e-01,  5.11718750e-01,  7.03125000e-01],\n",
      "          [-4.00390625e-01, -3.02734375e-01,  4.00390625e-01,  ...,\n",
      "            1.07910156e-01,  5.11718750e-01,  7.03125000e-01]],\n",
      "\n",
      "         [[ 2.60925293e-03, -2.67578125e-01, -1.50390625e-01,  ...,\n",
      "           -2.87109375e-01, -2.85644531e-02, -3.18359375e-01],\n",
      "          [ 1.89453125e-01,  2.67578125e-01,  5.78125000e-01,  ...,\n",
      "            6.21093750e-01, -6.91406250e-01, -8.86718750e-01],\n",
      "          [ 5.98144531e-02, -1.58203125e-01,  1.51977539e-02,  ...,\n",
      "            1.51367188e-01, -3.96484375e-01, -6.64062500e-01],\n",
      "          ...,\n",
      "          [ 5.42968750e-01, -3.35937500e-01, -1.26953125e-01,  ...,\n",
      "           -1.03125000e+00,  2.87109375e-01,  2.73437500e-01],\n",
      "          [ 5.42968750e-01, -3.35937500e-01, -1.26953125e-01,  ...,\n",
      "           -1.03125000e+00,  2.87109375e-01,  2.73437500e-01],\n",
      "          [ 5.42968750e-01, -3.35937500e-01, -1.26953125e-01,  ...,\n",
      "           -1.03125000e+00,  2.87109375e-01,  2.73437500e-01]],\n",
      "\n",
      "         [[ 5.50781250e-01, -7.92968750e-01, -1.38671875e-01,  ...,\n",
      "           -3.35937500e-01,  2.65625000e-01, -3.30078125e-01],\n",
      "          [ 3.12500000e-01, -1.84570312e-01, -1.64062500e-01,  ...,\n",
      "           -2.94921875e-01,  1.17675781e-01, -1.66992188e-01],\n",
      "          [ 2.39257812e-01, -3.47656250e-01, -1.46484375e-01,  ...,\n",
      "           -1.82617188e-01,  1.06933594e-01, -2.57812500e-01],\n",
      "          ...,\n",
      "          [ 5.42968750e-01, -1.24218750e+00,  4.32128906e-02,  ...,\n",
      "           -7.26562500e-01,  3.51562500e-01, -3.88671875e-01],\n",
      "          [ 5.42968750e-01, -1.24218750e+00,  4.32128906e-02,  ...,\n",
      "           -7.26562500e-01,  3.51562500e-01, -3.88671875e-01],\n",
      "          [ 5.42968750e-01, -1.24218750e+00,  4.32128906e-02,  ...,\n",
      "           -7.26562500e-01,  3.51562500e-01, -3.88671875e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.89062500e-01, -8.05664062e-02, -7.08007812e-02,  ...,\n",
      "            2.85156250e-01, -5.54199219e-02,  3.08593750e-01],\n",
      "          [-6.05468750e-01,  2.63671875e-01,  5.46875000e-01,  ...,\n",
      "            4.96093750e-01, -6.98242188e-02,  2.03125000e-01],\n",
      "          [-6.67968750e-01,  4.46777344e-02,  1.00097656e-01,  ...,\n",
      "            2.71484375e-01, -1.47460938e-01,  1.16210938e-01],\n",
      "          ...,\n",
      "          [-8.20312500e-01, -4.51171875e-01, -5.07812500e-01,  ...,\n",
      "           -3.10546875e-01, -4.88281250e-01,  9.32617188e-02],\n",
      "          [-8.20312500e-01, -4.51171875e-01, -5.07812500e-01,  ...,\n",
      "           -3.10546875e-01, -4.88281250e-01,  9.32617188e-02],\n",
      "          [-8.20312500e-01, -4.51171875e-01, -5.07812500e-01,  ...,\n",
      "           -3.10546875e-01, -4.88281250e-01,  9.32617188e-02]],\n",
      "\n",
      "         [[ 1.77001953e-02, -3.61328125e-01,  9.60937500e-01,  ...,\n",
      "            1.17968750e+00, -1.04687500e+00,  3.01513672e-02],\n",
      "          [-8.25195312e-02, -5.00000000e-01, -1.80664062e-02,  ...,\n",
      "           -5.85937500e-01,  2.98828125e-01,  2.77343750e-01],\n",
      "          [ 5.10253906e-02, -4.29687500e-01,  9.17968750e-02,  ...,\n",
      "           -3.30078125e-01,  2.51953125e-01,  2.40234375e-01],\n",
      "          ...,\n",
      "          [-2.22656250e-01, -7.42187500e-01,  1.07031250e+00,  ...,\n",
      "            1.60156250e+00, -1.16406250e+00,  4.61425781e-02],\n",
      "          [-2.22656250e-01, -7.42187500e-01,  1.07031250e+00,  ...,\n",
      "            1.60156250e+00, -1.16406250e+00,  4.61425781e-02],\n",
      "          [-2.22656250e-01, -7.42187500e-01,  1.07031250e+00,  ...,\n",
      "            1.60156250e+00, -1.16406250e+00,  4.61425781e-02]],\n",
      "\n",
      "         [[-3.53515625e-01, -9.17968750e-02, -3.41796875e-01,  ...,\n",
      "            2.81250000e-01,  2.65625000e-01,  3.33984375e-01],\n",
      "          [-6.21093750e-01, -8.86718750e-01, -2.11914062e-01,  ...,\n",
      "            1.80664062e-01,  7.65625000e-01,  4.08203125e-01],\n",
      "          [-7.73437500e-01, -9.14062500e-01, -1.93359375e-01,  ...,\n",
      "            7.17773438e-02,  9.29687500e-01,  3.51562500e-01],\n",
      "          ...,\n",
      "          [-3.88183594e-02, -4.33593750e-01, -7.46093750e-01,  ...,\n",
      "            2.11914062e-01,  6.39648438e-02,  3.20312500e-01],\n",
      "          [-3.88183594e-02, -4.33593750e-01, -7.46093750e-01,  ...,\n",
      "            2.11914062e-01,  6.39648438e-02,  3.20312500e-01],\n",
      "          [-3.88183594e-02, -4.33593750e-01, -7.46093750e-01,  ...,\n",
      "            2.11914062e-01,  6.39648438e-02,  3.20312500e-01]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 1.07910156e-01, -1.29882812e-01,  1.22558594e-01,  ...,\n",
      "           -5.70312500e-01,  1.25000000e-01,  1.63574219e-02],\n",
      "          [ 3.63281250e-01, -2.65625000e-01, -8.20312500e-02,  ...,\n",
      "           -1.00781250e+00,  2.25585938e-01, -3.29589844e-02],\n",
      "          [ 2.89062500e-01, -3.26171875e-01,  9.22851562e-02,  ...,\n",
      "           -4.51171875e-01,  4.23828125e-01, -2.99072266e-02],\n",
      "          ...,\n",
      "          [ 3.02734375e-01, -1.84570312e-01,  2.77343750e-01,  ...,\n",
      "           -5.70312500e-01,  5.97656250e-01, -1.22558594e-01],\n",
      "          [ 3.02734375e-01, -1.84570312e-01,  2.77343750e-01,  ...,\n",
      "           -5.70312500e-01,  5.97656250e-01, -1.22558594e-01],\n",
      "          [ 3.02734375e-01, -1.84570312e-01,  2.77343750e-01,  ...,\n",
      "           -5.70312500e-01,  5.97656250e-01, -1.22558594e-01]],\n",
      "\n",
      "         [[ 4.29687500e-01, -8.08593750e-01, -1.20605469e-01,  ...,\n",
      "            1.48773193e-03,  1.61132812e-01, -1.46484375e-02],\n",
      "          [ 1.70898438e-01, -4.39453125e-01, -3.41796875e-02,  ...,\n",
      "           -1.86523438e-01,  3.98437500e-01, -7.91015625e-02],\n",
      "          [-1.48437500e-01, -5.50781250e-01, -1.98242188e-01,  ...,\n",
      "           -1.73828125e-01,  4.88281250e-02, -4.93164062e-02],\n",
      "          ...,\n",
      "          [-6.05468750e-01, -9.47265625e-02,  1.00781250e+00,  ...,\n",
      "            4.90234375e-01, -1.42578125e-01, -2.89062500e-01],\n",
      "          [-6.05468750e-01, -9.47265625e-02,  1.00781250e+00,  ...,\n",
      "            4.90234375e-01, -1.42578125e-01, -2.89062500e-01],\n",
      "          [-6.05468750e-01, -9.47265625e-02,  1.00781250e+00,  ...,\n",
      "            4.90234375e-01, -1.42578125e-01, -2.89062500e-01]],\n",
      "\n",
      "         [[-5.00000000e-01, -3.92578125e-01,  3.32031250e-01,  ...,\n",
      "            6.32812500e-01,  6.60156250e-01,  7.34375000e-01],\n",
      "          [ 2.49023438e-01, -1.30859375e-01,  3.82812500e-01,  ...,\n",
      "            4.84375000e-01,  4.55078125e-01,  8.93554688e-02],\n",
      "          [ 1.09375000e-01, -9.37500000e-02,  1.28906250e-01,  ...,\n",
      "            2.55859375e-01,  3.02734375e-01, -1.25976562e-01],\n",
      "          ...,\n",
      "          [ 1.46875000e+00,  5.15625000e-01, -1.12500000e+00,  ...,\n",
      "            7.85156250e-01,  2.40625000e+00, -9.37500000e-01],\n",
      "          [ 1.46875000e+00,  5.15625000e-01, -1.12500000e+00,  ...,\n",
      "            7.85156250e-01,  2.40625000e+00, -9.37500000e-01],\n",
      "          [ 1.46875000e+00,  5.15625000e-01, -1.12500000e+00,  ...,\n",
      "            7.85156250e-01,  2.40625000e+00, -9.37500000e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.48315430e-02,  1.27563477e-02, -2.67333984e-02,  ...,\n",
      "            9.42382812e-02,  1.83593750e-01,  1.31835938e-01],\n",
      "          [ 4.60937500e-01, -2.59765625e-01,  2.89062500e-01,  ...,\n",
      "           -4.72656250e-01,  1.75781250e-02, -3.63281250e-01],\n",
      "          [ 5.03906250e-01, -1.67968750e-01,  2.00195312e-01,  ...,\n",
      "           -5.15625000e-01,  4.34570312e-02, -3.10546875e-01],\n",
      "          ...,\n",
      "          [ 5.63964844e-02,  8.00781250e-02, -7.37304688e-02,  ...,\n",
      "            4.66796875e-01, -9.13085938e-02,  7.92968750e-01],\n",
      "          [ 5.63964844e-02,  8.00781250e-02, -7.37304688e-02,  ...,\n",
      "            4.66796875e-01, -9.13085938e-02,  7.92968750e-01],\n",
      "          [ 5.63964844e-02,  8.00781250e-02, -7.37304688e-02,  ...,\n",
      "            4.66796875e-01, -9.13085938e-02,  7.92968750e-01]],\n",
      "\n",
      "         [[ 2.65625000e-01, -1.27929688e-01, -2.65625000e-01,  ...,\n",
      "            2.36328125e-01, -4.16015625e-01, -1.72851562e-01],\n",
      "          [ 3.04687500e-01, -1.51977539e-02,  1.17187500e+00,  ...,\n",
      "            4.29687500e-01, -5.46875000e-01,  4.76562500e-01],\n",
      "          [ 2.20703125e-01, -3.45703125e-01,  1.05468750e+00,  ...,\n",
      "            5.31250000e-01, -7.61718750e-01, -1.10156250e+00],\n",
      "          ...,\n",
      "          [ 4.72656250e-01, -2.41210938e-01,  4.94140625e-01,  ...,\n",
      "           -5.93261719e-02, -7.95898438e-02, -1.18750000e+00],\n",
      "          [ 4.72656250e-01, -2.41210938e-01,  4.94140625e-01,  ...,\n",
      "           -5.93261719e-02, -7.95898438e-02, -1.18750000e+00],\n",
      "          [ 4.72656250e-01, -2.41210938e-01,  4.94140625e-01,  ...,\n",
      "           -5.93261719e-02, -7.95898438e-02, -1.18750000e+00]],\n",
      "\n",
      "         [[-5.54687500e-01, -2.85156250e-01,  2.69531250e-01,  ...,\n",
      "           -2.81250000e-01, -3.69140625e-01,  2.67578125e-01],\n",
      "          [ 1.85546875e-01,  7.96875000e-01, -2.87109375e-01,  ...,\n",
      "           -3.39843750e-01, -4.23828125e-01,  2.05078125e-02],\n",
      "          [ 1.25000000e-01,  4.98046875e-01, -1.07910156e-01,  ...,\n",
      "           -1.52343750e-01, -1.72851562e-01, -1.81884766e-02],\n",
      "          ...,\n",
      "          [ 7.56835938e-02,  2.91015625e-01, -4.12109375e-01,  ...,\n",
      "           -3.97949219e-02, -5.02929688e-02, -6.29882812e-02],\n",
      "          [ 7.56835938e-02,  2.91015625e-01, -4.12109375e-01,  ...,\n",
      "           -3.97949219e-02, -5.02929688e-02, -6.29882812e-02],\n",
      "          [ 7.56835938e-02,  2.91015625e-01, -4.12109375e-01,  ...,\n",
      "           -3.97949219e-02, -5.02929688e-02, -6.29882812e-02]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-2.92968750e-02,  1.87500000e-01,  8.15429688e-02,  ...,\n",
      "           -1.13769531e-01, -1.62109375e-01,  4.78515625e-02],\n",
      "          [-2.49023438e-01, -1.13281250e-01, -1.12304688e-02,  ...,\n",
      "           -1.06933594e-01, -2.48046875e-01,  5.70678711e-03],\n",
      "          [-2.53906250e-01, -5.85937500e-02,  6.25000000e-02,  ...,\n",
      "           -1.04980469e-01, -2.07031250e-01,  1.31835938e-01],\n",
      "          ...,\n",
      "          [-3.75000000e-01,  4.44335938e-02, -1.11816406e-01,  ...,\n",
      "           -1.48437500e-01,  1.73339844e-02,  1.20117188e-01],\n",
      "          [-3.75000000e-01,  4.44335938e-02, -1.11816406e-01,  ...,\n",
      "           -1.48437500e-01,  1.73339844e-02,  1.20117188e-01],\n",
      "          [-3.75000000e-01,  4.44335938e-02, -1.11816406e-01,  ...,\n",
      "           -1.48437500e-01,  1.73339844e-02,  1.20117188e-01]],\n",
      "\n",
      "         [[-1.47460938e-01,  4.76562500e-01,  1.86523438e-01,  ...,\n",
      "           -1.54296875e-01, -3.73046875e-01,  1.97265625e-01],\n",
      "          [ 2.23632812e-01,  1.25781250e+00,  1.34375000e+00,  ...,\n",
      "           -2.10937500e-01,  4.02343750e-01,  1.40625000e+00],\n",
      "          [ 2.21679688e-01,  9.14062500e-01,  6.91406250e-01,  ...,\n",
      "           -2.63671875e-01,  1.04980469e-01,  5.54687500e-01],\n",
      "          ...,\n",
      "          [-1.58203125e-01,  4.66796875e-01, -1.57226562e-01,  ...,\n",
      "           -6.03027344e-02, -1.38549805e-02, -2.59765625e-01],\n",
      "          [-1.58203125e-01,  4.66796875e-01, -1.57226562e-01,  ...,\n",
      "           -6.03027344e-02, -1.38549805e-02, -2.59765625e-01],\n",
      "          [-1.58203125e-01,  4.66796875e-01, -1.57226562e-01,  ...,\n",
      "           -6.03027344e-02, -1.38549805e-02, -2.59765625e-01]],\n",
      "\n",
      "         [[ 1.26953125e-01, -1.08886719e-01, -2.51953125e-01,  ...,\n",
      "           -1.11328125e-01,  8.00781250e-02,  1.36718750e-01],\n",
      "          [ 3.24707031e-02,  1.13769531e-01, -5.11718750e-01,  ...,\n",
      "           -1.47460938e-01,  1.92382812e-01,  2.78320312e-02],\n",
      "          [ 7.81250000e-02,  4.90722656e-02, -3.65234375e-01,  ...,\n",
      "           -2.67578125e-01,  1.90429688e-01, -9.57031250e-02],\n",
      "          ...,\n",
      "          [ 2.86865234e-02, -2.68554688e-02, -1.36718750e-01,  ...,\n",
      "           -1.79687500e-01, -4.10156250e-02,  3.78906250e-01],\n",
      "          [ 2.86865234e-02, -2.68554688e-02, -1.36718750e-01,  ...,\n",
      "           -1.79687500e-01, -4.10156250e-02,  3.78906250e-01],\n",
      "          [ 2.86865234e-02, -2.68554688e-02, -1.36718750e-01,  ...,\n",
      "           -1.79687500e-01, -4.10156250e-02,  3.78906250e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.63085938e-01, -7.91015625e-02,  1.20117188e-01,  ...,\n",
      "           -2.04101562e-01, -2.46093750e-01, -1.42578125e-01],\n",
      "          [ 2.14843750e-02,  1.33056641e-02,  1.47460938e-01,  ...,\n",
      "           -1.59179688e-01, -1.08886719e-01,  2.48718262e-03],\n",
      "          [-1.48315430e-02,  2.75390625e-01,  2.50000000e-01,  ...,\n",
      "           -2.53906250e-01, -2.55126953e-02,  1.84570312e-01],\n",
      "          ...,\n",
      "          [-1.41406250e+00, -8.59375000e-01, -2.67578125e-01,  ...,\n",
      "           -7.46093750e-01, -7.65625000e-01,  3.43750000e-01],\n",
      "          [-1.41406250e+00, -8.59375000e-01, -2.67578125e-01,  ...,\n",
      "           -7.46093750e-01, -7.65625000e-01,  3.43750000e-01],\n",
      "          [-1.41406250e+00, -8.59375000e-01, -2.67578125e-01,  ...,\n",
      "           -7.46093750e-01, -7.65625000e-01,  3.43750000e-01]],\n",
      "\n",
      "         [[-4.96093750e-01, -2.58789062e-02,  3.41796875e-01,  ...,\n",
      "           -2.86865234e-02, -2.24609375e-02, -1.48437500e-01],\n",
      "          [-8.71093750e-01, -3.47900391e-03,  1.17968750e+00,  ...,\n",
      "            2.63671875e-01, -9.71679688e-02,  2.08007812e-01],\n",
      "          [-9.10156250e-01, -4.06250000e-01,  1.25781250e+00,  ...,\n",
      "            2.89062500e-01, -3.32031250e-02, -9.81445312e-02],\n",
      "          ...,\n",
      "          [-1.90429688e-01,  1.75781250e-01,  2.73437500e-01,  ...,\n",
      "           -1.64062500e-01,  8.39843750e-02,  2.17285156e-02],\n",
      "          [-1.90429688e-01,  1.75781250e-01,  2.73437500e-01,  ...,\n",
      "           -1.64062500e-01,  8.39843750e-02,  2.17285156e-02],\n",
      "          [-1.90429688e-01,  1.75781250e-01,  2.73437500e-01,  ...,\n",
      "           -1.64062500e-01,  8.39843750e-02,  2.17285156e-02]],\n",
      "\n",
      "         [[ 6.48437500e-01,  1.07910156e-01,  1.09375000e-01,  ...,\n",
      "           -4.49218750e-01,  3.78906250e-01,  1.25732422e-02],\n",
      "          [ 1.63085938e-01,  1.72851562e-01,  6.04248047e-03,  ...,\n",
      "           -1.04003906e-01,  5.61523438e-03, -2.57812500e-01],\n",
      "          [ 2.48046875e-01,  1.91406250e-01,  2.63671875e-02,  ...,\n",
      "           -1.51367188e-01,  6.82830811e-04, -1.87500000e-01],\n",
      "          ...,\n",
      "          [ 4.37500000e-01, -4.23828125e-01,  7.30468750e-01,  ...,\n",
      "            4.27246094e-02, -1.87500000e-01, -7.38525391e-03],\n",
      "          [ 4.37500000e-01, -4.23828125e-01,  7.30468750e-01,  ...,\n",
      "            4.27246094e-02, -1.87500000e-01, -7.38525391e-03],\n",
      "          [ 4.37500000e-01, -4.23828125e-01,  7.30468750e-01,  ...,\n",
      "            4.27246094e-02, -1.87500000e-01, -7.38525391e-03]]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[ 0.05371094,  0.16894531, -0.11083984,  ..., -0.01068115,\n",
      "            0.09423828,  0.06298828],\n",
      "          [-0.13867188,  0.43359375, -0.01171875,  ..., -0.08349609,\n",
      "           -0.19921875, -0.15429688],\n",
      "          [ 0.07958984,  0.26562500, -0.01031494,  ...,  0.06542969,\n",
      "           -0.25585938, -0.24414062],\n",
      "          ...,\n",
      "          [ 0.04882812,  0.25976562, -0.14941406,  ..., -0.11718750,\n",
      "           -0.33203125, -0.04687500],\n",
      "          [ 0.04882812,  0.25976562, -0.14941406,  ..., -0.11718750,\n",
      "           -0.33203125, -0.04687500],\n",
      "          [ 0.04882812,  0.25976562, -0.14941406,  ..., -0.11718750,\n",
      "           -0.33203125, -0.04687500]],\n",
      "\n",
      "         [[ 0.34570312,  0.46093750, -0.08203125,  ..., -0.03491211,\n",
      "           -0.34960938, -0.31445312],\n",
      "          [ 0.00120544,  0.03906250, -0.20117188,  ..., -0.01153564,\n",
      "           -0.12792969, -0.37890625],\n",
      "          [-0.00210571,  0.22949219, -0.17382812,  ...,  0.11523438,\n",
      "           -0.17187500, -0.40429688],\n",
      "          ...,\n",
      "          [ 0.01867676,  0.25781250, -0.11962891,  ...,  0.14453125,\n",
      "            0.26367188, -0.08398438],\n",
      "          [ 0.01867676,  0.25781250, -0.11962891,  ...,  0.14453125,\n",
      "            0.26367188, -0.08398438],\n",
      "          [ 0.01867676,  0.25781250, -0.11962891,  ...,  0.14453125,\n",
      "            0.26367188, -0.08398438]],\n",
      "\n",
      "         [[ 0.04541016, -0.01611328,  0.41992188,  ..., -0.08203125,\n",
      "           -0.04663086,  0.03295898],\n",
      "          [-0.16894531,  0.01855469,  0.03637695,  ..., -0.04833984,\n",
      "           -0.03540039,  0.53515625],\n",
      "          [-0.31640625,  0.17382812, -0.23339844,  ...,  0.08837891,\n",
      "            0.02905273,  0.50390625],\n",
      "          ...,\n",
      "          [-0.25976562,  0.17480469,  0.47851562,  ...,  0.15820312,\n",
      "           -0.07958984, -0.15429688],\n",
      "          [-0.25976562,  0.17480469,  0.47851562,  ...,  0.15820312,\n",
      "           -0.07958984, -0.15429688],\n",
      "          [-0.25976562,  0.17480469,  0.47851562,  ...,  0.15820312,\n",
      "           -0.07958984, -0.15429688]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.00561523,  0.26953125, -0.04809570,  ..., -0.10253906,\n",
      "            0.07910156, -0.08300781],\n",
      "          [ 0.27929688, -0.00866699, -0.07226562,  ..., -0.20312500,\n",
      "           -0.17773438, -0.98046875],\n",
      "          [ 0.15039062, -0.14941406, -0.24023438,  ..., -0.37109375,\n",
      "           -0.22265625, -0.81250000],\n",
      "          ...,\n",
      "          [ 0.00897217,  0.05346680,  0.00194550,  ..., -0.34570312,\n",
      "           -0.31640625, -0.17968750],\n",
      "          [ 0.00897217,  0.05346680,  0.00194550,  ..., -0.34570312,\n",
      "           -0.31640625, -0.17968750],\n",
      "          [ 0.00897217,  0.05346680,  0.00194550,  ..., -0.34570312,\n",
      "           -0.31640625, -0.17968750]],\n",
      "\n",
      "         [[-0.12011719, -0.03125000, -0.32421875,  ...,  0.22460938,\n",
      "            0.16601562,  0.12500000],\n",
      "          [-0.04882812,  0.06640625,  0.42773438,  ..., -0.24609375,\n",
      "            0.87890625,  0.16015625],\n",
      "          [ 0.31445312, -0.13281250,  0.35742188,  ..., -0.40625000,\n",
      "            0.55859375,  0.27929688],\n",
      "          ...,\n",
      "          [-0.10449219, -0.11035156, -0.18359375,  ...,  0.04541016,\n",
      "            0.12597656,  0.21191406],\n",
      "          [-0.10449219, -0.11035156, -0.18359375,  ...,  0.04541016,\n",
      "            0.12597656,  0.21191406],\n",
      "          [-0.10449219, -0.11035156, -0.18359375,  ...,  0.04541016,\n",
      "            0.12597656,  0.21191406]],\n",
      "\n",
      "         [[ 0.62500000,  0.32617188, -0.05834961,  ..., -0.07275391,\n",
      "            0.12402344, -0.25000000],\n",
      "          [ 0.39843750,  0.00823975,  0.23046875,  ..., -0.10595703,\n",
      "           -0.01324463,  0.08886719],\n",
      "          [ 0.44531250,  0.17480469,  0.09326172,  ..., -0.07812500,\n",
      "           -0.27148438,  0.32617188],\n",
      "          ...,\n",
      "          [ 0.45898438,  0.10253906, -0.11230469,  ...,  0.02319336,\n",
      "           -0.17187500, -0.18457031],\n",
      "          [ 0.45898438,  0.10253906, -0.11230469,  ...,  0.02319336,\n",
      "           -0.17187500, -0.18457031],\n",
      "          [ 0.45898438,  0.10253906, -0.11230469,  ...,  0.02319336,\n",
      "           -0.17187500, -0.18457031]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-0.08837891, -0.07177734,  0.14648438,  ..., -0.13671875,\n",
      "           -0.05517578,  0.25781250],\n",
      "          [-0.27343750, -0.08837891,  0.02490234,  ...,  0.63281250,\n",
      "           -1.28906250,  0.56640625],\n",
      "          [-0.29296875, -0.16503906,  0.23339844,  ...,  0.31835938,\n",
      "           -0.95312500,  0.58984375],\n",
      "          ...,\n",
      "          [-0.48046875, -0.22363281,  0.30468750,  ...,  0.17285156,\n",
      "           -0.12988281,  0.29882812],\n",
      "          [-0.48046875, -0.22363281,  0.30468750,  ...,  0.17285156,\n",
      "           -0.12988281,  0.29882812],\n",
      "          [-0.48046875, -0.22363281,  0.30468750,  ...,  0.17285156,\n",
      "           -0.12988281,  0.29882812]],\n",
      "\n",
      "         [[-0.34375000, -1.04687500, -0.10400391,  ..., -0.11621094,\n",
      "           -0.27734375, -0.25195312],\n",
      "          [-0.43554688, -0.46289062,  0.81250000,  ...,  0.78906250,\n",
      "           -0.36132812,  0.04931641],\n",
      "          [-0.44726562, -0.54296875,  0.51953125,  ...,  0.36523438,\n",
      "           -1.14843750,  0.73828125],\n",
      "          ...,\n",
      "          [-0.02819824, -0.00787354,  0.13476562,  ...,  0.08300781,\n",
      "            0.09814453,  0.06787109],\n",
      "          [-0.02819824, -0.00787354,  0.13476562,  ...,  0.08300781,\n",
      "            0.09814453,  0.06787109],\n",
      "          [-0.02819824, -0.00787354,  0.13476562,  ...,  0.08300781,\n",
      "            0.09814453,  0.06787109]],\n",
      "\n",
      "         [[ 0.22851562,  0.00215149, -0.36914062,  ..., -0.37304688,\n",
      "            0.20117188, -0.16015625],\n",
      "          [ 0.20703125,  0.41796875, -0.38281250,  ..., -0.30078125,\n",
      "            0.41601562, -1.48437500],\n",
      "          [-0.11328125, -0.33398438, -0.30078125,  ..., -0.61328125,\n",
      "            0.12109375, -1.24218750],\n",
      "          ...,\n",
      "          [-0.25781250, -0.47851562, -0.02697754,  ...,  0.05541992,\n",
      "            0.06494141,  0.04199219],\n",
      "          [-0.25781250, -0.47851562, -0.02697754,  ...,  0.05541992,\n",
      "            0.06494141,  0.04199219],\n",
      "          [-0.25781250, -0.47851562, -0.02697754,  ...,  0.05541992,\n",
      "            0.06494141,  0.04199219]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.29492188,  0.23046875, -0.22070312,  ...,  0.16699219,\n",
      "            0.28125000,  0.28125000],\n",
      "          [ 0.44531250,  0.23828125,  0.87109375,  ...,  0.35937500,\n",
      "           -0.28906250,  0.44335938],\n",
      "          [ 0.56250000,  0.24218750,  0.69140625,  ...,  0.26953125,\n",
      "           -0.18164062,  0.33593750],\n",
      "          ...,\n",
      "          [ 0.31835938,  0.06884766,  0.57812500,  ..., -0.20898438,\n",
      "            0.06250000,  0.45898438],\n",
      "          [ 0.31835938,  0.06884766,  0.57812500,  ..., -0.20898438,\n",
      "            0.06250000,  0.45898438],\n",
      "          [ 0.31835938,  0.06884766,  0.57812500,  ..., -0.20898438,\n",
      "            0.06250000,  0.45898438]],\n",
      "\n",
      "         [[-0.18750000, -0.41796875, -0.11328125,  ...,  0.04931641,\n",
      "           -0.25585938, -0.13378906],\n",
      "          [ 0.38085938, -0.12353516,  0.79687500,  ..., -0.26562500,\n",
      "            0.09765625, -0.55859375],\n",
      "          [ 0.14062500,  0.00723267,  0.40429688,  ..., -0.04003906,\n",
      "            0.07812500, -0.36914062],\n",
      "          ...,\n",
      "          [-0.44531250,  0.18554688, -0.34765625,  ...,  0.53125000,\n",
      "           -0.32226562,  0.57812500],\n",
      "          [-0.44531250,  0.18554688, -0.34765625,  ...,  0.53125000,\n",
      "           -0.32226562,  0.57812500],\n",
      "          [-0.44531250,  0.18554688, -0.34765625,  ...,  0.53125000,\n",
      "           -0.32226562,  0.57812500]],\n",
      "\n",
      "         [[-0.04345703, -0.16015625, -0.09326172,  ..., -0.05737305,\n",
      "           -0.00427246, -0.06542969],\n",
      "          [-0.39257812,  0.18652344,  0.39453125,  ...,  0.37109375,\n",
      "            0.54296875,  0.50390625],\n",
      "          [-0.26367188,  0.11523438,  0.38476562,  ...,  0.31640625,\n",
      "            0.47656250,  0.30468750],\n",
      "          ...,\n",
      "          [ 0.06494141, -0.12792969, -0.21484375,  ..., -0.09228516,\n",
      "           -0.01165771, -0.02307129],\n",
      "          [ 0.06494141, -0.12792969, -0.21484375,  ..., -0.09228516,\n",
      "           -0.01165771, -0.02307129],\n",
      "          [ 0.06494141, -0.12792969, -0.21484375,  ..., -0.09228516,\n",
      "           -0.01165771, -0.02307129]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n",
      "torch torch.Size([1, 16, 4128, 80]) tensor([[[[-0.69531250,  0.48242188,  0.42578125,  ..., -0.27734375,\n",
      "           -0.60937500, -0.15136719],\n",
      "          [ 0.23046875, -0.58593750, -0.18066406,  ...,  0.26953125,\n",
      "           -0.37109375,  0.94531250],\n",
      "          [-0.52734375, -0.48828125,  0.28515625,  ...,  0.35156250,\n",
      "           -0.85937500,  0.86328125],\n",
      "          ...,\n",
      "          [-0.25781250,  0.54296875,  0.08349609,  ..., -0.21386719,\n",
      "           -0.01403809,  0.02978516],\n",
      "          [-0.25781250,  0.54296875,  0.08349609,  ..., -0.21386719,\n",
      "           -0.01403809,  0.02978516],\n",
      "          [-0.25781250,  0.54296875,  0.08349609,  ..., -0.21386719,\n",
      "           -0.01403809,  0.02978516]],\n",
      "\n",
      "         [[-0.19238281, -0.16308594,  0.09179688,  ..., -0.15625000,\n",
      "            0.05468750,  0.23925781],\n",
      "          [ 0.36328125, -0.30664062, -0.05322266,  ..., -0.45507812,\n",
      "            0.46093750, -1.41406250],\n",
      "          [ 0.85937500, -0.27734375, -0.00964355,  ..., -0.58984375,\n",
      "            1.10937500, -1.03125000],\n",
      "          ...,\n",
      "          [-0.57812500,  0.67187500,  0.96875000,  ...,  0.43945312,\n",
      "           -0.51562500,  0.53515625],\n",
      "          [-0.57812500,  0.67187500,  0.96875000,  ...,  0.43945312,\n",
      "           -0.51562500,  0.53515625],\n",
      "          [-0.57812500,  0.67187500,  0.96875000,  ...,  0.43945312,\n",
      "           -0.51562500,  0.53515625]],\n",
      "\n",
      "         [[ 0.42968750, -0.40625000,  0.16601562,  ..., -0.02172852,\n",
      "            0.24707031, -0.06835938],\n",
      "          [-0.10644531, -0.18554688, -0.08447266,  ..., -0.58593750,\n",
      "            0.61718750,  0.53515625],\n",
      "          [-0.21679688, -0.12890625, -0.67187500,  ..., -0.89453125,\n",
      "            0.55078125,  0.89062500],\n",
      "          ...,\n",
      "          [ 0.90625000, -0.60546875,  0.43359375,  ..., -0.18164062,\n",
      "            0.63281250,  0.16210938],\n",
      "          [ 0.90625000, -0.60546875,  0.43359375,  ..., -0.18164062,\n",
      "            0.63281250,  0.16210938],\n",
      "          [ 0.90625000, -0.60546875,  0.43359375,  ..., -0.18164062,\n",
      "            0.63281250,  0.16210938]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.43554688,  1.44531250,  0.62109375,  ..., -1.57812500,\n",
      "            1.60937500, -0.91015625],\n",
      "          [ 0.16894531, -0.30078125,  0.43945312,  ...,  0.02734375,\n",
      "           -0.49804688, -0.21386719],\n",
      "          [-0.14160156, -0.02246094,  0.37500000,  ...,  0.08398438,\n",
      "           -0.15136719, -0.38281250],\n",
      "          ...,\n",
      "          [ 0.67578125,  1.96093750,  1.53125000,  ..., -1.31250000,\n",
      "            2.65625000, -1.22656250],\n",
      "          [ 0.67578125,  1.96093750,  1.53125000,  ..., -1.31250000,\n",
      "            2.65625000, -1.22656250],\n",
      "          [ 0.67578125,  1.96093750,  1.53125000,  ..., -1.31250000,\n",
      "            2.65625000, -1.22656250]],\n",
      "\n",
      "         [[-0.02978516, -0.09716797, -0.09716797,  ...,  0.00711060,\n",
      "            0.20214844,  0.01300049],\n",
      "          [-0.53906250, -0.26953125, -0.87890625,  ...,  0.23339844,\n",
      "           -0.69921875, -0.11474609],\n",
      "          [-0.54687500, -0.20703125, -0.45507812,  ...,  0.28710938,\n",
      "           -0.58203125, -0.10205078],\n",
      "          ...,\n",
      "          [ 0.57421875, -0.45507812,  0.25390625,  ...,  0.34960938,\n",
      "           -0.33398438, -0.05078125],\n",
      "          [ 0.57421875, -0.45507812,  0.25390625,  ...,  0.34960938,\n",
      "           -0.33398438, -0.05078125],\n",
      "          [ 0.57421875, -0.45507812,  0.25390625,  ...,  0.34960938,\n",
      "           -0.33398438, -0.05078125]],\n",
      "\n",
      "         [[-0.57031250,  0.20410156, -0.06298828,  ..., -0.02709961,\n",
      "            0.34570312,  0.19628906],\n",
      "          [-0.13964844,  0.37695312, -0.23632812,  ..., -0.05029297,\n",
      "            0.66015625,  0.51562500],\n",
      "          [-0.33007812, -0.03955078, -0.16210938,  ..., -0.07226562,\n",
      "            0.42773438,  0.18164062],\n",
      "          ...,\n",
      "          [ 1.92187500,  0.96093750, -0.43359375,  ..., -0.45507812,\n",
      "           -0.32421875,  0.44140625],\n",
      "          [ 1.92187500,  0.96093750, -0.43359375,  ..., -0.45507812,\n",
      "           -0.32421875,  0.44140625],\n",
      "          [ 1.92187500,  0.96093750, -0.43359375,  ..., -0.45507812,\n",
      "           -0.32421875,  0.44140625]]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<ScaledDotProductEfficientAttentionBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs_jax = processor(images=image, return_tensors=\"jax\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "output_torch = model_torch(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax (1, 16, 4128, 80) [[[[-0.0112305 0.208984 -0.0090332 ... 0.0286865 0.0180664 -0.0120239]\n",
      "   [0.00622559 -0.137695 -0.143555 ... -0.0332031 0.0495605 -0.0332031]\n",
      "   [0.010437 -0.179688 -0.160156 ... -0.0554199 0.050293 -0.026123]\n",
      "   ...\n",
      "   [0.0664062 0.398438 0.000583649 ... -0.0228271 0.0305176 0.0593262]\n",
      "   [0.0664062 0.398438 0.000583649 ... -0.0228271 0.0305176 0.0593262]\n",
      "   [0.0664062 0.398438 0.000583649 ... -0.0228271 0.0305176 0.0593262]]\n",
      "\n",
      "  [[-0.00735474 0.0449219 0.0239258 ... -0.0154419 -0.00366211\n",
      "    0.0332031]\n",
      "   [0.00139618 0.0539551 0.0375977 ... -0.00506592 -0.120117 0.0615234]\n",
      "   [0.00346375 0.0551758 0.0375977 ... -0.0027771 -0.126953 0.0639648]\n",
      "   ...\n",
      "   [0.00352478 0.0341797 0.0249023 ... -0.0183105 0.101562 0.00848389]\n",
      "   [0.00352478 0.0341797 0.0249023 ... -0.0183105 0.101562 0.00848389]\n",
      "   [0.00352478 0.0341797 0.0249023 ... -0.0183105 0.101562 0.00848389]]\n",
      "\n",
      "  [[-0.137695 0.0132446 0.0234375 ... -0.015625 -0.0159912 -0.107422]\n",
      "   [-0.139648 0.00701904 0.0172119 ... -0.0266113 -0.015625 -0.0849609]\n",
      "   [-0.138672 0.00704956 0.013855 ... -0.0256348 -0.0150757 -0.0922852]\n",
      "   ...\n",
      "   [-0.141602 0.0102539 0.0297852 ... -0.0274658 -0.0185547 -0.0634766]\n",
      "   [-0.141602 0.0102539 0.0297852 ... -0.0274658 -0.0185547 -0.0634766]\n",
      "   [-0.141602 0.0102539 0.0297852 ... -0.0274658 -0.0185547 -0.0634766]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0471191 -0.0732422 0.00485229 ... 0.0106812 0.034668 0.0412598]\n",
      "   [0.0140991 -0.147461 -0.200195 ... -0.355469 -0.294922 -0.142578]\n",
      "   [0.0192871 -0.158203 -0.214844 ... -0.359375 -0.302734 -0.152344]\n",
      "   ...\n",
      "   [-0.0996094 0.0195312 -0.123047 ... -0.0211182 0.0981445 -0.0405273]\n",
      "   [-0.0996094 0.0195312 -0.123047 ... -0.0211182 0.0981445 -0.0405273]\n",
      "   [-0.0996094 0.0195312 -0.123047 ... -0.0211182 0.0981445 -0.0405273]]\n",
      "\n",
      "  [[-0.0810547 -0.0927734 0.00772095 ... -0.00527954 -0.0444336\n",
      "    0.0125732]\n",
      "   [-0.0571289 -0.0235596 0.0515137 ... -0.0288086 -0.022583 0.0286865]\n",
      "   [-0.0583496 -0.0281982 0.0515137 ... -0.0274658 -0.022583 0.0319824]\n",
      "   ...\n",
      "   [-0.0673828 -0.0893555 0.00204468 ... -0.00799561 -0.0458984\n",
      "    0.00933838]\n",
      "   [-0.0673828 -0.0893555 0.00204468 ... -0.00799561 -0.0458984\n",
      "    0.00933838]\n",
      "   [-0.0673828 -0.0893555 0.00204468 ... -0.00799561 -0.0458984\n",
      "    0.00933838]]\n",
      "\n",
      "  [[0.0266113 -0.0197754 -0.0488281 ... 0.017334 -0.0297852 0.0184326]\n",
      "   [-0.0888672 -0.110352 0.211914 ... 0.137695 0.0654297 -0.114746]\n",
      "   [-0.137695 -0.112305 0.259766 ... 0.113281 0.134766 -0.140625]\n",
      "   ...\n",
      "   [-0.00878906 -0.00939941 -0.00405884 ... -0.0463867 0.0495605\n",
      "    0.0037384]\n",
      "   [-0.00878906 -0.00939941 -0.00405884 ... -0.0463867 0.0495605\n",
      "    0.0037384]\n",
      "   [-0.00878906 -0.00939941 -0.00405884 ... -0.0463867 0.0495605\n",
      "    0.0037384]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0245361 0.0678711 -0.0498047 ... 0.00805664 0.0283203 -0.078125]\n",
      "   [0.0322266 0.0578613 -0.0246582 ... -0.0108032 0.0192871 -0.114258]\n",
      "   [0.0314941 0.0595703 -0.0224609 ... -0.000774384 0.0109863 -0.111816]\n",
      "   ...\n",
      "   [0.0253906 0.0854492 -0.046875 ... -0.00970459 0.0150757 -0.09375]\n",
      "   [0.0253906 0.0854492 -0.046875 ... -0.00970459 0.0150757 -0.09375]\n",
      "   [0.0253906 0.0854492 -0.046875 ... -0.00970459 0.0150757 -0.09375]]\n",
      "\n",
      "  [[-0.0263672 0.0162354 -0.0917969 ... -0.0280762 -0.0539551 -0.052002]\n",
      "   [-0.0273438 0.160156 -0.0585938 ... -0.000637054 -0.135742 0.0272217]\n",
      "   [-0.0218506 0.186523 -0.0593262 ... 9.10759e-05 -0.152344 0.0324707]\n",
      "   ...\n",
      "   [0.0161133 0.0303955 -0.102539 ... 0.163086 -0.160156 -0.0405273]\n",
      "   [0.0161133 0.0303955 -0.102539 ... 0.163086 -0.160156 -0.0405273]\n",
      "   [0.0161133 0.0303955 -0.102539 ... 0.163086 -0.160156 -0.0405273]]\n",
      "\n",
      "  [[-0.0402832 -0.129883 -0.384766 ... 0.00622559 0.00418091 -0.0756836]\n",
      "   [0.000255585 -0.0153809 0.220703 ... 0.148438 0.00946045 -0.0400391]\n",
      "   [0.00631714 -0.00271606 0.337891 ... 0.155273 0.00317383 -0.043457]\n",
      "   ...\n",
      "   [0.0554199 -0.145508 0.570312 ... 0.0568848 -0.00396729 -0.169922]\n",
      "   [0.0554199 -0.145508 0.570312 ... 0.0568848 -0.00396729 -0.169922]\n",
      "   [0.0554199 -0.145508 0.570312 ... 0.0568848 -0.00396729 -0.169922]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0154419 0.0319824 0.0114746 ... -0.00946045 -0.128906 0.00668335]\n",
      "   [0.0167236 0.0349121 0.00878906 ... -0.010498 -0.145508 0.0098877]\n",
      "   [0.0168457 0.0349121 0.0090332 ... -0.0106812 -0.144531 0.00897217]\n",
      "   ...\n",
      "   [0.0432129 0.00946045 -0.0238037 ... -0.0197754 -0.0412598 0.074707]\n",
      "   [0.0432129 0.00946045 -0.0238037 ... -0.0197754 -0.0412598 0.074707]\n",
      "   [0.0432129 0.00946045 -0.0238037 ... -0.0197754 -0.0412598 0.074707]]\n",
      "\n",
      "  [[-0.0541992 -0.00497437 0.0539551 ... -0.00201416 -0.0319824\n",
      "    -0.000900269]\n",
      "   [-0.0515137 0.0136108 0.0132446 ... -0.0180664 -0.0449219 -0.0106201]\n",
      "   [-0.0441895 0.0022583 0.0231934 ... -0.00300598 -0.0668945\n",
      "    -0.00601196]\n",
      "   ...\n",
      "   [-0.103516 0.00405884 0.00765991 ... -0.0407715 -0.0183105\n",
      "    -0.0303955]\n",
      "   [-0.103516 0.00405884 0.00765991 ... -0.0407715 -0.0183105\n",
      "    -0.0303955]\n",
      "   [-0.103516 0.00405884 0.00765991 ... -0.0407715 -0.0183105\n",
      "    -0.0303955]]\n",
      "\n",
      "  [[0.0507812 0.0654297 0.00952148 ... -0.0603027 0.0559082 0.0319824]\n",
      "   [0.10498 -0.100098 -0.0559082 ... 0.138672 0.0585938 -0.0688477]\n",
      "   [0.106934 -0.144531 -0.0578613 ... 0.145508 0.0991211 -0.0688477]\n",
      "   ...\n",
      "   [0.0568848 -0.117676 -0.0629883 ... 0.074707 0.0654297 -0.0358887]\n",
      "   [0.0568848 -0.117676 -0.0629883 ... 0.074707 0.0654297 -0.0358887]\n",
      "   [0.0568848 -0.117676 -0.0629883 ... 0.074707 0.0654297 -0.0358887]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0288086 0.0126953 0.00787354 ... 0.0198975 0.0541992 -0.0336914]\n",
      "   [0.0157471 0.0178223 0.0233154 ... 0.041748 0.00643921 -0.0432129]\n",
      "   [-0.000564575 0.0385742 0.0292969 ... 0.0683594 -0.0712891\n",
      "    -0.0878906]\n",
      "   ...\n",
      "   [-0.0986328 0.0268555 0.0255127 ... -0.0603027 -0.146484 -0.0576172]\n",
      "   [-0.0986328 0.0268555 0.0255127 ... -0.0603027 -0.146484 -0.0576172]\n",
      "   [-0.0986328 0.0268555 0.0255127 ... -0.0603027 -0.146484 -0.0576172]]\n",
      "\n",
      "  [[-0.00799561 -0.0510254 0.00915527 ... 0.0717773 -0.074707\n",
      "    -0.0186768]\n",
      "   [0.0255127 -0.105957 0.0634766 ... 0.0893555 -0.0217285 0.00909424]\n",
      "   [0.0334473 -0.0986328 0.0634766 ... 0.0864258 -0.0236816 0.0145264]\n",
      "   ...\n",
      "   [0.0332031 -0.0422363 -0.0150146 ... 0.0888672 -0.0393066 -0.0849609]\n",
      "   [0.0332031 -0.0422363 -0.0150146 ... 0.0888672 -0.0393066 -0.0849609]\n",
      "   [0.0332031 -0.0422363 -0.0150146 ... 0.0888672 -0.0393066 -0.0849609]]\n",
      "\n",
      "  [[0.0678711 0.0062561 -0.174805 ... -0.0480957 0.0878906 -0.0473633]\n",
      "   [0.0588379 -0.00358582 -0.160156 ... -0.0581055 0.0810547 -0.0495605]\n",
      "   [0.0539551 -0.000434875 -0.155273 ... -0.059082 0.0810547 -0.045166]\n",
      "   ...\n",
      "   [0.0233154 0.0859375 -0.0742188 ... 0.172852 0.0756836 0.00686646]\n",
      "   [0.0233154 0.0859375 -0.0742188 ... 0.172852 0.0756836 0.00686646]\n",
      "   [0.0233154 0.0859375 -0.0742188 ... 0.172852 0.0756836 0.00686646]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00311279 0.0776367 -0.0307617 ... -0.0122681 -0.00476074\n",
      "    0.0065918]\n",
      "   [0.0664062 0.189453 -0.172852 ... -0.00982666 -0.137695 0.167969]\n",
      "   [0.0698242 0.235352 -0.167969 ... -0.0130005 -0.128906 0.168945]\n",
      "   ...\n",
      "   [0.0296631 0.0424805 -0.0332031 ... -0.00561523 -0.182617 0.0361328]\n",
      "   [0.0296631 0.0424805 -0.0332031 ... -0.00561523 -0.182617 0.0361328]\n",
      "   [0.0296631 0.0424805 -0.0332031 ... -0.00561523 -0.182617 0.0361328]]\n",
      "\n",
      "  [[-0.0693359 0.000999451 -0.0322266 ... -0.0174561 -0.0693359\n",
      "    0.0181885]\n",
      "   [0.302734 -0.0239258 -0.103027 ... 0.147461 -0.0893555 0.0820312]\n",
      "   [0.484375 -0.0322266 -0.150391 ... 0.22168 -0.0878906 0.124512]\n",
      "   ...\n",
      "   [0.0223389 -0.104492 -0.171875 ... 0.0625 -0.0305176 0.0766602]\n",
      "   [0.0223389 -0.104492 -0.171875 ... 0.0625 -0.0305176 0.0766602]\n",
      "   [0.0223389 -0.104492 -0.171875 ... 0.0625 -0.0305176 0.0766602]]\n",
      "\n",
      "  [[0.017334 -0.0385742 -0.0148926 ... -0.0235596 -0.0322266 0.0490723]\n",
      "   [0.0172119 -0.0383301 -0.0150146 ... -0.0236816 -0.0322266 0.0488281]\n",
      "   [0.0172119 -0.0385742 -0.0148315 ... -0.024292 -0.0332031 0.0480957]\n",
      "   ...\n",
      "   [0.0032196 0.020874 -0.00361633 ... 0.00823975 -0.0722656 -0.0678711]\n",
      "   [0.0032196 0.020874 -0.00361633 ... 0.00823975 -0.0722656 -0.0678711]\n",
      "   [0.0032196 0.020874 -0.00361633 ... 0.00823975 -0.0722656 -0.0678711]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0201416 -0.0454102 0.00759888 ... -0.0366211 0.0568848 -0.0202637]\n",
      "   [0.0432129 -0.0476074 -0.0131226 ... -0.0480957 0.0830078 0.119141]\n",
      "   [0.0446777 -0.0490723 -0.00872803 ... -0.0354004 0.0776367 0.0625]\n",
      "   ...\n",
      "   [0.0151367 0.0654297 -0.00994873 ... 0.0446777 0.145508 -0.375]\n",
      "   [0.0151367 0.0654297 -0.00994873 ... 0.0446777 0.145508 -0.375]\n",
      "   [0.0151367 0.0654297 -0.00994873 ... 0.0446777 0.145508 -0.375]]\n",
      "\n",
      "  [[-0.00704956 0.017334 0.0878906 ... 0.065918 -0.0634766 0.470703]\n",
      "   [-0.0100098 0.0678711 -0.00421143 ... -0.12793 0.100098 0.388672]\n",
      "   [-0.000244141 0.0668945 0.00921631 ... -0.113281 0.0922852 0.394531]\n",
      "   ...\n",
      "   [-0.00340271 -0.0688477 0.216797 ... 0.337891 -0.259766 0.597656]\n",
      "   [-0.00340271 -0.0688477 0.216797 ... 0.337891 -0.259766 0.597656]\n",
      "   [-0.00340271 -0.0688477 0.216797 ... 0.337891 -0.259766 0.597656]]\n",
      "\n",
      "  [[-0.0167236 -0.0189209 0.032959 ... 0.00811768 0.0490723 -0.0368652]\n",
      "   [0.00159454 -0.0251465 -0.0397949 ... 0.0270996 0.0495605 0.00518799]\n",
      "   [-0.00254822 -0.0241699 -0.0354004 ... 0.0319824 0.0529785\n",
      "    0.00463867]\n",
      "   ...\n",
      "   [0.0981445 -0.0250244 -0.183594 ... -0.0927734 -0.0581055 0.130859]\n",
      "   [0.0981445 -0.0250244 -0.183594 ... -0.0927734 -0.0581055 0.130859]\n",
      "   [0.0981445 -0.0250244 -0.183594 ... -0.0927734 -0.0581055 0.130859]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00946045 -0.00772095 -0.00254822 ... 0.0722656 0.022583\n",
      "    -0.048584]\n",
      "   [-0.00485229 -0.00701904 -0.00628662 ... 0.0712891 0.0267334\n",
      "    -0.0583496]\n",
      "   [-0.0124512 -0.00872803 -0.00218201 ... 0.0727539 0.0234375\n",
      "    -0.0441895]\n",
      "   ...\n",
      "   [-0.248047 0.0241699 -0.0922852 ... 0.177734 0.0117188 -0.229492]\n",
      "   [-0.248047 0.0241699 -0.0922852 ... 0.177734 0.0117188 -0.229492]\n",
      "   [-0.248047 0.0241699 -0.0922852 ... 0.177734 0.0117188 -0.229492]]\n",
      "\n",
      "  [[0.00976562 -0.177734 -0.0336914 ... -0.00823975 0.0014801\n",
      "    -0.0283203]\n",
      "   [0.0639648 -0.0493164 0.0412598 ... -0.0410156 -0.00390625\n",
      "    -0.0167236]\n",
      "   [0.0167236 -0.163086 0.00778198 ... -0.0280762 -0.000999451\n",
      "    -0.0240479]\n",
      "   ...\n",
      "   [0.0664062 -0.357422 0.0446777 ... -0.0140381 0.0874023 0.050293]\n",
      "   [0.0664062 -0.357422 0.0446777 ... -0.0140381 0.0874023 0.050293]\n",
      "   [0.0664062 -0.357422 0.0446777 ... -0.0140381 0.0874023 0.050293]]\n",
      "\n",
      "  [[-0.0603027 0.0522461 0.048584 ... -0.0126953 -0.0654297 0.162109]\n",
      "   [-0.050293 0.0629883 0.0561523 ... -0.017334 -0.0629883 0.163086]\n",
      "   [-0.0476074 0.0654297 0.0583496 ... -0.019043 -0.0615234 0.163086]\n",
      "   ...\n",
      "   [0.0527344 -0.0098877 0.196289 ... 0.0498047 -0.251953 0.136719]\n",
      "   [0.0527344 -0.0098877 0.196289 ... 0.0498047 -0.251953 0.136719]\n",
      "   [0.0527344 -0.0098877 0.196289 ... 0.0498047 -0.251953 0.136719]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.048584 0.00897217 0.0057373 ... -0.0480957 -0.0161133 0.0308838]\n",
      "   [0.0439453 0.0166016 0.0090332 ... -0.0422363 -0.0222168 0.0412598]\n",
      "   [0.045166 0.0180664 0.0090332 ... -0.0415039 -0.0224609 0.0424805]\n",
      "   ...\n",
      "   [-0.240234 -0.130859 0.101562 ... 0.00296021 0.136719 -0.175781]\n",
      "   [-0.240234 -0.130859 0.101562 ... 0.00296021 0.136719 -0.175781]\n",
      "   [-0.240234 -0.130859 0.101562 ... 0.00296021 0.136719 -0.175781]]\n",
      "\n",
      "  [[-0.029541 -0.0155029 -0.0113525 ... -0.0566406 0.00115204\n",
      "    -0.0737305]\n",
      "   [-0.0269775 -0.0150757 -0.0106812 ... -0.059082 0.00125885\n",
      "    -0.0727539]\n",
      "   [-0.029541 -0.0155029 -0.0113525 ... -0.0566406 0.00115967\n",
      "    -0.0737305]\n",
      "   ...\n",
      "   [-0.0172119 -0.0202637 -0.0319824 ... -0.0412598 -0.0228271\n",
      "    -0.0322266]\n",
      "   [-0.0172119 -0.0202637 -0.0319824 ... -0.0412598 -0.0228271\n",
      "    -0.0322266]\n",
      "   [-0.0172119 -0.0202637 -0.0319824 ... -0.0412598 -0.0228271\n",
      "    -0.0322266]]\n",
      "\n",
      "  [[-0.0976562 -0.0419922 -0.0157471 ... -0.0986328 -0.00601196\n",
      "    0.0161133]\n",
      "   [-0.0976562 -0.0429688 -0.0142822 ... -0.0976562 -0.0055542\n",
      "    0.0155029]\n",
      "   [-0.0908203 -0.0439453 -0.013855 ... -0.0976562 -0.00527954\n",
      "    0.0155029]\n",
      "   ...\n",
      "   [1.04688 -0.0334473 0.00735474 ... -0.0693359 -0.0378418 0.222656]\n",
      "   [1.04688 -0.0334473 0.00735474 ... -0.0693359 -0.0378418 0.222656]\n",
      "   [1.04688 -0.0334473 0.00735474 ... -0.0693359 -0.0378418 0.222656]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0512695 0.0288086 0.00637817 ... 0.057373 -0.0405273 0.0163574]\n",
      "   [0.020752 0.0512695 -0.00257874 ... 0.0549316 -0.00341797 0.0200195]\n",
      "   [0.0251465 0.0449219 -0.0101929 ... 0.0441895 -0.00204468 0.013916]\n",
      "   ...\n",
      "   [0.0356445 0.0844727 0.0612793 ... 0.0629883 -0.032959 0.0756836]\n",
      "   [0.0356445 0.0844727 0.0612793 ... 0.0629883 -0.032959 0.0756836]\n",
      "   [0.0356445 0.0844727 0.0612793 ... 0.0629883 -0.032959 0.0756836]]\n",
      "\n",
      "  [[-0.222656 -0.0339355 -0.417969 ... 0.0522461 0.02771 -0.0116577]\n",
      "   [-1.375 0.289062 0.214844 ... 0.933594 -0.102539 0.578125]\n",
      "   [-1.39062 0.0654297 0.404297 ... 2.23438 0.144531 0.726562]\n",
      "   ...\n",
      "   [0.220703 0.0427246 -0.439453 ... -0.808594 0.146484 0.0839844]\n",
      "   [0.220703 0.0427246 -0.439453 ... -0.808594 0.146484 0.0839844]\n",
      "   [0.220703 0.0427246 -0.439453 ... -0.808594 0.146484 0.0839844]]\n",
      "\n",
      "  [[-0.0179443 0.0800781 0.0786133 ... 0.0825195 -0.0673828 -0.111328]\n",
      "   [-0.0205078 0.0771484 0.0776367 ... 0.0810547 -0.0673828 -0.104492]\n",
      "   [-0.0195312 0.0771484 0.0761719 ... 0.0791016 -0.0639648 -0.0991211]\n",
      "   ...\n",
      "   [0.0693359 0.208008 0.0112915 ... 0.137695 -0.050293 -0.111328]\n",
      "   [0.0693359 0.208008 0.0112915 ... 0.137695 -0.050293 -0.111328]\n",
      "   [0.0693359 0.208008 0.0112915 ... 0.137695 -0.050293 -0.111328]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0839844 0.0245361 0.0234375 ... 0.0185547 -0.0228271 0.013916]\n",
      "   [0.0854492 0.0249023 0.024292 ... 0.0147095 -0.0252686 0.0147095]\n",
      "   [0.0849609 0.0255127 0.0234375 ... 0.0147095 -0.026123 0.0144043]\n",
      "   ...\n",
      "   [0.00860596 0.125977 -0.0201416 ... -0.0544434 -0.21582 0.0722656]\n",
      "   [0.00860596 0.125977 -0.0201416 ... -0.0544434 -0.21582 0.0722656]\n",
      "   [0.00860596 0.125977 -0.0201416 ... -0.0544434 -0.21582 0.0722656]]\n",
      "\n",
      "  [[0.00494385 -0.00141144 0.0612793 ... -0.0238037 -0.0854492 0.113281]\n",
      "   [-0.0289307 0.0301514 -0.115234 ... -0.0981445 -0.065918 0.057373]\n",
      "   [-0.074707 0.0556641 -0.239258 ... -0.15625 -0.161133 0.0135498]\n",
      "   ...\n",
      "   [-0.0366211 0.0144043 0.00485229 ... -0.0834961 -0.0534668 0.133789]\n",
      "   [-0.0366211 0.0144043 0.00485229 ... -0.0834961 -0.0534668 0.133789]\n",
      "   [-0.0366211 0.0144043 0.00485229 ... -0.0834961 -0.0534668 0.133789]]\n",
      "\n",
      "  [[0.0405273 0.022583 -0.0177002 ... -0.0153809 -0.0466309 -0.0407715]\n",
      "   [-0.0578613 0.0128174 -0.034668 ... -0.0366211 0.0483398 0.0157471]\n",
      "   [-0.010437 0.0349121 -0.00552368 ... -0.0366211 0.0568848 -0.0136108]\n",
      "   ...\n",
      "   [-0.112305 -0.0556641 -0.000930786 ... -0.0515137 0.0152588\n",
      "    -0.0383301]\n",
      "   [-0.112305 -0.0556641 -0.000930786 ... -0.0515137 0.0152588\n",
      "    -0.0383301]\n",
      "   [-0.112305 -0.0556641 -0.000930786 ... -0.0515137 0.0152588\n",
      "    -0.0383301]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.046875 -0.0427246 0.19043 ... -0.22168 0.0466309 -0.202148]\n",
      "   [-0.205078 -0.147461 -0.365234 ... -0.108887 -0.0314941 -0.0839844]\n",
      "   [-0.431641 -0.149414 -0.441406 ... -0.102051 -0.0220947 -0.097168]\n",
      "   ...\n",
      "   [0.00442505 -0.0385742 0.131836 ... -0.228516 0.0563965 -0.144531]\n",
      "   [0.00442505 -0.0385742 0.131836 ... -0.228516 0.0563965 -0.144531]\n",
      "   [0.00442505 -0.0385742 0.131836 ... -0.228516 0.0563965 -0.144531]]\n",
      "\n",
      "  [[-0.0830078 -0.101074 -0.0688477 ... -0.0517578 -0.232422 0.041748]\n",
      "   [-0.219727 -0.00312805 0.108887 ... -0.0147705 -0.0339355 -0.0583496]\n",
      "   [-0.21875 0.00970459 0.0554199 ... 0.0142212 -0.0629883 -0.158203]\n",
      "   ...\n",
      "   [0.0473633 0.171875 -0.0703125 ... 0.0032959 -0.137695 -0.166016]\n",
      "   [0.0473633 0.171875 -0.0703125 ... 0.0032959 -0.137695 -0.166016]\n",
      "   [0.0473633 0.171875 -0.0703125 ... 0.0032959 -0.137695 -0.166016]]\n",
      "\n",
      "  [[0.0170898 -0.0644531 0.0698242 ... 0.0830078 0.0664062 -0.00680542]\n",
      "   [0.0184326 -0.065918 0.0722656 ... 0.0869141 0.0693359 -0.00534058]\n",
      "   [0.0186768 -0.0654297 0.0732422 ... 0.0878906 0.0698242 -0.00537109]\n",
      "   ...\n",
      "   [0.0300293 0.181641 0.0500488 ... -0.0339355 0.0273438 0.0310059]\n",
      "   [0.0300293 0.181641 0.0500488 ... -0.0339355 0.0273438 0.0310059]\n",
      "   [0.0300293 0.181641 0.0500488 ... -0.0339355 0.0273438 0.0310059]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0830078 -0.111816 0.205078 ... -0.078125 0.00151825 -0.0300293]\n",
      "   [-0.118164 -0.0629883 0.131836 ... -0.0996094 0.0917969 -0.0593262]\n",
      "   [-0.0869141 -0.0463867 0.124023 ... -0.115234 0.128906 -0.0463867]\n",
      "   ...\n",
      "   [-0.0368652 -0.0952148 0.171875 ... -0.09375 0.0274658 -0.000667572]\n",
      "   [-0.0368652 -0.0952148 0.171875 ... -0.09375 0.0274658 -0.000667572]\n",
      "   [-0.0368652 -0.0952148 0.171875 ... -0.09375 0.0274658 -0.000667572]]\n",
      "\n",
      "  [[0.417969 0.330078 0.166016 ... -0.110352 0.345703 0.183594]\n",
      "   [0.851562 1.03125 0.292969 ... -0.0146484 -0.0878906 0.111328]\n",
      "   [1.46875 0.835938 0.722656 ... -0.0466309 0.318359 0.275391]\n",
      "   ...\n",
      "   [-0.116211 0.104492 0.239258 ... -0.0766602 0.318359 0.322266]\n",
      "   [-0.116211 0.104492 0.239258 ... -0.0766602 0.318359 0.322266]\n",
      "   [-0.116211 0.104492 0.239258 ... -0.0766602 0.318359 0.322266]]\n",
      "\n",
      "  [[-0.146484 0.0163574 0.0952148 ... 0.0698242 -0.0378418 -0.0368652]\n",
      "   [-0.132812 -0.00411987 0.115234 ... 0.104004 -0.0664062 -0.0322266]\n",
      "   [-0.137695 -0.00436401 0.115234 ... 0.105957 -0.0708008 -0.0324707]\n",
      "   ...\n",
      "   [-0.169922 0.0473633 -0.0179443 ... -0.0144653 0.0449219 -0.172852]\n",
      "   [-0.169922 0.0473633 -0.0179443 ... -0.0144653 0.0449219 -0.172852]\n",
      "   [-0.169922 0.0473633 -0.0179443 ... -0.0144653 0.0449219 -0.172852]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0517578 -0.104492 -0.0432129 ... -0.0137329 0.185547 -0.259766]\n",
      "   [-0.204102 -0.416016 0.271484 ... -0.141602 0.257812 -0.231445]\n",
      "   [-0.349609 -0.285156 0.116211 ... -0.0397949 0.19043 -0.332031]\n",
      "   ...\n",
      "   [-0.197266 -0.0854492 0.0334473 ... -0.169922 0.114258 -0.259766]\n",
      "   [-0.197266 -0.0854492 0.0334473 ... -0.169922 0.114258 -0.259766]\n",
      "   [-0.197266 -0.0854492 0.0334473 ... -0.169922 0.114258 -0.259766]]\n",
      "\n",
      "  [[0.0966797 0.0703125 0.0563965 ... -0.103516 0.0390625 -0.0703125]\n",
      "   [0.0942383 0.0698242 0.0510254 ... -0.101562 0.0412598 -0.0683594]\n",
      "   [0.0947266 0.0703125 0.0529785 ... -0.103027 0.0429688 -0.0688477]\n",
      "   ...\n",
      "   [0.231445 -0.0820312 -0.00799561 ... -0.0164795 -0.136719 -0.0231934]\n",
      "   [0.231445 -0.0820312 -0.00799561 ... -0.0164795 -0.136719 -0.0231934]\n",
      "   [0.231445 -0.0820312 -0.00799561 ... -0.0164795 -0.136719 -0.0231934]]\n",
      "\n",
      "  [[-0.0546875 0.0249023 -0.193359 ... -0.191406 0.0270996 -0.269531]\n",
      "   [-0.363281 -0.0639648 -0.765625 ... -0.0678711 0.15625 -0.78125]\n",
      "   [0.00793457 0.392578 -0.429688 ... 0.0810547 0.0825195 -0.5625]\n",
      "   ...\n",
      "   [-0.0693359 0.0805664 -0.137695 ... -0.146484 -0.00909424 -0.410156]\n",
      "   [-0.0693359 0.0805664 -0.137695 ... -0.146484 -0.00909424 -0.410156]\n",
      "   [-0.0693359 0.0805664 -0.137695 ... -0.146484 -0.00909424 -0.410156]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.100586 -0.144531 -0.144531 ... -0.229492 0.0412598 0.0595703]\n",
      "   [-0.0622559 -0.0625 -0.121582 ... -0.144531 0.0113525 -0.0286865]\n",
      "   [-0.0612793 -0.0922852 -0.126953 ... -0.157227 0.00564575 -0.0148926]\n",
      "   ...\n",
      "   [-0.169922 0.0727539 -0.172852 ... -0.3125 0.235352 0.036377]\n",
      "   [-0.169922 0.0727539 -0.172852 ... -0.3125 0.235352 0.036377]\n",
      "   [-0.169922 0.0727539 -0.172852 ... -0.3125 0.235352 0.036377]]\n",
      "\n",
      "  [[0.00674438 -0.120117 0.020752 ... -0.115723 -0.147461 -0.138672]\n",
      "   [0.0163574 -0.182617 0.0603027 ... -0.10498 -0.048584 -0.119141]\n",
      "   [0.0179443 -0.180664 0.0527344 ... -0.111328 -0.0583496 -0.128906]\n",
      "   ...\n",
      "   [0.105957 0.0593262 0.213867 ... 0.000307083 -0.287109 -0.134766]\n",
      "   [0.105957 0.0593262 0.213867 ... 0.000307083 -0.287109 -0.134766]\n",
      "   [0.105957 0.0593262 0.213867 ... 0.000307083 -0.287109 -0.134766]]\n",
      "\n",
      "  [[0.0688477 0.0805664 0.0563965 ... 0.0664062 -0.129883 -0.0961914]\n",
      "   [0.078125 0.0471191 0.0507812 ... 0.0688477 -0.0996094 -0.0786133]\n",
      "   [0.0810547 0.0400391 0.0517578 ... 0.065918 -0.0849609 -0.0805664]\n",
      "   ...\n",
      "   [0.172852 0.178711 0.115234 ... 0.041748 -0.0375977 -0.326172]\n",
      "   [0.172852 0.178711 0.115234 ... 0.041748 -0.0375977 -0.326172]\n",
      "   [0.172852 0.178711 0.115234 ... 0.041748 -0.0375977 -0.326172]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.145508 0.172852 0.176758 ... 0.0644531 0.0498047 -0.0678711]\n",
      "   [-0.145508 0.0603027 0.0291748 ... 0.00628662 0.0703125 -0.0306396]\n",
      "   [-0.0437012 0.121094 0.0976562 ... 0.0407715 0.0830078 -0.0166016]\n",
      "   ...\n",
      "   [0.201172 0.197266 0.140625 ... 0.048584 0.0483398 -0.0893555]\n",
      "   [0.201172 0.197266 0.140625 ... 0.048584 0.0483398 -0.0893555]\n",
      "   [0.201172 0.197266 0.140625 ... 0.048584 0.0483398 -0.0893555]]\n",
      "\n",
      "  [[0.0922852 0.229492 0.0761719 ... 0.145508 -0.0527344 0.0688477]\n",
      "   [0.0986328 0.188477 -0.161133 ... 0.138672 0.034668 0.117188]\n",
      "   [0.0922852 0.166016 -0.111328 ... 0.167969 0.0454102 0.0849609]\n",
      "   ...\n",
      "   [0.164062 0.185547 0.019165 ... 0.138672 -0.0756836 0.0878906]\n",
      "   [0.164062 0.185547 0.019165 ... 0.138672 -0.0756836 0.0878906]\n",
      "   [0.164062 0.185547 0.019165 ... 0.138672 -0.0756836 0.0878906]]\n",
      "\n",
      "  [[0.109863 0.00279236 -0.365234 ... -0.10791 -0.0183105 -0.0480957]\n",
      "   [0.0834961 0.029541 -0.367188 ... -0.128906 -0.0224609 -0.0761719]\n",
      "   [0.11084 0.00334167 -0.363281 ... -0.107422 -0.0154419 -0.0478516]\n",
      "   ...\n",
      "   [-0.0449219 0.104492 -0.408203 ... -0.120605 -0.0976562 -0.0437012]\n",
      "   [-0.0449219 0.104492 -0.408203 ... -0.120605 -0.0976562 -0.0437012]\n",
      "   [-0.0449219 0.104492 -0.408203 ... -0.120605 -0.0976562 -0.0437012]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.172852 0.0505371 0.105957 ... 0.15332 -0.310547 0.0412598]\n",
      "   [-0.208984 0.100586 -0.147461 ... 0.0786133 -0.0310059 0.172852]\n",
      "   [-0.304688 0.119629 -0.125977 ... 0.0532227 -0.246094 0.154297]\n",
      "   ...\n",
      "   [0.0859375 0.0854492 0.0766602 ... 0.0622559 0.289062 0.0786133]\n",
      "   [0.0859375 0.0854492 0.0766602 ... 0.0622559 0.289062 0.0786133]\n",
      "   [0.0859375 0.0854492 0.0766602 ... 0.0622559 0.289062 0.0786133]]\n",
      "\n",
      "  [[-0.0595703 -0.151367 -0.129883 ... -0.106934 -0.0786133 -0.0305176]\n",
      "   [-0.980469 0.287109 -0.118652 ... 0.240234 -0.171875 0.179688]\n",
      "   [-0.683594 0.0932617 -0.0544434 ... -0.10498 -0.326172 -0.0349121]\n",
      "   ...\n",
      "   [-0.144531 -0.136719 -0.0249023 ... -0.124023 -0.182617 -0.0222168]\n",
      "   [-0.144531 -0.136719 -0.0249023 ... -0.124023 -0.182617 -0.0222168]\n",
      "   [-0.144531 -0.136719 -0.0249023 ... -0.124023 -0.182617 -0.0222168]]\n",
      "\n",
      "  [[0.0390625 0.0559082 0.320312 ... -0.180664 0.121094 0.0834961]\n",
      "   [-0.21875 0.345703 0.269531 ... 0.00540161 -0.0480957 0.197266]\n",
      "   [-0.12793 0.246094 0.180664 ... 0.146484 -0.175781 0.106934]\n",
      "   ...\n",
      "   [-0.0461426 0.0250244 0.359375 ... -0.116211 0.0961914 0.090332]\n",
      "   [-0.0461426 0.0250244 0.359375 ... -0.116211 0.0961914 0.090332]\n",
      "   [-0.0461426 0.0250244 0.359375 ... -0.116211 0.0961914 0.090332]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.173828 -0.00683594 0.0776367 ... -0.0595703 -0.117676 0.0820312]\n",
      "   [-0.132812 -0.808594 0.462891 ... -0.578125 -0.228516 -0.375]\n",
      "   [-0.292969 -0.507812 0.486328 ... -0.601562 -0.105469 -0.263672]\n",
      "   ...\n",
      "   [-0.0257568 -0.050293 0.00286865 ... 0.0539551 -0.139648 0.00640869]\n",
      "   [-0.0257568 -0.050293 0.00286865 ... 0.0539551 -0.139648 0.00640869]\n",
      "   [-0.0257568 -0.050293 0.00286865 ... 0.0539551 -0.139648 0.00640869]]\n",
      "\n",
      "  [[-0.0878906 -0.217773 0.285156 ... 0.020752 0.00518799 -0.183594]\n",
      "   [-0.169922 -0.065918 0.217773 ... 0.0334473 -0.0593262 -0.259766]\n",
      "   [-0.188477 -0.0854492 0.104492 ... 0.0834961 -0.0603027 -0.269531]\n",
      "   ...\n",
      "   [-0.165039 -0.141602 0.376953 ... -0.0712891 -0.0625 -0.224609]\n",
      "   [-0.165039 -0.141602 0.376953 ... -0.0712891 -0.0625 -0.224609]\n",
      "   [-0.165039 -0.141602 0.376953 ... -0.0712891 -0.0625 -0.224609]]\n",
      "\n",
      "  [[0.103516 0.165039 -0.306641 ... -0.390625 -0.11377 0.21875]\n",
      "   [0.0810547 0.230469 -0.390625 ... -0.390625 -0.160156 0.222656]\n",
      "   [0.115723 0.253906 -0.476562 ... -0.330078 -0.167969 0.238281]\n",
      "   ...\n",
      "   [0.0257568 0.209961 -0.283203 ... -0.371094 -0.135742 0.102539]\n",
      "   [0.0257568 0.209961 -0.283203 ... -0.371094 -0.135742 0.102539]\n",
      "   [0.0257568 0.209961 -0.283203 ... -0.371094 -0.135742 0.102539]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.228516 0.0610352 0.0410156 ... -0.0410156 -0.19043 0.0185547]\n",
      "   [-0.21582 0.255859 0.0908203 ... 0.0229492 -0.275391 -0.0776367]\n",
      "   [-0.392578 0.306641 0.0134888 ... -0.100586 -0.152344 -0.146484]\n",
      "   ...\n",
      "   [0.0849609 0.0466309 0.0883789 ... 0.0654297 -0.105469 -0.0854492]\n",
      "   [0.0849609 0.0466309 0.0883789 ... 0.0654297 -0.105469 -0.0854492]\n",
      "   [0.0849609 0.0466309 0.0883789 ... 0.0654297 -0.105469 -0.0854492]]\n",
      "\n",
      "  [[0.0415039 0.078125 -0.150391 ... -0.0128174 -0.10498 0.839844]\n",
      "   [-0.0245361 0.0961914 -0.133789 ... -0.0991211 -0.232422 0.302734]\n",
      "   [-0.0324707 0.135742 -0.0098877 ... -0.0164795 -0.21582 0.212891]\n",
      "   ...\n",
      "   [0.00082016 0.0771484 -0.283203 ... 0.000185013 -0.176758 0.644531]\n",
      "   [0.00082016 0.0771484 -0.283203 ... 0.000185013 -0.176758 0.644531]\n",
      "   [0.00082016 0.0771484 -0.283203 ... 0.000185013 -0.176758 0.644531]]\n",
      "\n",
      "  [[0.0888672 -0.185547 -0.167969 ... 0.251953 -0.0549316 -0.233398]\n",
      "   [-0.310547 0.219727 0.648438 ... 0.373047 -0.4375 0.296875]\n",
      "   [-0.191406 0.0634766 0.652344 ... 0.291016 -0.404297 0.371094]\n",
      "   ...\n",
      "   [0.0219727 -0.163086 -0.155273 ... 0.217773 -0.132812 -0.102539]\n",
      "   [0.0219727 -0.163086 -0.155273 ... 0.217773 -0.132812 -0.102539]\n",
      "   [0.0219727 -0.163086 -0.155273 ... 0.217773 -0.132812 -0.102539]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0218506 -0.0708008 -0.00686646 ... -0.129883 0.0932617 0.0344238]\n",
      "   [0.294922 0.0839844 -0.0849609 ... -0.322266 0.208008 0.429688]\n",
      "   [0.289062 -0.0272217 -0.0820312 ... -0.235352 0.214844 0.429688]\n",
      "   ...\n",
      "   [0.0510254 -0.078125 -0.0708008 ... -0.275391 0.0927734 0.271484]\n",
      "   [0.0510254 -0.078125 -0.0708008 ... -0.275391 0.0927734 0.271484]\n",
      "   [0.0510254 -0.078125 -0.0708008 ... -0.275391 0.0927734 0.271484]]\n",
      "\n",
      "  [[0.147461 -0.0349121 -0.219727 ... 0.081543 0.271484 -0.203125]\n",
      "   [-0.0727539 0.100098 0.484375 ... -0.5625 0.445312 -0.34375]\n",
      "   [-0.226562 0.161133 0.5 ... -0.398438 0.480469 -0.447266]\n",
      "   ...\n",
      "   [0.148438 0.0493164 -0.140625 ... 0.259766 0.129883 -0.253906]\n",
      "   [0.148438 0.0493164 -0.140625 ... 0.259766 0.129883 -0.253906]\n",
      "   [0.148438 0.0493164 -0.140625 ... 0.259766 0.129883 -0.253906]]\n",
      "\n",
      "  [[-0.111328 0.074707 -0.212891 ... -0.22168 -0.0703125 0.0966797]\n",
      "   [-0.114258 0.333984 0.101562 ... 0.0166016 0.175781 -0.0507812]\n",
      "   [-0.228516 0.149414 0.144531 ... -0.0898438 0.0703125 0.000356674]\n",
      "   ...\n",
      "   [-0.306641 0.0258789 -0.00028801 ... -0.0375977 0.0251465 -0.0244141]\n",
      "   [-0.306641 0.0258789 -0.00028801 ... -0.0375977 0.0251465 -0.0244141]\n",
      "   [-0.306641 0.0258789 -0.00028801 ... -0.0375977 0.0251465 -0.0244141]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0532227 -0.146484 -0.0854492 ... 0.123047 -0.237305 0.123535]\n",
      "   [0.384766 0.0854492 -0.107422 ... 0.292969 -0.0549316 -0.318359]\n",
      "   [0.419922 0.0446777 -0.118164 ... 0.53125 0.0388184 -0.730469]\n",
      "   ...\n",
      "   [0.172852 0.0554199 -0.147461 ... -0.0223389 -0.130859 -0.116211]\n",
      "   [0.172852 0.0554199 -0.147461 ... -0.0223389 -0.130859 -0.116211]\n",
      "   [0.172852 0.0554199 -0.147461 ... -0.0223389 -0.130859 -0.116211]]\n",
      "\n",
      "  [[0.115723 0.155273 -0.0742188 ... -0.108887 0.193359 -0.177734]\n",
      "   [0.277344 -0.714844 -0.104492 ... 0.476562 -0.239258 -0.310547]\n",
      "   [0.28125 -0.816406 -0.0820312 ... 0.511719 -0.294922 -0.380859]\n",
      "   ...\n",
      "   [-0.0727539 -0.150391 -0.101562 ... 0.648438 0.139648 -0.0961914]\n",
      "   [-0.0727539 -0.150391 -0.101562 ... 0.648438 0.139648 -0.0961914]\n",
      "   [-0.0727539 -0.150391 -0.101562 ... 0.648438 0.139648 -0.0961914]]\n",
      "\n",
      "  [[0.112305 -0.0593262 0.289062 ... -0.00198364 -0.168945 -0.208008]\n",
      "   [0.609375 0.294922 0.429688 ... -0.130859 -0.730469 -0.101074]\n",
      "   [0.441406 0.133789 0.139648 ... -0.105957 -0.464844 0.00686646]\n",
      "   ...\n",
      "   [-0.494141 0.251953 0.369141 ... -0.177734 -0.613281 -0.478516]\n",
      "   [-0.494141 0.251953 0.369141 ... -0.177734 -0.613281 -0.478516]\n",
      "   [-0.494141 0.251953 0.369141 ... -0.177734 -0.613281 -0.478516]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0534668 0.369141 0.142578 ... 0.158203 -0.255859 -0.100098]\n",
      "   [-0.0649414 0.117676 0.447266 ... 0.609375 0.0255127 -0.539062]\n",
      "   [0.169922 0.230469 0.161133 ... 0.300781 -0.194336 -0.0976562]\n",
      "   ...\n",
      "   [-0.120605 0.304688 0.140625 ... 0.121582 -0.285156 -0.115723]\n",
      "   [-0.120605 0.304688 0.140625 ... 0.121582 -0.285156 -0.115723]\n",
      "   [-0.120605 0.304688 0.140625 ... 0.121582 -0.285156 -0.115723]]\n",
      "\n",
      "  [[-0.224609 0.202148 0.193359 ... -0.292969 -0.394531 -0.277344]\n",
      "   [-0.357422 -0.0427246 -0.328125 ... -0.234375 0.15332 0.131836]\n",
      "   [-0.375 0.00982666 -0.419922 ... -0.170898 0.195312 0.139648]\n",
      "   ...\n",
      "   [-0.388672 0.213867 0.316406 ... -0.120605 -0.359375 -0.240234]\n",
      "   [-0.388672 0.213867 0.316406 ... -0.120605 -0.359375 -0.240234]\n",
      "   [-0.388672 0.213867 0.316406 ... -0.120605 -0.359375 -0.240234]]\n",
      "\n",
      "  [[-0.0129395 -0.0222168 -0.0981445 ... 0.00149536 -0.486328\n",
      "    -0.0424805]\n",
      "   [-0.178711 -1.07812 -0.539062 ... 0.589844 1.53906 -0.238281]\n",
      "   [-0.138672 -0.0732422 -0.875 ... 0.671875 1.40625 -0.139648]\n",
      "   ...\n",
      "   [0.167969 0.104492 0.169922 ... -0.00488281 0.045166 0.253906]\n",
      "   [0.167969 0.104492 0.169922 ... -0.00488281 0.045166 0.253906]\n",
      "   [0.167969 0.104492 0.169922 ... -0.00488281 0.045166 0.253906]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0152588 -0.476562 0.0600586 ... 0.168945 0.179688 0.0932617]\n",
      "   [-0.0668945 0.277344 0.566406 ... 0.390625 0.108887 0.0576172]\n",
      "   [-0.0245361 0.412109 0.566406 ... 0.443359 0.255859 -0.197266]\n",
      "   ...\n",
      "   [-0.150391 -0.200195 0.126953 ... 0.213867 0.211914 0.0159912]\n",
      "   [-0.150391 -0.200195 0.126953 ... 0.213867 0.211914 0.0159912]\n",
      "   [-0.150391 -0.200195 0.126953 ... 0.213867 0.211914 0.0159912]]\n",
      "\n",
      "  [[-0.347656 0.194336 -0.226562 ... -0.197266 0.013916 -0.375]\n",
      "   [-0.910156 0.242188 -1.03906 ... -1.03125 -0.353516 -0.177734]\n",
      "   [-0.275391 0.132812 -0.515625 ... -0.722656 -0.335938 -0.0622559]\n",
      "   ...\n",
      "   [-0.185547 0.322266 -0.194336 ... -0.249023 -0.0446777 -0.263672]\n",
      "   [-0.185547 0.322266 -0.194336 ... -0.249023 -0.0446777 -0.263672]\n",
      "   [-0.185547 0.322266 -0.194336 ... -0.249023 -0.0446777 -0.263672]]\n",
      "\n",
      "  [[-0.296875 0.171875 0.574219 ... -0.304688 0.328125 -0.0103149]\n",
      "   [-0.275391 0.236328 1.10156 ... -0.12207 -0.300781 -0.171875]\n",
      "   [-0.414062 0.412109 0.914062 ... -0.0255127 -0.131836 -0.345703]\n",
      "   ...\n",
      "   [-0.191406 0.204102 0.714844 ... -0.298828 0.330078 0.0480957]\n",
      "   [-0.191406 0.204102 0.714844 ... -0.298828 0.330078 0.0480957]\n",
      "   [-0.191406 0.204102 0.714844 ... -0.298828 0.330078 0.0480957]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.219727 -0.02771 0.106445 ... 0.213867 0.316406 -0.176758]\n",
      "   [-0.445312 -0.265625 0.166016 ... 0.429688 -0.0512695 0.10791]\n",
      "   [-0.445312 -0.202148 0.180664 ... 0.333984 -0.0839844 -0.0236816]\n",
      "   ...\n",
      "   [-0.154297 -0.198242 0.150391 ... 0.135742 0.271484 -0.253906]\n",
      "   [-0.154297 -0.198242 0.150391 ... 0.135742 0.271484 -0.253906]\n",
      "   [-0.154297 -0.198242 0.150391 ... 0.135742 0.271484 -0.253906]]\n",
      "\n",
      "  [[0.0849609 0.104492 -0.0893555 ... 0.3125 -0.0539551 0.135742]\n",
      "   [0.171875 -0.365234 -0.0332031 ... 0.149414 0.601562 0.0255127]\n",
      "   [0.380859 -0.507812 0.0336914 ... 0.065918 0.640625 -0.251953]\n",
      "   ...\n",
      "   [0.137695 0.291016 -0.236328 ... 0.145508 -0.178711 0.3125]\n",
      "   [0.137695 0.291016 -0.236328 ... 0.145508 -0.178711 0.3125]\n",
      "   [0.137695 0.291016 -0.236328 ... 0.145508 -0.178711 0.3125]]\n",
      "\n",
      "  [[0.106934 0.345703 -0.0251465 ... 0.114746 0.074707 0.00701904]\n",
      "   [0.0874023 0.855469 -0.116699 ... 0.0742188 0.175781 0.0888672]\n",
      "   [0.196289 0.0205078 -0.169922 ... 0.0869141 0.196289 0.273438]\n",
      "   ...\n",
      "   [0.0727539 0.294922 -0.046875 ... 0.193359 0.117676 0.0629883]\n",
      "   [0.0727539 0.294922 -0.046875 ... 0.193359 0.117676 0.0629883]\n",
      "   [0.0727539 0.294922 -0.046875 ... 0.193359 0.117676 0.0629883]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.245117 0.0761719 -0.285156 ... -0.0673828 -0.0332031 -0.189453]\n",
      "   [0.419922 0.246094 -0.324219 ... 0.322266 0.243164 -0.248047]\n",
      "   [0.289062 -0.363281 -0.165039 ... 0.0223389 -0.0275879 0.287109]\n",
      "   ...\n",
      "   [0.154297 -0.102539 -0.111328 ... -0.125977 -0.0605469 0.125]\n",
      "   [0.154297 -0.102539 -0.111328 ... -0.125977 -0.0605469 0.125]\n",
      "   [0.154297 -0.102539 -0.111328 ... -0.125977 -0.0605469 0.125]]\n",
      "\n",
      "  [[-0.15625 0.0820312 0.201172 ... 0.0703125 -0.0693359 0.149414]\n",
      "   [-0.294922 -1.02344 0.738281 ... -0.194336 -0.378906 0.353516]\n",
      "   [-0.357422 -1.03125 0.683594 ... -0.148438 -0.373047 0.369141]\n",
      "   ...\n",
      "   [-0.363281 -0.197266 0.449219 ... 0.140625 -0.0507812 0.275391]\n",
      "   [-0.363281 -0.197266 0.449219 ... 0.140625 -0.0507812 0.275391]\n",
      "   [-0.363281 -0.197266 0.449219 ... 0.140625 -0.0507812 0.275391]]\n",
      "\n",
      "  [[0.345703 -0.0834961 0.139648 ... -0.149414 0.275391 -0.130859]\n",
      "   [-0.361328 0.382812 -0.181641 ... 0.238281 -0.332031 -0.523438]\n",
      "   [-0.285156 0.558594 -0.111328 ... 0.225586 0.112793 -0.462891]\n",
      "   ...\n",
      "   [-0.133789 0.0864258 0.0270996 ... -0.0371094 0.0703125 -0.0517578]\n",
      "   [-0.133789 0.0864258 0.0270996 ... -0.0371094 0.0703125 -0.0517578]\n",
      "   [-0.133789 0.0864258 0.0270996 ... -0.0371094 0.0703125 -0.0517578]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.25 0.202148 0.0566406 ... -0.233398 -0.15918 -0.439453]\n",
      "   [0.208008 0.394531 -0.225586 ... 0.382812 0.248047 -0.359375]\n",
      "   [0.671875 -0.0368652 0.394531 ... -0.129883 -0.0306396 -0.189453]\n",
      "   ...\n",
      "   [-0.0693359 0.460938 0.0761719 ... -0.0483398 0.0800781 -0.416016]\n",
      "   [-0.0693359 0.460938 0.0761719 ... -0.0483398 0.0800781 -0.416016]\n",
      "   [-0.0693359 0.460938 0.0761719 ... -0.0483398 0.0800781 -0.416016]]\n",
      "\n",
      "  [[0.316406 0.341797 0.249023 ... -0.137695 -0.034668 0.0170898]\n",
      "   [0.263672 -0.112305 0.421875 ... -0.414062 -0.496094 0.652344]\n",
      "   [0.306641 -0.217773 0.382812 ... -0.423828 -0.550781 0.945312]\n",
      "   ...\n",
      "   [0.439453 0.253906 0.253906 ... -0.209961 -0.104492 0.0568848]\n",
      "   [0.439453 0.253906 0.253906 ... -0.209961 -0.104492 0.0568848]\n",
      "   [0.439453 0.253906 0.253906 ... -0.209961 -0.104492 0.0568848]]\n",
      "\n",
      "  [[0.0223389 -0.0136108 0.143555 ... -0.0162354 0.310547 0.00891113]\n",
      "   [-0.0629883 0.578125 -1.07031 ... 0.0581055 0.5625 -0.953125]\n",
      "   [0.328125 0.201172 -0.0422363 ... -0.511719 1.03906 -0.835938]\n",
      "   ...\n",
      "   [0.0603027 -0.259766 0.177734 ... -0.0461426 0.296875 -0.0067749]\n",
      "   [0.0603027 -0.259766 0.177734 ... -0.0461426 0.296875 -0.0067749]\n",
      "   [0.0603027 -0.259766 0.177734 ... -0.0461426 0.296875 -0.0067749]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0639648 0.0270996 -0.0668945 ... 0.113281 0.236328 -0.302734]\n",
      "   [-0.302734 0.149414 0.144531 ... -0.150391 -0.34375 -0.171875]\n",
      "   [-0.353516 -0.0174561 0.332031 ... -0.202148 -0.248047 -0.15918]\n",
      "   ...\n",
      "   [-0.097168 0.177734 0.126953 ... 0.0109863 0.227539 -0.251953]\n",
      "   [-0.097168 0.177734 0.126953 ... 0.0109863 0.227539 -0.251953]\n",
      "   [-0.097168 0.177734 0.126953 ... 0.0109863 0.227539 -0.251953]]\n",
      "\n",
      "  [[-0.253906 -0.0123901 -0.207031 ... -0.03125 0.433594 -0.0922852]\n",
      "   [-0.21582 -0.417969 -0.267578 ... -0.333984 0.119141 0.0639648]\n",
      "   [-0.367188 -0.220703 -0.108887 ... -0.371094 0.0566406 0.179688]\n",
      "   ...\n",
      "   [-0.292969 -0.0291748 -0.267578 ... -0.119141 0.632812 -0.142578]\n",
      "   [-0.292969 -0.0291748 -0.267578 ... -0.119141 0.632812 -0.142578]\n",
      "   [-0.292969 -0.0291748 -0.267578 ... -0.119141 0.632812 -0.142578]]\n",
      "\n",
      "  [[-0.138672 -0.129883 -0.0996094 ... 0.192383 0.542969 -0.0722656]\n",
      "   [-0.171875 0.28125 -0.0162354 ... 0.369141 0.835938 -0.193359]\n",
      "   [-0.0164795 0.0668945 -0.193359 ... 0.277344 0.667969 -0.243164]\n",
      "   ...\n",
      "   [-0.130859 0.0123291 0.255859 ... 0.101562 0.392578 -0.114258]\n",
      "   [-0.130859 0.0123291 0.255859 ... 0.101562 0.392578 -0.114258]\n",
      "   [-0.130859 0.0123291 0.255859 ... 0.101562 0.392578 -0.114258]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0698242 -0.322266 0.0317383 ... -0.396484 0.102051 0.128906]\n",
      "   [-0.0478516 -0.173828 0.339844 ... -0.152344 0.165039 -0.597656]\n",
      "   [-0.00634766 -0.0115967 0.435547 ... -0.19043 0.339844 -0.550781]\n",
      "   ...\n",
      "   [-0.263672 0.111328 -0.000312805 ... -0.138672 0.267578 -0.0639648]\n",
      "   [-0.263672 0.111328 -0.000312805 ... -0.138672 0.267578 -0.0639648]\n",
      "   [-0.263672 0.111328 -0.000312805 ... -0.138672 0.267578 -0.0639648]]\n",
      "\n",
      "  [[-0.158203 0.484375 0.322266 ... -0.191406 0.263672 -0.28125]\n",
      "   [-0.333984 0.585938 -0.115234 ... 0.121094 0.433594 -0.546875]\n",
      "   [-0.267578 0.535156 -0.107422 ... 0.12793 0.394531 -0.527344]\n",
      "   ...\n",
      "   [-0.00466919 0.235352 0.0186768 ... 0.175781 -0.186523 -0.1875]\n",
      "   [-0.00466919 0.235352 0.0186768 ... 0.175781 -0.186523 -0.1875]\n",
      "   [-0.00466919 0.235352 0.0186768 ... 0.175781 -0.186523 -0.1875]]\n",
      "\n",
      "  [[-0.017334 -0.230469 0.0390625 ... 0.257812 -0.261719 0.122559]\n",
      "   [0.0598145 -0.296875 -0.355469 ... -0.0622559 0.0588379 0.0150757]\n",
      "   [-0.0541992 -0.28125 -0.361328 ... -0.130859 0.0339355 -0.0727539]\n",
      "   ...\n",
      "   [0.217773 -0.152344 -0.097168 ... 0.139648 -0.285156 0.0554199]\n",
      "   [0.217773 -0.152344 -0.097168 ... 0.139648 -0.285156 0.0554199]\n",
      "   [0.217773 -0.152344 -0.097168 ... 0.139648 -0.285156 0.0554199]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.279297 0.425781 0.237305 ... 0.074707 -0.257812 0.578125]\n",
      "   [0.154297 0.507812 0.416016 ... 0.00823975 0.28125 -1.67969]\n",
      "   [0.208008 0.53125 0.382812 ... -0.0203857 0.417969 -1.58594]\n",
      "   ...\n",
      "   [-0.0810547 -0.378906 0.010437 ... 0.0463867 0.527344 0.394531]\n",
      "   [-0.0810547 -0.378906 0.010437 ... 0.0463867 0.527344 0.394531]\n",
      "   [-0.0810547 -0.378906 0.010437 ... 0.0463867 0.527344 0.394531]]\n",
      "\n",
      "  [[0.251953 0.0761719 0.115234 ... 0.0351562 -0.0219727 0.11377]\n",
      "   [0.139648 -0.361328 0.060791 ... -0.476562 -0.490234 0.115723]\n",
      "   [0.231445 -0.126953 -0.108398 ... -0.539062 -0.398438 0.027832]\n",
      "   ...\n",
      "   [-0.714844 0.161133 -0.195312 ... -0.194336 0.523438 -0.484375]\n",
      "   [-0.714844 0.161133 -0.195312 ... -0.194336 0.523438 -0.484375]\n",
      "   [-0.714844 0.161133 -0.195312 ... -0.194336 0.523438 -0.484375]]\n",
      "\n",
      "  [[0.235352 0.0913086 0.0515137 ... -0.0947266 0.196289 -0.292969]\n",
      "   [0.171875 -0.902344 0.121094 ... -0.359375 0.578125 -0.453125]\n",
      "   [0.12793 -0.652344 0.0800781 ... -0.494141 0.679688 -0.527344]\n",
      "   ...\n",
      "   [0.124023 -0.220703 -0.0181885 ... -0.133789 -0.000736237 -0.0786133]\n",
      "   [0.124023 -0.220703 -0.0181885 ... -0.133789 -0.000736237 -0.0786133]\n",
      "   [0.124023 -0.220703 -0.0181885 ... -0.133789 -0.000736237 -0.0786133]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.129883 0.170898 0.188477 ... -0.0224609 -0.28125 0.0839844]\n",
      "   [0.116211 0.134766 0.742188 ... 0.34375 -0.232422 0.00104523]\n",
      "   [0.103027 0.210938 0.625 ... 0.494141 -0.1875 0.0844727]\n",
      "   ...\n",
      "   [0.0517578 0.208984 0.230469 ... -0.0130615 -0.337891 -0.0786133]\n",
      "   [0.0517578 0.208984 0.230469 ... -0.0130615 -0.337891 -0.0786133]\n",
      "   [0.0517578 0.208984 0.230469 ... -0.0130615 -0.337891 -0.0786133]]\n",
      "\n",
      "  [[-0.230469 0.435547 -0.180664 ... -0.0593262 0.207031 -0.204102]\n",
      "   [-0.150391 -0.0334473 0.208008 ... -1.25781 0.757812 0.170898]\n",
      "   [-0.0280762 -0.034668 0.029541 ... -0.53125 -0.0385742 0.133789]\n",
      "   ...\n",
      "   [-0.186523 -0.078125 0.0996094 ... -0.216797 0.0698242 -0.0286865]\n",
      "   [-0.186523 -0.078125 0.0996094 ... -0.216797 0.0698242 -0.0286865]\n",
      "   [-0.186523 -0.078125 0.0996094 ... -0.216797 0.0698242 -0.0286865]]\n",
      "\n",
      "  [[0.0583496 -0.0913086 -0.132812 ... -0.145508 0.193359 0.106934]\n",
      "   [-0.146484 -0.283203 1.08594 ... -0.667969 0.455078 -0.0383301]\n",
      "   [-0.0908203 -0.246094 1.14844 ... -0.683594 0.523438 0.0732422]\n",
      "   ...\n",
      "   [0.141602 -0.0239258 -0.429688 ... -0.00331116 0.298828 -0.0917969]\n",
      "   [0.141602 -0.0239258 -0.429688 ... -0.00331116 0.298828 -0.0917969]\n",
      "   [0.141602 -0.0239258 -0.429688 ... -0.00331116 0.298828 -0.0917969]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.451172 -0.365234 -0.198242 ... 0.384766 0.863281 -0.466797]\n",
      "   [-0.100586 -0.18457 -0.75 ... 0.566406 1.26562 -0.429688]\n",
      "   [-0.133789 -0.24707 -0.757812 ... 0.566406 1.15625 -0.191406]\n",
      "   ...\n",
      "   [0.0510254 -0.0488281 -0.296875 ... 0.164062 0.382812 -0.269531]\n",
      "   [0.0510254 -0.0488281 -0.296875 ... 0.164062 0.382812 -0.269531]\n",
      "   [0.0510254 -0.0488281 -0.296875 ... 0.164062 0.382812 -0.269531]]\n",
      "\n",
      "  [[0.400391 -0.0125122 0.169922 ... -0.355469 -0.176758 -0.22168]\n",
      "   [0.130859 0.185547 0.267578 ... -0.515625 -0.294922 -0.441406]\n",
      "   [0.365234 0.00860596 0.507812 ... -0.478516 -0.116699 -0.279297]\n",
      "   ...\n",
      "   [0.351562 -0.0524902 0.240234 ... -0.00640869 -0.367188 -0.339844]\n",
      "   [0.351562 -0.0524902 0.240234 ... -0.00640869 -0.367188 -0.339844]\n",
      "   [0.351562 -0.0524902 0.240234 ... -0.00640869 -0.367188 -0.339844]]\n",
      "\n",
      "  [[0.172852 0.201172 0.226562 ... 0.192383 -0.292969 0.326172]\n",
      "   [0.183594 0.207031 0.228516 ... 0.18457 -0.28125 0.347656]\n",
      "   [0.226562 0.214844 0.28125 ... 0.148438 -0.269531 0.320312]\n",
      "   ...\n",
      "   [0.182617 0.202148 0.222656 ... 0.188477 -0.300781 0.322266]\n",
      "   [0.182617 0.202148 0.222656 ... 0.188477 -0.300781 0.322266]\n",
      "   [0.182617 0.202148 0.222656 ... 0.188477 -0.300781 0.322266]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0444336 -0.029541 -0.324219 ... -0.109375 0.0456543 -0.0402832]\n",
      "   [-0.11377 0.0551758 -0.241211 ... 0.146484 -0.3125 0.222656]\n",
      "   [-0.137695 0.0668945 -0.0800781 ... -0.00714111 -0.225586 0.474609]\n",
      "   ...\n",
      "   [-0.00735474 -0.130859 -0.269531 ... -0.0874023 0.0830078 0.111328]\n",
      "   [-0.00735474 -0.130859 -0.269531 ... -0.0874023 0.0830078 0.111328]\n",
      "   [-0.00735474 -0.130859 -0.269531 ... -0.0874023 0.0830078 0.111328]]\n",
      "\n",
      "  [[0.172852 0.0439453 -0.145508 ... 0.0280762 -0.168945 0.213867]\n",
      "   [0.283203 0.208984 -0.271484 ... 0.0610352 0.427734 1.17188]\n",
      "   [0.345703 0.21582 -0.267578 ... -0.257812 0.455078 0.917969]\n",
      "   ...\n",
      "   [0.304688 0.0305176 -0.249023 ... 0.0761719 -0.339844 0.112305]\n",
      "   [0.304688 0.0305176 -0.249023 ... 0.0761719 -0.339844 0.112305]\n",
      "   [0.304688 0.0305176 -0.249023 ... 0.0761719 -0.339844 0.112305]]\n",
      "\n",
      "  [[0.224609 0.00402832 0.0407715 ... 0.162109 0.0629883 -0.412109]\n",
      "   [0.139648 -0.0378418 0.0922852 ... 0.0878906 -0.0708008 -0.00982666]\n",
      "   [0.147461 -0.135742 0.0727539 ... 0.119141 -0.0786133 0.048584]\n",
      "   ...\n",
      "   [0.287109 -0.139648 -0.0578613 ... 0.0351562 0.0585938 -0.125]\n",
      "   [0.287109 -0.139648 -0.0578613 ... 0.0351562 0.0585938 -0.125]\n",
      "   [0.287109 -0.139648 -0.0578613 ... 0.0351562 0.0585938 -0.125]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.453125 -0.244141 0.0888672 ... 0.101074 0.0825195 -0.251953]\n",
      "   [-0.558594 -0.318359 -0.285156 ... -0.00396729 -0.0170898 -0.113281]\n",
      "   [-0.275391 -0.478516 0.0461426 ... -0.185547 -0.137695 -0.890625]\n",
      "   ...\n",
      "   [0.00141907 -0.21875 0.0888672 ... 0.0019989 0.111816 -0.275391]\n",
      "   [0.00141907 -0.21875 0.0888672 ... 0.0019989 0.111816 -0.275391]\n",
      "   [0.00141907 -0.21875 0.0888672 ... 0.0019989 0.111816 -0.275391]]\n",
      "\n",
      "  [[-0.318359 0.304688 0.19043 ... -0.318359 0.0678711 -0.0913086]\n",
      "   [0.227539 0.136719 -0.527344 ... -0.0786133 -0.0222168 0.179688]\n",
      "   [0.277344 0.137695 -0.722656 ... -0.0625 -0.0510254 0.186523]\n",
      "   ...\n",
      "   [-0.074707 0.376953 0.0922852 ... -0.128906 0.0456543 0.189453]\n",
      "   [-0.074707 0.376953 0.0922852 ... -0.128906 0.0456543 0.189453]\n",
      "   [-0.074707 0.376953 0.0922852 ... -0.128906 0.0456543 0.189453]]\n",
      "\n",
      "  [[0.324219 -0.196289 -0.261719 ... -0.115234 0.125977 -0.00466919]\n",
      "   [0.0180664 -0.535156 0.154297 ... -0.251953 0.100098 -0.219727]\n",
      "   [0.0576172 -0.65625 0.0245361 ... -0.601562 0.0732422 0.0634766]\n",
      "   ...\n",
      "   [0.0466309 -0.170898 -0.201172 ... -0.269531 0.045166 0.0275879]\n",
      "   [0.0466309 -0.170898 -0.201172 ... -0.269531 0.045166 0.0275879]\n",
      "   [0.0466309 -0.170898 -0.201172 ... -0.269531 0.045166 0.0275879]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0198975 -0.0375977 0.0554199 ... -0.10791 0.10498 -0.0067749]\n",
      "   [-0.141602 -0.855469 -0.601562 ... -0.519531 -0.122559 -0.0917969]\n",
      "   [-0.396484 -0.957031 -0.439453 ... -0.353516 -0.125 0.259766]\n",
      "   ...\n",
      "   [-0.0544434 0.146484 0.0201416 ... -0.0981445 0.0732422 0.0766602]\n",
      "   [-0.0544434 0.146484 0.0201416 ... -0.0981445 0.0732422 0.0766602]\n",
      "   [-0.0544434 0.146484 0.0201416 ... -0.0981445 0.0732422 0.0766602]]\n",
      "\n",
      "  [[-0.136719 0.00497437 0.449219 ... 0.097168 0.310547 0.244141]\n",
      "   [-0.511719 -0.769531 0.0649414 ... 0.503906 0.341797 0.0727539]\n",
      "   [-0.65625 -0.10791 0.0800781 ... 0.855469 -0.335938 -0.0303955]\n",
      "   ...\n",
      "   [0.227539 0.102051 0.371094 ... 0.152344 0.320312 -0.193359]\n",
      "   [0.227539 0.102051 0.371094 ... 0.152344 0.320312 -0.193359]\n",
      "   [0.227539 0.102051 0.371094 ... 0.152344 0.320312 -0.193359]]\n",
      "\n",
      "  [[-0.194336 0.0981445 0.208008 ... 0.0854492 0.119629 -0.0162354]\n",
      "   [0.302734 -0.419922 0.081543 ... 0.283203 0.277344 0.204102]\n",
      "   [0.322266 -0.574219 0.128906 ... 0.233398 0.219727 0.527344]\n",
      "   ...\n",
      "   [-0.147461 0.00909424 0.106445 ... 0.010498 0.355469 -0.304688]\n",
      "   [-0.147461 0.00909424 0.106445 ... 0.010498 0.355469 -0.304688]\n",
      "   [-0.147461 0.00909424 0.106445 ... 0.010498 0.355469 -0.304688]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0306396 0.414062 0.0378418 ... -0.0172119 -0.0203857 0.0332031]\n",
      "   [-0.294922 0.341797 0.196289 ... -0.15918 0.0383301 0.129883]\n",
      "   [-0.333984 0.292969 0.0297852 ... -0.0192871 -0.0334473 0.119141]\n",
      "   ...\n",
      "   [-0.539062 -0.0341797 0.0888672 ... -0.0262451 -0.155273 0.296875]\n",
      "   [-0.539062 -0.0341797 0.0888672 ... -0.0262451 -0.155273 0.296875]\n",
      "   [-0.539062 -0.0341797 0.0888672 ... -0.0262451 -0.155273 0.296875]]\n",
      "\n",
      "  [[-0.902344 0.632812 -0.0183105 ... -0.519531 -0.25 -0.178711]\n",
      "   [-0.773438 -0.476562 -1.10156 ... 0.667969 0.369141 -0.00744629]\n",
      "   [0.249023 -0.0402832 0.027832 ... 0.283203 -0.328125 0.460938]\n",
      "   ...\n",
      "   [0.216797 0.277344 0.345703 ... 0.253906 -0.192383 0.0664062]\n",
      "   [0.216797 0.277344 0.345703 ... 0.253906 -0.192383 0.0664062]\n",
      "   [0.216797 0.277344 0.345703 ... 0.253906 -0.192383 0.0664062]]\n",
      "\n",
      "  [[0.195312 0.249023 0.128906 ... -0.265625 -0.326172 -0.152344]\n",
      "   [0.761719 0.59375 0.289062 ... -0.145508 -1.13281 -0.423828]\n",
      "   [0.859375 0.523438 -0.0639648 ... -0.304688 -1.17969 -0.71875]\n",
      "   ...\n",
      "   [0.138672 0.0932617 0.161133 ... -0.228516 -0.243164 -0.048584]\n",
      "   [0.138672 0.0932617 0.161133 ... -0.228516 -0.243164 -0.048584]\n",
      "   [0.138672 0.0932617 0.161133 ... -0.228516 -0.243164 -0.048584]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.470703 0.0043335 -0.136719 ... -0.271484 -0.298828 0.855469]\n",
      "   [0.130859 -0.129883 -1.01562 ... -0.228516 1.00781 -0.597656]\n",
      "   [0.460938 -0.566406 -0.664062 ... -0.269531 0.757812 0.109375]\n",
      "   ...\n",
      "   [-0.605469 -0.195312 -0.0164795 ... -0.118652 -0.090332 0.246094]\n",
      "   [-0.605469 -0.195312 -0.0164795 ... -0.118652 -0.090332 0.246094]\n",
      "   [-0.605469 -0.195312 -0.0164795 ... -0.118652 -0.090332 0.246094]]\n",
      "\n",
      "  [[0.0541992 -0.136719 0.0625 ... -0.0125732 -0.186523 -0.143555]\n",
      "   [-0.0795898 -0.0229492 -0.130859 ... 0.222656 -0.15918 0.378906]\n",
      "   [0.133789 -0.246094 0.00946045 ... 0.482422 -0.53125 0.9375]\n",
      "   ...\n",
      "   [-0.0512695 -0.0551758 0.0673828 ... -0.0688477 -0.267578 -0.175781]\n",
      "   [-0.0512695 -0.0551758 0.0673828 ... -0.0688477 -0.267578 -0.175781]\n",
      "   [-0.0512695 -0.0551758 0.0673828 ... -0.0688477 -0.267578 -0.175781]]\n",
      "\n",
      "  [[-0.462891 0.111328 0.554688 ... 0.220703 -0.257812 -0.180664]\n",
      "   [0.181641 0.707031 -0.205078 ... 0.296875 1.00781 1.10938]\n",
      "   [0.447266 0.453125 0.0625 ... 0.302734 1.95312 1.57031]\n",
      "   ...\n",
      "   [0.188477 -0.0981445 -0.367188 ... -0.390625 0.808594 0.0908203]\n",
      "   [0.188477 -0.0981445 -0.367188 ... -0.390625 0.808594 0.0908203]\n",
      "   [0.188477 -0.0981445 -0.367188 ... -0.390625 0.808594 0.0908203]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.380859 0.337891 -0.283203 ... -0.185547 0.304688 0.0612793]\n",
      "   [0.259766 -0.404297 0.882812 ... -0.835938 1.875 -0.0771484]\n",
      "   [0.181641 0.589844 -0.0717773 ... -0.043457 2.34375 0.535156]\n",
      "   ...\n",
      "   [-0.234375 0.105469 0.125977 ... -0.102051 0.191406 0.0756836]\n",
      "   [-0.234375 0.105469 0.125977 ... -0.102051 0.191406 0.0756836]\n",
      "   [-0.234375 0.105469 0.125977 ... -0.102051 0.191406 0.0756836]]\n",
      "\n",
      "  [[0.294922 0.898438 0.167969 ... 0.21582 0.109863 -0.476562]\n",
      "   [-0.163086 0.566406 0.177734 ... 0.271484 -0.396484 0.464844]\n",
      "   [-1.07031 -0.316406 -0.0698242 ... 0.238281 -0.253906 -0.161133]\n",
      "   ...\n",
      "   [-0.00482178 0.417969 -0.00772095 ... 0.0546875 0.090332 -0.228516]\n",
      "   [-0.00482178 0.417969 -0.00772095 ... 0.0546875 0.090332 -0.228516]\n",
      "   [-0.00482178 0.417969 -0.00772095 ... 0.0546875 0.090332 -0.228516]]\n",
      "\n",
      "  [[0.222656 -0.0534668 0.21582 ... 0.296875 0.535156 -0.111328]\n",
      "   [0.000576019 -0.208984 -0.306641 ... 0.172852 0.0854492 0.00567627]\n",
      "   [-0.09375 -0.120605 -0.304688 ... 0.231445 0.158203 0.0241699]\n",
      "   ...\n",
      "   [-0.257812 -0.111816 0.1875 ... 0.227539 0.357422 -0.195312]\n",
      "   [-0.257812 -0.111816 0.1875 ... 0.227539 0.357422 -0.195312]\n",
      "   [-0.257812 -0.111816 0.1875 ... 0.227539 0.357422 -0.195312]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.149414 0.886719 -0.163086 ... -0.120605 0.382812 -0.40625]\n",
      "   [0.00274658 0.429688 0.165039 ... -0.243164 0.0158691 0.324219]\n",
      "   [0.0390625 0.324219 0.365234 ... 0.257812 0.0256348 0.429688]\n",
      "   ...\n",
      "   [0.134766 0.128906 0.0458984 ... 0.0786133 -0.115723 0.09375]\n",
      "   [0.134766 0.128906 0.0458984 ... 0.0786133 -0.115723 0.09375]\n",
      "   [0.134766 0.128906 0.0458984 ... 0.0786133 -0.115723 0.09375]]\n",
      "\n",
      "  [[-0.185547 -0.1875 0.539062 ... -1.82031 -0.211914 -1.04688]\n",
      "   [0.296875 -0.314453 -0.0302734 ... 0.22168 0.0319824 -0.875]\n",
      "   [0.330078 0.0180664 0.138672 ... 0.417969 -0.00982666 -0.703125]\n",
      "   ...\n",
      "   [-0.18457 -0.0493164 0.294922 ... 1.42188 0.238281 0.0634766]\n",
      "   [-0.18457 -0.0493164 0.294922 ... 1.42188 0.238281 0.0634766]\n",
      "   [-0.18457 -0.0493164 0.294922 ... 1.42188 0.238281 0.0634766]]\n",
      "\n",
      "  [[-0.251953 0.188477 0.134766 ... -0.0288086 -0.206055 0.246094]\n",
      "   [-0.161133 0.263672 0.193359 ... -0.046875 -0.015625 0.188477]\n",
      "   [-0.328125 0.449219 -0.0114136 ... -0.0654297 0.0756836 0.328125]\n",
      "   ...\n",
      "   [-0.275391 0.158203 0.28125 ... -0.0324707 -0.234375 0.191406]\n",
      "   [-0.275391 0.158203 0.28125 ... -0.0324707 -0.234375 0.191406]\n",
      "   [-0.275391 0.158203 0.28125 ... -0.0324707 -0.234375 0.191406]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0712891 -0.0722656 -0.18457 ... -0.179688 0.445312 -0.417969]\n",
      "   [0.515625 -0.664062 -0.228516 ... -0.0795898 -0.53125 0.0262451]\n",
      "   [0.523438 -1.14844 -0.550781 ... 0.144531 -0.558594 -0.000835419]\n",
      "   ...\n",
      "   [-0.125977 -0.10498 0.118164 ... -0.373047 0.0844727 -0.28125]\n",
      "   [-0.125977 -0.10498 0.118164 ... -0.373047 0.0844727 -0.28125]\n",
      "   [-0.125977 -0.10498 0.118164 ... -0.373047 0.0844727 -0.28125]]\n",
      "\n",
      "  [[0.0432129 -0.00193787 -0.0678711 ... 0.0212402 0.285156 0.0776367]\n",
      "   [-0.00491333 0.135742 0.120605 ... 0.283203 0.0495605 0.226562]\n",
      "   [0.8125 0.511719 0.12207 ... 0.229492 0.0407715 0.119629]\n",
      "   ...\n",
      "   [0.194336 -0.0217285 -0.137695 ... 0.0722656 0.429688 0.119629]\n",
      "   [0.194336 -0.0217285 -0.137695 ... 0.0722656 0.429688 0.119629]\n",
      "   [0.194336 -0.0217285 -0.137695 ... 0.0722656 0.429688 0.119629]]\n",
      "\n",
      "  [[-0.117676 -0.189453 0.170898 ... 0.0488281 -0.249023 0.392578]\n",
      "   [-0.21875 -0.208008 -0.257812 ... 0.484375 -0.427734 -0.074707]\n",
      "   [-0.816406 -0.914062 -0.433594 ... 0.601562 -0.792969 0.910156]\n",
      "   ...\n",
      "   [-0.0119629 -0.128906 0.0593262 ... 0.0598145 -0.000448227 0.3125]\n",
      "   [-0.0119629 -0.128906 0.0593262 ... 0.0598145 -0.000448227 0.3125]\n",
      "   [-0.0119629 -0.128906 0.0593262 ... 0.0598145 -0.000448227 0.3125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0961914 -0.5625 -0.291016 ... 0.585938 0.101074 0.0368652]\n",
      "   [0.828125 -1.19531 0.863281 ... -0.138672 1.10938 2.79688]\n",
      "   [0.345703 -0.644531 0.183594 ... -0.00970459 0.423828 1.25781]\n",
      "   ...\n",
      "   [-0.347656 -0.176758 -0.652344 ... 0.318359 -0.0612793 -0.271484]\n",
      "   [-0.347656 -0.176758 -0.652344 ... 0.318359 -0.0612793 -0.271484]\n",
      "   [-0.347656 -0.176758 -0.652344 ... 0.318359 -0.0612793 -0.271484]]\n",
      "\n",
      "  [[0.0151367 -0.0268555 -0.0151367 ... 0.111816 0.0791016 0.197266]\n",
      "   [0.460938 0.242188 0.890625 ... -0.241211 -0.104004 -0.351562]\n",
      "   [0.255859 0.34375 0.707031 ... -0.212891 0.0932617 -0.189453]\n",
      "   ...\n",
      "   [0.104004 0.246094 0.110352 ... -0.0834961 0.111328 -0.0883789]\n",
      "   [0.104004 0.246094 0.110352 ... -0.0834961 0.111328 -0.0883789]\n",
      "   [0.104004 0.246094 0.110352 ... -0.0834961 0.111328 -0.0883789]]\n",
      "\n",
      "  [[0.0463867 0.048584 0.194336 ... 0.177734 0.179688 0.238281]\n",
      "   [-0.243164 0.121094 -0.078125 ... -0.0410156 -0.112793 -0.53125]\n",
      "   [-0.0495605 0.0458984 -0.0942383 ... -0.0251465 -0.111816 -0.125977]\n",
      "   ...\n",
      "   [-0.118164 0.0610352 0.129883 ... 0.116211 0.078125 0.200195]\n",
      "   [-0.118164 0.0610352 0.129883 ... 0.116211 0.078125 0.200195]\n",
      "   [-0.118164 0.0610352 0.129883 ... 0.116211 0.078125 0.200195]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0859375 -0.449219 -0.194336 ... -0.0761719 -0.21875 -0.494141]\n",
      "   [-0.0869141 0.157227 -0.378906 ... 0.480469 0.269531 -0.261719]\n",
      "   [-0.0825195 -0.122559 -0.425781 ... 0.219727 0.667969 0.0634766]\n",
      "   ...\n",
      "   [-0.0639648 -0.0893555 -0.251953 ... 0.242188 -0.124512 -0.351562]\n",
      "   [-0.0639648 -0.0893555 -0.251953 ... 0.242188 -0.124512 -0.351562]\n",
      "   [-0.0639648 -0.0893555 -0.251953 ... 0.242188 -0.124512 -0.351562]]\n",
      "\n",
      "  [[-0.163086 0.287109 -0.15918 ... -0.0187988 0.0419922 0.135742]\n",
      "   [0.453125 0.472656 0.263672 ... -0.229492 0.230469 0.0883789]\n",
      "   [0.820312 0.458984 1.20312 ... -1.03125 0.460938 -0.490234]\n",
      "   ...\n",
      "   [-0.0351562 0.0490723 -0.242188 ... -0.40625 -0.191406 0.213867]\n",
      "   [-0.0351562 0.0490723 -0.242188 ... -0.40625 -0.191406 0.213867]\n",
      "   [-0.0351562 0.0490723 -0.242188 ... -0.40625 -0.191406 0.213867]]\n",
      "\n",
      "  [[0.738281 -0.120117 0.318359 ... -0.123047 0.417969 0.0712891]\n",
      "   [0.026123 -0.753906 -0.15625 ... 0.396484 -0.287109 -0.112793]\n",
      "   [-0.045166 -0.832031 -0.447266 ... 0.34375 0.130859 -0.231445]\n",
      "   ...\n",
      "   [0.320312 -0.314453 -0.0976562 ... 0.0539551 0.242188 0.394531]\n",
      "   [0.320312 -0.314453 -0.0976562 ... 0.0539551 0.242188 0.394531]\n",
      "   [0.320312 -0.314453 -0.0976562 ... 0.0539551 0.242188 0.394531]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.00579834 0.0246582 -0.0250244 ... 0.0344238 0.0196533 -0.194336]\n",
      "   [-0.188477 0.0286865 -0.204102 ... 0.143555 -0.15625 -0.19043]\n",
      "   [-0.074707 0.0554199 -0.138672 ... 0.124023 -0.0625 -0.204102]\n",
      "   ...\n",
      "   [-0.0913086 0.0810547 -0.328125 ... -0.0183105 -0.0529785 -0.209961]\n",
      "   [-0.0913086 0.0810547 -0.328125 ... -0.0183105 -0.0529785 -0.209961]\n",
      "   [-0.0913086 0.0810547 -0.328125 ... -0.0183105 -0.0529785 -0.209961]]\n",
      "\n",
      "  [[-0.382812 -0.308594 -0.043457 ... 0.328125 0.0498047 -0.193359]\n",
      "   [0.0351562 0.0947266 -0.392578 ... -0.155273 -0.306641 -0.322266]\n",
      "   [-0.0030365 -0.0678711 -0.330078 ... -0.10498 -0.104004 -0.101074]\n",
      "   ...\n",
      "   [-0.0229492 -0.212891 -0.314453 ... -0.0463867 -0.0766602 0.168945]\n",
      "   [-0.0229492 -0.212891 -0.314453 ... -0.0463867 -0.0766602 0.168945]\n",
      "   [-0.0229492 -0.212891 -0.314453 ... -0.0463867 -0.0766602 0.168945]]\n",
      "\n",
      "  [[-0.511719 -0.0324707 -0.427734 ... 0.632812 0.875 0.1875]\n",
      "   [-0.034668 -0.0834961 -0.151367 ... -0.046875 -0.111328 0.0761719]\n",
      "   [-0.230469 -0.120605 -0.0429688 ... 0.24707 0.074707 -0.00744629]\n",
      "   ...\n",
      "   [-0.052002 0.217773 0.0294189 ... 0.102539 0.261719 0.0206299]\n",
      "   [-0.052002 0.217773 0.0294189 ... 0.102539 0.261719 0.0206299]\n",
      "   [-0.052002 0.217773 0.0294189 ... 0.102539 0.261719 0.0206299]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.229492 0.113281 0.0266113 ... -0.421875 -0.149414 -0.306641]\n",
      "   [-0.175781 0.271484 0.0603027 ... -0.472656 0.703125 -2.51562]\n",
      "   [-0.0629883 0.337891 0.142578 ... -0.275391 0.636719 -2.26562]\n",
      "   ...\n",
      "   [-0.714844 -0.28125 -0.320312 ... 0.296875 -0.304688 0.0610352]\n",
      "   [-0.714844 -0.28125 -0.320312 ... 0.296875 -0.304688 0.0610352]\n",
      "   [-0.714844 -0.28125 -0.320312 ... 0.296875 -0.304688 0.0610352]]\n",
      "\n",
      "  [[-0.227539 0.320312 0.6875 ... -0.601562 -0.287109 -0.265625]\n",
      "   [0.613281 -0.0688477 -0.211914 ... -0.300781 0.15625 -0.160156]\n",
      "   [0.578125 -0.00854492 -0.240234 ... -0.065918 0.239258 -0.392578]\n",
      "   ...\n",
      "   [0.359375 -0.0893555 -0.0756836 ... -0.202148 0.0529785 -0.245117]\n",
      "   [0.359375 -0.0893555 -0.0756836 ... -0.202148 0.0529785 -0.245117]\n",
      "   [0.359375 -0.0893555 -0.0756836 ... -0.202148 0.0529785 -0.245117]]\n",
      "\n",
      "  [[-0.0289307 0.0134277 -0.00668335 ... -0.0371094 0.1875 0.15332]\n",
      "   [-0.357422 0.132812 0.12793 ... -0.18457 -0.287109 -0.019043]\n",
      "   [-0.550781 0.0598145 0.0566406 ... -0.114258 -0.197266 0.0108032]\n",
      "   ...\n",
      "   [-0.189453 -0.0108643 0.0181885 ... -0.0268555 -0.0849609 -0.137695]\n",
      "   [-0.189453 -0.0108643 0.0181885 ... -0.0268555 -0.0849609 -0.137695]\n",
      "   [-0.189453 -0.0108643 0.0181885 ... -0.0268555 -0.0849609 -0.137695]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0202637 -0.245117 -0.174805 ... -0.0795898 -0.0600586 -0.484375]\n",
      "   [0.0898438 0.143555 -0.0942383 ... -0.112305 -0.257812 0.0317383]\n",
      "   [0.150391 0.0319824 -0.0664062 ... -0.0498047 -0.148438 0.0427246]\n",
      "   ...\n",
      "   [-0.045166 0.100098 -0.102051 ... -0.134766 -0.265625 -0.057373]\n",
      "   [-0.045166 0.100098 -0.102051 ... -0.134766 -0.265625 -0.057373]\n",
      "   [-0.045166 0.100098 -0.102051 ... -0.134766 -0.265625 -0.057373]]\n",
      "\n",
      "  [[-0.464844 0.0610352 -0.147461 ... -0.0390625 -0.0952148 0.160156]\n",
      "   [-0.0664062 -0.0150146 0.125977 ... 0.151367 -0.0664062 0.0166016]\n",
      "   [-0.216797 0.376953 0.423828 ... 0.265625 0.0373535 0.371094]\n",
      "   ...\n",
      "   [0.0361328 -0.130859 0.00665283 ... -0.269531 -0.0127563 -0.0541992]\n",
      "   [0.0361328 -0.130859 0.00665283 ... -0.269531 -0.0127563 -0.0541992]\n",
      "   [0.0361328 -0.130859 0.00665283 ... -0.269531 -0.0127563 -0.0541992]]\n",
      "\n",
      "  [[0.484375 0.349609 -0.195312 ... -0.180664 0.392578 0.220703]\n",
      "   [1.07812 0.679688 -0.263672 ... 0.257812 0.609375 -0.0437012]\n",
      "   [0.957031 0.402344 -0.417969 ... 0.269531 0.332031 -0.186523]\n",
      "   ...\n",
      "   [0.0212402 0.0478516 0.0791016 ... 0.0145874 0.0198975 -0.0297852]\n",
      "   [0.0212402 0.0478516 0.0791016 ... 0.0145874 0.0198975 -0.0297852]\n",
      "   [0.0212402 0.0478516 0.0791016 ... 0.0145874 0.0198975 -0.0297852]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0292969 0.0717773 0.0576172 ... -0.0422363 0.00622559 0.0693359]\n",
      "   [0.0439453 -0.036377 0.582031 ... -0.104004 0.0020752 0.347656]\n",
      "   [0.0825195 -0.00939941 0.46875 ... -0.148438 -0.0583496 0.423828]\n",
      "   ...\n",
      "   [-0.107422 -0.257812 0.357422 ... 0.0683594 -0.103516 0.138672]\n",
      "   [-0.107422 -0.257812 0.357422 ... 0.0683594 -0.103516 0.138672]\n",
      "   [-0.107422 -0.257812 0.357422 ... 0.0683594 -0.103516 0.138672]]\n",
      "\n",
      "  [[-0.300781 0.194336 1.54688 ... -0.792969 -0.511719 -0.108887]\n",
      "   [0.146484 -0.294922 0.0766602 ... -0.178711 -0.0238037 -0.0498047]\n",
      "   [0.0568848 -0.261719 0.00558472 ... -0.165039 -0.208984 -0.0678711]\n",
      "   ...\n",
      "   [0.0324707 -0.155273 0.0373535 ... 0.0118408 -0.12207 -0.0986328]\n",
      "   [0.0324707 -0.155273 0.0373535 ... 0.0118408 -0.12207 -0.0986328]\n",
      "   [0.0324707 -0.155273 0.0373535 ... 0.0118408 -0.12207 -0.0986328]]\n",
      "\n",
      "  [[0.144531 0.0883789 0.0791016 ... -0.151367 0.341797 -0.0908203]\n",
      "   [0.0549316 0.0712891 0.240234 ... -0.400391 0.117188 -0.109863]\n",
      "   [0.11377 -0.111328 0.217773 ... -0.460938 0.175781 -0.231445]\n",
      "   ...\n",
      "   [-0.0795898 -0.103516 0.00793457 ... -0.341797 -0.0751953 -0.249023]\n",
      "   [-0.0795898 -0.103516 0.00793457 ... -0.341797 -0.0751953 -0.249023]\n",
      "   [-0.0795898 -0.103516 0.00793457 ... -0.341797 -0.0751953 -0.249023]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.859375 -0.416016 0.097168 ... 0.289062 0.511719 0.060791]\n",
      "   [-0.259766 0.404297 -0.205078 ... 0.300781 0.0693359 -0.216797]\n",
      "   [-0.310547 0.181641 -0.230469 ... 0.188477 0.00162506 -0.026123]\n",
      "   ...\n",
      "   [0.216797 -0.265625 -0.105469 ... -0.0673828 -0.174805 0.0148926]\n",
      "   [0.216797 -0.265625 -0.105469 ... -0.0673828 -0.174805 0.0148926]\n",
      "   [0.216797 -0.265625 -0.105469 ... -0.0673828 -0.174805 0.0148926]]\n",
      "\n",
      "  [[-0.0228271 -0.0515137 -0.0257568 ... 0.166992 0.0505371 -0.213867]\n",
      "   [0.15625 0.0598145 -0.308594 ... 0.234375 -0.228516 0.178711]\n",
      "   [0.322266 0.167969 -0.390625 ... 0.291016 -0.287109 0.0361328]\n",
      "   ...\n",
      "   [-0.0101929 0.065918 -0.0500488 ... -0.269531 -0.441406 -0.519531]\n",
      "   [-0.0101929 0.065918 -0.0500488 ... -0.269531 -0.441406 -0.519531]\n",
      "   [-0.0101929 0.065918 -0.0500488 ... -0.269531 -0.441406 -0.519531]]\n",
      "\n",
      "  [[-0.539062 -0.427734 -0.129883 ... 0.255859 -0.433594 -0.205078]\n",
      "   [0.326172 -0.122559 0.155273 ... -0.263672 -0.115723 -0.253906]\n",
      "   [0.361328 -0.00872803 0.145508 ... -0.243164 -0.104004 -0.160156]\n",
      "   ...\n",
      "   [-0.209961 0.133789 -0.251953 ... 0.0932617 -0.28125 -0.0336914]\n",
      "   [-0.209961 0.133789 -0.251953 ... 0.0932617 -0.28125 -0.0336914]\n",
      "   [-0.209961 0.133789 -0.251953 ... 0.0932617 -0.28125 -0.0336914]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0673828 0.133789 -0.0795898 ... 0.00344849 0.122559 0.0145264]\n",
      "   [0.226562 0.474609 -0.396484 ... -0.143555 -0.251953 -0.0634766]\n",
      "   [0.0361328 0.111816 -0.144531 ... -0.0123291 -0.179688 0.240234]\n",
      "   ...\n",
      "   [-0.052002 -0.19043 -0.100098 ... 0.12793 0.271484 0.251953]\n",
      "   [-0.052002 -0.19043 -0.100098 ... 0.12793 0.271484 0.251953]\n",
      "   [-0.052002 -0.19043 -0.100098 ... 0.12793 0.271484 0.251953]]\n",
      "\n",
      "  [[-0.746094 0.5 -0.169922 ... -0.349609 1.58594 0.5625]\n",
      "   [0.204102 0.167969 0.020874 ... 0.0732422 -0.0117798 0.0732422]\n",
      "   [-0.155273 0.116211 -0.0175781 ... 0.239258 0.196289 0.0108032]\n",
      "   ...\n",
      "   [0.21875 0.267578 0.0125732 ... 0.121094 0.112793 -0.0859375]\n",
      "   [0.21875 0.267578 0.0125732 ... 0.121094 0.112793 -0.0859375]\n",
      "   [0.21875 0.267578 0.0125732 ... 0.121094 0.112793 -0.0859375]]\n",
      "\n",
      "  [[-0.292969 -0.228516 0.0402832 ... 0.285156 0.0732422 0.186523]\n",
      "   [-0.535156 -0.4375 0.229492 ... -0.0654297 -0.154297 0.609375]\n",
      "   [-0.789062 -0.46875 -0.15918 ... -0.0825195 -0.0878906 1.28906]\n",
      "   ...\n",
      "   [-0.0195312 -0.213867 -0.0327148 ... -0.0952148 0.277344 -0.00485229]\n",
      "   [-0.0195312 -0.213867 -0.0327148 ... -0.0952148 0.277344 -0.00485229]\n",
      "   [-0.0195312 -0.213867 -0.0327148 ... -0.0952148 0.277344 -0.00485229]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.157227 -0.222656 0.125977 ... 0.116211 0.0810547 -0.143555]\n",
      "   [-0.835938 -0.498047 -0.0402832 ... -0.386719 -0.925781 0.945312]\n",
      "   [-1.54688 -0.75 -0.208984 ... -0.414062 -0.210938 0.808594]\n",
      "   ...\n",
      "   [0.059082 -0.267578 0.369141 ... 0.251953 0.138672 -0.275391]\n",
      "   [0.059082 -0.267578 0.369141 ... 0.251953 0.138672 -0.275391]\n",
      "   [0.059082 -0.267578 0.369141 ... 0.251953 0.138672 -0.275391]]\n",
      "\n",
      "  [[-0.699219 -0.0126343 -0.265625 ... -0.259766 0.417969 -0.271484]\n",
      "   [0.0110474 0.449219 -0.40625 ... -0.197266 0.636719 0.582031]\n",
      "   [-0.228516 0.351562 -0.566406 ... -0.0756836 0.824219 0.414062]\n",
      "   ...\n",
      "   [0.0541992 0.109375 0.176758 ... 0.180664 0.289062 0.0186768]\n",
      "   [0.0541992 0.109375 0.176758 ... 0.180664 0.289062 0.0186768]\n",
      "   [0.0541992 0.109375 0.176758 ... 0.180664 0.289062 0.0186768]]\n",
      "\n",
      "  [[-0.249023 -0.160156 -0.116699 ... 0.157227 -0.0139771 0.186523]\n",
      "   [-0.300781 0.306641 0.00408936 ... 0.337891 0.133789 0.259766]\n",
      "   [-0.369141 0.292969 -0.195312 ... 0.423828 -0.186523 0.359375]\n",
      "   ...\n",
      "   [-0.3125 0.150391 -0.149414 ... 0.21582 -0.0366211 0.287109]\n",
      "   [-0.3125 0.150391 -0.149414 ... 0.21582 -0.0366211 0.287109]\n",
      "   [-0.3125 0.150391 -0.149414 ... 0.21582 -0.0366211 0.287109]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0678711 -0.065918 -0.419922 ... -0.219727 0.132812 0.371094]\n",
      "   [-0.0791016 -0.0378418 -0.0209961 ... 0.112305 -0.0703125 -0.0198975]\n",
      "   [-0.267578 -0.378906 0.314453 ... 0.417969 -0.273438 -0.314453]\n",
      "   ...\n",
      "   [0.248047 -0.166992 -0.53125 ... -0.220703 0.115234 0.333984]\n",
      "   [0.248047 -0.166992 -0.53125 ... -0.220703 0.115234 0.333984]\n",
      "   [0.248047 -0.166992 -0.53125 ... -0.220703 0.115234 0.333984]]\n",
      "\n",
      "  [[0.241211 -0.000644684 0.00497437 ... -0.0585938 -0.133789 0.0209961]\n",
      "   [0.320312 -0.0405273 -0.0717773 ... 0.148438 0.0264893 0.0634766]\n",
      "   [0.157227 0.00823975 0.0991211 ... 0.283203 0.175781 -0.15918]\n",
      "   ...\n",
      "   [0.335938 0.0211182 -0.0222168 ... -0.00382996 -0.0961914 -0.134766]\n",
      "   [0.335938 0.0211182 -0.0222168 ... -0.00382996 -0.0961914 -0.134766]\n",
      "   [0.335938 0.0211182 -0.0222168 ... -0.00382996 -0.0961914 -0.134766]]\n",
      "\n",
      "  [[-0.022583 -0.106934 -0.0142212 ... -0.0620117 0.0805664 -0.0751953]\n",
      "   [0.0196533 -0.078125 0.234375 ... 0.136719 0.200195 -0.15332]\n",
      "   [0.141602 -0.0800781 0.135742 ... 0.310547 0.202148 -0.141602]\n",
      "   ...\n",
      "   [-0.0119019 0.322266 -0.205078 ... 0.158203 0.0893555 0.118164]\n",
      "   [-0.0119019 0.322266 -0.205078 ... 0.158203 0.0893555 0.118164]\n",
      "   [-0.0119019 0.322266 -0.205078 ... 0.158203 0.0893555 0.118164]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.0893555 0.0825195 -0.125977 ... 0.162109 -0.105469 -0.078125]\n",
      "   [-0.173828 -0.640625 -0.265625 ... -0.199219 0.206055 0.074707]\n",
      "   [-0.308594 -1.3125 -0.464844 ... -0.365234 0.753906 0.0795898]\n",
      "   ...\n",
      "   [0.0010376 0.248047 0.0198975 ... -0.123047 -0.134766 -0.125]\n",
      "   [0.0010376 0.248047 0.0198975 ... -0.123047 -0.134766 -0.125]\n",
      "   [0.0010376 0.248047 0.0198975 ... -0.123047 -0.134766 -0.125]]\n",
      "\n",
      "  [[0.026123 0.024292 -0.0805664 ... 0.0192871 -0.105469 0.112305]\n",
      "   [-0.882812 -0.0373535 0.460938 ... -0.351562 0.0159912 0.300781]\n",
      "   [0.0102539 -0.507812 0.886719 ... 0.341797 0.242188 0.057373]\n",
      "   ...\n",
      "   [-0.0216064 0.118652 -0.134766 ... 0.0874023 -0.0961914 0.402344]\n",
      "   [-0.0216064 0.118652 -0.134766 ... 0.0874023 -0.0961914 0.402344]\n",
      "   [-0.0216064 0.118652 -0.134766 ... 0.0874023 -0.0961914 0.402344]]\n",
      "\n",
      "  [[0.181641 0.110352 -0.100098 ... 0.119629 -0.0164795 -0.118652]\n",
      "   [-0.0111084 -0.111816 0.0437012 ... -0.0186768 0.0441895 -0.106445]\n",
      "   [-0.0622559 -0.0288086 0.0274658 ... 0.0308838 -0.0512695 -0.142578]\n",
      "   ...\n",
      "   [0.404297 0.0371094 -0.100586 ... 0.132812 0.0991211 -0.0732422]\n",
      "   [0.404297 0.0371094 -0.100586 ... 0.132812 0.0991211 -0.0732422]\n",
      "   [0.404297 0.0371094 -0.100586 ... 0.132812 0.0991211 -0.0732422]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0698242 -0.103027 0.155273 ... 0.143555 -0.310547 0.0844727]\n",
      "   [-0.122559 -0.0737305 -0.0654297 ... -0.0561523 0.0218506 -0.0217285]\n",
      "   [-0.0673828 -0.133789 -0.0654297 ... -0.0088501 -0.029541 -0.0126953]\n",
      "   ...\n",
      "   [0.126953 0.0742188 0.404297 ... 0.220703 -0.390625 0.104004]\n",
      "   [0.126953 0.0742188 0.404297 ... 0.220703 -0.390625 0.104004]\n",
      "   [0.126953 0.0742188 0.404297 ... 0.220703 -0.390625 0.104004]]\n",
      "\n",
      "  [[-0.285156 0.0488281 -0.146484 ... -0.0908203 -0.0727539 0.21582]\n",
      "   [0.660156 -0.476562 0.667969 ... 1.27344 -0.460938 -0.241211]\n",
      "   [0.617188 -0.464844 0.6875 ... 1.14062 -0.244141 -0.141602]\n",
      "   ...\n",
      "   [-0.419922 0.0317383 -0.151367 ... -0.126953 0.00233459 -0.0157471]\n",
      "   [-0.419922 0.0317383 -0.151367 ... -0.126953 0.00233459 -0.0157471]\n",
      "   [-0.419922 0.0317383 -0.151367 ... -0.126953 0.00233459 -0.0157471]]\n",
      "\n",
      "  [[0.244141 -0.0375977 0.0771484 ... -0.0722656 0.390625 -0.0500488]\n",
      "   [-0.195312 -0.143555 0.404297 ... -0.324219 0.0932617 0.0112305]\n",
      "   [-0.373047 0.172852 0.341797 ... -0.832031 0.0629883 0.0234375]\n",
      "   ...\n",
      "   [-0.363281 0.0898438 0.140625 ... 0.149414 -0.110352 0.102051]\n",
      "   [-0.363281 0.0898438 0.140625 ... 0.149414 -0.110352 0.102051]\n",
      "   [-0.363281 0.0898438 0.140625 ... 0.149414 -0.110352 0.102051]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.131836 -0.431641 0.457031 ... -0.431641 -0.119629 0.151367]\n",
      "   [-0.136719 0.0178223 0.310547 ... 0.227539 0.185547 0.0952148]\n",
      "   [-0.019043 -0.0549316 0.322266 ... 0.118164 0.15625 0.0205078]\n",
      "   ...\n",
      "   [-0.166016 -0.298828 0.090332 ... -0.259766 0.174805 0.267578]\n",
      "   [-0.166016 -0.298828 0.090332 ... -0.259766 0.174805 0.267578]\n",
      "   [-0.166016 -0.298828 0.090332 ... -0.259766 0.174805 0.267578]]\n",
      "\n",
      "  [[-0.0976562 -0.0732422 0.010498 ... -0.142578 0.186523 0.15918]\n",
      "   [0.0151978 -0.0177002 0.000534058 ... -0.0116577 -0.0732422\n",
      "    -0.133789]\n",
      "   [0.0522461 0.0639648 0.0854492 ... -0.00723267 0.0605469 -0.0366211]\n",
      "   ...\n",
      "   [0.214844 -0.283203 0.0500488 ... -0.0610352 -0.166992 -0.196289]\n",
      "   [0.214844 -0.283203 0.0500488 ... -0.0610352 -0.166992 -0.196289]\n",
      "   [0.214844 -0.283203 0.0500488 ... -0.0610352 -0.166992 -0.196289]]\n",
      "\n",
      "  [[0.0913086 0.0314941 -0.0883789 ... -0.0688477 -0.0322266 -0.0634766]\n",
      "   [0.296875 0.206055 0.0947266 ... -0.223633 -0.116699 -0.314453]\n",
      "   [0.152344 0.376953 -0.135742 ... -0.0664062 -0.0218506 0.19043]\n",
      "   ...\n",
      "   [-0.0088501 -0.131836 -0.253906 ... -0.585938 -0.124023 -0.75]\n",
      "   [-0.0088501 -0.131836 -0.253906 ... -0.585938 -0.124023 -0.75]\n",
      "   [-0.0088501 -0.131836 -0.253906 ... -0.585938 -0.124023 -0.75]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0322266 -0.0625 -0.108398 ... 0.178711 0.0415039 0.0771484]\n",
      "   [0.131836 0.168945 -0.189453 ... 0.257812 0.00274658 0.128906]\n",
      "   [0.10791 0.273438 -0.134766 ... 0.217773 -0.0371094 0.00830078]\n",
      "   ...\n",
      "   [0.128906 -0.138672 0.0306396 ... 0.0255127 -0.0361328 0.128906]\n",
      "   [0.128906 -0.138672 0.0306396 ... 0.0255127 -0.0361328 0.128906]\n",
      "   [0.128906 -0.138672 0.0306396 ... 0.0255127 -0.0361328 0.128906]]\n",
      "\n",
      "  [[-0.15332 -0.0339355 -0.0541992 ... 0.478516 0.738281 -0.458984]\n",
      "   [0.0305176 -0.0294189 0.0991211 ... -0.0263672 -0.1875 0.166992]\n",
      "   [0.0693359 -0.0922852 -0.0986328 ... 0.114258 -0.228516 -0.0512695]\n",
      "   ...\n",
      "   [-0.191406 -0.255859 0.1875 ... -0.0688477 -0.217773 0.361328]\n",
      "   [-0.191406 -0.255859 0.1875 ... -0.0688477 -0.217773 0.361328]\n",
      "   [-0.191406 -0.255859 0.1875 ... -0.0688477 -0.217773 0.361328]]\n",
      "\n",
      "  [[-0.0712891 -0.0693359 -0.11084 ... -0.148438 -0.0197754 -0.097168]\n",
      "   [0.0610352 -0.00769043 -0.0390625 ... 0.0180664 -0.105469 -0.0211182]\n",
      "   [-0.0219727 -0.0932617 0.0390625 ... 0.0771484 -0.00860596\n",
      "    -0.0524902]\n",
      "   ...\n",
      "   [-0.130859 -0.154297 -0.28125 ... -0.199219 -0.186523 0.027832]\n",
      "   [-0.130859 -0.154297 -0.28125 ... -0.199219 -0.186523 0.027832]\n",
      "   [-0.130859 -0.154297 -0.28125 ... -0.199219 -0.186523 0.027832]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0444336 0.11377 0.0476074 ... 0.0131226 -0.137695 -0.0119019]\n",
      "   [0.195312 0.110352 -0.0327148 ... 0.146484 -0.164062 -0.19043]\n",
      "   [0.0864258 0.116699 0.0341797 ... 0.143555 -0.0917969 -0.0717773]\n",
      "   ...\n",
      "   [0.169922 0.0581055 0.171875 ... -0.11084 0.0241699 -0.0422363]\n",
      "   [0.169922 0.0581055 0.171875 ... -0.11084 0.0241699 -0.0422363]\n",
      "   [0.169922 0.0581055 0.171875 ... -0.11084 0.0241699 -0.0422363]]\n",
      "\n",
      "  [[0.0756836 -0.0371094 -0.523438 ... 0.644531 0.894531 0.172852]\n",
      "   [1.30469 0.769531 0.0419922 ... 0.527344 1.01562 1.08594]\n",
      "   [1.05469 0.304688 -0.00720215 ... 0.151367 0.235352 0.652344]\n",
      "   ...\n",
      "   [0.408203 -0.0123291 0.458984 ... 0.535156 -0.206055 0.168945]\n",
      "   [0.408203 -0.0123291 0.458984 ... 0.535156 -0.206055 0.168945]\n",
      "   [0.408203 -0.0123291 0.458984 ... 0.535156 -0.206055 0.168945]]\n",
      "\n",
      "  [[0.15918 -0.0888672 0.106934 ... -0.169922 0.102051 -0.169922]\n",
      "   [0.196289 -0.738281 0.217773 ... -0.992188 -0.21582 0.0351562]\n",
      "   [0.180664 -0.652344 0.263672 ... -0.765625 0.00442505 0.0688477]\n",
      "   ...\n",
      "   [-0.322266 -0.558594 -0.507812 ... -0.283203 0.137695 -0.131836]\n",
      "   [-0.322266 -0.558594 -0.507812 ... -0.283203 0.137695 -0.131836]\n",
      "   [-0.322266 -0.558594 -0.507812 ... -0.283203 0.137695 -0.131836]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.197266 -0.0966797 0.118652 ... 0.125977 0.00123596 -0.0358887]\n",
      "   [-0.0761719 -0.0732422 0.140625 ... 0.0634766 0.0354004 -0.0942383]\n",
      "   [-0.0344238 -0.126953 0.157227 ... 0.0981445 0.0722656 -0.101074]\n",
      "   ...\n",
      "   [0.345703 0.277344 0.177734 ... -0.0258789 0.416016 0.118652]\n",
      "   [0.345703 0.277344 0.177734 ... -0.0258789 0.416016 0.118652]\n",
      "   [0.345703 0.277344 0.177734 ... -0.0258789 0.416016 0.118652]]\n",
      "\n",
      "  [[-0.12793 -0.0422363 0.0766602 ... -0.0751953 -0.163086 -0.112793]\n",
      "   [0.0571289 -0.211914 0.0150757 ... -0.0196533 -0.102051 0.017334]\n",
      "   [-0.0449219 -0.174805 -0.0554199 ... -0.0339355 -0.167969 0.0126343]\n",
      "   ...\n",
      "   [-0.617188 0.0561523 -0.0458984 ... -0.0410156 -0.0224609 -0.243164]\n",
      "   [-0.617188 0.0561523 -0.0458984 ... -0.0410156 -0.0224609 -0.243164]\n",
      "   [-0.617188 0.0561523 -0.0458984 ... -0.0410156 -0.0224609 -0.243164]]\n",
      "\n",
      "  [[-0.147461 0.110352 0.0688477 ... 0.289062 -0.365234 -0.0178223]\n",
      "   [-0.0233154 -0.0957031 0.0294189 ... -0.134766 -0.121582 -0.0742188]\n",
      "   [0.0554199 -0.0493164 0.019043 ... -0.0859375 -0.140625 -0.0327148]\n",
      "   ...\n",
      "   [-0.263672 0.121582 -0.108398 ... 0.337891 -0.15918 -0.710938]\n",
      "   [-0.263672 0.121582 -0.108398 ... 0.337891 -0.15918 -0.710938]\n",
      "   [-0.263672 0.121582 -0.108398 ... 0.337891 -0.15918 -0.710938]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.229492 0.000207901 0.0380859 ... 0.0786133 -0.0615234 -0.0766602]\n",
      "   [0.0286865 0.0134888 0.0566406 ... -0.0341797 -0.0147705 -0.119629]\n",
      "   [0.0776367 -0.00830078 -0.0400391 ... -0.0581055 0.10498 -0.164062]\n",
      "   ...\n",
      "   [-0.0678711 0.147461 0.177734 ... 0.0578613 -0.00933838 -0.1875]\n",
      "   [-0.0678711 0.147461 0.177734 ... 0.0578613 -0.00933838 -0.1875]\n",
      "   [-0.0678711 0.147461 0.177734 ... 0.0578613 -0.00933838 -0.1875]]\n",
      "\n",
      "  [[-0.0927734 -0.0751953 0.0610352 ... -0.179688 -0.0220947 0.0410156]\n",
      "   [0.0297852 -0.0168457 0.0169678 ... 0.0373535 -0.0400391 -0.0317383]\n",
      "   [0.0766602 -0.166016 0.0771484 ... -0.0629883 0.0262451 -0.119629]\n",
      "   ...\n",
      "   [0.192383 -0.0539551 -0.160156 ... 0.0198975 -0.000610352 -0.0539551]\n",
      "   [0.192383 -0.0539551 -0.160156 ... 0.0198975 -0.000610352 -0.0539551]\n",
      "   [0.192383 -0.0539551 -0.160156 ... 0.0198975 -0.000610352 -0.0539551]]\n",
      "\n",
      "  [[0.0327148 -0.0878906 -0.135742 ... 0.0180664 0.0390625 -0.059082]\n",
      "   [-0.101074 -0.128906 -0.178711 ... -0.00741577 0.0476074 -0.0213623]\n",
      "   [-0.139648 -0.0830078 -0.101074 ... -0.0539551 0.103516 -0.0164795]\n",
      "   ...\n",
      "   [-0.112305 -0.179688 -0.597656 ... -0.101562 0.00872803 0.138672]\n",
      "   [-0.112305 -0.179688 -0.597656 ... -0.101562 0.00872803 0.138672]\n",
      "   [-0.112305 -0.179688 -0.597656 ... -0.101562 0.00872803 0.138672]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.074707 -0.121582 -0.0585938 ... -0.108887 -0.0109253 0.0512695]\n",
      "   [0.0373535 -0.0368652 -0.0306396 ... -0.0588379 -0.00613403 0.105957]\n",
      "   [0.0854492 -0.0415039 0.0864258 ... -0.0800781 0.00576782 0.0878906]\n",
      "   ...\n",
      "   [-0.398438 0.394531 0.0654297 ... -0.126953 0.0427246 -0.0356445]\n",
      "   [-0.398438 0.394531 0.0654297 ... -0.126953 0.0427246 -0.0356445]\n",
      "   [-0.398438 0.394531 0.0654297 ... -0.126953 0.0427246 -0.0356445]]\n",
      "\n",
      "  [[-0.839844 0.644531 -0.628906 ... -0.174805 0.111816 -0.198242]\n",
      "   [0.057373 -0.439453 -0.212891 ... 0.154297 -0.200195 -0.105957]\n",
      "   [0.111328 -0.445312 -0.0294189 ... 0.359375 -0.032959 -0.0751953]\n",
      "   ...\n",
      "   [0.507812 0.21875 0.566406 ... 0.0874023 0.277344 -0.0196533]\n",
      "   [0.507812 0.21875 0.566406 ... 0.0874023 0.277344 -0.0196533]\n",
      "   [0.507812 0.21875 0.566406 ... 0.0874023 0.277344 -0.0196533]]\n",
      "\n",
      "  [[-0.277344 -0.0834961 -0.144531 ... -0.0375977 -0.0727539 0.136719]\n",
      "   [0.0751953 -0.160156 -0.0844727 ... 0.0307617 0.199219 0.00312805]\n",
      "   [-0.146484 -0.125977 -0.0683594 ... 0.0174561 0.232422 -0.100586]\n",
      "   ...\n",
      "   [-0.667969 -0.12793 -0.480469 ... -0.105469 0.498047 -0.120605]\n",
      "   [-0.667969 -0.12793 -0.480469 ... -0.105469 0.498047 -0.120605]\n",
      "   [-0.667969 -0.12793 -0.480469 ... -0.105469 0.498047 -0.120605]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.261719 -0.490234 0.4375 ... 0.041748 0.109375 0.045166]\n",
      "   [-0.129883 -0.207031 -0.0154419 ... 0.910156 -0.416016 -0.498047]\n",
      "   [-0.240234 -0.132812 -0.292969 ... 1.03906 0.0524902 -0.503906]\n",
      "   ...\n",
      "   [-0.120605 -0.652344 -0.111328 ... -0.703125 -0.294922 -0.0888672]\n",
      "   [-0.120605 -0.652344 -0.111328 ... -0.703125 -0.294922 -0.0888672]\n",
      "   [-0.120605 -0.652344 -0.111328 ... -0.703125 -0.294922 -0.0888672]]\n",
      "\n",
      "  [[0.125977 0.0585938 -0.043457 ... -0.105469 0.166992 0.283203]\n",
      "   [0.0893555 -0.0292969 -0.134766 ... 0.0532227 -0.0991211 0.208984]\n",
      "   [0.0512695 -0.0395508 -0.117676 ... 0.0742188 -0.139648 0.220703]\n",
      "   ...\n",
      "   [0.289062 0.546875 -0.318359 ... -0.231445 -0.043457 0.211914]\n",
      "   [0.289062 0.546875 -0.318359 ... -0.231445 -0.043457 0.211914]\n",
      "   [0.289062 0.546875 -0.318359 ... -0.231445 -0.043457 0.211914]]\n",
      "\n",
      "  [[0.0383301 -0.100586 0.322266 ... -0.169922 -0.208984 0.166992]\n",
      "   [0.057373 -0.168945 -0.173828 ... -0.135742 -0.0566406 -0.0566406]\n",
      "   [-0.0507812 -0.186523 -0.296875 ... -0.179688 0.043457 -0.205078]\n",
      "   ...\n",
      "   [-0.163086 -0.176758 -0.160156 ... 0.0140381 0.287109 0.0429688]\n",
      "   [-0.163086 -0.176758 -0.160156 ... 0.0140381 0.287109 0.0429688]\n",
      "   [-0.163086 -0.176758 -0.160156 ... 0.0140381 0.287109 0.0429688]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0712891 -0.78125 -0.277344 ... -0.292969 -0.570312 -0.225586]\n",
      "   [-0.328125 -0.176758 -0.00124359 ... 0.00646973 -0.186523 -0.036377]\n",
      "   [-0.8125 -0.249023 0.200195 ... 0.202148 -0.474609 -0.109863]\n",
      "   ...\n",
      "   [-0.310547 -0.273438 -0.117676 ... -0.398438 -0.220703 0.871094]\n",
      "   [-0.310547 -0.273438 -0.117676 ... -0.398438 -0.220703 0.871094]\n",
      "   [-0.310547 -0.273438 -0.117676 ... -0.398438 -0.220703 0.871094]]\n",
      "\n",
      "  [[0.0913086 -0.0483398 0.109375 ... 0.112305 -0.0351562 -0.0164795]\n",
      "   [-0.0274658 0.0444336 -0.143555 ... -0.03125 -0.197266 0.167969]\n",
      "   [-0.238281 0.0169678 -0.316406 ... -0.237305 -0.0864258 0.78125]\n",
      "   ...\n",
      "   [-0.636719 0.144531 0.208984 ... -0.404297 0.15918 0.451172]\n",
      "   [-0.636719 0.144531 0.208984 ... -0.404297 0.15918 0.451172]\n",
      "   [-0.636719 0.144531 0.208984 ... -0.404297 0.15918 0.451172]]\n",
      "\n",
      "  [[0.416016 0.0688477 0.371094 ... 0.417969 0.345703 0.125]\n",
      "   [0.253906 -0.859375 -0.0256348 ... 0.345703 -0.257812 0.226562]\n",
      "   [0.455078 -0.621094 -0.19043 ... 0.21875 -0.0466309 0.120605]\n",
      "   ...\n",
      "   [0.195312 0.113281 -0.292969 ... 0.10791 -0.351562 0.474609]\n",
      "   [0.195312 0.113281 -0.292969 ... 0.10791 -0.351562 0.474609]\n",
      "   [0.195312 0.113281 -0.292969 ... 0.10791 -0.351562 0.474609]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.285156 -0.171875 -0.119629 ... -0.0859375 0.304688 0.248047]\n",
      "   [0.103027 0.550781 0.168945 ... -0.142578 -0.185547 0.0419922]\n",
      "   [0.435547 0.882812 -0.0898438 ... 0.0250244 -0.427734 -0.0427246]\n",
      "   ...\n",
      "   [0.421875 -0.367188 0.1875 ... -0.0159912 0.0476074 0.151367]\n",
      "   [0.421875 -0.367188 0.1875 ... -0.0159912 0.0476074 0.151367]\n",
      "   [0.421875 -0.367188 0.1875 ... -0.0159912 0.0476074 0.151367]]\n",
      "\n",
      "  [[-0.292969 0.0319824 -0.921875 ... 0.699219 -0.392578 -1.70312]\n",
      "   [0.0644531 0.269531 0.105957 ... 0.0388184 -0.0400391 -0.059082]\n",
      "   [0.0795898 0.161133 0.0732422 ... 0.0172119 -0.00982666 0.00244141]\n",
      "   ...\n",
      "   [-0.0164795 -0.396484 0.174805 ... 0.205078 0.371094 0.484375]\n",
      "   [-0.0164795 -0.396484 0.174805 ... 0.205078 0.371094 0.484375]\n",
      "   [-0.0164795 -0.396484 0.174805 ... 0.205078 0.371094 0.484375]]\n",
      "\n",
      "  [[0.285156 0.341797 0.558594 ... -0.339844 -0.101562 0.225586]\n",
      "   [0.0412598 0.46875 0.203125 ... -0.357422 -1.125 1.14844]\n",
      "   [-0.12793 0.0976562 -0.0654297 ... -0.177734 -0.396484 0.466797]\n",
      "   ...\n",
      "   [0.244141 0.550781 0.285156 ... -0.574219 0.375 -0.304688]\n",
      "   [0.244141 0.550781 0.285156 ... -0.574219 0.375 -0.304688]\n",
      "   [0.244141 0.550781 0.285156 ... -0.574219 0.375 -0.304688]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.132812 -0.419922 0.253906 ... 0.291016 0.0712891 0.435547]\n",
      "   [-0.137695 -0.193359 0.392578 ... -0.0888672 0.375 0.730469]\n",
      "   [-0.365234 -0.0527344 0.339844 ... -0.0522461 0.5625 0.730469]\n",
      "   ...\n",
      "   [-0.384766 -0.172852 0.414062 ... 0.182617 0.167969 1.03125]\n",
      "   [-0.384766 -0.172852 0.414062 ... 0.182617 0.167969 1.03125]\n",
      "   [-0.384766 -0.172852 0.414062 ... 0.182617 0.167969 1.03125]]\n",
      "\n",
      "  [[-1.53906 0.458984 2.125 ... 2.42188 -0.00283813 0.832031]\n",
      "   [0.041748 -0.10498 -0.472656 ... 0.202148 0.808594 0.169922]\n",
      "   [0.373047 -0.0612793 -0.326172 ... 0.3125 0.498047 0.0961914]\n",
      "   ...\n",
      "   [-0.394531 -0.322266 0.041748 ... 0.796875 0.169922 0.421875]\n",
      "   [-0.394531 -0.322266 0.041748 ... 0.796875 0.169922 0.421875]\n",
      "   [-0.394531 -0.322266 0.041748 ... 0.796875 0.169922 0.421875]]\n",
      "\n",
      "  [[-0.027832 0.0529785 -0.400391 ... -0.0683594 -0.275391 0.141602]\n",
      "   [-0.189453 0.0498047 -0.423828 ... 0.113281 0.304688 -0.0427246]\n",
      "   [-0.294922 0.00309753 -0.480469 ... 0.105957 0.324219 -0.147461]\n",
      "   ...\n",
      "   [0.0986328 -0.625 0.0893555 ... -0.929688 -0.609375 -0.125]\n",
      "   [0.0986328 -0.625 0.0893555 ... -0.929688 -0.609375 -0.125]\n",
      "   [0.0986328 -0.625 0.0893555 ... -0.929688 -0.609375 -0.125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.462891 0.192383 -0.285156 ... 0.139648 -0.265625 0.255859]\n",
      "   [0.212891 0.149414 -0.421875 ... -0.046875 0.149414 0.121582]\n",
      "   [0.220703 0.197266 -0.439453 ... -0.090332 0.185547 0.173828]\n",
      "   ...\n",
      "   [0.777344 0.100098 0.133789 ... 0.496094 -0.9375 0.0598145]\n",
      "   [0.777344 0.100098 0.133789 ... 0.496094 -0.9375 0.0598145]\n",
      "   [0.777344 0.100098 0.133789 ... 0.496094 -0.9375 0.0598145]]\n",
      "\n",
      "  [[-0.133789 -0.026123 0.00549316 ... -0.183594 0.0153198 -0.494141]\n",
      "   [0.0717773 -0.0065918 0.0668945 ... -0.0625 0.0761719 -0.578125]\n",
      "   [-0.0186768 -0.225586 0.0498047 ... 0.0167236 0.195312 -0.902344]\n",
      "   ...\n",
      "   [-0.601562 0.273438 -0.211914 ... 0.447266 -0.53125 -0.269531]\n",
      "   [-0.601562 0.273438 -0.211914 ... 0.447266 -0.53125 -0.269531]\n",
      "   [-0.601562 0.273438 -0.211914 ... 0.447266 -0.53125 -0.269531]]\n",
      "\n",
      "  [[-0.275391 0.19043 -0.171875 ... -0.371094 0.108398 -0.227539]\n",
      "   [-0.182617 0.173828 -0.111328 ... -0.306641 0.0625 -0.212891]\n",
      "   [-0.249023 0.157227 -0.0776367 ... -0.421875 0.0991211 -0.298828]\n",
      "   ...\n",
      "   [0.0883789 0.386719 0.375 ... 0.162109 0.601562 -0.0654297]\n",
      "   [0.0883789 0.386719 0.375 ... 0.162109 0.601562 -0.0654297]\n",
      "   [0.0883789 0.386719 0.375 ... 0.162109 0.601562 -0.0654297]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.00994873 0.478516 -0.605469 ... 0.18457 -0.458984 -0.640625]\n",
      "   [-0.198242 -0.185547 0.259766 ... 0.482422 -0.0698242 0.302734]\n",
      "   [0.173828 -0.125 0.201172 ... 0.234375 0.0615234 0.28125]\n",
      "   ...\n",
      "   [0.167969 0.00485229 -0.734375 ... 0.699219 0.960938 -0.474609]\n",
      "   [0.167969 0.00485229 -0.734375 ... 0.699219 0.960938 -0.474609]\n",
      "   [0.167969 0.00485229 -0.734375 ... 0.699219 0.960938 -0.474609]]\n",
      "\n",
      "  [[-0.0307617 0.279297 0.111328 ... -0.269531 0.0603027 0.244141]\n",
      "   [-0.800781 -0.369141 0.476562 ... 0.000656128 -1.61719 1.75781]\n",
      "   [-0.515625 0.0483398 0.683594 ... -0.167969 -1.72656 2.04688]\n",
      "   ...\n",
      "   [-0.123047 0.147461 0.306641 ... -0.255859 0.022583 0.416016]\n",
      "   [-0.123047 0.147461 0.306641 ... -0.255859 0.022583 0.416016]\n",
      "   [-0.123047 0.147461 0.306641 ... -0.255859 0.022583 0.416016]]\n",
      "\n",
      "  [[0.117188 0.244141 0.0183105 ... 0.269531 -0.199219 0.134766]\n",
      "   [1.19531 0.382812 0.177734 ... -0.664062 -0.898438 0.175781]\n",
      "   [0.632812 0.396484 0.104492 ... -0.371094 -0.730469 0.142578]\n",
      "   ...\n",
      "   [-0.048584 0.0578613 0.169922 ... 0.112305 -0.710938 0.167969]\n",
      "   [-0.048584 0.0578613 0.169922 ... 0.112305 -0.710938 0.167969]\n",
      "   [-0.048584 0.0578613 0.169922 ... 0.112305 -0.710938 0.167969]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0339355 -0.0844727 -0.0942383 ... -0.219727 0.488281 0.0991211]\n",
      "   [0.233398 -0.078125 0.269531 ... -0.237305 0.0170898 0.0703125]\n",
      "   [0.298828 0.11084 0.435547 ... -0.180664 -0.172852 0.00177002]\n",
      "   ...\n",
      "   [0.0274658 0.328125 0.310547 ... -0.394531 0.65625 0.246094]\n",
      "   [0.0274658 0.328125 0.310547 ... -0.394531 0.65625 0.246094]\n",
      "   [0.0274658 0.328125 0.310547 ... -0.394531 0.65625 0.246094]]\n",
      "\n",
      "  [[-0.219727 -0.116211 0.164062 ... 0.243164 0.0373535 -0.302734]\n",
      "   [0.251953 -0.1875 -0.0576172 ... 0.765625 0.976562 0.239258]\n",
      "   [0.347656 -0.326172 -0.398438 ... 1.125 1.50781 0.878906]\n",
      "   ...\n",
      "   [1.04688 0.0163574 0.074707 ... -0.519531 0.0229492 -0.71875]\n",
      "   [1.04688 0.0163574 0.074707 ... -0.519531 0.0229492 -0.71875]\n",
      "   [1.04688 0.0163574 0.074707 ... -0.519531 0.0229492 -0.71875]]\n",
      "\n",
      "  [[0.976562 -1.03906 1.57031 ... -1.86719 0.161133 1.47656]\n",
      "   [-0.0132446 -0.214844 0.194336 ... -0.135742 -0.131836 0.507812]\n",
      "   [0.233398 -0.494141 0.511719 ... -0.5 0.244141 0.304688]\n",
      "   ...\n",
      "   [0.273438 -0.0458984 -0.318359 ... 0.141602 -0.570312 -0.253906]\n",
      "   [0.273438 -0.0458984 -0.318359 ... 0.141602 -0.570312 -0.253906]\n",
      "   [0.273438 -0.0458984 -0.318359 ... 0.141602 -0.570312 -0.253906]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0634766 -0.285156 -0.108887 ... 0.273438 0.0766602 0.173828]\n",
      "   [-0.15918 -0.0284424 -0.0554199 ... 0.0153198 -0.539062 0.114258]\n",
      "   [-0.304688 0.216797 -0.0114136 ... -0.133789 -0.400391 -0.0437012]\n",
      "   ...\n",
      "   [-0.18457 -0.211914 -0.138672 ... 0.0155029 0.194336 -0.277344]\n",
      "   [-0.18457 -0.211914 -0.138672 ... 0.0155029 0.194336 -0.277344]\n",
      "   [-0.18457 -0.211914 -0.138672 ... 0.0155029 0.194336 -0.277344]]\n",
      "\n",
      "  [[0.126953 -0.306641 -0.114746 ... 0.117676 -0.165039 -0.390625]\n",
      "   [0.478516 0.00915527 0.546875 ... -0.00202942 -0.121094 -0.769531]\n",
      "   [0.396484 -0.0145874 0.597656 ... -0.119141 -0.135742 -0.734375]\n",
      "   ...\n",
      "   [-0.144531 0.180664 -0.220703 ... -0.433594 0.625 -0.667969]\n",
      "   [-0.144531 0.180664 -0.220703 ... -0.433594 0.625 -0.667969]\n",
      "   [-0.144531 0.180664 -0.220703 ... -0.433594 0.625 -0.667969]]\n",
      "\n",
      "  [[0.225586 0.0368652 -0.318359 ... -0.0280762 0.169922 0.0258789]\n",
      "   [-0.707031 0.478516 -0.230469 ... -0.898438 0.503906 -0.416016]\n",
      "   [-0.695312 0.404297 0.0649414 ... -1.07812 0.425781 -0.390625]\n",
      "   ...\n",
      "   [-0.21582 0.144531 -0.043457 ... 0.208984 0.320312 0.28125]\n",
      "   [-0.21582 0.144531 -0.043457 ... 0.208984 0.320312 0.28125]\n",
      "   [-0.21582 0.144531 -0.043457 ... 0.208984 0.320312 0.28125]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.242188 -0.472656 -0.777344 ... -0.683594 -0.503906 -0.142578]\n",
      "   [0.0218506 -0.291016 -0.726562 ... -0.421875 -0.204102 0.026123]\n",
      "   [0.198242 -0.25 -0.519531 ... -0.341797 -0.332031 -0.227539]\n",
      "   ...\n",
      "   [0.0849609 -0.347656 -0.585938 ... -0.449219 -0.349609 -0.394531]\n",
      "   [0.0849609 -0.347656 -0.585938 ... -0.449219 -0.349609 -0.394531]\n",
      "   [0.0849609 -0.347656 -0.585938 ... -0.449219 -0.349609 -0.394531]]\n",
      "\n",
      "  [[0.251953 -0.121094 0.117188 ... -0.131836 -0.145508 -0.114746]\n",
      "   [0.0981445 -0.222656 -0.0688477 ... 0.206055 -0.478516 0.308594]\n",
      "   [0.150391 0.206055 0.0463867 ... -0.0341797 -0.335938 0.472656]\n",
      "   ...\n",
      "   [0.193359 -0.101074 0.133789 ... -0.0654297 -0.285156 -0.0957031]\n",
      "   [0.193359 -0.101074 0.133789 ... -0.0654297 -0.285156 -0.0957031]\n",
      "   [0.193359 -0.101074 0.133789 ... -0.0654297 -0.285156 -0.0957031]]\n",
      "\n",
      "  [[0.19043 -0.0776367 -0.542969 ... 0.0405273 -0.451172 0.443359]\n",
      "   [0.198242 0.199219 -0.632812 ... 0.660156 0.0776367 0.796875]\n",
      "   [0.101074 0.148438 -0.628906 ... 0.515625 -0.0476074 0.714844]\n",
      "   ...\n",
      "   [0.216797 -0.0786133 -0.503906 ... 0.115234 -0.320312 0.472656]\n",
      "   [0.216797 -0.0786133 -0.503906 ... 0.115234 -0.320312 0.472656]\n",
      "   [0.216797 -0.0786133 -0.503906 ... 0.115234 -0.320312 0.472656]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.3125 0.291016 -0.742188 ... -0.804688 -0.433594 0.0976562]\n",
      "   [-0.585938 -0.375 0.15625 ... -1.05469 0.15625 1.01562]\n",
      "   [-0.519531 -0.527344 -0.300781 ... -0.96875 0.0834961 1.36719]\n",
      "   ...\n",
      "   [-0.78125 -0.0415039 -0.103027 ... -1.04688 0.228516 0.710938]\n",
      "   [-0.78125 -0.0415039 -0.103027 ... -1.04688 0.228516 0.710938]\n",
      "   [-0.78125 -0.0415039 -0.103027 ... -1.04688 0.228516 0.710938]]\n",
      "\n",
      "  [[-0.183594 -0.609375 0.102539 ... 0.921875 0.785156 -0.123535]\n",
      "   [-0.287109 -0.53125 0.0722656 ... 1.02344 0.78125 -0.0605469]\n",
      "   [-0.132812 -0.589844 0.171875 ... 1.125 0.808594 -0.0292969]\n",
      "   ...\n",
      "   [-0.621094 -0.644531 -0.296875 ... 0.90625 0.878906 -0.273438]\n",
      "   [-0.621094 -0.644531 -0.296875 ... 0.90625 0.878906 -0.273438]\n",
      "   [-0.621094 -0.644531 -0.296875 ... 0.90625 0.878906 -0.273438]]\n",
      "\n",
      "  [[-0.140625 -0.511719 0.0576172 ... -0.542969 -0.550781 1.14844]\n",
      "   [-0.00540161 -0.296875 0.246094 ... -0.120117 -0.53125 0.396484]\n",
      "   [-0.019165 -0.273438 -0.147461 ... -0.116699 -0.394531 1.24219]\n",
      "   ...\n",
      "   [0.010376 -0.464844 0.539062 ... -0.203125 0.160156 -0.0267334]\n",
      "   [0.010376 -0.464844 0.539062 ... -0.203125 0.160156 -0.0267334]\n",
      "   [0.010376 -0.464844 0.539062 ... -0.203125 0.160156 -0.0267334]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.917969 -1.03906 0.139648 ... -0.484375 0.859375 1.33594]\n",
      "   [-0.429688 -1.00781 -0.0339355 ... -0.941406 1.14062 1.25781]\n",
      "   [-0.566406 -1.11719 -0.192383 ... -1.05469 1.07812 1.33594]\n",
      "   ...\n",
      "   [-1.01562 -1.11719 0.00540161 ... 0.144531 0.964844 1.35938]\n",
      "   [-1.01562 -1.11719 0.00540161 ... 0.144531 0.964844 1.35938]\n",
      "   [-1.01562 -1.11719 0.00540161 ... 0.144531 0.964844 1.35938]]\n",
      "\n",
      "  [[-0.224609 0.824219 -0.847656 ... 0.0688477 1.14062 0.384766]\n",
      "   [-0.46875 0.765625 0.0859375 ... -0.259766 0.0505371 -0.0727539]\n",
      "   [-0.757812 0.820312 0.714844 ... -0.949219 -0.239258 -0.18457]\n",
      "   ...\n",
      "   [-0.769531 0.714844 0.050293 ... -0.691406 0.308594 -0.566406]\n",
      "   [-0.769531 0.714844 0.050293 ... -0.691406 0.308594 -0.566406]\n",
      "   [-0.769531 0.714844 0.050293 ... -0.691406 0.308594 -0.566406]]\n",
      "\n",
      "  [[0.675781 -0.546875 -1.98438 ... -1.60156 0.419922 0.498047]\n",
      "   [0.632812 -0.804688 -2.98438 ... -0.363281 -0.462891 0.133789]\n",
      "   [0.617188 -1.28125 -3.51562 ... -1.01562 -0.210938 0.0180664]\n",
      "   ...\n",
      "   [0.357422 -0.734375 -1.79688 ... -1.61719 0.300781 -0.152344]\n",
      "   [0.357422 -0.734375 -1.79688 ... -1.61719 0.300781 -0.152344]\n",
      "   [0.357422 -0.734375 -1.79688 ... -1.61719 0.300781 -0.152344]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.105469 -0.306641 0.0281982 ... 0.193359 -0.273438 0.539062]\n",
      "   [0.824219 0.949219 -0.480469 ... 0.0162354 0.613281 0.0961914]\n",
      "   [0.447266 0.0869141 -0.396484 ... 0.183594 -0.267578 0.130859]\n",
      "   ...\n",
      "   [0.103516 -0.761719 -0.125977 ... 0.271484 -0.882812 0.216797]\n",
      "   [0.103516 -0.761719 -0.125977 ... 0.271484 -0.882812 0.216797]\n",
      "   [0.103516 -0.761719 -0.125977 ... 0.271484 -0.882812 0.216797]]\n",
      "\n",
      "  [[0.742188 -0.00811768 -0.482422 ... -0.177734 0.490234 -0.349609]\n",
      "   [0.777344 0.369141 -0.09375 ... 0.384766 0.0303955 -0.574219]\n",
      "   [0.640625 0.138672 -0.277344 ... 0.12207 0.208984 -0.478516]\n",
      "   ...\n",
      "   [0.851562 -0.00662231 -0.683594 ... -0.6875 0.396484 0.249023]\n",
      "   [0.851562 -0.00662231 -0.683594 ... -0.6875 0.396484 0.249023]\n",
      "   [0.851562 -0.00662231 -0.683594 ... -0.6875 0.396484 0.249023]]\n",
      "\n",
      "  [[1.02344 -0.365234 0.703125 ... -0.535156 -0.332031 -0.980469]\n",
      "   [0.949219 -0.326172 0.652344 ... -0.617188 -0.285156 -0.855469]\n",
      "   [0.863281 0.0717773 0.527344 ... -0.515625 -0.304688 -0.964844]\n",
      "   ...\n",
      "   [1.02344 -0.804688 0.65625 ... -0.550781 -0.261719 -0.695312]\n",
      "   [1.02344 -0.804688 0.65625 ... -0.550781 -0.261719 -0.695312]\n",
      "   [1.02344 -0.804688 0.65625 ... -0.550781 -0.261719 -0.695312]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.0339355 0.209961 0.245117 ... -1.39844 -0.248047 -1.07812]\n",
      "   [-0.212891 0.228516 0.196289 ... -1.49219 -0.193359 -0.960938]\n",
      "   [-0.267578 0.105469 -0.114258 ... -1.72656 -0.166016 -0.941406]\n",
      "   ...\n",
      "   [0.00315857 0.263672 -0.119141 ... -1.58594 -0.269531 -0.929688]\n",
      "   [0.00315857 0.263672 -0.119141 ... -1.58594 -0.269531 -0.929688]\n",
      "   [0.00315857 0.263672 -0.119141 ... -1.58594 -0.269531 -0.929688]]\n",
      "\n",
      "  [[-0.199219 0.546875 1.27344 ... 0.263672 -1.34375 0.384766]\n",
      "   [-0.53125 0.470703 0.589844 ... -0.162109 -0.546875 0.660156]\n",
      "   [-0.75 0.617188 0.527344 ... -0.339844 -0.261719 0.824219]\n",
      "   ...\n",
      "   [-0.245117 0.25 0.929688 ... 0.421875 -0.945312 0.542969]\n",
      "   [-0.245117 0.25 0.929688 ... 0.421875 -0.945312 0.542969]\n",
      "   [-0.245117 0.25 0.929688 ... 0.421875 -0.945312 0.542969]]\n",
      "\n",
      "  [[-0.078125 0.271484 -0.738281 ... 0.949219 0.714844 0.106934]\n",
      "   [-0.200195 0.106445 -0.773438 ... 1.04688 0.785156 0.0644531]\n",
      "   [-0.279297 0.0908203 -0.667969 ... 0.953125 0.859375 0.0617676]\n",
      "   ...\n",
      "   [0.00842285 0.189453 -0.933594 ... 0.855469 0.425781 0.000667572]\n",
      "   [0.00842285 0.189453 -0.933594 ... 0.855469 0.425781 0.000667572]\n",
      "   [0.00842285 0.189453 -0.933594 ... 0.855469 0.425781 0.000667572]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-0.0869141 0.314453 0.0336914 ... -0.287109 0.151367 0.585938]\n",
      "   [-0.0314941 0.335938 -0.0549316 ... -0.249023 0.294922 0.597656]\n",
      "   [-0.0673828 0.378906 0.0118408 ... -0.257812 0.261719 0.570312]\n",
      "   ...\n",
      "   [0.0286865 0.294922 0.0286865 ... -0.257812 0.150391 0.570312]\n",
      "   [0.0286865 0.294922 0.0286865 ... -0.257812 0.150391 0.570312]\n",
      "   [0.0286865 0.294922 0.0286865 ... -0.257812 0.150391 0.570312]]\n",
      "\n",
      "  [[-1.09375 -0.0322266 0.640625 ... 0.170898 1.04688 1.02344]\n",
      "   [-1.21094 0.605469 0.960938 ... -0.632812 0.789062 0.527344]\n",
      "   [-1.30469 0.625 0.929688 ... -0.542969 0.839844 0.388672]\n",
      "   ...\n",
      "   [-1.33594 0.462891 0.789062 ... -0.257812 0.78125 0.550781]\n",
      "   [-1.33594 0.462891 0.789062 ... -0.257812 0.78125 0.550781]\n",
      "   [-1.33594 0.462891 0.789062 ... -0.257812 0.78125 0.550781]]\n",
      "\n",
      "  [[-0.263672 0.882812 0.320312 ... 0.012146 0.243164 1.20312]\n",
      "   [-0.253906 0.898438 0.316406 ... -0.137695 0.4375 1.24219]\n",
      "   [-0.223633 0.863281 0.302734 ... -0.146484 0.535156 1.35156]\n",
      "   ...\n",
      "   [-0.177734 0.851562 0.310547 ... -0.0227051 0.482422 1.39844]\n",
      "   [-0.177734 0.851562 0.310547 ... -0.0227051 0.482422 1.39844]\n",
      "   [-0.177734 0.851562 0.310547 ... -0.0227051 0.482422 1.39844]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.785156 1.11719 0.628906 ... 1.0625 0.589844 1.32031]\n",
      "   [-0.714844 1.33594 0.458984 ... 0.910156 -0.1875 1.09375]\n",
      "   [-0.785156 1.36719 0.550781 ... 0.878906 -0.138672 1.03125]\n",
      "   ...\n",
      "   [-0.609375 1.08594 0.451172 ... 1.03906 0.53125 1.51562]\n",
      "   [-0.609375 1.08594 0.451172 ... 1.03906 0.53125 1.51562]\n",
      "   [-0.609375 1.08594 0.451172 ... 1.03906 0.53125 1.51562]]\n",
      "\n",
      "  [[0.632812 -1.90625 -0.0371094 ... -1.97656 -1.25 -0.660156]\n",
      "   [0.566406 -2.0625 0.201172 ... -2.15625 -1.33594 -0.585938]\n",
      "   [0.671875 -1.99219 0.0712891 ... -2.04688 -1.25 -0.816406]\n",
      "   ...\n",
      "   [0.570312 -1.88281 0.119629 ... -2.03125 -1.28906 -0.357422]\n",
      "   [0.570312 -1.88281 0.119629 ... -2.03125 -1.28906 -0.357422]\n",
      "   [0.570312 -1.88281 0.119629 ... -2.03125 -1.28906 -0.357422]]\n",
      "\n",
      "  [[0.292969 -0.484375 0.746094 ... 0.878906 0.498047 -1.03906]\n",
      "   [0.353516 -0.546875 0.425781 ... 0.894531 0.703125 -1.71875]\n",
      "   [0.314453 -0.570312 0.453125 ... 0.898438 0.722656 -1.65625]\n",
      "   ...\n",
      "   [0.367188 -0.492188 0.601562 ... 0.945312 0.792969 -1.58594]\n",
      "   [0.367188 -0.492188 0.601562 ... 0.945312 0.792969 -1.58594]\n",
      "   [0.367188 -0.492188 0.601562 ... 0.945312 0.792969 -1.58594]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.279297 0.871094 -0.388672 ... -0.566406 1.03125 2.17188]\n",
      "   [0.216797 0.5625 -0.511719 ... -0.585938 0.621094 1.99219]\n",
      "   [0.213867 0.494141 -0.357422 ... -0.359375 0.59375 1.63281]\n",
      "   ...\n",
      "   [0.19043 0.8125 -0.523438 ... -0.582031 1.10156 2.42188]\n",
      "   [0.19043 0.8125 -0.523438 ... -0.582031 1.10156 2.42188]\n",
      "   [0.19043 0.8125 -0.523438 ... -0.582031 1.10156 2.42188]]\n",
      "\n",
      "  [[0.373047 1.10156 -3.25 ... -0.0776367 0.0922852 -2.76562]\n",
      "   [0.878906 1.17969 -2.35938 ... 0.00408936 -0.166016 -1.55469]\n",
      "   [0.816406 1.30469 -2.45312 ... -0.0106201 -0.0186768 -1.80469]\n",
      "   ...\n",
      "   [0.351562 0.535156 -3.90625 ... -0.21582 0.078125 -3.09375]\n",
      "   [0.351562 0.535156 -3.90625 ... -0.21582 0.078125 -3.09375]\n",
      "   [0.351562 0.535156 -3.90625 ... -0.21582 0.078125 -3.09375]]\n",
      "\n",
      "  [[-2.75 -0.408203 0.195312 ... -2.07812 1.35938 0.394531]\n",
      "   [-2.5 -0.570312 0.0917969 ... -2.0625 1.03125 0.535156]\n",
      "   [-2.45312 -0.480469 0.00405884 ... -2.07812 1.15625 0.519531]\n",
      "   ...\n",
      "   [-3 -0.585938 0.170898 ... -1.96875 1.52344 0.621094]\n",
      "   [-3 -0.585938 0.170898 ... -1.96875 1.52344 0.621094]\n",
      "   [-3 -0.585938 0.170898 ... -1.96875 1.52344 0.621094]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.742188 -0.792969 2.29688 ... -0.400391 -0.15918 -1.28906]\n",
      "   [0.789062 -0.734375 2.32812 ... -0.378906 -0.111816 -1.22656]\n",
      "   [0.75 -0.585938 2.34375 ... -0.515625 -0.0122681 -1.03906]\n",
      "   ...\n",
      "   [-0.664062 -0.753906 2.54688 ... -0.914062 0.186523 -0.59375]\n",
      "   [-0.664062 -0.753906 2.54688 ... -0.914062 0.186523 -0.59375]\n",
      "   [-0.664062 -0.753906 2.54688 ... -0.914062 0.186523 -0.59375]]\n",
      "\n",
      "  [[-2.17188 1.10938 0.625 ... 1.60938 -1.22656 1.33594]\n",
      "   [-2.1875 1.07031 0.910156 ... 1.66406 -1.11719 1.32812]\n",
      "   [-2.20312 1.03125 0.921875 ... 1.61719 -1.30469 1.1875]\n",
      "   ...\n",
      "   [-2.0625 1.14062 0.574219 ... 1.57031 -1.17188 1.32031]\n",
      "   [-2.0625 1.14062 0.574219 ... 1.57031 -1.17188 1.32031]\n",
      "   [-2.0625 1.14062 0.574219 ... 1.57031 -1.17188 1.32031]]\n",
      "\n",
      "  [[1.45312 -2.625 0.310547 ... -1.125 -0.773438 0.503906]\n",
      "   [1.5 -2.21875 0.194336 ... -1.125 -0.558594 0.200195]\n",
      "   [1.47656 -2.3125 0.294922 ... -1.11719 -0.683594 0.337891]\n",
      "   ...\n",
      "   [1.3125 -3.10938 0.355469 ... -0.9375 -0.980469 0.890625]\n",
      "   [1.3125 -3.10938 0.355469 ... -0.9375 -0.980469 0.890625]\n",
      "   [1.3125 -3.10938 0.355469 ... -0.9375 -0.980469 0.890625]]]]\n",
      "jax (1, 16, 4128, 80) [[[[-2.17188 -0.408203 0.213867 ... -0.283203 0.441406 1.92188]\n",
      "   [-2.15625 -0.308594 0.322266 ... -0.298828 0.263672 1.99219]\n",
      "   [-2.09375 -0.373047 0.353516 ... -0.306641 0.294922 2]\n",
      "   ...\n",
      "   [-1.94531 -0.363281 0.133789 ... -0.0976562 0.460938 2.14062]\n",
      "   [-1.94531 -0.363281 0.133789 ... -0.0976562 0.460938 2.14062]\n",
      "   [-1.94531 -0.363281 0.133789 ... -0.0976562 0.460938 2.14062]]\n",
      "\n",
      "  [[0.898438 0.40625 -1.32031 ... -1.625 1.0625 -1.42188]\n",
      "   [0.691406 0.464844 -1.32812 ... -1.60938 0.839844 -1.42188]\n",
      "   [0.671875 0.40625 -1.33594 ... -1.55469 0.789062 -1.42969]\n",
      "   ...\n",
      "   [0.894531 0.480469 -1.26562 ... -1.64844 1.07812 -1.35156]\n",
      "   [0.894531 0.480469 -1.26562 ... -1.64844 1.07812 -1.35156]\n",
      "   [0.894531 0.480469 -1.26562 ... -1.64844 1.07812 -1.35156]]\n",
      "\n",
      "  [[0.421875 0.117188 -0.804688 ... 0.925781 0.00582886 0.235352]\n",
      "   [0.375 0.28125 -0.648438 ... 1.08594 -0.0541992 0.554688]\n",
      "   [0.433594 0.191406 -0.792969 ... 0.964844 -0.0839844 0.386719]\n",
      "   ...\n",
      "   [0.371094 0.0898438 -0.835938 ... 1.03125 -0.078125 0.271484]\n",
      "   [0.371094 0.0898438 -0.835938 ... 1.03125 -0.078125 0.271484]\n",
      "   [0.371094 0.0898438 -0.835938 ... 1.03125 -0.078125 0.271484]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.67188 -2.79688 -0.324219 ... 0.855469 -0.408203 0.255859]\n",
      "   [1.46875 -2.48438 -0.291016 ... 0.503906 -0.263672 -0.0493164]\n",
      "   [1.65625 -2.45312 -0.243164 ... 0.570312 -0.5 -0.022583]\n",
      "   ...\n",
      "   [1.72656 -2.70312 -0.253906 ... 0.816406 -0.59375 0.414062]\n",
      "   [1.72656 -2.70312 -0.253906 ... 0.816406 -0.59375 0.414062]\n",
      "   [1.72656 -2.70312 -0.253906 ... 0.816406 -0.59375 0.414062]]\n",
      "\n",
      "  [[-0.546875 -0.209961 2.90625 ... 0.902344 -0.371094 -0.625]\n",
      "   [-0.427734 -0.169922 2.60938 ... 0.84375 -0.224609 -0.863281]\n",
      "   [-0.445312 -0.192383 2.64062 ... 0.890625 -0.172852 -0.800781]\n",
      "   ...\n",
      "   [-0.5 -0.0883789 2.64062 ... 1.01562 -0.412109 -0.8125]\n",
      "   [-0.5 -0.0883789 2.64062 ... 1.01562 -0.412109 -0.8125]\n",
      "   [-0.5 -0.0883789 2.64062 ... 1.01562 -0.412109 -0.8125]]\n",
      "\n",
      "  [[3.64062 4.34375 3.75 ... 1.25 -5.1875 1.625]\n",
      "   [3.76562 4.46875 3.9375 ... 1.32031 -5.40625 1.74219]\n",
      "   [3.73438 4.4375 3.92188 ... 1.23438 -5.34375 1.75781]\n",
      "   ...\n",
      "   [3.78125 4.4375 4 ... 1.36719 -5.5 1.65625]\n",
      "   [3.78125 4.4375 4 ... 1.36719 -5.5 1.65625]\n",
      "   [3.78125 4.4375 4 ... 1.36719 -5.5 1.65625]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.439453 1.07031 -0.223633 ... -1.44531 -1.30469 -0.652344]\n",
      "   [0.0673828 1.05469 -0.392578 ... -1.32031 -1.98438 -0.753906]\n",
      "   [0.0698242 0.996094 -0.431641 ... -1.39844 -2.0625 -0.738281]\n",
      "   ...\n",
      "   [0.271484 0.78125 0.0148926 ... -1.75781 -1.41406 -0.847656]\n",
      "   [0.271484 0.78125 0.0148926 ... -1.75781 -1.41406 -0.847656]\n",
      "   [0.271484 0.78125 0.0148926 ... -1.75781 -1.41406 -0.847656]]\n",
      "\n",
      "  [[-0.375 0.90625 -0.107422 ... -0.527344 0.291016 -0.416016]\n",
      "   [-0.394531 1.22656 -0.249023 ... -0.648438 0.507812 -0.570312]\n",
      "   [-0.462891 1.07031 -0.339844 ... -0.660156 0.404297 -0.5]\n",
      "   ...\n",
      "   [-0.287109 1.26562 -0.478516 ... -0.90625 0.515625 -0.425781]\n",
      "   [-0.287109 1.26562 -0.478516 ... -0.90625 0.515625 -0.425781]\n",
      "   [-0.287109 1.26562 -0.478516 ... -0.90625 0.515625 -0.425781]]\n",
      "\n",
      "  [[-0.400391 0.145508 0.730469 ... -0.921875 -0.246094 -0.917969]\n",
      "   [-0.314453 -0.277344 0.59375 ... -0.90625 -0.208984 -0.929688]\n",
      "   [-0.408203 -0.378906 0.53125 ... -1 -0.332031 -0.96875]\n",
      "   ...\n",
      "   [-0.707031 -0.253906 0.597656 ... -1.17969 -0.777344 -1.0625]\n",
      "   [-0.707031 -0.253906 0.597656 ... -1.17969 -0.777344 -1.0625]\n",
      "   [-0.707031 -0.253906 0.597656 ... -1.17969 -0.777344 -1.0625]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.304688 0.0476074 -0.71875 ... 1.58594 -0.213867 1.17188]\n",
      "   [-0.139648 0.314453 -0.103027 ... 1.03125 -0.211914 1.13281]\n",
      "   [-0.230469 0.341797 -0.15332 ... 1.07812 -0.0839844 1.21875]\n",
      "   ...\n",
      "   [-0.300781 0.139648 -0.427734 ... 1.3125 -0.396484 1.21094]\n",
      "   [-0.300781 0.139648 -0.427734 ... 1.3125 -0.396484 1.21094]\n",
      "   [-0.300781 0.139648 -0.427734 ... 1.3125 -0.396484 1.21094]]\n",
      "\n",
      "  [[0.835938 -2.03125 -1.0625 ... -0.24707 -1.00781 -0.261719]\n",
      "   [1.09375 -2.14062 -0.425781 ... -0.515625 -1.07031 -0.396484]\n",
      "   [1.08594 -2.09375 -0.53125 ... -0.445312 -0.863281 -0.425781]\n",
      "   ...\n",
      "   [0.917969 -1.92188 -1.28125 ... 0.0327148 -0.632812 -0.223633]\n",
      "   [0.917969 -1.92188 -1.28125 ... 0.0327148 -0.632812 -0.223633]\n",
      "   [0.917969 -1.92188 -1.28125 ... 0.0327148 -0.632812 -0.223633]]\n",
      "\n",
      "  [[-0.902344 1.07812 1.35938 ... 0.964844 -1.26562 -1.32031]\n",
      "   [-0.433594 1.28906 1.875 ... 0.738281 -0.414062 -1.69531]\n",
      "   [-0.161133 1.11719 1.57031 ... 0.486328 -0.333984 -1.6875]\n",
      "   ...\n",
      "   [-1 1 1.26562 ... 0.945312 -1.32031 -1.22656]\n",
      "   [-1 1 1.26562 ... 0.945312 -1.32031 -1.22656]\n",
      "   [-1 1 1.26562 ... 0.945312 -1.32031 -1.22656]]]]\n",
      "jax (1, 16, 4128, 80) [[[[0.0495605 0.871094 1.52344 ... -0.554688 0.145508 0.238281]\n",
      "   [-0.173828 0.671875 1.0625 ... -0.953125 -0.496094 0.636719]\n",
      "   [-0.373047 0.71875 0.9375 ... -1.03125 -0.734375 0.804688]\n",
      "   ...\n",
      "   [0.167969 0.917969 1.71875 ... -0.482422 0.408203 0.170898]\n",
      "   [0.167969 0.917969 1.71875 ... -0.482422 0.408203 0.170898]\n",
      "   [0.167969 0.917969 1.71875 ... -0.482422 0.408203 0.170898]]\n",
      "\n",
      "  [[4.0625 -0.695312 -0.213867 ... 0.180664 -0.597656 0.046875]\n",
      "   [4.21875 -0.211914 -0.135742 ... -0.279297 -0.0163574 -0.0441895]\n",
      "   [4.15625 -0.199219 0.0539551 ... -0.318359 0.059082 -0.154297]\n",
      "   ...\n",
      "   [4.03125 -0.636719 -0.135742 ... 0.0732422 -0.503906 -0.0019989]\n",
      "   [4.03125 -0.636719 -0.135742 ... 0.0732422 -0.503906 -0.0019989]\n",
      "   [4.03125 -0.636719 -0.135742 ... 0.0732422 -0.503906 -0.0019989]]\n",
      "\n",
      "  [[0.632812 1.42188 0.275391 ... 0.232422 1.27344 -0.953125]\n",
      "   [0.800781 1.21094 -0.408203 ... -0.0588379 0.875 -0.0541992]\n",
      "   [0.9375 1.0625 -0.498047 ... -0.22168 0.808594 0.212891]\n",
      "   ...\n",
      "   [0.652344 1.40625 0.419922 ... 0.162109 1.36719 -0.957031]\n",
      "   [0.652344 1.40625 0.419922 ... 0.162109 1.36719 -0.957031]\n",
      "   [0.652344 1.40625 0.419922 ... 0.162109 1.36719 -0.957031]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.229492 -1.25 0.984375 ... 0.761719 2.01562 0.929688]\n",
      "   [-0.427734 -1.24219 1.10156 ... 0.722656 2.125 0.9375]\n",
      "   [-0.320312 -1.47656 0.957031 ... 0.660156 1.94531 0.828125]\n",
      "   ...\n",
      "   [-0.267578 -1.1875 0.914062 ... 0.773438 2.10938 0.9375]\n",
      "   [-0.267578 -1.1875 0.914062 ... 0.773438 2.10938 0.9375]\n",
      "   [-0.267578 -1.1875 0.914062 ... 0.773438 2.10938 0.9375]]\n",
      "\n",
      "  [[-1.80469 -1.20312 2.17188 ... 1.85938 0.335938 -0.839844]\n",
      "   [-1.82812 -1 1.71875 ... 1.88281 0.753906 -0.84375]\n",
      "   [-1.90625 -1.03906 1.57031 ... 1.78125 0.789062 -0.792969]\n",
      "   ...\n",
      "   [-1.875 -1.20312 2.20312 ... 1.77344 0.326172 -0.765625]\n",
      "   [-1.875 -1.20312 2.20312 ... 1.77344 0.326172 -0.765625]\n",
      "   [-1.875 -1.20312 2.20312 ... 1.77344 0.326172 -0.765625]]\n",
      "\n",
      "  [[-1.67188 -0.390625 1.04688 ... 1.13281 -3.40625 -1.86719]\n",
      "   [-1.72656 -0.21875 1.13281 ... 1.08594 -3.0625 -1.52344]\n",
      "   [-1.77344 -0.171875 1.14062 ... 1.05469 -3 -1.38281]\n",
      "   ...\n",
      "   [-1.71875 -0.875 1.01562 ... 1.25 -3.53125 -2.17188]\n",
      "   [-1.71875 -0.875 1.01562 ... 1.25 -3.53125 -2.17188]\n",
      "   [-1.71875 -0.875 1.01562 ... 1.25 -3.53125 -2.17188]]]]\n"
     ]
    }
   ],
   "source": [
    "output_jax = model(**inputs_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1]]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['aspect_ratio_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.53125000,  0.47265625, -0.35742188,  0.23925781, -2.00000000,\n",
       "        -0.24902344,  0.36718750, -0.90625000, -2.68750000, -4.12500000],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_torch.last_hidden_state[0,0,0,0,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.554688, 0.332031, -0.0800781, 4.34375, 7.125, -0.386719,\n",
       "       0.636719, -0.601562, -0.289062, -0.617188], dtype=bfloat16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax.last_hidden_state[0,0,0,0,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MllamaVisionModel, FlaxMllamaVisionModel\n",
    "from transformers import AutoProcessor, MllamaTextModel\n",
    "import requests\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image\n",
    "from huggingface_hub import login\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "hf_token = \"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\"\n",
    "login(hf_token)\n",
    "checkpoint = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs_torch = processor(images=image, return_tensors=\"pt\")\n",
    "inputs_jax = processor(images=image, return_tensors=\"jax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class TorchConv(nn.Module):\n",
    "    def __init__(self, dtype=torch.bfloat16):\n",
    "        super(TorchConv, self).__init__()\n",
    "        self.patch_embedding = nn.Conv2d(\n",
    "            in_channels=3, #3\n",
    "            out_channels=1280, #1280\n",
    "            kernel_size=14, #14\n",
    "            stride=14, #14\n",
    "            padding=\"valid\",\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "\n",
    "    ):\n",
    "        batch_size, num_concurrent_media, num_tiles, num_channels, height, width = pixel_values.shape #(1, 1, 4, 3, 448, 448)\n",
    "\n",
    "        pixel_values = pixel_values.reshape(batch_size * num_concurrent_media * num_tiles, num_channels, height, width) #(4, 3, 448, 448)\n",
    "        # Patch embedding\n",
    "        patch_embeds = self.patch_embedding(pixel_values.to(torch.bfloat16).to('cuda')) # (batch_size * num_concurrent_media * num_tiles, hidden_size=1280, 32, 32)\n",
    "        return patch_embeds\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "torch_model = TorchConv(dtype=torch.bfloat16).to('cuda')\n",
    "\n",
    "\n",
    "# Get the parameters from the TorchConv model\n",
    "torch_params = torch_model.patch_embedding.weight\n",
    "# # Example PyTorch tensor\n",
    "# torch_params_32 = torch.randn(torch_params.shape, dtype=torch.float32)\n",
    "\n",
    "# # Permute the tensor's dimensions\n",
    "# torch_params_permuted = torch_params_32.permute(2, 3, 1, 0)\n",
    "\n",
    "# # Convert the PyTorch tensor to a NumPy array\n",
    "# torch_params_numpy = torch_params_permuted.detach().cpu().numpy()\n",
    "\n",
    "# # Convert the NumPy array to a JAX tensor with dtype bfloat16\n",
    "# jax_params = jnp.array(torch_params_numpy, dtype=jnp.bfloat16)\n",
    "# torch_params = torch.tensor(torch_params_32, dtype=torch.bfloat16)\n",
    "# torch_params = torch.nn.Parameter(torch.tensor(torch_params_32, dtype=torch.bfloat16, device='cuda'))\n",
    "# torch_model.patch_embedding.weight = torch_params\n",
    "torch_model.patch_embedding.weight = model_torch.patch_embedding.weight\n",
    "# Perform a forward pass through the model\n",
    "output_torch = torch_model(inputs_torch.pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as fnn\n",
    "class JaxConv(fnn.Module):\n",
    "  dtype: jnp.dtype = jnp.bfloat16\n",
    "\n",
    "  def setup(self):\n",
    "\n",
    "    self.patch_embedding = fnn.Conv(\n",
    "        1280,\n",
    "        kernel_size=(14, 14),\n",
    "        strides=(14, 14),\n",
    "        padding=\"VALID\",\n",
    "        use_bias=False,\n",
    "        dtype=self.dtype,\n",
    "        kernel_init=jax.nn.initializers.normal(),\n",
    "    )\n",
    " \n",
    "  def __call__(\n",
    "      self,\n",
    "      pixel_values: jnp.ndarray,\n",
    "  ):\n",
    "        batch_size, num_concurrent_media, num_tiles, num_channels, height, width = pixel_values.shape\n",
    "\n",
    "        pixel_values = pixel_values.reshape((batch_size * num_concurrent_media * num_tiles, num_channels, height, width))\n",
    "\n",
    "        # Patch embedding\n",
    "        patch_embeds = self.patch_embedding(pixel_values.transpose((0, 2, 3, 1)))\n",
    "\n",
    "        patch_embeds = patch_embeds.transpose((0, 3, 1, 2))\n",
    "\n",
    "        return patch_embeds\n",
    "        \n",
    "# Initialize the model\n",
    "flax_model = JaxConv()\n",
    "# Initialize parameters\n",
    "params = flax_model.init(jax.random.PRNGKey(0), jnp.ones((1, 1, 4, 3, 448, 448)))\n",
    "\n",
    "# # Convert PyTorch parameters to JAX parameters\n",
    "params = unfreeze(params)\n",
    "params['params']['patch_embedding']['kernel'] = model.params['vision_model']['patch_embedding']['kernel']\n",
    "params = freeze(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_jax = flax_model.apply(params, inputs_jax.pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[-0.191406, -0.176758, -0.185547, ..., -0.175781, -0.174805,\n",
       "          -0.0688477],\n",
       "         [0.00186157, -0.0678711, -0.234375, ..., -0.175781, -0.172852,\n",
       "          -0.170898],\n",
       "         [0.0534668, 0.114258, 0.0119629, ..., -0.203125, -0.191406,\n",
       "          -0.192383],\n",
       "         ...,\n",
       "         [0.0219727, 0.0603027, 0.0556641, ..., -0.0135498, -0.0859375,\n",
       "          -0.121582],\n",
       "         [0.034668, 0.103516, 0.032959, ..., 0.00430298, 0.010376,\n",
       "          -0.111328],\n",
       "         [0.0181885, 0.0126953, 0.00482178, ..., 0.0419922, 0.0241699,\n",
       "          -0.0947266]],\n",
       "\n",
       "        [[0.0412598, 0.0356445, 0.0444336, ..., 0.0368652, 0.0410156,\n",
       "          0.176758],\n",
       "         [0.12207, 0.0373535, 0.090332, ..., 0.0291748, 0.0358887,\n",
       "          0.0664062],\n",
       "         [-0.0280762, 0.0534668, -0.0334473, ..., 0.0456543, 0.0317383,\n",
       "          0.0152588],\n",
       "         ...,\n",
       "         [-0.0566406, 0.0668945, 0.0385742, ..., 0.0158691, -0.022583,\n",
       "          0.0622559],\n",
       "         [0.0108032, 0.0429688, 0.0495605, ..., 0.0634766,\n",
       "          -0.000610352, 0.113281],\n",
       "         [0.00497437, 0.0568848, -0.0142212, ..., -0.0751953,\n",
       "          -0.0062561, 0.115723]],\n",
       "\n",
       "        [[-0.0961914, -0.287109, -0.386719, ..., -0.277344, -0.25,\n",
       "          0.139648],\n",
       "         [0.523438, 0.10498, 0.162109, ..., -0.242188, -0.275391,\n",
       "          -0.296875],\n",
       "         [0.0634766, -0.0185547, -0.203125, ..., -0.326172, -0.248047,\n",
       "          -0.21582],\n",
       "         ...,\n",
       "         [0.122559, -0.149414, -0.0917969, ..., 0.138672, -0.439453,\n",
       "          -0.273438],\n",
       "         [0.133789, -0.1875, 0.222656, ..., -0.335938, 0.375, 0.384766],\n",
       "         [-0.359375, -0.0527344, -0.150391, ..., 0.202148, 0.135742,\n",
       "          0.213867]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.451172, -0.410156, -0.402344, ..., -0.386719, -0.378906,\n",
       "          -0.224609],\n",
       "         [0.0898438, -0.157227, -0.181641, ..., -0.384766, -0.394531,\n",
       "          -0.416016],\n",
       "         [0.135742, 0.148438, 0.171875, ..., -0.5, -0.503906,\n",
       "          -0.464844],\n",
       "         ...,\n",
       "         [0.111328, -0.0615234, -0.213867, ..., 0.249023, 0.12793,\n",
       "          -0.419922],\n",
       "         [-0.0708008, -0.0563965, -0.134766, ..., 0.28125, 0.248047,\n",
       "          -0.378906],\n",
       "         [-0.267578, -0.158203, -0.0400391, ..., 0.324219, 0.25,\n",
       "          -0.104492]],\n",
       "\n",
       "        [[-0.136719, -0.427734, -0.332031, ..., -0.357422, -0.341797,\n",
       "          -2.20312],\n",
       "         [1.27344, 0.789062, 0.746094, ..., -0.355469, -0.423828,\n",
       "          -0.542969],\n",
       "         [-0.0466309, 0.621094, 1.03125, ..., -0.808594, -0.59375,\n",
       "          -0.503906],\n",
       "         ...,\n",
       "         [0.769531, 0.382812, -0.107422, ..., 0.361328, 3.76562,\n",
       "          -0.367188],\n",
       "         [-0.298828, 0.59375, 0.277344, ..., 0.0673828, 2.32812,\n",
       "          -0.386719],\n",
       "         [0.120117, 0.333984, 0.0795898, ..., 0.652344, 1.32812, 2.5]],\n",
       "\n",
       "        [[0.112793, 0.0751953, 0.0683594, ..., 0.0668945, 0.0664062,\n",
       "          0.106445],\n",
       "         [0.0795898, 0.117676, 0.0228271, ..., 0.0522461, 0.0703125,\n",
       "          0.065918],\n",
       "         [-0.00454712, 0.0388184, -0.0181885, ..., 0.0654297,\n",
       "          0.0673828, 0.0629883],\n",
       "         ...,\n",
       "         [-0.0124512, -0.0127563, 0.0255127, ..., -0.0588379, 0.036377,\n",
       "          0.0849609],\n",
       "         [-0.0742188, -0.0422363, 0.00994873, ..., -0.101562,\n",
       "          -0.0119629, 0.134766],\n",
       "         [0.043457, -0.0395508, -0.0280762, ..., -0.121582, -0.0532227,\n",
       "          0.0568848]]],\n",
       "\n",
       "\n",
       "       [[[-0.0134277, -0.0683594, 0.0361328, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.163086, -0.196289, -0.0834961, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.261719, -0.138672, -0.0473633, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         ...,\n",
       "         [-0.151367, -0.137695, -0.0412598, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.123535, -0.0378418, 0.0219727, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.105957, 0.00878906, -0.0339355, ..., 0.18457, 0.18457,\n",
       "          0.18457]],\n",
       "\n",
       "        [[0.101562, 0.103516, -0.0786133, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.0480957, 0.0854492, -0.172852, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [-0.118164, 0.0922852, -0.162109, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         ...,\n",
       "         [0.0117188, 0.0466309, 0.0322266, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.052002, 0.034668, 0.020752, ..., -0.0625, -0.0625, -0.0625],\n",
       "         [0.0888672, 0.0554199, -0.0168457, ..., -0.0625, -0.0625,\n",
       "          -0.0625]],\n",
       "\n",
       "        [[-1, -0.613281, 0.785156, ..., 0.292969, 0.292969, 0.292969],\n",
       "         [-0.155273, 0.020874, -0.349609, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [-0.00613403, 0.359375, -0.202148, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         ...,\n",
       "         [-0.207031, -0.166016, 0.106934, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [-0.257812, 0.408203, -0.28125, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [-0.166016, 0.241211, -0.249023, ..., 0.292969, 0.292969,\n",
       "          0.292969]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.429688, -0.4375, 0.00369263, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.410156, -0.267578, -0.164062, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.337891, -0.182617, -0.110352, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         ...,\n",
       "         [-0.431641, -0.410156, -0.244141, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.373047, -0.211914, -0.175781, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.314453, -0.185547, -0.246094, ..., 0.519531, 0.519531,\n",
       "          0.519531]],\n",
       "\n",
       "        [[0.433594, 0.675781, -0.527344, ..., 0.5, 0.5, 0.5],\n",
       "         [0.143555, -1.40625, -0.929688, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.0136719, -1.625, 1.01562, ..., 0.5, 0.5, 0.5],\n",
       "         ...,\n",
       "         [-0.402344, -0.511719, -0.863281, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.320312, -0.660156, -0.953125, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.878906, -1.05469, -0.207031, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "        [[0.0615234, 0.00187683, -0.0644531, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [0.0373535, 0.050293, -0.0654297, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         [-0.0634766, 0.15332, -0.0290527, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         ...,\n",
       "         [0.0515137, 0.0634766, 0.0568848, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         [0.0551758, 0.0424805, 0.0127563, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         [0.0766602, 0.0285645, -0.0483398, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664]]],\n",
       "\n",
       "\n",
       "       [[[0.0112305, 0.0727539, 0.0344238, ..., 0.0952148, 0.0786133,\n",
       "          -0.0446777],\n",
       "         [0.0351562, 0.00805664, 0.100586, ..., 0.0649414, 0.12207,\n",
       "          0.122559],\n",
       "         [-0.0368652, -0.059082, -0.0332031, ..., 0.107422, 0.116699,\n",
       "          0.0854492],\n",
       "         ...,\n",
       "         [0.0859375, 0.130859, 0.235352, ..., 0.0908203, 0.144531,\n",
       "          -0.0177002],\n",
       "         [0.0722656, 0.198242, 0.125977, ..., 0.0961914, 0.0585938,\n",
       "          0.0649414],\n",
       "         [0.132812, 0.208008, 0.158203, ..., 0.0539551, 0.0693359,\n",
       "          0.0218506]],\n",
       "\n",
       "        [[0.0456543, -0.0218506, 0.0678711, ..., -0.160156, -0.0289307,\n",
       "          0.146484],\n",
       "         [-0.00379944, -0.0717773, -0.0598145, ..., -0.0820312,\n",
       "          -0.0098877, -0.052002],\n",
       "         [0.045166, 0.00300598, 0.00233459, ..., -0.139648, 0.0493164,\n",
       "          -0.0253906],\n",
       "         ...,\n",
       "         [-0.0172119, -0.0568848, -0.0830078, ..., -0.00939941,\n",
       "          0.0272217, -0.0791016],\n",
       "         [-0.0220947, 0.0664062, 0.138672, ..., -0.0400391, 0.0194092,\n",
       "          -0.00485229],\n",
       "         [-0.145508, 0.019043, -0.0834961, ..., 0.135742, -0.0415039,\n",
       "          -0.0378418]],\n",
       "\n",
       "        [[-0.314453, -0.396484, 0.554688, ..., 0.40625, 0.144531,\n",
       "          0.0544434],\n",
       "         [-0.3125, 0.0351562, 0.106445, ..., 0.0103149, 0.441406,\n",
       "          0.166992],\n",
       "         [-0.203125, -0.171875, -0.198242, ..., -0.125, 0.296875,\n",
       "          0.118164],\n",
       "         ...,\n",
       "         [0.0708008, 0.09375, 0.15332, ..., 0.392578, -0.0908203,\n",
       "          0.0751953],\n",
       "         [-0.539062, 0.306641, -0.101562, ..., 0.173828, 0.53125,\n",
       "          0.164062],\n",
       "         [0.511719, 0.617188, 0.365234, ..., 0.425781, 0.229492,\n",
       "          0.106934]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.259766, 0.015625, 0.0942383, ..., 0.365234, 0.232422,\n",
       "          0.104492],\n",
       "         [-0.140625, -0.15625, -0.0976562, ..., 0.322266, 0.376953,\n",
       "          0.213867],\n",
       "         [-0.3125, -0.287109, -0.243164, ..., 0.330078, 0.427734,\n",
       "          0.304688],\n",
       "         ...,\n",
       "         [0.231445, 0.419922, 0.357422, ..., 0.180664, 0.115234,\n",
       "          0.21582],\n",
       "         [0.265625, 0.378906, 0.40625, ..., 0.147461, 0.208984,\n",
       "          0.233398],\n",
       "         [0.457031, 0.335938, 0.330078, ..., 0.115723, 0.0693359,\n",
       "          -0.0341797]],\n",
       "\n",
       "        [[-0.539062, -0.871094, 0.367188, ..., 0.0717773, 1.52344,\n",
       "          3.28125],\n",
       "         [0.00141907, -0.22168, 0.104492, ..., -0.65625, 0.59375,\n",
       "          0.722656],\n",
       "         [-0.112305, 0.161133, 0.0751953, ..., -0.890625, 1.21094,\n",
       "          1.64844],\n",
       "         ...,\n",
       "         [0.423828, 0.0732422, 0.130859, ..., 0.238281, -0.101562,\n",
       "          0.367188],\n",
       "         [-0.707031, 0.511719, 1.00781, ..., 0.0844727, 0.601562,\n",
       "          0.00311279],\n",
       "         [0.644531, 0.246094, 0.878906, ..., 0.929688, -0.365234,\n",
       "          0.460938]],\n",
       "\n",
       "        [[-0.0117798, -0.00634766, -0.0349121, ..., -0.0106812,\n",
       "          -0.0512695, 0.0834961],\n",
       "         [-0.0146484, -0.0605469, 0.0200195, ..., -0.0498047,\n",
       "          -0.0378418, -0.0429688],\n",
       "         [-0.0510254, -0.078125, -0.0130615, ..., -0.105469,\n",
       "          -0.0673828, -0.0546875],\n",
       "         ...,\n",
       "         [-0.0678711, -0.0537109, -0.050293, ..., -0.0373535,\n",
       "          -0.0220947, -0.106934],\n",
       "         [-0.0712891, -0.0251465, -0.0108032, ..., 0.0766602,\n",
       "          -0.0195312, 0.0488281],\n",
       "         [-0.0849609, -0.0273438, -0.0402832, ..., -0.0255127,\n",
       "          0.0303955, -0.0534668]]],\n",
       "\n",
       "\n",
       "       [[[-0.0332031, 0.00720215, -0.0375977, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [0.0415039, 0.0196533, -0.0563965, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [0.0834961, -0.0378418, 0.0218506, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         ...,\n",
       "         [0.0649414, 0.0766602, 0.0996094, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [0.112793, 0.108398, 0.118652, ..., 0.18457, 0.18457, 0.18457],\n",
       "         [0.052002, 0.0673828, 0.0397949, ..., 0.18457, 0.18457,\n",
       "          0.18457]],\n",
       "\n",
       "        [[0.0544434, 0.0432129, 0.0649414, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.0227051, 3.19481e-05, 0.0693359, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.203125, -0.000888824, 0.0410156, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         ...,\n",
       "         [0.0534668, 0.0708008, -0.0957031, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.0585938, 0.0177002, 0.0541992, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [-0.00817871, 0.0131226, 0.0371094, ..., -0.0625, -0.0625,\n",
       "          -0.0625]],\n",
       "\n",
       "        [[0.347656, 0.128906, -0.310547, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [0.219727, 0.142578, -0.457031, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [1.01562, -0.322266, -0.359375, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         ...,\n",
       "         [0.28125, 0.193359, 0.371094, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [0.0649414, 0.0263672, 0.326172, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [0.065918, -0.144531, 0.197266, ..., 0.292969, 0.292969,\n",
       "          0.292969]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.249023, -0.251953, -0.298828, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.00775146, -0.193359, -0.380859, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.10498, -0.324219, -0.271484, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         ...,\n",
       "         [0.176758, 0.123535, 0.125977, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.114258, 0.209961, 0.292969, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.111816, 0.0556641, 0.166016, ..., 0.519531, 0.519531,\n",
       "          0.519531]],\n",
       "\n",
       "        [[-1.28906, -0.208008, -0.570312, ..., 0.5, 0.5, 0.5],\n",
       "         [1.16406, -0.369141, 0.335938, ..., 0.5, 0.5, 0.5],\n",
       "         [2.29688, 0.789062, -0.482422, ..., 0.5, 0.5, 0.5],\n",
       "         ...,\n",
       "         [-0.0466309, 0.457031, -0.484375, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.157227, 0.123047, 0.259766, ..., 0.5, 0.5, 0.5],\n",
       "         [0.308594, -0.369141, 0.196289, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "        [[0.0264893, -0.00463867, 0.0140381, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [-0.00106049, -0.0119019, 0.027832, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [-0.0267334, -0.0263672, 0.0776367, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         ...,\n",
       "         [-0.0186768, 0.0649414, -0.0581055, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [-0.00787354, -0.03125, 0.0262451, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [0.0141602, 0.0223389, -0.0272217, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664]]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.91406250e-01, -1.76757812e-01, -1.85546875e-01,  ...,\n",
       "           -1.75781250e-01, -1.74804688e-01, -6.88476562e-02],\n",
       "          [ 1.86157227e-03, -6.78710938e-02, -2.34375000e-01,  ...,\n",
       "           -1.75781250e-01, -1.72851562e-01, -1.70898438e-01],\n",
       "          [ 5.34667969e-02,  1.14257812e-01,  1.19628906e-02,  ...,\n",
       "           -2.03125000e-01, -1.91406250e-01, -1.92382812e-01],\n",
       "          ...,\n",
       "          [ 2.19726562e-02,  6.03027344e-02,  5.56640625e-02,  ...,\n",
       "           -1.35498047e-02, -8.59375000e-02, -1.21582031e-01],\n",
       "          [ 3.46679688e-02,  1.03515625e-01,  3.29589844e-02,  ...,\n",
       "            4.30297852e-03,  1.03759766e-02, -1.11328125e-01],\n",
       "          [ 1.81884766e-02,  1.26953125e-02,  4.82177734e-03,  ...,\n",
       "            4.19921875e-02,  2.41699219e-02, -9.47265625e-02]],\n",
       "\n",
       "         [[ 4.12597656e-02,  3.56445312e-02,  4.44335938e-02,  ...,\n",
       "            3.68652344e-02,  4.10156250e-02,  1.76757812e-01],\n",
       "          [ 1.22070312e-01,  3.73535156e-02,  9.03320312e-02,  ...,\n",
       "            2.91748047e-02,  3.58886719e-02,  6.64062500e-02],\n",
       "          [-2.80761719e-02,  5.34667969e-02, -3.34472656e-02,  ...,\n",
       "            4.56542969e-02,  3.17382812e-02,  1.52587891e-02],\n",
       "          ...,\n",
       "          [-5.66406250e-02,  6.68945312e-02,  3.85742188e-02,  ...,\n",
       "            1.58691406e-02, -2.25830078e-02,  6.22558594e-02],\n",
       "          [ 1.08032227e-02,  4.29687500e-02,  4.95605469e-02,  ...,\n",
       "            6.34765625e-02, -6.10351562e-04,  1.13281250e-01],\n",
       "          [ 4.97436523e-03,  5.68847656e-02, -1.42211914e-02,  ...,\n",
       "           -7.51953125e-02, -6.25610352e-03,  1.15722656e-01]],\n",
       "\n",
       "         [[-9.61914062e-02, -2.87109375e-01, -3.86718750e-01,  ...,\n",
       "           -2.77343750e-01, -2.50000000e-01,  1.39648438e-01],\n",
       "          [ 5.23437500e-01,  1.04980469e-01,  1.62109375e-01,  ...,\n",
       "           -2.42187500e-01, -2.75390625e-01, -2.96875000e-01],\n",
       "          [ 6.34765625e-02, -1.85546875e-02, -2.03125000e-01,  ...,\n",
       "           -3.26171875e-01, -2.48046875e-01, -2.15820312e-01],\n",
       "          ...,\n",
       "          [ 1.22558594e-01, -1.49414062e-01, -9.17968750e-02,  ...,\n",
       "            1.38671875e-01, -4.39453125e-01, -2.73437500e-01],\n",
       "          [ 1.33789062e-01, -1.87500000e-01,  2.22656250e-01,  ...,\n",
       "           -3.35937500e-01,  3.75000000e-01,  3.84765625e-01],\n",
       "          [-3.59375000e-01, -5.27343750e-02, -1.50390625e-01,  ...,\n",
       "            2.02148438e-01,  1.35742188e-01,  2.13867188e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.51171875e-01, -4.10156250e-01, -4.02343750e-01,  ...,\n",
       "           -3.86718750e-01, -3.78906250e-01, -2.24609375e-01],\n",
       "          [ 8.98437500e-02, -1.57226562e-01, -1.81640625e-01,  ...,\n",
       "           -3.84765625e-01, -3.94531250e-01, -4.16015625e-01],\n",
       "          [ 1.35742188e-01,  1.48437500e-01,  1.71875000e-01,  ...,\n",
       "           -5.00000000e-01, -5.03906250e-01, -4.64843750e-01],\n",
       "          ...,\n",
       "          [ 1.11328125e-01, -6.15234375e-02, -2.13867188e-01,  ...,\n",
       "            2.49023438e-01,  1.27929688e-01, -4.19921875e-01],\n",
       "          [-7.08007812e-02, -5.63964844e-02, -1.34765625e-01,  ...,\n",
       "            2.81250000e-01,  2.48046875e-01, -3.78906250e-01],\n",
       "          [-2.67578125e-01, -1.58203125e-01, -4.00390625e-02,  ...,\n",
       "            3.24218750e-01,  2.50000000e-01, -1.04492188e-01]],\n",
       "\n",
       "         [[-1.36718750e-01, -4.27734375e-01, -3.32031250e-01,  ...,\n",
       "           -3.57421875e-01, -3.41796875e-01, -2.20312500e+00],\n",
       "          [ 1.27343750e+00,  7.89062500e-01,  7.46093750e-01,  ...,\n",
       "           -3.55468750e-01, -4.23828125e-01, -5.42968750e-01],\n",
       "          [-4.66308594e-02,  6.21093750e-01,  1.03125000e+00,  ...,\n",
       "           -8.08593750e-01, -5.93750000e-01, -5.03906250e-01],\n",
       "          ...,\n",
       "          [ 7.69531250e-01,  3.82812500e-01, -1.07421875e-01,  ...,\n",
       "            3.61328125e-01,  3.76562500e+00, -3.67187500e-01],\n",
       "          [-2.98828125e-01,  5.93750000e-01,  2.77343750e-01,  ...,\n",
       "            6.73828125e-02,  2.32812500e+00, -3.86718750e-01],\n",
       "          [ 1.20117188e-01,  3.33984375e-01,  7.95898438e-02,  ...,\n",
       "            6.52343750e-01,  1.32812500e+00,  2.50000000e+00]],\n",
       "\n",
       "         [[ 1.12792969e-01,  7.51953125e-02,  6.83593750e-02,  ...,\n",
       "            6.68945312e-02,  6.64062500e-02,  1.06445312e-01],\n",
       "          [ 7.95898438e-02,  1.17675781e-01,  2.28271484e-02,  ...,\n",
       "            5.22460938e-02,  7.03125000e-02,  6.59179688e-02],\n",
       "          [-4.54711914e-03,  3.88183594e-02, -1.81884766e-02,  ...,\n",
       "            6.54296875e-02,  6.73828125e-02,  6.29882812e-02],\n",
       "          ...,\n",
       "          [-1.24511719e-02, -1.27563477e-02,  2.55126953e-02,  ...,\n",
       "           -5.88378906e-02,  3.63769531e-02,  8.49609375e-02],\n",
       "          [-7.42187500e-02, -4.22363281e-02,  9.94873047e-03,  ...,\n",
       "           -1.01562500e-01, -1.19628906e-02,  1.34765625e-01],\n",
       "          [ 4.34570312e-02, -3.95507812e-02, -2.80761719e-02,  ...,\n",
       "           -1.21582031e-01, -5.32226562e-02,  5.68847656e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.34277344e-02, -6.83593750e-02,  3.61328125e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-1.63085938e-01, -1.96289062e-01, -8.34960938e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-2.61718750e-01, -1.38671875e-01, -4.73632812e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          ...,\n",
       "          [-1.51367188e-01, -1.37695312e-01, -4.12597656e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-1.23535156e-01, -3.78417969e-02,  2.19726562e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-1.05957031e-01,  8.78906250e-03, -3.39355469e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01]],\n",
       "\n",
       "         [[ 1.01562500e-01,  1.03515625e-01, -7.86132812e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 4.80957031e-02,  8.54492188e-02, -1.72851562e-01,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [-1.18164062e-01,  9.22851562e-02, -1.62109375e-01,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          ...,\n",
       "          [ 1.17187500e-02,  4.66308594e-02,  3.22265625e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 5.20019531e-02,  3.46679688e-02,  2.07519531e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 8.88671875e-02,  5.54199219e-02, -1.68457031e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02]],\n",
       "\n",
       "         [[-1.00000000e+00, -6.13281250e-01,  7.85156250e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-1.55273438e-01,  2.08740234e-02, -3.49609375e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-6.13403320e-03,  3.59375000e-01, -2.02148438e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          ...,\n",
       "          [-2.07031250e-01, -1.66015625e-01,  1.06933594e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-2.57812500e-01,  4.08203125e-01, -2.81250000e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-1.66015625e-01,  2.41210938e-01, -2.49023438e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.29687500e-01, -4.37500000e-01,  3.69262695e-03,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-4.10156250e-01, -2.67578125e-01, -1.64062500e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-3.37890625e-01, -1.82617188e-01, -1.10351562e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          ...,\n",
       "          [-4.31640625e-01, -4.10156250e-01, -2.44140625e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-3.73046875e-01, -2.11914062e-01, -1.75781250e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-3.14453125e-01, -1.85546875e-01, -2.46093750e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01]],\n",
       "\n",
       "         [[ 4.33593750e-01,  6.75781250e-01, -5.27343750e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 1.43554688e-01, -1.40625000e+00, -9.29687500e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-1.36718750e-02, -1.62500000e+00,  1.01562500e+00,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          ...,\n",
       "          [-4.02343750e-01, -5.11718750e-01, -8.63281250e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-3.20312500e-01, -6.60156250e-01, -9.53125000e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-8.78906250e-01, -1.05468750e+00, -2.07031250e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01]],\n",
       "\n",
       "         [[ 6.15234375e-02,  1.87683105e-03, -6.44531250e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 3.73535156e-02,  5.02929688e-02, -6.54296875e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-6.34765625e-02,  1.53320312e-01, -2.90527344e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          ...,\n",
       "          [ 5.15136719e-02,  6.34765625e-02,  5.68847656e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 5.51757812e-02,  4.24804688e-02,  1.27563477e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 7.66601562e-02,  2.85644531e-02, -4.83398438e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.12304688e-02,  7.27539062e-02,  3.44238281e-02,  ...,\n",
       "            9.52148438e-02,  7.86132812e-02, -4.46777344e-02],\n",
       "          [ 3.51562500e-02,  8.05664062e-03,  1.00585938e-01,  ...,\n",
       "            6.49414062e-02,  1.22070312e-01,  1.22558594e-01],\n",
       "          [-3.68652344e-02, -5.90820312e-02, -3.32031250e-02,  ...,\n",
       "            1.07421875e-01,  1.16699219e-01,  8.54492188e-02],\n",
       "          ...,\n",
       "          [ 8.59375000e-02,  1.30859375e-01,  2.35351562e-01,  ...,\n",
       "            9.08203125e-02,  1.44531250e-01, -1.77001953e-02],\n",
       "          [ 7.22656250e-02,  1.98242188e-01,  1.25976562e-01,  ...,\n",
       "            9.61914062e-02,  5.85937500e-02,  6.49414062e-02],\n",
       "          [ 1.32812500e-01,  2.08007812e-01,  1.58203125e-01,  ...,\n",
       "            5.39550781e-02,  6.93359375e-02,  2.18505859e-02]],\n",
       "\n",
       "         [[ 4.56542969e-02, -2.18505859e-02,  6.78710938e-02,  ...,\n",
       "           -1.60156250e-01, -2.89306641e-02,  1.46484375e-01],\n",
       "          [-3.79943848e-03, -7.17773438e-02, -5.98144531e-02,  ...,\n",
       "           -8.20312500e-02, -9.88769531e-03, -5.20019531e-02],\n",
       "          [ 4.51660156e-02,  3.00598145e-03,  2.33459473e-03,  ...,\n",
       "           -1.39648438e-01,  4.93164062e-02, -2.53906250e-02],\n",
       "          ...,\n",
       "          [-1.72119141e-02, -5.68847656e-02, -8.30078125e-02,  ...,\n",
       "           -9.39941406e-03,  2.72216797e-02, -7.91015625e-02],\n",
       "          [-2.20947266e-02,  6.64062500e-02,  1.38671875e-01,  ...,\n",
       "           -4.00390625e-02,  1.94091797e-02, -4.85229492e-03],\n",
       "          [-1.45507812e-01,  1.90429688e-02, -8.34960938e-02,  ...,\n",
       "            1.35742188e-01, -4.15039062e-02, -3.78417969e-02]],\n",
       "\n",
       "         [[-3.14453125e-01, -3.96484375e-01,  5.54687500e-01,  ...,\n",
       "            4.06250000e-01,  1.44531250e-01,  5.44433594e-02],\n",
       "          [-3.12500000e-01,  3.51562500e-02,  1.06445312e-01,  ...,\n",
       "            1.03149414e-02,  4.41406250e-01,  1.66992188e-01],\n",
       "          [-2.03125000e-01, -1.71875000e-01, -1.98242188e-01,  ...,\n",
       "           -1.25000000e-01,  2.96875000e-01,  1.18164062e-01],\n",
       "          ...,\n",
       "          [ 7.08007812e-02,  9.37500000e-02,  1.53320312e-01,  ...,\n",
       "            3.92578125e-01, -9.08203125e-02,  7.51953125e-02],\n",
       "          [-5.39062500e-01,  3.06640625e-01, -1.01562500e-01,  ...,\n",
       "            1.73828125e-01,  5.31250000e-01,  1.64062500e-01],\n",
       "          [ 5.11718750e-01,  6.17187500e-01,  3.65234375e-01,  ...,\n",
       "            4.25781250e-01,  2.29492188e-01,  1.06933594e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.59765625e-01,  1.56250000e-02,  9.42382812e-02,  ...,\n",
       "            3.65234375e-01,  2.32421875e-01,  1.04492188e-01],\n",
       "          [-1.40625000e-01, -1.56250000e-01, -9.76562500e-02,  ...,\n",
       "            3.22265625e-01,  3.76953125e-01,  2.13867188e-01],\n",
       "          [-3.12500000e-01, -2.87109375e-01, -2.43164062e-01,  ...,\n",
       "            3.30078125e-01,  4.27734375e-01,  3.04687500e-01],\n",
       "          ...,\n",
       "          [ 2.31445312e-01,  4.19921875e-01,  3.57421875e-01,  ...,\n",
       "            1.80664062e-01,  1.15234375e-01,  2.15820312e-01],\n",
       "          [ 2.65625000e-01,  3.78906250e-01,  4.06250000e-01,  ...,\n",
       "            1.47460938e-01,  2.08984375e-01,  2.33398438e-01],\n",
       "          [ 4.57031250e-01,  3.35937500e-01,  3.30078125e-01,  ...,\n",
       "            1.15722656e-01,  6.93359375e-02, -3.41796875e-02]],\n",
       "\n",
       "         [[-5.39062500e-01, -8.71093750e-01,  3.67187500e-01,  ...,\n",
       "            7.17773438e-02,  1.52343750e+00,  3.28125000e+00],\n",
       "          [ 1.41906738e-03, -2.21679688e-01,  1.04492188e-01,  ...,\n",
       "           -6.56250000e-01,  5.93750000e-01,  7.22656250e-01],\n",
       "          [-1.12304688e-01,  1.61132812e-01,  7.51953125e-02,  ...,\n",
       "           -8.90625000e-01,  1.21093750e+00,  1.64843750e+00],\n",
       "          ...,\n",
       "          [ 4.23828125e-01,  7.32421875e-02,  1.30859375e-01,  ...,\n",
       "            2.38281250e-01, -1.01562500e-01,  3.67187500e-01],\n",
       "          [-7.07031250e-01,  5.11718750e-01,  1.00781250e+00,  ...,\n",
       "            8.44726562e-02,  6.01562500e-01,  3.11279297e-03],\n",
       "          [ 6.44531250e-01,  2.46093750e-01,  8.78906250e-01,  ...,\n",
       "            9.29687500e-01, -3.65234375e-01,  4.60937500e-01]],\n",
       "\n",
       "         [[-1.17797852e-02, -6.34765625e-03, -3.49121094e-02,  ...,\n",
       "           -1.06811523e-02, -5.12695312e-02,  8.34960938e-02],\n",
       "          [-1.46484375e-02, -6.05468750e-02,  2.00195312e-02,  ...,\n",
       "           -4.98046875e-02, -3.78417969e-02, -4.29687500e-02],\n",
       "          [-5.10253906e-02, -7.81250000e-02, -1.30615234e-02,  ...,\n",
       "           -1.05468750e-01, -6.73828125e-02, -5.46875000e-02],\n",
       "          ...,\n",
       "          [-6.78710938e-02, -5.37109375e-02, -5.02929688e-02,  ...,\n",
       "           -3.73535156e-02, -2.20947266e-02, -1.06933594e-01],\n",
       "          [-7.12890625e-02, -2.51464844e-02, -1.08032227e-02,  ...,\n",
       "            7.66601562e-02, -1.95312500e-02,  4.88281250e-02],\n",
       "          [-8.49609375e-02, -2.73437500e-02, -4.02832031e-02,  ...,\n",
       "           -2.55126953e-02,  3.03955078e-02, -5.34667969e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.32031250e-02,  7.20214844e-03, -3.75976562e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 4.15039062e-02,  1.96533203e-02, -5.63964844e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 8.34960938e-02, -3.78417969e-02,  2.18505859e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          ...,\n",
       "          [ 6.49414062e-02,  7.66601562e-02,  9.96093750e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 1.12792969e-01,  1.08398438e-01,  1.18652344e-01,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 5.20019531e-02,  6.73828125e-02,  3.97949219e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01]],\n",
       "\n",
       "         [[ 5.44433594e-02,  4.32128906e-02,  6.49414062e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 2.27050781e-02,  3.19480896e-05,  6.93359375e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 2.03125000e-01, -8.88824463e-04,  4.10156250e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          ...,\n",
       "          [ 5.34667969e-02,  7.08007812e-02, -9.57031250e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 5.85937500e-02,  1.77001953e-02,  5.41992188e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [-8.17871094e-03,  1.31225586e-02,  3.71093750e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02]],\n",
       "\n",
       "         [[ 3.47656250e-01,  1.28906250e-01, -3.10546875e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 2.19726562e-01,  1.42578125e-01, -4.57031250e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 1.01562500e+00, -3.22265625e-01, -3.59375000e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          ...,\n",
       "          [ 2.81250000e-01,  1.93359375e-01,  3.71093750e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 6.49414062e-02,  2.63671875e-02,  3.26171875e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 6.59179688e-02, -1.44531250e-01,  1.97265625e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.49023438e-01, -2.51953125e-01, -2.98828125e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 7.75146484e-03, -1.93359375e-01, -3.80859375e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 1.04980469e-01, -3.24218750e-01, -2.71484375e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          ...,\n",
       "          [ 1.76757812e-01,  1.23535156e-01,  1.25976562e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 1.14257812e-01,  2.09960938e-01,  2.92968750e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 1.11816406e-01,  5.56640625e-02,  1.66015625e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01]],\n",
       "\n",
       "         [[-1.28906250e+00, -2.08007812e-01, -5.70312500e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 1.16406250e+00, -3.69140625e-01,  3.35937500e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 2.29687500e+00,  7.89062500e-01, -4.82421875e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          ...,\n",
       "          [-4.66308594e-02,  4.57031250e-01, -4.84375000e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-1.57226562e-01,  1.23046875e-01,  2.59765625e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 3.08593750e-01, -3.69140625e-01,  1.96289062e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01]],\n",
       "\n",
       "         [[ 2.64892578e-02, -4.63867188e-03,  1.40380859e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-1.06048584e-03, -1.19018555e-02,  2.78320312e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-2.67333984e-02, -2.63671875e-02,  7.76367188e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          ...,\n",
       "          [-1.86767578e-02,  6.49414062e-02, -5.81054688e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-7.87353516e-03, -3.12500000e-02,  2.62451172e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 1.41601562e-02,  2.23388672e-02, -2.72216797e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02]]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.5507771, 1.477785 , 1.4047928, 1.3172023, 1.2442101, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.5215802, 1.4631865, 1.3901944, 1.3172023, 1.2442101, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.5069818, 1.4339896, 1.3609976, 1.2880055, 1.2296118, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.477785 , 1.3901944, 1.3172023, 1.2442101, 1.2150133, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.4047928, 1.3463992, 1.3026038, 1.2442101, 1.2150133, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.3318007, 1.3026038, 1.2880055, 1.273407 , 1.273407 , 1.2588086,\n",
       "        1.2588086, 1.2588086, 1.2880055, 1.2880055],\n",
       "       [1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.273407 ,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055],\n",
       "       [1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.273407 ,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055],\n",
       "       [1.2296118, 1.2588086, 1.2880055, 1.3026038, 1.3026038, 1.2880055,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055],\n",
       "       [1.1858164, 1.2150133, 1.2588086, 1.273407 , 1.273407 , 1.273407 ,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_jax.pixel_values[0,0,0,0,:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_modules at 0x7ef9b8d478b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch.named_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43moutput_torch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:, :, :, \u001b[38;5;241m0\u001b[39m, i:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10\u001b[39m)]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "output_torch['last_hidden_state'][:, :, :, 0, i:(i+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[5.65625, -5.25, -5.375, 5.8125, 4.90625, -4.21875, 1.55469,\n",
       "          -3.15625, 0.984375, 3.90625],\n",
       "         [6.34375, -3.03125, -6.4375, 6.03125, 7.8125, -3.59375,\n",
       "          2.48438, -7.15625, -0.753906, 4.1875],\n",
       "         [14, -4.09375, -7.625, 2.76562, 11.8125, -10.5, 0.722656,\n",
       "          -6.59375, 0.808594, 5.59375],\n",
       "         [4.21875, 3.5, -2.51562, -3.89062, -1.25, 0.566406, 4.65625,\n",
       "          2.09375, 8.8125, 4.5625]]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax1['last_hidden_state'][:, :, :, 0, i:(i+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[5.65625, -5.25, -5.375, 5.8125, 4.90625, -4.21875, 1.55469,\n",
       "          -3.15625, 0.984375, 3.90625],\n",
       "         [6.34375, -3.03125, -6.4375, 6.03125, 7.8125, -3.59375,\n",
       "          2.48438, -7.15625, -0.753906, 4.1875],\n",
       "         [14, -4.09375, -7.625, 2.76562, 11.8125, -10.5, 0.722656,\n",
       "          -6.59375, 0.808594, 5.59375],\n",
       "         [4.21875, 3.5, -2.51562, -3.89062, -1.25, 0.566406, 4.65625,\n",
       "          2.09375, 8.8125, 4.5625]]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax2['last_hidden_state'][:, :, :, 0, i:(i+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import tree_util\n",
    "\n",
    "def print_detailed_info(name, param):\n",
    "    print(f\"{name}   {param.shape}; {param.dtype}\")\n",
    "\n",
    "tree_util.tree_map_with_path(\n",
    "    lambda path, x: print_detailed_info(\"\".join(str(p) for p in path), x),\n",
    "    model.params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_torch.named_parameters():\n",
    "    print(f\"[\\\"{name}\\\"]   {param.shape}; {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch.state_dict()[\"transformer.layers.31.self_attn.q_proj.weight\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params['vision_model']['transformer']['layers.31']['self_attn']['q_proj']['kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_jax['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_jax['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
