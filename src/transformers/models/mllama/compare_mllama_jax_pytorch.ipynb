{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `SDPA` attention implementation on multi-gpu setup with ROCM may lead to performance issues due to the FA backend. Disabling it to use alternative backends.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:00<00:00,  6.06it/s]\n",
      "E1125 20:16:02.935544 1348778 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1125 20:16:02.935582 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.935586 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.935588 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:02.935591 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.935683 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.935686 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.935688 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.935691 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:02.935693 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-25 20:16:02.935705: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.937968 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.937981 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.937983 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.937986 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.937988 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.938080 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.938083 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.938086 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.938088 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.938090 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-25 20:16:02.938096: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.940708 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.940720 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.940723 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.940725 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.940728 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:02.940730 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.940732 1348778 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1125 20:16:02.940734 1348778 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1125 20:16:02.940826 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.940829 1348778 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-25 20:16:02.940833: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.943207 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.943218 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.943221 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.943223 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.943226 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.943317 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.943320 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.943323 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.943325 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.943327 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-25 20:16:02.943331: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.945969 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.945980 1348778 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1125 20:16:02.945983 1348778 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1125 20:16:02.945986 1348778 buffer_comparator.cc:157] Difference at 20665: -inf, expected -2.76479e+38\n",
      "E1125 20:16:02.945988 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.945991 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:02.945993 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.945996 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:02.946088 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.946092 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "2024-11-25 20:16:02.946096: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.948563 1348778 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1125 20:16:02.948574 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.948577 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.948579 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:02.948581 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.948673 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.948676 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.948679 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.948681 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:02.948683 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-25 20:16:02.948687: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.951700 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.951711 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.951714 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.951716 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.951718 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:02.951721 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.951723 1348778 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1125 20:16:02.951725 1348778 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1125 20:16:02.951816 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.951820 1348778 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-25 20:16:02.951824: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.954246 1348778 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1125 20:16:02.954258 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.954260 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.954262 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:02.954264 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.954379 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.954383 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.954385 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.954388 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:02.954390 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-25 20:16:02.954393: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.956599 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.956610 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.956613 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.956615 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.956618 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.956709 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.956713 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.956715 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.956717 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.956719 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-25 20:16:02.956723: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.959317 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.959330 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.959333 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.959335 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.959337 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:02.959340 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.959342 1348778 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1125 20:16:02.959344 1348778 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1125 20:16:02.959435 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.959438 1348778 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-25 20:16:02.959442: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.961815 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.961825 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.961827 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.961830 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.961832 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.961924 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.961927 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.961929 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.961931 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.961933 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "2024-11-25 20:16:02.961937: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.964597 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.964609 1348778 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1125 20:16:02.964612 1348778 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1125 20:16:02.964615 1348778 buffer_comparator.cc:157] Difference at 20665: -inf, expected -2.76479e+38\n",
      "E1125 20:16:02.964617 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.964619 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:02.964621 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.964624 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:02.964716 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.964719 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "2024-11-25 20:16:02.964724: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.967205 1348778 buffer_comparator.cc:157] Difference at 19685: -inf, expected -2.88442e+38\n",
      "E1125 20:16:02.967216 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.967219 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.967221 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:02.967223 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.967315 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.967318 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.967321 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:02.967323 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:02.967325 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "2024-11-25 20:16:02.967329: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.970335 1348778 buffer_comparator.cc:157] Difference at 19473: -inf, expected -3.01735e+38\n",
      "E1125 20:16:02.970355 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.970358 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.970360 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.970364 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:02.970366 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.970369 1348778 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1125 20:16:02.970371 1348778 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1125 20:16:02.970462 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:02.970465 1348778 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "2024-11-25 20:16:02.970469: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.972087 1348778 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1125 20:16:02.972095 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.972098 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.972101 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:02.972192 1348778 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1125 20:16:02.972195 1348778 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1125 20:16:02.972198 1348778 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1125 20:16:02.972200 1348778 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "E1125 20:16:02.972202 1348778 buffer_comparator.cc:157] Difference at 83353: inf, expected 4.38645e+37\n",
      "E1125 20:16:02.972204 1348778 buffer_comparator.cc:157] Difference at 83361: 9.03875e+37, expected inf\n",
      "2024-11-25 20:16:02.972208: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.973823 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.973831 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.973834 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:02.973836 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.973928 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1125 20:16:02.973931 1348778 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1125 20:16:02.973933 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.973935 1348778 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1125 20:16:02.973937 1348778 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1125 20:16:02.973940 1348778 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-25 20:16:02.973944: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.975571 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.975581 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.975584 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:02.975586 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.975678 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.975683 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:02.975685 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:02.975688 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "E1125 20:16:02.975690 1348778 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1125 20:16:02.975692 1348778 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "2024-11-25 20:16:02.975695: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.977346 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.977353 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.977356 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:02.977358 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.977450 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1125 20:16:02.977453 1348778 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1125 20:16:02.977455 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.977457 1348778 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1125 20:16:02.977459 1348778 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1125 20:16:02.977462 1348778 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-25 20:16:02.977465: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.979091 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.979101 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.979103 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:02.979105 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.979197 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1125 20:16:02.979200 1348778 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1125 20:16:02.979202 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.979204 1348778 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1125 20:16:02.979206 1348778 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1125 20:16:02.979208 1348778 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-25 20:16:02.979212: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.980836 1348778 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1125 20:16:02.980845 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.980848 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.980851 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:02.980942 1348778 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1125 20:16:02.980945 1348778 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1125 20:16:02.980947 1348778 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1125 20:16:02.980949 1348778 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "E1125 20:16:02.980951 1348778 buffer_comparator.cc:157] Difference at 83353: inf, expected 4.38645e+37\n",
      "E1125 20:16:02.980954 1348778 buffer_comparator.cc:157] Difference at 83361: 9.03875e+37, expected inf\n",
      "2024-11-25 20:16:02.980957: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.982569 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.982578 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.982580 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:02.982583 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.982674 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1125 20:16:02.982678 1348778 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1125 20:16:02.982680 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.982682 1348778 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1125 20:16:02.982684 1348778 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1125 20:16:02.982686 1348778 buffer_comparator.cc:157] Difference at 83405: inf, expected 2.31286e+38\n",
      "2024-11-25 20:16:02.982690: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.984476 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.984484 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.984486 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.984490 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:02.984581 1348778 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.984584 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.984586 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:02.984588 1348778 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1125 20:16:02.984590 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1125 20:16:02.984592 1348778 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-25 20:16:02.984596: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.986269 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.986277 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.986280 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.986380 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.986384 1348778 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.986386 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:02.986388 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.986390 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:02.986392 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:02.986394 1348778 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "2024-11-25 20:16:02.986398: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.988196 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.988204 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.988207 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.988210 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:02.988302 1348778 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.988305 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.988307 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:02.988309 1348778 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1125 20:16:02.988311 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1125 20:16:02.988314 1348778 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-25 20:16:02.988318: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.990088 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.990096 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.990099 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:02.990101 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.990193 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1125 20:16:02.990196 1348778 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1125 20:16:02.990198 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.990200 1348778 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1125 20:16:02.990202 1348778 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1125 20:16:02.990204 1348778 buffer_comparator.cc:157] Difference at 83305: inf, expected 2.03372e+38\n",
      "2024-11-25 20:16:02.990208: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.991889 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:02.991899 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.991901 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:02.991904 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.991996 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1125 20:16:02.991999 1348778 buffer_comparator.cc:157] Difference at 83281: -inf, expected 3.90461e+37\n",
      "E1125 20:16:02.992001 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.992003 1348778 buffer_comparator.cc:157] Difference at 83289: -inf, expected -1.74129e+38\n",
      "E1125 20:16:02.992005 1348778 buffer_comparator.cc:157] Difference at 83301: -inf, expected -2.48566e+38\n",
      "E1125 20:16:02.992007 1348778 buffer_comparator.cc:157] Difference at 83305: inf, expected 2.03372e+38\n",
      "2024-11-25 20:16:02.992011: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.993641 1348778 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1125 20:16:02.993651 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.993653 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.993656 1348778 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1125 20:16:02.993659 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:02.993750 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.993753 1348778 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1125 20:16:02.993755 1348778 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1125 20:16:02.993757 1348778 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1125 20:16:02.993759 1348778 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "2024-11-25 20:16:02.993764: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.995375 1348778 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1125 20:16:02.995384 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.995386 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.995389 1348778 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1125 20:16:02.995392 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:02.995483 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.995486 1348778 buffer_comparator.cc:157] Difference at 83329: -9.70336e+37, expected -inf\n",
      "E1125 20:16:02.995488 1348778 buffer_comparator.cc:157] Difference at 83335: -inf, expected -2.56541e+38\n",
      "E1125 20:16:02.995490 1348778 buffer_comparator.cc:157] Difference at 83345: -inf, expected -2.41919e+38\n",
      "E1125 20:16:02.995493 1348778 buffer_comparator.cc:157] Difference at 83347: 1.43557e+38, expected inf\n",
      "2024-11-25 20:16:02.995496: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.997073 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.997082 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.997084 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:02.997086 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.997089 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:02.997180 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.997184 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.997186 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:02.997188 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:02.997191 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:02.997194: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:02.998749 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:02.998759 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:02.998762 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:02.998764 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:02.998856 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:02.998859 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:02.998862 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:02.998864 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:02.998867 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:02.998869 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:02.998872: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.000409 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.000417 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.000419 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.000422 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.000425 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.000516 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.000519 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.000521 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.000523 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.000526 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.000530: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.002110 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.002118 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.002121 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.002123 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.002126 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.002217 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.002220 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.002223 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.002225 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.002227 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.002231: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.003776 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.003785 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.003787 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.003790 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.003793 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.003884 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.003887 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.003889 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.003891 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.003893 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.003897: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.005446 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.005455 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.005457 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.005460 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.005462 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.005553 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.005557 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.005559 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.005561 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.005563 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.005567: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.007151 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.007160 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.007163 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.007165 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.007257 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.007260 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.007262 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.007264 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.007266 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.007269 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.007272: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.008814 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.008822 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.008824 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.008827 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.008829 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.008920 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.008924 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.008926 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.008928 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.008930 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.008934: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.010523 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.010534 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.010537 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.010539 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.010630 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.010634 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.010636 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.010638 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.010640 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.010642 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.010646: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.012225 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.012235 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.012237 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.012240 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.012242 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.012333 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.012337 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.012339 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.012341 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.012343 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.012347: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.013926 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.013934 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.013937 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.013939 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.013942 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.014033 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.014036 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.014039 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.014041 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.014043 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.014047: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.015636 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.015644 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.015647 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.015649 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.015652 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.015743 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.015746 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.015748 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.015751 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.015753 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.015757: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.017292 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.017301 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.017304 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.017306 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.017309 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.017400 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.017403 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.017405 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.017407 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.017410 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.017413: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.019014 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.019023 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.019026 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.019028 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.019120 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.019124 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.019126 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.019128 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.019130 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.019132 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.019136: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.020678 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.020686 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.020688 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.020690 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.020693 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.020784 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.020787 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.020790 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.020792 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.020794 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.020797: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.022387 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.022396 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.022398 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.022401 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.022405 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.022496 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.022499 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.022501 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.022503 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.022505 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.022511: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.024058 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.024066 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.024069 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.024071 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.024163 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.024166 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.024168 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.024170 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.024173 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.024175 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.024179: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.025756 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.025764 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.025766 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.025769 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.025860 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.025863 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.025865 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.025868 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.025870 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.025872 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.025875: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.027461 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.027469 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.027472 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.027474 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.027565 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.027569 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.027571 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.027573 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.027576 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.027578 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.027582: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.029163 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.029172 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.029175 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.029177 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.029269 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.029272 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.029274 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.029277 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.029279 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.029281 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.029285: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.030885 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.030895 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.030898 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.030900 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.030903 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.030995 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.030998 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.031000 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.031003 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.031006 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.031009: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.032610 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.032618 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.032621 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.032623 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.032626 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.032717 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.032720 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.032723 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.032725 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.032727 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.032730: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.034320 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.034329 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.034332 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.034335 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.034433 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.034437 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.034439 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.034441 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.034444 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.034446 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.034450: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.036050 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.036058 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.036061 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.036063 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.036155 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.036158 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.036160 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.036162 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.036164 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.036166 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.036170: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.037773 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.037783 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.037785 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.037788 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.037790 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.037881 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.037884 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.037886 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.037889 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.037891 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.037894: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.039502 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.039511 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.039514 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.039516 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.039519 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.039610 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.039613 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.039615 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.039617 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.039619 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.039623: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.041211 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.041220 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.041223 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.041225 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.041228 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.041319 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.041323 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.041325 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.041327 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.041329 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.041332: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.044251 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.044351 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.044355 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.044357 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.044360 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.044362 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.044364 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.044367 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.044369 1348778 buffer_comparator.cc:157] Difference at 83723: -inf, expected -2.76479e+38\n",
      "E1125 20:16:03.044371 1348778 buffer_comparator.cc:157] Difference at 83777: -2.32615e+38, expected -inf\n",
      "2024-11-25 20:16:03.044375: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.046031 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.046038 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.046041 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.046044 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.046136 1348778 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.046140 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.046142 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.046144 1348778 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1125 20:16:03.046146 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1125 20:16:03.046148 1348778 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-25 20:16:03.046153: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.047815 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.047824 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.047827 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.047830 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.047922 1348778 buffer_comparator.cc:157] Difference at 83381: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.047925 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.047927 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.047929 1348778 buffer_comparator.cc:157] Difference at 83427: -inf, expected -2.25969e+38\n",
      "E1125 20:16:03.047931 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "E1125 20:16:03.047934 1348778 buffer_comparator.cc:157] Difference at 83443: inf, expected 3.0971e+38\n",
      "2024-11-25 20:16:03.047937: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.049590 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.049599 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.049601 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.049604 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.049697 1348778 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1125 20:16:03.049700 1348778 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1125 20:16:03.049703 1348778 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "E1125 20:16:03.049705 1348778 buffer_comparator.cc:157] Difference at 83911: inf, expected 3.36295e+38\n",
      "E1125 20:16:03.049707 1348778 buffer_comparator.cc:157] Difference at 83917: 2.65846e+38, expected inf\n",
      "E1125 20:16:03.049709 1348778 buffer_comparator.cc:157] Difference at 83925: 2.44578e+38, expected inf\n",
      "2024-11-25 20:16:03.049713: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.051318 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.051327 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.051329 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.051332 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.051425 1348778 buffer_comparator.cc:157] Difference at 83521: -inf, expected -2.28627e+38\n",
      "E1125 20:16:03.051428 1348778 buffer_comparator.cc:157] Difference at 83535: inf, expected 2.68504e+38\n",
      "E1125 20:16:03.051430 1348778 buffer_comparator.cc:157] Difference at 83565: 1.22289e+38, expected inf\n",
      "E1125 20:16:03.051432 1348778 buffer_comparator.cc:157] Difference at 83585: -inf, expected inf\n",
      "E1125 20:16:03.051434 1348778 buffer_comparator.cc:157] Difference at 83593: -2.87113e+38, expected -inf\n",
      "E1125 20:16:03.051436 1348778 buffer_comparator.cc:157] Difference at 83605: inf, expected 2.45907e+38\n",
      "2024-11-25 20:16:03.051440: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.053272 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.053283 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.053285 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.053288 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.053379 1348778 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1125 20:16:03.053382 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.053384 1348778 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1125 20:16:03.053386 1348778 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1125 20:16:03.053389 1348778 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1125 20:16:03.053391 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-25 20:16:03.053394: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.055229 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.055239 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.055242 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.055244 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.055337 1348778 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1125 20:16:03.055340 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.055342 1348778 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1125 20:16:03.055344 1348778 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1125 20:16:03.055346 1348778 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1125 20:16:03.055348 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-25 20:16:03.055352: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.057185 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.057193 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.057195 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.057197 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.057289 1348778 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1125 20:16:03.057292 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.057294 1348778 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1125 20:16:03.057296 1348778 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1125 20:16:03.057298 1348778 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1125 20:16:03.057300 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-25 20:16:03.057304: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.059156 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.059166 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.059168 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.059171 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.059262 1348778 buffer_comparator.cc:157] Difference at 83213: -inf, expected -1.15643e+38\n",
      "E1125 20:16:03.059265 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.059267 1348778 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1125 20:16:03.059270 1348778 buffer_comparator.cc:157] Difference at 83255: inf, expected 8.39075e+36\n",
      "E1125 20:16:03.059272 1348778 buffer_comparator.cc:157] Difference at 83257: -inf, expected 2.2331e+38\n",
      "E1125 20:16:03.059274 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "2024-11-25 20:16:03.059277: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.060856 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.060864 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.060867 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:03.060869 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.060961 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.060964 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:03.060966 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.060968 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.060971 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.060973 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-25 20:16:03.060976: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.062553 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.062563 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.062566 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:03.062568 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.062660 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.062663 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:03.062666 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.062668 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.062670 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.062672 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-25 20:16:03.062675: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.064248 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.064257 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.064259 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:03.064261 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.064354 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.064357 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:03.064359 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.064361 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.064363 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.064365 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-25 20:16:03.064369: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.065942 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.065950 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.065952 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:03.065955 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.066047 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.066051 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:03.066053 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.066055 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.066057 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.066059 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-25 20:16:03.066062: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.067789 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.067798 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.067800 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.067803 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.067894 1348778 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1125 20:16:03.067897 1348778 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1125 20:16:03.067900 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.067902 1348778 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1125 20:16:03.067904 1348778 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1125 20:16:03.067906 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-25 20:16:03.067910: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.069730 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.069739 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.069742 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.069744 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.069747 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.069749 1348778 buffer_comparator.cc:157] Difference at 21477: -inf, expected -2.81796e+38\n",
      "E1125 20:16:03.069752 1348778 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1125 20:16:03.069843 1348778 buffer_comparator.cc:157] Difference at 83251: -inf, expected 3.43938e+37\n",
      "E1125 20:16:03.069846 1348778 buffer_comparator.cc:157] Difference at 83267: 2.04701e+38, expected inf\n",
      "E1125 20:16:03.069849 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "2024-11-25 20:16:03.069852: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.071572 1348778 buffer_comparator.cc:157] Difference at 20111: -inf, expected -3.08381e+38\n",
      "E1125 20:16:03.071581 1348778 buffer_comparator.cc:157] Difference at 20665: -inf, expected -2.76479e+38\n",
      "E1125 20:16:03.071583 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.071586 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:03.071588 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.071590 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.071593 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.071684 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.071687 1348778 buffer_comparator.cc:157] Difference at 83325: inf, expected 6.18091e+37\n",
      "E1125 20:16:03.071689 1348778 buffer_comparator.cc:157] Difference at 83327: inf, expected 3.04393e+38\n",
      "2024-11-25 20:16:03.071693: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.073318 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.073327 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.073330 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.073332 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.073424 1348778 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1125 20:16:03.073427 1348778 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1125 20:16:03.073429 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.073431 1348778 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1125 20:16:03.073434 1348778 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1125 20:16:03.073436 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-25 20:16:03.073439: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.075159 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.075168 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.075170 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:03.075172 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.075265 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.075269 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:03.075271 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.075273 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.075275 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.075277 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-25 20:16:03.075281: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.076906 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.076914 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.076916 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.076919 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.076922 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.077013 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.077016 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.077018 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.077021 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.077023 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.077027: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.078648 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.078656 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.078658 1348778 buffer_comparator.cc:157] Difference at 20965: -inf, expected -3.04393e+38\n",
      "E1125 20:16:03.078661 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.078753 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.078756 1348778 buffer_comparator.cc:157] Difference at 83399: 2.21981e+38, expected inf\n",
      "E1125 20:16:03.078759 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.078761 1348778 buffer_comparator.cc:157] Difference at 83411: -inf, expected -2.19323e+38\n",
      "E1125 20:16:03.078763 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.078765 1348778 buffer_comparator.cc:157] Difference at 83435: -inf, expected 1.01686e+38\n",
      "2024-11-25 20:16:03.078769: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.080363 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.080372 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.080374 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.080377 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.080379 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.080470 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.080473 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.080475 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.080478 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.080480 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.080483: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.082037 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.082045 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.082047 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.082050 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.082052 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.082143 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.082146 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.082149 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.082151 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.082153 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.082157: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.083718 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.083726 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.083729 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.083731 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.083734 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.083825 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.083828 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.083831 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.083833 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.083835 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.083839: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.085549 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.085558 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.085561 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.085563 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.085654 1348778 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1125 20:16:03.085658 1348778 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1125 20:16:03.085660 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.085662 1348778 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1125 20:16:03.085664 1348778 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1125 20:16:03.085666 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-25 20:16:03.085670: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.087413 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.087423 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.087426 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.087428 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.087520 1348778 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1125 20:16:03.087523 1348778 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1125 20:16:03.087525 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.087527 1348778 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1125 20:16:03.087530 1348778 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1125 20:16:03.087532 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-25 20:16:03.087536: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.089133 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.089142 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.089144 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.089147 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.089238 1348778 buffer_comparator.cc:157] Difference at 83215: -inf, expected -9.03875e+37\n",
      "E1125 20:16:03.089242 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.089244 1348778 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1125 20:16:03.089246 1348778 buffer_comparator.cc:157] Difference at 83247: -inf, expected -1.14978e+38\n",
      "E1125 20:16:03.089248 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.089250 1348778 buffer_comparator.cc:157] Difference at 83291: 4.85168e+37, expected inf\n",
      "2024-11-25 20:16:03.089254: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.090858 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.090867 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.090869 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.090871 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.090958 1348778 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1125 20:16:03.090961 1348778 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1125 20:16:03.090963 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.090965 1348778 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1125 20:16:03.090968 1348778 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1125 20:16:03.090970 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-25 20:16:03.090973: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.092562 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.092570 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.092572 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.092575 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.092666 1348778 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1125 20:16:03.092669 1348778 buffer_comparator.cc:157] Difference at 83213: nan, expected -1.15643e+38\n",
      "E1125 20:16:03.092671 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.092673 1348778 buffer_comparator.cc:157] Difference at 83227: inf, expected -1.50203e+38\n",
      "E1125 20:16:03.092676 1348778 buffer_comparator.cc:157] Difference at 83229: -inf, expected -2.90769e+37\n",
      "E1125 20:16:03.092678 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "2024-11-25 20:16:03.092682: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.094297 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.094307 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.094309 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.094312 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.094413 1348778 buffer_comparator.cc:157] Difference at 83205: -inf, expected -2.83126e+38\n",
      "E1125 20:16:03.094416 1348778 buffer_comparator.cc:157] Difference at 83213: inf, expected -1.15643e+38\n",
      "E1125 20:16:03.094418 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.094421 1348778 buffer_comparator.cc:157] Difference at 83233: inf, expected 3.12369e+38\n",
      "E1125 20:16:03.094423 1348778 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1125 20:16:03.094425 1348778 buffer_comparator.cc:157] Difference at 83259: inf, expected 1.7147e+38\n",
      "2024-11-25 20:16:03.094429: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.096029 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.096038 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.096040 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.096042 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.096129 1348778 buffer_comparator.cc:157] Difference at 83215: -inf, expected -9.03875e+37\n",
      "E1125 20:16:03.096132 1348778 buffer_comparator.cc:157] Difference at 83217: 1.75458e+38, expected inf\n",
      "E1125 20:16:03.096134 1348778 buffer_comparator.cc:157] Difference at 83245: -6.31383e+37, expected -inf\n",
      "E1125 20:16:03.096137 1348778 buffer_comparator.cc:157] Difference at 83247: -inf, expected -1.14978e+38\n",
      "E1125 20:16:03.096139 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.096141 1348778 buffer_comparator.cc:157] Difference at 83291: 4.85168e+37, expected inf\n",
      "2024-11-25 20:16:03.096145: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.097708 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.097717 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.097719 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.097722 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.097813 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.097817 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.097819 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.097821 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.097824 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.097826 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.097830: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.099410 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.099418 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.099421 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.099423 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.099426 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.099517 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.099521 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.099523 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.099525 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.099527 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.099531: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.101107 1348778 buffer_comparator.cc:157] Difference at 20777: -inf, expected -3.37624e+38\n",
      "E1125 20:16:03.101117 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.101119 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.101122 1348778 buffer_comparator.cc:157] Difference at 21183: -3.38953e+38, expected -inf\n",
      "E1125 20:16:03.101125 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.101216 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.101219 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.101221 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.101223 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.101226 1348778 buffer_comparator.cc:157] Difference at 83585: -inf, expected inf\n",
      "2024-11-25 20:16:03.101229: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.102779 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.102789 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.102791 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.102794 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.102880 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.102883 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.102886 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.102888 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.102890 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.102892 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.102896: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.104440 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.104448 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.104451 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.104453 1348778 buffer_comparator.cc:157] Difference at 21637: -inf, expected -3.11039e+38\n",
      "E1125 20:16:03.104545 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.104548 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.104550 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.104552 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.104554 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "E1125 20:16:03.104557 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "2024-11-25 20:16:03.104560: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.106150 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.106160 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.106162 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.106249 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.106253 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.106255 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.106258 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "E1125 20:16:03.106260 1348778 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1125 20:16:03.106263 1348778 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1125 20:16:03.106265 1348778 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "2024-11-25 20:16:03.106270: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.107851 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.107860 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.107862 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.107864 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.107867 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.107869 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.107957 1348778 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1125 20:16:03.107960 1348778 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1125 20:16:03.107962 1348778 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "E1125 20:16:03.107964 1348778 buffer_comparator.cc:157] Difference at 83911: inf, expected 3.36295e+38\n",
      "2024-11-25 20:16:03.107968: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.109574 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.109583 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.109585 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.109588 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.109590 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.109682 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.109685 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.109687 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.109689 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.109692 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.109695: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.117590 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.117605 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.117608 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.117611 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.117614 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.117705 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.117708 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.117710 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.117713 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.117715 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.117719: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.119353 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.119364 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.119366 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.119369 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.119371 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.119463 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.119466 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.119468 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.119471 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.119474 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.119477: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.121081 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.121090 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.121092 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.121095 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.121098 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.121189 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.121192 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.121194 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.121196 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.121198 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.121203: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.122807 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.122817 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.122820 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.122822 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.122825 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.122916 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.122919 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.122921 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.122923 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.122926 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.122929: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.124529 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.124539 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.124541 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.124543 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.124546 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.124637 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.124640 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.124643 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.124645 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.124647 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.124651: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.126249 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.126259 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.126262 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.126264 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.126267 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.126366 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.126370 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.126372 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.126375 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.126378 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.126381: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.127978 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.127987 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.127989 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.127992 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.127994 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.128086 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.128089 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.128092 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.128094 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.128096 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.128101: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.129692 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.129701 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.129703 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.129706 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.129708 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.129799 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.129802 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.129804 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.129807 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.129809 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.129812: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.131417 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.131428 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.131431 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.131433 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.131436 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.131527 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.131530 1348778 buffer_comparator.cc:157] Difference at 83401: 2.20652e+38, expected inf\n",
      "E1125 20:16:03.131532 1348778 buffer_comparator.cc:157] Difference at 83417: -inf, expected -2.77809e+38\n",
      "E1125 20:16:03.131535 1348778 buffer_comparator.cc:157] Difference at 83539: -3.23002e+38, expected -inf\n",
      "E1125 20:16:03.131537 1348778 buffer_comparator.cc:157] Difference at 83591: inf, expected 5.74891e+37\n",
      "2024-11-25 20:16:03.131541: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.133154 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.133163 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.133166 1348778 buffer_comparator.cc:157] Difference at 21523: inf, expected 3.24332e+38\n",
      "E1125 20:16:03.133258 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.133262 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.133264 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.133267 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "E1125 20:16:03.133269 1348778 buffer_comparator.cc:157] Difference at 83843: -inf, expected -1.28935e+38\n",
      "E1125 20:16:03.133272 1348778 buffer_comparator.cc:157] Difference at 83861: -inf, expected 9.03875e+37\n",
      "E1125 20:16:03.133274 1348778 buffer_comparator.cc:157] Difference at 83877: -inf, expected -1.65489e+38\n",
      "2024-11-25 20:16:03.133278: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.134892 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.134902 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.134904 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.134907 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.134910 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.134912 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.135003 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.135008 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.135010 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.135013 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-25 20:16:03.135017: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.136626 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.136636 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.136639 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.136641 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.136644 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.136647 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.136738 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.136742 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.136744 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.136746 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-25 20:16:03.136750: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.138367 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.138379 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.138381 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.138384 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.138386 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.138389 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.138479 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.138483 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.138485 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.138487 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-25 20:16:03.138491: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.140100 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.140110 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.140112 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.140114 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.140117 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.140119 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.140210 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.140213 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.140215 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.140217 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-25 20:16:03.140221: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.141832 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.141842 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.141844 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.141846 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.141849 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.141851 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.141942 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.141946 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.141948 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.141950 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-25 20:16:03.141954: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.143565 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.143575 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.143578 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.143580 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.143582 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.143585 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.143676 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.143680 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.143682 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.143684 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-25 20:16:03.143689: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n",
      "E1125 20:16:03.145294 1348778 buffer_comparator.cc:157] Difference at 20867: 2.96418e+38, expected inf\n",
      "E1125 20:16:03.145303 1348778 buffer_comparator.cc:157] Difference at 21049: 2.89772e+38, expected inf\n",
      "E1125 20:16:03.145305 1348778 buffer_comparator.cc:157] Difference at 21093: -inf, expected -2.71163e+38\n",
      "E1125 20:16:03.145307 1348778 buffer_comparator.cc:157] Difference at 21139: -inf, expected -2.89772e+38\n",
      "E1125 20:16:03.145310 1348778 buffer_comparator.cc:157] Difference at 21391: -3.37624e+38, expected -inf\n",
      "E1125 20:16:03.145313 1348778 buffer_comparator.cc:157] Difference at 21747: inf, expected 3.11039e+38\n",
      "E1125 20:16:03.145404 1348778 buffer_comparator.cc:157] Difference at 83283: -inf, expected -3.16356e+38\n",
      "E1125 20:16:03.145407 1348778 buffer_comparator.cc:157] Difference at 83669: 3.07052e+38, expected inf\n",
      "E1125 20:16:03.145409 1348778 buffer_comparator.cc:157] Difference at 83697: inf, expected 2.87113e+38\n",
      "E1125 20:16:03.145411 1348778 buffer_comparator.cc:157] Difference at 83837: inf, expected -2.44578e+38\n",
      "2024-11-25 20:16:03.145415: E external/xla/xla/service/gpu/autotuning/gemm_algorithm_picker.cc:350] Results mismatch between different GEMM algorithms. This is likely a bug/unexpected loss of precision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax (1, 4128, 1280) [[[-0.00285339 -0.00141144 -0.000774384 ... -0.00125885 0.00296021\n",
      "   -0.000602722]\n",
      "  [-0.00100708 -0.00159454 -0.00115204 ... -0.00062561 0.000972748\n",
      "   -0.00112915]\n",
      "  [-0.00133514 -0.00189972 -0.00094986 ... -0.00144958 0.00354004\n",
      "   0.000976562]\n",
      "  ...\n",
      "  [-0.00189209 -0.00133514 -0.000865936 ... -0.00082016 0.00254822\n",
      "   0.000276566]\n",
      "  [-0.00189209 -0.00133514 -0.000865936 ... -0.00082016 0.00254822\n",
      "   0.000276566]\n",
      "  [-0.00189209 -0.00133514 -0.000865936 ... -0.00082016 0.00254822\n",
      "   0.000276566]]]\n",
      "jax (1, 4128, 1280) [[[-0.0133667 -0.00160217 0.0015564 ... 0.0090332 -0.00469971\n",
      "   0.000534058]\n",
      "  [-0.0140381 -0.00340271 0.00102997 ... 0.00860596 -0.0030365\n",
      "   0.000663757]\n",
      "  [-0.0140381 -0.00360107 0.00231934 ... 0.00823975 -0.0037384\n",
      "   0.000984192]\n",
      "  ...\n",
      "  [-0.0123291 -0.00231934 0.00202942 ... 0.00866699 -0.0050354\n",
      "   0.00273132]\n",
      "  [-0.0123291 -0.00231934 0.00202942 ... 0.00866699 -0.0050354\n",
      "   0.00273132]\n",
      "  [-0.0123291 -0.00231934 0.00202942 ... 0.00866699 -0.0050354\n",
      "   0.00273132]]]\n",
      "jax (1, 4128, 1280) [[[1.63317e-05 0.0071106 3.40939e-05 ... -0.00732422 -0.00488281\n",
      "   -0.00668335]\n",
      "  [0.000391006 0.00689697 0.000138283 ... -0.00692749 -0.00482178\n",
      "   -0.00701904]\n",
      "  [-0.000335693 0.00726318 0.000537872 ... -0.00683594 -0.0065918\n",
      "   -0.00570679]\n",
      "  ...\n",
      "  [-0.000478745 0.00692749 0.000881195 ... -0.00640869 -0.00300598\n",
      "   -0.0078125]\n",
      "  [-0.000478745 0.00692749 0.000881195 ... -0.00640869 -0.00300598\n",
      "   -0.0078125]\n",
      "  [-0.000478745 0.00692749 0.000881195 ... -0.00640869 -0.00300598\n",
      "   -0.0078125]]]\n",
      "jax (1, 4128, 1280) [[[0.000448227 0.00537109 -0.010376 ... 0.00891113 -0.0100708 0.00379944]\n",
      "  [-0.00133514 0.00384521 -0.0090332 ... 0.00747681 -0.00927734\n",
      "   0.00352478]\n",
      "  [0.00100708 0.00479126 -0.00970459 ... 0.00762939 -0.0108643\n",
      "   0.00494385]\n",
      "  ...\n",
      "  [0.000368118 0.00408936 -0.00787354 ... 0.00531006 -0.0101318\n",
      "   0.00386047]\n",
      "  [0.000368118 0.00408936 -0.00787354 ... 0.00531006 -0.0101318\n",
      "   0.00386047]\n",
      "  [0.000368118 0.00408936 -0.00787354 ... 0.00531006 -0.0101318\n",
      "   0.00386047]]]\n",
      "jax (1, 4128, 1280) [[[-0.00778198 -0.00361633 0.00497437 ... 0.0065918 0.00836182 0.0163574]\n",
      "  [-0.0113525 -0.00735474 0.0055542 ... 0.00421143 0.00793457 0.0201416]\n",
      "  [-0.00897217 -0.00579834 0.00701904 ... 0.00570679 0.00787354\n",
      "   0.0187988]\n",
      "  ...\n",
      "  [-0.00891113 -0.00686646 0.0039978 ... 0.00622559 0.00756836 0.0197754]\n",
      "  [-0.00891113 -0.00686646 0.0039978 ... 0.00622559 0.00756836 0.0197754]\n",
      "  [-0.00891113 -0.00686646 0.0039978 ... 0.00622559 0.00756836 0.0197754]]]\n",
      "jax (1, 4128, 1280) [[[-0.0205078 -0.0158691 -0.0133057 ... -0.00202942 0.00121307\n",
      "   -0.00787354]\n",
      "  [-0.0205078 -0.0145874 -0.0139771 ... -0.00149536 0.00150299\n",
      "   -0.00933838]\n",
      "  [-0.0209961 -0.0158691 -0.0136719 ... -0.00289917 0.0010376\n",
      "   -0.00891113]\n",
      "  ...\n",
      "  [-0.0212402 -0.0133057 -0.0152588 ... -0.0014267 0.000278473\n",
      "   -0.00753784]\n",
      "  [-0.0212402 -0.0133057 -0.0152588 ... -0.0014267 0.000278473\n",
      "   -0.00753784]\n",
      "  [-0.0212402 -0.0133057 -0.0152588 ... -0.0014267 0.000278473\n",
      "   -0.00753784]]]\n",
      "jax (1, 4128, 1280) [[[-0.00546265 0.00750732 0.00531006 ... 0.0122681 -0.00233459\n",
      "   0.00195312]\n",
      "  [-0.00601196 0.00811768 0.00405884 ... 0.0127563 -0.00189209\n",
      "   -0.000239372]\n",
      "  [-0.00604248 0.00701904 0.00524902 ... 0.0132446 -0.00296021\n",
      "   0.00141907]\n",
      "  ...\n",
      "  [-0.00570679 0.00646973 0.00402832 ... 0.0125122 -0.0019989 0.00236511]\n",
      "  [-0.00570679 0.00646973 0.00402832 ... 0.0125122 -0.0019989 0.00236511]\n",
      "  [-0.00570679 0.00646973 0.00402832 ... 0.0125122 -0.0019989 0.00236511]]]\n",
      "jax (1, 4128, 1280) [[[0.000923157 -0.00506592 0.00469971 ... 0.00680542 0.0161133\n",
      "   -0.0119019]\n",
      "  [0.00186157 -0.00650024 0.00469971 ... 0.00543213 0.0170898 -0.0119629]\n",
      "  [-0.00038147 -0.00427246 0.00552368 ... 0.00454712 0.0153198\n",
      "   -0.0108643]\n",
      "  ...\n",
      "  [-0.000934601 -0.00543213 0.00334167 ... 0.00491333 0.0163574\n",
      "   -0.0120239]\n",
      "  [-0.000934601 -0.00543213 0.00334167 ... 0.00491333 0.0163574\n",
      "   -0.0120239]\n",
      "  [-0.000934601 -0.00543213 0.00334167 ... 0.00491333 0.0163574\n",
      "   -0.0120239]]]\n",
      "jax (1, 4128, 1280) [[[-0.000220299 0.0205078 -0.00485229 ... 0.0118408 -0.0015564\n",
      "   0.00323486]\n",
      "  [0.00169373 0.0203857 -0.00445557 ... 0.012207 -0.00411987 0.00367737]\n",
      "  [0.00121307 0.0206299 -0.00485229 ... 0.0116577 -0.00100708 0.00221252]\n",
      "  ...\n",
      "  [0.00273132 0.0217285 -0.00366211 ... 0.0115967 -0.00314331 0.00283813]\n",
      "  [0.00273132 0.0217285 -0.00366211 ... 0.0115967 -0.00314331 0.00283813]\n",
      "  [0.00273132 0.0217285 -0.00366211 ... 0.0115967 -0.00314331 0.00283813]]]\n",
      "jax (1, 4128, 1280) [[[-0.0163574 -0.00488281 0.0117188 ... -0.0170898 0.00976562\n",
      "   -0.00460815]\n",
      "  [-0.0161133 -0.00588989 0.00952148 ... -0.0183105 0.00927734\n",
      "   -0.00466919]\n",
      "  [-0.0166016 -0.00466919 0.0125732 ... -0.0161133 0.010376 -0.00430298]\n",
      "  ...\n",
      "  [-0.0142212 -0.00653076 0.0129395 ... -0.0180664 0.00848389\n",
      "   -0.00256348]\n",
      "  [-0.0142212 -0.00653076 0.0129395 ... -0.0180664 0.00848389\n",
      "   -0.00256348]\n",
      "  [-0.0142212 -0.00653076 0.0129395 ... -0.0180664 0.00848389\n",
      "   -0.00256348]]]\n",
      "jax (1, 4128, 1280) [[[0.0169678 -0.0125122 0.0108032 ... 0.032959 -0.0133057 0.0088501]\n",
      "  [0.0166016 -0.0114746 0.0098877 ... 0.0351562 -0.0120239 0.010437]\n",
      "  [0.0180664 -0.0119629 0.0125732 ... 0.0332031 -0.012146 0.00842285]\n",
      "  ...\n",
      "  [0.0166016 -0.00964355 0.00964355 ... 0.0327148 -0.0134277 0.00933838]\n",
      "  [0.0166016 -0.00964355 0.00964355 ... 0.0327148 -0.0134277 0.00933838]\n",
      "  [0.0166016 -0.00964355 0.00964355 ... 0.0327148 -0.0134277 0.00933838]]]\n",
      "jax (1, 4128, 1280) [[[-0.0103149 -0.000101566 0.00668335 ... -0.00267029 -0.0107422\n",
      "   -0.00130463]\n",
      "  [-0.0114746 -0.000782013 0.00540161 ... -0.00436401 -0.00872803\n",
      "   -0.00296021]\n",
      "  [-0.0110474 -7.34329e-05 0.00537109 ... -0.00369263 -0.0100708\n",
      "   0.0001297]\n",
      "  ...\n",
      "  [-0.0117188 -0.00106812 0.00549316 ... -0.00306702 -0.0108032\n",
      "   -0.00161743]\n",
      "  [-0.0117188 -0.00106812 0.00549316 ... -0.00306702 -0.0108032\n",
      "   -0.00161743]\n",
      "  [-0.0117188 -0.00106812 0.00549316 ... -0.00306702 -0.0108032\n",
      "   -0.00161743]]]\n",
      "jax (1, 4128, 1280) [[[-0.0427246 -0.0108643 -0.00082016 ... 0.0120239 0.0107422 -0.0140381]\n",
      "  [-0.0424805 -0.00958252 0.000112534 ... 0.0116577 0.00946045\n",
      "   -0.0155029]\n",
      "  [-0.0427246 -0.0101318 -0.00147247 ... 0.0112305 0.0109863 -0.0161133]\n",
      "  ...\n",
      "  [-0.0424805 -0.00982666 0.000534058 ... 0.012085 0.00915527 -0.0147705]\n",
      "  [-0.0424805 -0.00982666 0.000534058 ... 0.012085 0.00915527 -0.0147705]\n",
      "  [-0.0424805 -0.00982666 0.000534058 ... 0.012085 0.00915527 -0.0147705]]]\n",
      "jax (1, 4128, 1280) [[[0.0098877 -0.0067749 0.00497437 ... -0.0110474 0.00402832 -0.00613403]\n",
      "  [0.0114136 -0.00714111 0.00576782 ... -0.0120239 0.00393677\n",
      "   -0.00628662]\n",
      "  [0.0101318 -0.00799561 0.00531006 ... -0.0119019 0.00582886\n",
      "   -0.00799561]\n",
      "  ...\n",
      "  [0.0113525 -0.0067749 0.00686646 ... -0.010437 0.00646973 -0.00640869]\n",
      "  [0.0113525 -0.0067749 0.00686646 ... -0.010437 0.00646973 -0.00640869]\n",
      "  [0.0113525 -0.0067749 0.00686646 ... -0.010437 0.00646973 -0.00640869]]]\n",
      "jax (1, 4128, 1280) [[[0.0158691 0.00805664 -0.00915527 ... -0.00772095 -0.0249023\n",
      "   0.00628662]\n",
      "  [0.0153198 0.00982666 -0.00952148 ... -0.00793457 -0.0231934\n",
      "   0.00363159]\n",
      "  [0.013916 0.0116577 -0.00823975 ... -0.0088501 -0.0244141 0.0057373]\n",
      "  ...\n",
      "  [0.015625 0.00823975 -0.00958252 ... -0.00805664 -0.0249023 0.00354004]\n",
      "  [0.015625 0.00823975 -0.00958252 ... -0.00805664 -0.0249023 0.00354004]\n",
      "  [0.015625 0.00823975 -0.00958252 ... -0.00805664 -0.0249023 0.00354004]]]\n",
      "jax (1, 4128, 1280) [[[0.0227051 -0.00231934 0.0108643 ... 0.00521851 -0.0186768 0.00473022]\n",
      "  [0.0229492 -0.00294495 0.0109863 ... 0.00463867 -0.0175781 0.00476074]\n",
      "  [0.020752 -0.00227356 0.0117188 ... 0.00466919 -0.0172119 0.00613403]\n",
      "  ...\n",
      "  [0.0224609 -0.00375366 0.0114746 ... 0.00485229 -0.017334 0.00331116]\n",
      "  [0.0224609 -0.00375366 0.0114746 ... 0.00485229 -0.017334 0.00331116]\n",
      "  [0.0224609 -0.00375366 0.0114746 ... 0.00485229 -0.017334 0.00331116]]]\n",
      "jax (1, 4128, 1280) [[[0.0128174 -0.00579834 -0.000968933 ... -0.0240479 0.00466919\n",
      "   0.0250244]\n",
      "  [0.0130615 -0.00445557 -0.0014267 ... -0.0250244 0.00387573 0.0239258]\n",
      "  [0.0147095 -0.00476074 -0.0013504 ... -0.0247803 0.00500488 0.024292]\n",
      "  ...\n",
      "  [0.0142822 -0.00436401 -0.00326538 ... -0.0235596 0.00421143 0.0236816]\n",
      "  [0.0142822 -0.00436401 -0.00326538 ... -0.0235596 0.00421143 0.0236816]\n",
      "  [0.0142822 -0.00436401 -0.00326538 ... -0.0235596 0.00421143 0.0236816]]]\n",
      "jax (1, 4128, 1280) [[[-0.0344238 0.00367737 -0.00549316 ... -0.0203857 -0.00436401 0.012085]\n",
      "  [-0.0351562 0.00331116 -0.00442505 ... -0.020874 -0.00424194 0.0127563]\n",
      "  [-0.0339355 0.00457764 -0.00402832 ... -0.0206299 -0.00209045\n",
      "   0.0136108]\n",
      "  ...\n",
      "  [-0.0322266 0.00376892 -0.00396729 ... -0.020874 -0.00263977 0.0128784]\n",
      "  [-0.0322266 0.00376892 -0.00396729 ... -0.020874 -0.00263977 0.0128784]\n",
      "  [-0.0322266 0.00376892 -0.00396729 ... -0.020874 -0.00263977 0.0128784]]]\n",
      "jax (1, 4128, 1280) [[[-0.0267334 0.0334473 -0.00897217 ... -0.00787354 0.00244141 0.0234375]\n",
      "  [-0.026001 0.034668 -0.00741577 ... -0.00778198 0.0050354 0.0238037]\n",
      "  [-0.027832 0.0336914 -0.00939941 ... -0.00701904 0.00201416 0.0217285]\n",
      "  ...\n",
      "  [-0.0272217 0.034668 -0.00747681 ... -0.00601196 0.00222778 0.0231934]\n",
      "  [-0.0272217 0.034668 -0.00747681 ... -0.00601196 0.00222778 0.0231934]\n",
      "  [-0.0272217 0.034668 -0.00747681 ... -0.00601196 0.00222778 0.0231934]]]\n",
      "jax (1, 4128, 1280) [[[-0.0228271 -0.019165 0.00256348 ... -0.0142822 -0.0263672 0.0209961]\n",
      "  [-0.0235596 -0.0201416 0.0030365 ... -0.0125122 -0.0270996 0.0197754]\n",
      "  [-0.0241699 -0.0195312 0.00360107 ... -0.0131836 -0.0267334 0.0192871]\n",
      "  ...\n",
      "  [-0.0262451 -0.0197754 0.00430298 ... -0.0142212 -0.0244141 0.0206299]\n",
      "  [-0.0262451 -0.0197754 0.00430298 ... -0.0142212 -0.0244141 0.0206299]\n",
      "  [-0.0262451 -0.0197754 0.00430298 ... -0.0142212 -0.0244141 0.0206299]]]\n",
      "jax (1, 4128, 1280) [[[0.019165 -0.0296631 -0.0300293 ... 0.00473022 -0.00543213 -0.0133057]\n",
      "  [0.019165 -0.0284424 -0.0306396 ... 0.00601196 -0.00491333 -0.0155029]\n",
      "  [0.0201416 -0.0279541 -0.0288086 ... 0.00469971 -0.00512695 -0.015625]\n",
      "  ...\n",
      "  [0.0192871 -0.0286865 -0.0281982 ... 0.00674438 -0.00396729 -0.0148315]\n",
      "  [0.0192871 -0.0286865 -0.0281982 ... 0.00674438 -0.00396729 -0.0148315]\n",
      "  [0.0192871 -0.0286865 -0.0281982 ... 0.00674438 -0.00396729 -0.0148315]]]\n",
      "jax (1, 4128, 1280) [[[-0.0109253 0.00195312 -0.0349121 ... 0.0133667 -0.00131226 -0.0303955]\n",
      "  [-0.0107422 0.00280762 -0.0351562 ... 0.0128784 -0.00224304 -0.0322266]\n",
      "  [-0.00878906 0.00337219 -0.0361328 ... 0.0126343 -0.00250244\n",
      "   -0.0319824]\n",
      "  ...\n",
      "  [-0.0117188 0.00308228 -0.0358887 ... 0.0134888 -0.00189972 -0.0308838]\n",
      "  [-0.0117188 0.00308228 -0.0358887 ... 0.0134888 -0.00189972 -0.0308838]\n",
      "  [-0.0117188 0.00308228 -0.0358887 ... 0.0134888 -0.00189972 -0.0308838]]]\n",
      "jax (1, 4128, 1280) [[[0.00469971 -0.00723267 -0.00595093 ... 0.0301514 -0.0022583\n",
      "   -0.000843048]\n",
      "  [0.00418091 -0.00546265 -0.00494385 ... 0.0280762 -0.00124359\n",
      "   -0.00136566]\n",
      "  [0.00521851 -0.00689697 -0.00497437 ... 0.0284424 -0.00117493\n",
      "   8.96454e-05]\n",
      "  ...\n",
      "  [0.00341797 -0.00701904 -0.00610352 ... 0.0306396 -0.00224304\n",
      "   -0.000904083]\n",
      "  [0.00341797 -0.00701904 -0.00610352 ... 0.0306396 -0.00224304\n",
      "   -0.000904083]\n",
      "  [0.00341797 -0.00701904 -0.00610352 ... 0.0306396 -0.00224304\n",
      "   -0.000904083]]]\n",
      "jax (1, 4128, 1280) [[[-0.0126343 -0.00830078 0.0280762 ... 0.0124512 0.0184326 0.00376892]\n",
      "  [-0.0161133 -0.00842285 0.0272217 ... 0.0110474 0.0169678 0.00421143]\n",
      "  [-0.0133057 -0.00921631 0.0273438 ... 0.0126343 0.0161133 0.00335693]\n",
      "  ...\n",
      "  [-0.012085 -0.00787354 0.0274658 ... 0.0135498 0.0161133 0.00357056]\n",
      "  [-0.012085 -0.00787354 0.0274658 ... 0.0135498 0.0161133 0.00357056]\n",
      "  [-0.012085 -0.00787354 0.0274658 ... 0.0135498 0.0161133 0.00357056]]]\n",
      "jax (1, 4128, 1280) [[[-0.0285645 0.015625 -0.00222778 ... -0.0296631 -0.0339355 0.00860596]\n",
      "  [-0.0286865 0.0163574 -0.00218201 ... -0.0296631 -0.0341797 0.00866699]\n",
      "  [-0.0299072 0.0163574 -0.000900269 ... -0.0301514 -0.0349121\n",
      "   0.00836182]\n",
      "  ...\n",
      "  [-0.0290527 0.0168457 -0.00427246 ... -0.0291748 -0.032959 0.00518799]\n",
      "  [-0.0290527 0.0168457 -0.00427246 ... -0.0291748 -0.032959 0.00518799]\n",
      "  [-0.0290527 0.0168457 -0.00427246 ... -0.0291748 -0.032959 0.00518799]]]\n",
      "jax (1, 4128, 1280) [[[-0.0305176 -0.0090332 -0.02771 ... 0.00228882 -0.0267334 0.012085]\n",
      "  [-0.0296631 -0.010498 -0.0274658 ... -0.000141144 -0.0236816 0.0122681]\n",
      "  [-0.0308838 -0.0106812 -0.0288086 ... 0.00115967 -0.0251465 0.0110474]\n",
      "  ...\n",
      "  [-0.0297852 -0.0109253 -0.0263672 ... 0.000659943 -0.026001 0.0102539]\n",
      "  [-0.0297852 -0.0109253 -0.0263672 ... 0.000659943 -0.026001 0.0102539]\n",
      "  [-0.0297852 -0.0109253 -0.0263672 ... 0.000659943 -0.026001 0.0102539]]]\n",
      "jax (1, 4128, 1280) [[[-0.00933838 0.000938416 0.00506592 ... 0.00367737 0.0032196\n",
      "   -0.0307617]\n",
      "  [-0.00970459 -0.000999451 0.00302124 ... 0.00256348 0.00131226\n",
      "   -0.03125]\n",
      "  [-0.0108643 0.00132751 0.00323486 ... 0.00280762 0.00209045 -0.0324707]\n",
      "  ...\n",
      "  [-0.00891113 0.00191498 0.00402832 ... 0.00176239 0.00292969\n",
      "   -0.0334473]\n",
      "  [-0.00891113 0.00191498 0.00402832 ... 0.00176239 0.00292969\n",
      "   -0.0334473]\n",
      "  [-0.00891113 0.00191498 0.00402832 ... 0.00176239 0.00292969\n",
      "   -0.0334473]]]\n",
      "jax (1, 4128, 1280) [[[0.0444336 -0.0117798 -0.00793457 ... -0.00141907 0.00735474 0.0327148]\n",
      "  [0.0456543 -0.013855 -0.00653076 ... -0.000816345 0.00756836 0.03125]\n",
      "  [0.0463867 -0.0131226 -0.0088501 ... -0.000728607 0.00717163 0.0332031]\n",
      "  ...\n",
      "  [0.0458984 -0.0111694 -0.00753784 ... -0.000926971 0.00570679\n",
      "   0.0307617]\n",
      "  [0.0458984 -0.0111694 -0.00753784 ... -0.000926971 0.00570679\n",
      "   0.0307617]\n",
      "  [0.0458984 -0.0111694 -0.00753784 ... -0.000926971 0.00570679\n",
      "   0.0307617]]]\n",
      "jax (1, 4128, 1280) [[[-0.00704956 0.00759888 -0.0251465 ... -0.034668 -0.0133057 0.0366211]\n",
      "  [-0.00811768 0.00628662 -0.0223389 ... -0.0361328 -0.0113525 0.0375977]\n",
      "  [-0.0107422 0.00921631 -0.0216064 ... -0.0368652 -0.0141602 0.0378418]\n",
      "  ...\n",
      "  [-0.00866699 0.0078125 -0.0192871 ... -0.036377 -0.0153809 0.0373535]\n",
      "  [-0.00866699 0.0078125 -0.0192871 ... -0.036377 -0.0153809 0.0373535]\n",
      "  [-0.00866699 0.0078125 -0.0192871 ... -0.036377 -0.0153809 0.0373535]]]\n",
      "jax (1, 4128, 1280) [[[-0.0109253 0.0158691 0.00570679 ... 0.00524902 0.00585938 -0.00765991]\n",
      "  [-0.00976562 0.0145264 0.00842285 ... 0.0055542 0.00665283 -0.00753784]\n",
      "  [-0.0109253 0.0147095 0.00714111 ... 0.00582886 0.00512695 -0.00674438]\n",
      "  ...\n",
      "  [-0.0115356 0.0149536 0.00463867 ... 0.00436401 0.00683594 -0.00976562]\n",
      "  [-0.0115356 0.0149536 0.00463867 ... 0.00436401 0.00683594 -0.00976562]\n",
      "  [-0.0115356 0.0149536 0.00463867 ... 0.00436401 0.00683594 -0.00976562]]]\n",
      "jax (1, 4128, 1280) [[[-0.0123901 0.0211182 0.0175781 ... 0.017334 0.0241699 -0.0055542]\n",
      "  [-0.0136108 0.020752 0.0209961 ... 0.0163574 0.024292 -0.0045166]\n",
      "  [-0.0142212 0.0213623 0.019043 ... 0.0164795 0.0252686 -0.00479126]\n",
      "  ...\n",
      "  [-0.0128174 0.0192871 0.020874 ... 0.0145874 0.0244141 -0.00257874]\n",
      "  [-0.0128174 0.0192871 0.020874 ... 0.0145874 0.0244141 -0.00257874]\n",
      "  [-0.0128174 0.0192871 0.020874 ... 0.0145874 0.0244141 -0.00257874]]]\n",
      "jax (1, 4128, 1280) [[[-0.0129395 -0.00732422 0.0151978 ... 0.0143433 -0.0354004 0.0192871]\n",
      "  [-0.0152588 -0.00476074 0.0150757 ... 0.0111694 -0.0380859 0.0195312]\n",
      "  [-0.0144043 -0.00521851 0.0153809 ... 0.0133057 -0.036377 0.0198975]\n",
      "  ...\n",
      "  [-0.0130615 -0.00735474 0.013855 ... 0.0135498 -0.0358887 0.0203857]\n",
      "  [-0.0130615 -0.00735474 0.013855 ... 0.0135498 -0.0358887 0.0203857]\n",
      "  [-0.0130615 -0.00735474 0.013855 ... 0.0135498 -0.0358887 0.0203857]]]\n",
      "jax (1, 4128, 1280) [[[0.0344238 -0.0111084 0.00421143 ... 0.0201416 -0.0195312 -0.0184326]\n",
      "  [0.0332031 -0.012207 0.00463867 ... 0.0205078 -0.0201416 -0.0179443]\n",
      "  [0.032959 -0.0119629 0.00378418 ... 0.0198975 -0.0206299 -0.017334]\n",
      "  ...\n",
      "  [0.0332031 -0.00952148 0.00567627 ... 0.0212402 -0.0203857 -0.0179443]\n",
      "  [0.0332031 -0.00952148 0.00567627 ... 0.0212402 -0.0203857 -0.0179443]\n",
      "  [0.0332031 -0.00952148 0.00567627 ... 0.0212402 -0.0203857 -0.0179443]]]\n",
      "jax (1, 4128, 1280) [[[0.0145874 0.0220947 -0.032959 ... 0.00427246 0.0498047 -0.0289307]\n",
      "  [0.0152588 0.0214844 -0.0300293 ... 0.00588989 0.0488281 -0.0294189]\n",
      "  [0.015625 0.0219727 -0.0324707 ... 0.00479126 0.048584 -0.0286865]\n",
      "  ...\n",
      "  [0.0170898 0.0209961 -0.0317383 ... 0.00506592 0.0493164 -0.0262451]\n",
      "  [0.0170898 0.0209961 -0.0317383 ... 0.00506592 0.0493164 -0.0262451]\n",
      "  [0.0170898 0.0209961 -0.0317383 ... 0.00506592 0.0493164 -0.0262451]]]\n",
      "jax (1, 4128, 1280) [[[0.0148926 0.00921631 0.00793457 ... -0.0170898 0.0274658 -0.00421143]\n",
      "  [0.0164795 0.00759888 0.00823975 ... -0.0157471 0.0285645 -0.00424194]\n",
      "  [0.0163574 0.00524902 0.00744629 ... -0.0151367 0.0280762 -0.00379944]\n",
      "  ...\n",
      "  [0.0153198 0.00933838 0.00708008 ... -0.0167236 0.0262451 -0.00485229]\n",
      "  [0.0153198 0.00933838 0.00708008 ... -0.0167236 0.0262451 -0.00485229]\n",
      "  [0.0153198 0.00933838 0.00708008 ... -0.0167236 0.0262451 -0.00485229]]]\n",
      "jax (1, 4128, 1280) [[[-0.000934601 0.0205078 -0.026123 ... 0.00616455 0.0395508 -0.0120239]\n",
      "  [-0.000239372 0.0201416 -0.0257568 ... 0.00500488 0.0385742 -0.0125732]\n",
      "  [-2.8491e-05 0.0196533 -0.0250244 ... 0.00552368 0.0393066 -0.0125122]\n",
      "  ...\n",
      "  [0.000352859 0.0201416 -0.0273438 ... 0.0078125 0.0383301 -0.0129395]\n",
      "  [0.000352859 0.0201416 -0.0273438 ... 0.0078125 0.0383301 -0.0129395]\n",
      "  [0.000352859 0.0201416 -0.0273438 ... 0.0078125 0.0383301 -0.0129395]]]\n",
      "jax (1, 4128, 1280) [[[-0.00860596 -0.000354767 -0.00469971 ... 0.0101318 0.026123\n",
      "   -0.0169678]\n",
      "  [-0.00662231 5.8651e-05 -0.00346375 ... 0.0116577 0.0258789 -0.017334]\n",
      "  [-0.00595093 0.0011673 -0.00424194 ... 0.0101929 0.0270996 -0.0186768]\n",
      "  ...\n",
      "  [-0.0078125 0.00126648 -0.00267029 ... 0.0117188 0.0256348 -0.0179443]\n",
      "  [-0.0078125 0.00126648 -0.00267029 ... 0.0117188 0.0256348 -0.0179443]\n",
      "  [-0.0078125 0.00126648 -0.00267029 ... 0.0117188 0.0256348 -0.0179443]]]\n",
      "jax (1, 4128, 1280) [[[0.0267334 -0.0393066 -0.00215149 ... -0.0117188 -0.0140991 -0.0356445]\n",
      "  [0.0280762 -0.0388184 -0.00337219 ... -0.0111694 -0.0143433 -0.0368652]\n",
      "  [0.0281982 -0.0402832 -0.00457764 ... -0.0114746 -0.0167236 -0.0371094]\n",
      "  ...\n",
      "  [0.0306396 -0.0407715 -0.0057373 ... -0.0125122 -0.0161133 -0.0339355]\n",
      "  [0.0306396 -0.0407715 -0.0057373 ... -0.0125122 -0.0161133 -0.0339355]\n",
      "  [0.0306396 -0.0407715 -0.0057373 ... -0.0125122 -0.0161133 -0.0339355]]]\n",
      "jax (1, 4128, 1280) [[[0.0234375 -0.0274658 0.00799561 ... 0.020874 -0.0137939 -0.0495605]\n",
      "  [0.0218506 -0.0279541 0.00836182 ... 0.0200195 -0.0132446 -0.0488281]\n",
      "  [0.022583 -0.0269775 0.00897217 ... 0.0206299 -0.0129395 -0.0480957]\n",
      "  ...\n",
      "  [0.0227051 -0.0275879 0.00958252 ... 0.0200195 -0.0111084 -0.0476074]\n",
      "  [0.0227051 -0.0275879 0.00958252 ... 0.0200195 -0.0111084 -0.0476074]\n",
      "  [0.0227051 -0.0275879 0.00958252 ... 0.0200195 -0.0111084 -0.0476074]]]\n",
      "jax (1, 4128, 1280) [[[-0.001091 0.00872803 0.0493164 ... -0.010376 -0.0184326 -0.0356445]\n",
      "  [-0.00215149 0.00939941 0.0498047 ... -0.0128174 -0.0181885 -0.0358887]\n",
      "  [-0.00177002 0.010437 0.0488281 ... -0.0126343 -0.0187988 -0.0356445]\n",
      "  ...\n",
      "  [-0.00228882 0.00915527 0.0478516 ... -0.0101318 -0.0167236 -0.0361328]\n",
      "  [-0.00228882 0.00915527 0.0478516 ... -0.0101318 -0.0167236 -0.0361328]\n",
      "  [-0.00228882 0.00915527 0.0478516 ... -0.0101318 -0.0167236 -0.0361328]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/amd/model/hub/models--meta-llama--Llama-3.2-11B-Vision/pytorch were not used when initializing FlaxMllamaVisionModel: {('language_model', 'model', 'layers.3', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.39', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.1', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.31', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.7', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.0', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.32', 'self_attn', 'k_proj', 'kernel'), ('multi_modal_projector', 'bias'), ('language_model', 'model', 'layers.30', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.1', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.17', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.7', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.6', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.9', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.36', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.38', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.33', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.13', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.6', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'mlp', 'down_proj', 'kernel'), ('multi_modal_projector', 'kernel'), ('language_model', 'model', 'layers.20', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.11', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.20', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.30', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.35', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'norm', 'kernel'), ('language_model', 'model', 'layers.39', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.39', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.14', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.9', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.20', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.3', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.34', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.26', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.10', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.12', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.11', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.16', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.26', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.8', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.36', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'lm_head', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.29', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.34', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.5', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.20', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.7', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.26', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.8', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.7', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.1', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.22', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.7', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'embed_tokens', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.25', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.12', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.30', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.35', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.27', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.27', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.28', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.6', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn_mlp_gate'), ('language_model', 'model', 'layers.0', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.5', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.8', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.6', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.32', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.6', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.12', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.17', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.9', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.4', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.33', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.39', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.21', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.37', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.36', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.23', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.14', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.10', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.23', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.35', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.15', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.19', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.18', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.9', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.21', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.4', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.31', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.19', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.35', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.2', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.9', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.15', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.14', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.20', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.2', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'self_attn', 'o_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.3', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'self_attn', 'k_proj', 'kernel'), ('language_model', 'model', 'layers.33', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.14', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.14', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.22', 'mlp', 'down_proj', 'kernel'), ('language_model', 'model', 'layers.29', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.38', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.28', 'cross_attn', 'q_norm', 'kernel'), ('language_model', 'model', 'layers.27', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn_attn_gate'), ('language_model', 'model', 'layers.12', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.27', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.23', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.30', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.0', 'post_attention_layernorm', 'kernel'), ('language_model', 'model', 'layers.17', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.11', 'mlp', 'up_proj', 'kernel'), ('language_model', 'model', 'layers.1', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.25', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.16', 'self_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.27', 'self_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.12', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'k_norm', 'kernel'), ('language_model', 'model', 'layers.13', 'cross_attn', 'q_proj', 'kernel'), ('language_model', 'model', 'layers.34', 'mlp', 'gate_proj', 'kernel'), ('language_model', 'model', 'layers.20', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.3', 'cross_attn', 'v_proj', 'kernel'), ('language_model', 'model', 'layers.24', 'input_layernorm', 'kernel'), ('language_model', 'model', 'layers.39', 'input_layernorm', 'kernel')}\n",
      "- This IS expected if you are initializing FlaxMllamaVisionModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing FlaxMllamaVisionModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some of the weights of FlaxMllamaVisionModel were initialized in bfloat16 precision from the model checkpoint at /home/amd/model/hub/models--meta-llama--Llama-3.2-11B-Vision/pytorch:\n",
      "[('vision_model', 'class_embedding'), ('vision_model', 'gated_positional_embedding', 'embedding'), ('vision_model', 'gated_positional_embedding', 'gate'), ('vision_model', 'gated_positional_embedding', 'tile_embedding', 'embedding'), ('vision_model', 'global_transformer', 'layers.0', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.0', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.0', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.0', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.0', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.1', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.1', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.1', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.1', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.2', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.2', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.2', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.2', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.3', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.3', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.3', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.3', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.4', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.4', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.4', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.4', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.5', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.5', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.5', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.5', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.6', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.6', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.6', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.6', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'gate_attn'), ('vision_model', 'global_transformer', 'layers.7', 'gate_ffn'), ('vision_model', 'global_transformer', 'layers.7', 'input_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'input_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc1', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc1', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc2', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'mlp', 'fc2', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'post_attention_layernorm', 'bias'), ('vision_model', 'global_transformer', 'layers.7', 'post_attention_layernorm', 'scale'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'global_transformer', 'layers.7', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'layernorm_post', 'bias'), ('vision_model', 'layernorm_post', 'scale'), ('vision_model', 'layernorm_pre', 'bias'), ('vision_model', 'layernorm_pre', 'scale'), ('vision_model', 'patch_embedding', 'kernel'), ('vision_model', 'post_tile_positional_embedding', 'embedding', 'embedding'), ('vision_model', 'post_tile_positional_embedding', 'gate'), ('vision_model', 'pre_tile_positional_embedding', 'embedding', 'embedding'), ('vision_model', 'pre_tile_positional_embedding', 'gate'), ('vision_model', 'transformer', 'layers.0', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.0', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.0', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.0', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.0', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.1', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.1', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.1', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.1', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.10', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.10', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.10', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.10', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.11', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.11', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.11', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.11', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.12', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.12', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.12', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.12', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.13', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.13', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.13', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.13', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.14', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.14', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.14', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.14', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.15', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.15', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.15', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.15', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.16', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.16', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.16', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.16', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.17', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.17', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.17', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.17', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.18', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.18', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.18', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.18', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.19', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.19', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.19', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.19', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.2', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.2', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.2', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.2', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.20', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.20', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.20', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.20', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.21', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.21', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.21', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.21', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.22', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.22', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.22', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.22', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.23', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.23', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.23', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.23', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.24', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.24', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.24', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.24', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.25', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.25', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.25', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.25', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.26', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.26', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.26', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.26', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.27', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.27', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.27', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.27', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.28', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.28', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.28', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.28', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.29', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.29', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.29', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.29', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.3', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.3', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.3', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.3', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.30', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.30', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.30', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.30', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.31', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.31', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.31', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.31', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.4', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.4', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.4', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.4', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.5', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.5', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.5', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.5', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.6', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.6', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.6', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.6', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.7', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.7', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.7', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.7', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.8', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.8', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.8', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.8', 'self_attn', 'v_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'input_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.9', 'input_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc1', 'bias'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc1', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc2', 'bias'), ('vision_model', 'transformer', 'layers.9', 'mlp', 'fc2', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'post_attention_layernorm', 'bias'), ('vision_model', 'transformer', 'layers.9', 'post_attention_layernorm', 'scale'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'k_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'o_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'q_proj', 'kernel'), ('vision_model', 'transformer', 'layers.9', 'self_attn', 'v_proj', 'kernel')]\n",
      "You should probably UPCAST the model weights to float32 if this was not intended. See [`~FlaxPreTrainedModel.to_fp32`] for further information on how to do this.\n"
     ]
    }
   ],
   "source": [
    "from transformers import MllamaVisionModel, FlaxMllamaVisionModel\n",
    "from transformers import AutoProcessor, MllamaTextModel\n",
    "import requests\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image\n",
    "from huggingface_hub import login\n",
    "torch.set_printoptions(precision=8)\n",
    "jax.numpy.set_printoptions(precision=10)\n",
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.5'\n",
    "\n",
    "hf_token = \"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\"\n",
    "login(hf_token)\n",
    "checkpoint = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "\n",
    "model_torch = MllamaVisionModel.from_pretrained(checkpoint, torch_dtype=torch.bfloat16).to(\"cuda\")\n",
    "\n",
    "model = FlaxMllamaVisionModel.from_pretrained(\"/home/amd/model/hub/models--meta-llama--Llama-3.2-11B-Vision/pytorch\", from_pt=True, dtype=jnp.bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.25195312, -0.06542969, -0.02661133,  ...,  0.25781250,\n",
      "          -0.01263428,  0.31054688],\n",
      "         [-0.33007812, -0.01623535,  0.09814453,  ...,  0.22167969,\n",
      "          -0.09863281,  0.48046875],\n",
      "         [-0.34179688, -0.02038574,  0.11181641,  ...,  0.22070312,\n",
      "          -0.10449219,  0.47656250],\n",
      "         ...,\n",
      "         [-0.53906250,  0.02600098,  0.16503906,  ...,  0.17773438,\n",
      "          -0.05615234, -0.05346680],\n",
      "         [-0.53906250,  0.02600098,  0.16503906,  ...,  0.17773438,\n",
      "          -0.05615234, -0.05346680],\n",
      "         [-0.53906250,  0.02600098,  0.16503906,  ...,  0.17773438,\n",
      "          -0.05615234, -0.05346680]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.05151367, -0.01531982, -0.06152344,  ...,  0.02380371,\n",
      "           0.09423828, -0.00494385],\n",
      "         [-0.18066406, -0.01855469, -0.04980469,  ...,  0.06396484,\n",
      "           0.29882812, -0.05273438],\n",
      "         [-0.19335938, -0.02331543, -0.02978516,  ...,  0.05981445,\n",
      "           0.34179688, -0.04321289],\n",
      "         ...,\n",
      "         [ 0.05786133, -0.00043869, -0.19531250,  ..., -0.07421875,\n",
      "           0.11474609, -0.11816406],\n",
      "         [ 0.05786133, -0.00043869, -0.19531250,  ..., -0.07421875,\n",
      "           0.11474609, -0.11816406],\n",
      "         [ 0.05786133, -0.00043869, -0.19531250,  ..., -0.07421875,\n",
      "           0.11474609, -0.11816406]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.02917480,  0.10498047, -0.06225586,  ...,  0.03808594,\n",
      "          -0.10937500, -0.17675781],\n",
      "         [-0.03149414, -0.04809570, -0.10986328,  ..., -0.14453125,\n",
      "          -0.00558472, -0.02368164],\n",
      "         [-0.02355957,  0.02221680, -0.01098633,  ..., -0.06982422,\n",
      "           0.04736328, -0.03466797],\n",
      "         ...,\n",
      "         [ 0.34570312, -0.17382812, -0.08300781,  ...,  0.16601562,\n",
      "          -0.03881836, -0.15136719],\n",
      "         [ 0.34570312, -0.17382812, -0.08300781,  ...,  0.16601562,\n",
      "          -0.03881836, -0.15136719],\n",
      "         [ 0.34570312, -0.17382812, -0.08300781,  ...,  0.16601562,\n",
      "          -0.03881836, -0.15136719]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.26171875, -0.21679688,  0.10595703,  ...,  0.22656250,\n",
      "           0.08789062,  0.07861328],\n",
      "         [ 0.25000000, -0.35742188, -0.02563477,  ...,  0.11962891,\n",
      "          -0.01843262,  0.18652344],\n",
      "         [ 0.44335938, -0.55468750,  0.33398438,  ...,  0.33593750,\n",
      "           0.09423828,  0.29296875],\n",
      "         ...,\n",
      "         [ 0.58203125, -0.32421875,  0.06884766,  ...,  0.01263428,\n",
      "           0.29296875,  0.06982422],\n",
      "         [ 0.58203125, -0.32421875,  0.06884766,  ...,  0.01263428,\n",
      "           0.29296875,  0.06982422],\n",
      "         [ 0.58203125, -0.32421875,  0.06884766,  ...,  0.01263428,\n",
      "           0.29296875,  0.06982422]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.01672363, -0.18457031, -0.19824219,  ...,  0.09082031,\n",
      "           0.18261719, -0.04443359],\n",
      "         [ 0.13671875, -0.18261719, -0.42382812,  ..., -0.08496094,\n",
      "          -0.28320312, -0.03857422],\n",
      "         [ 0.15429688, -0.13085938, -0.40234375,  ...,  0.13281250,\n",
      "          -0.11621094, -0.03442383],\n",
      "         ...,\n",
      "         [ 0.38867188, -0.21679688, -0.04467773,  ...,  0.05395508,\n",
      "          -0.03784180,  0.01477051],\n",
      "         [ 0.38867188, -0.21679688, -0.04467773,  ...,  0.05395508,\n",
      "          -0.03784180,  0.01477051],\n",
      "         [ 0.38867188, -0.21679688, -0.04467773,  ...,  0.05395508,\n",
      "          -0.03784180,  0.01477051]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.10986328, -0.26953125, -0.06835938,  ...,  0.05664062,\n",
      "          -0.00149536, -0.11523438],\n",
      "         [ 0.12890625,  0.07226562, -0.19140625,  ...,  0.12060547,\n",
      "           0.06005859, -0.25585938],\n",
      "         [ 0.07275391,  0.09765625, -0.24316406,  ...,  0.07617188,\n",
      "           0.03588867, -0.29687500],\n",
      "         ...,\n",
      "         [ 0.46093750, -0.16015625, -0.01513672,  ..., -0.02319336,\n",
      "           0.10107422, -0.17675781],\n",
      "         [ 0.46093750, -0.16015625, -0.01513672,  ..., -0.02319336,\n",
      "           0.10107422, -0.17675781],\n",
      "         [ 0.46093750, -0.16015625, -0.01513672,  ..., -0.02319336,\n",
      "           0.10107422, -0.17675781]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.60546875,  0.01989746,  0.03784180,  ..., -0.11279297,\n",
      "           0.27343750,  0.08593750],\n",
      "         [-0.00732422, -0.52734375,  0.07031250,  ..., -0.39843750,\n",
      "          -0.06005859,  0.00137329],\n",
      "         [ 0.36914062, -0.06933594,  0.24804688,  ..., -0.30078125,\n",
      "          -0.10888672, -0.41796875],\n",
      "         ...,\n",
      "         [ 0.71093750,  0.02319336,  0.01977539,  ..., -0.26953125,\n",
      "          -0.05981445, -0.19531250],\n",
      "         [ 0.71093750,  0.02319336,  0.01977539,  ..., -0.26953125,\n",
      "          -0.05981445, -0.19531250],\n",
      "         [ 0.71093750,  0.02319336,  0.01977539,  ..., -0.26953125,\n",
      "          -0.05981445, -0.19531250]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.20507812,  0.39257812, -0.12158203,  ..., -0.18261719,\n",
      "           0.18750000, -0.12597656],\n",
      "         [-0.08886719,  0.29687500, -0.31445312,  ...,  0.22363281,\n",
      "          -0.11035156, -0.04907227],\n",
      "         [-0.05786133,  0.31640625, -0.16015625,  ...,  0.01635742,\n",
      "           0.01470947, -0.07421875],\n",
      "         ...,\n",
      "         [ 0.24121094,  0.32812500, -0.10009766,  ..., -0.28515625,\n",
      "           0.12500000, -0.24609375],\n",
      "         [ 0.24121094,  0.32812500, -0.10009766,  ..., -0.28515625,\n",
      "           0.12500000, -0.24609375],\n",
      "         [ 0.24121094,  0.32812500, -0.10009766,  ..., -0.28515625,\n",
      "           0.12500000, -0.24609375]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.25195312, -0.36718750, -0.20800781,  ..., -0.11035156,\n",
      "          -0.33007812, -0.06591797],\n",
      "         [ 0.41015625,  0.27929688,  0.35546875,  ...,  0.18554688,\n",
      "          -0.40039062, -0.25195312],\n",
      "         [-0.04565430,  0.18164062,  0.15820312,  ...,  0.03613281,\n",
      "          -0.48437500, -0.48437500],\n",
      "         ...,\n",
      "         [-0.04418945, -0.33007812,  0.10498047,  ..., -0.05468750,\n",
      "          -0.31250000, -0.01507568],\n",
      "         [-0.04418945, -0.33007812,  0.10498047,  ..., -0.05468750,\n",
      "          -0.31250000, -0.01507568],\n",
      "         [-0.04418945, -0.33007812,  0.10498047,  ..., -0.05468750,\n",
      "          -0.31250000, -0.01507568]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.17480469,  0.36718750,  0.10839844,  ..., -0.24316406,\n",
      "           0.38085938,  0.12500000],\n",
      "         [-0.79296875,  0.51953125,  0.64062500,  ...,  0.28906250,\n",
      "          -0.03100586,  0.20410156],\n",
      "         [-0.79687500,  0.70703125,  0.59375000,  ...,  0.40234375,\n",
      "          -0.37890625,  0.32226562],\n",
      "         ...,\n",
      "         [-0.04980469,  0.28320312, -0.02832031,  ..., -0.07177734,\n",
      "           0.25976562, -0.08007812],\n",
      "         [-0.04980469,  0.28320312, -0.02832031,  ..., -0.07177734,\n",
      "           0.25976562, -0.08007812],\n",
      "         [-0.04980469,  0.28320312, -0.02832031,  ..., -0.07177734,\n",
      "           0.25976562, -0.08007812]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.18066406, -0.10205078,  0.06127930,  ...,  0.06884766,\n",
      "           0.23046875, -0.14746094],\n",
      "         [-1.10937500, -0.86328125, -0.26757812,  ...,  0.12792969,\n",
      "          -0.15625000, -0.44726562],\n",
      "         [-1.15625000, -0.99218750, -0.46875000,  ..., -0.06884766,\n",
      "           0.02233887, -0.22753906],\n",
      "         ...,\n",
      "         [-0.08398438, -0.45507812,  0.29492188,  ..., -0.01672363,\n",
      "           0.31250000,  0.05761719],\n",
      "         [-0.08398438, -0.45507812,  0.29492188,  ..., -0.01672363,\n",
      "           0.31250000,  0.05761719],\n",
      "         [-0.08398438, -0.45507812,  0.29492188,  ..., -0.01672363,\n",
      "           0.31250000,  0.05761719]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.35742188, -0.24316406,  0.35156250,  ..., -0.19726562,\n",
      "          -0.16894531,  0.43750000],\n",
      "         [-0.51953125, -0.57031250, -0.26367188,  ...,  0.01965332,\n",
      "          -0.62890625,  0.24902344],\n",
      "         [ 0.11376953, -0.29296875, -0.39062500,  ...,  0.90625000,\n",
      "          -0.49804688,  0.46093750],\n",
      "         ...,\n",
      "         [-0.37109375, -0.20800781,  0.29687500,  ...,  0.04492188,\n",
      "           0.07080078,  0.36132812],\n",
      "         [-0.37109375, -0.20800781,  0.29687500,  ...,  0.04492188,\n",
      "           0.07080078,  0.36132812],\n",
      "         [-0.37109375, -0.20800781,  0.29687500,  ...,  0.04492188,\n",
      "           0.07080078,  0.36132812]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.11328125, -0.13574219, -0.27734375,  ..., -0.12109375,\n",
      "           0.01977539, -0.28906250],\n",
      "         [ 0.29296875, -0.03784180, -0.14843750,  ...,  0.07861328,\n",
      "           0.12500000, -0.52343750],\n",
      "         [ 0.02758789, -0.45312500, -0.19140625,  ...,  0.26757812,\n",
      "           0.28125000, -0.27734375],\n",
      "         ...,\n",
      "         [ 0.22167969, -0.11572266, -0.13085938,  ..., -0.11621094,\n",
      "           0.29882812, -0.21191406],\n",
      "         [ 0.22167969, -0.11572266, -0.13085938,  ..., -0.11621094,\n",
      "           0.29882812, -0.21191406],\n",
      "         [ 0.22167969, -0.11572266, -0.13085938,  ..., -0.11621094,\n",
      "           0.29882812, -0.21191406]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.17871094, -0.13281250, -0.30664062,  ..., -0.07177734,\n",
      "          -0.09033203, -0.33984375],\n",
      "         [ 0.83203125,  0.22265625, -0.30468750,  ...,  0.03930664,\n",
      "          -0.04467773, -0.68750000],\n",
      "         [ 1.09375000,  0.19726562, -0.10644531,  ...,  0.35937500,\n",
      "           0.06640625, -0.71484375],\n",
      "         ...,\n",
      "         [ 0.62500000,  0.08300781,  0.09570312,  ...,  0.08056641,\n",
      "           0.33984375, -0.01458740],\n",
      "         [ 0.62500000,  0.08300781,  0.09570312,  ...,  0.08056641,\n",
      "           0.33984375, -0.01458740],\n",
      "         [ 0.62500000,  0.08300781,  0.09570312,  ...,  0.08056641,\n",
      "           0.33984375, -0.01458740]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.20019531,  0.09277344, -0.04101562,  ...,  0.48437500,\n",
      "           0.50390625, -0.38671875],\n",
      "         [-0.76171875,  0.43750000, -0.53125000,  ..., -1.40625000,\n",
      "           0.21386719,  1.06250000],\n",
      "         [-0.75781250,  0.28320312, -0.58203125,  ..., -0.92968750,\n",
      "           0.30273438,  0.84375000],\n",
      "         ...,\n",
      "         [ 0.16015625,  0.57812500, -0.45117188,  ...,  0.01007080,\n",
      "           0.56640625, -0.03564453],\n",
      "         [ 0.16015625,  0.57812500, -0.45117188,  ...,  0.01007080,\n",
      "           0.56640625, -0.03564453],\n",
      "         [ 0.16015625,  0.57812500, -0.45117188,  ...,  0.01007080,\n",
      "           0.56640625, -0.03564453]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.34960938, -1.15625000, -0.33593750,  ..., -0.53515625,\n",
      "           0.05249023,  0.13281250],\n",
      "         [ 0.26562500, -0.66796875, -0.04199219,  ..., -0.93750000,\n",
      "           0.10742188,  0.21484375],\n",
      "         [-0.01989746, -1.07812500, -0.44726562,  ..., -1.25781250,\n",
      "           0.09570312,  0.25781250],\n",
      "         ...,\n",
      "         [-0.06835938, -0.42382812, -0.34179688,  ...,  0.22851562,\n",
      "          -0.13281250,  0.19921875],\n",
      "         [-0.06835938, -0.42382812, -0.34179688,  ...,  0.22851562,\n",
      "          -0.13281250,  0.19921875],\n",
      "         [-0.06835938, -0.42382812, -0.34179688,  ...,  0.22851562,\n",
      "          -0.13281250,  0.19921875]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.53515625,  0.07324219, -1.28906250,  ...,  0.48046875,\n",
      "          -0.48242188, -0.40625000],\n",
      "         [-0.26757812,  0.21093750, -0.57031250,  ..., -0.50000000,\n",
      "          -0.10302734, -0.03295898],\n",
      "         [-0.57421875,  0.39843750, -0.41210938,  ..., -0.59375000,\n",
      "           0.05517578,  0.22949219],\n",
      "         ...,\n",
      "         [ 0.48046875,  0.06079102, -0.12158203,  ...,  0.30468750,\n",
      "          -0.00665283, -0.08642578],\n",
      "         [ 0.48046875,  0.06079102, -0.12158203,  ...,  0.30468750,\n",
      "          -0.00665283, -0.08642578],\n",
      "         [ 0.48046875,  0.06079102, -0.12158203,  ...,  0.30468750,\n",
      "          -0.00665283, -0.08642578]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-1.70312500,  0.21093750,  1.08593750,  ..., -0.36914062,\n",
      "           0.03540039,  0.16601562],\n",
      "         [-0.79296875,  0.16796875,  0.32226562,  ..., -0.18554688,\n",
      "           0.16992188, -0.58984375],\n",
      "         [-0.21093750, -0.60156250,  0.36132812,  ..., -0.23925781,\n",
      "          -0.21484375, -0.94921875],\n",
      "         ...,\n",
      "         [-0.15332031, -0.62890625,  0.26757812,  ..., -0.25390625,\n",
      "           0.17285156,  0.15820312],\n",
      "         [-0.15332031, -0.62890625,  0.26757812,  ..., -0.25390625,\n",
      "           0.17285156,  0.15820312],\n",
      "         [-0.15332031, -0.62890625,  0.26757812,  ..., -0.25390625,\n",
      "           0.17285156,  0.15820312]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.60156250, -0.20019531,  0.47656250,  ..., -0.12500000,\n",
      "           0.14355469, -0.39648438],\n",
      "         [-0.49023438,  0.69921875,  0.01953125,  ..., -0.01757812,\n",
      "          -0.12011719, -0.61718750],\n",
      "         [-0.43359375,  0.59375000, -0.04492188,  ..., -0.45117188,\n",
      "          -0.12890625, -0.03857422],\n",
      "         ...,\n",
      "         [ 0.36523438, -0.34179688, -0.19042969,  ...,  0.03466797,\n",
      "          -0.22265625, -0.11669922],\n",
      "         [ 0.36523438, -0.34179688, -0.19042969,  ...,  0.03466797,\n",
      "          -0.22265625, -0.11669922],\n",
      "         [ 0.36523438, -0.34179688, -0.19042969,  ...,  0.03466797,\n",
      "          -0.22265625, -0.11669922]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.50781250,  0.05590820,  0.01708984,  ...,  0.14062500,\n",
      "          -0.16796875, -0.00952148],\n",
      "         [-0.07910156, -0.02453613, -0.24609375,  ...,  0.30664062,\n",
      "          -0.61328125,  0.11767578],\n",
      "         [-0.06298828, -0.69140625,  0.31835938,  ...,  0.48046875,\n",
      "          -0.67578125, -0.12353516],\n",
      "         ...,\n",
      "         [ 0.59375000, -0.14843750, -0.38671875,  ...,  0.13769531,\n",
      "           0.19140625, -0.14941406],\n",
      "         [ 0.59375000, -0.14843750, -0.38671875,  ...,  0.13769531,\n",
      "           0.19140625, -0.14941406],\n",
      "         [ 0.59375000, -0.14843750, -0.38671875,  ...,  0.13769531,\n",
      "           0.19140625, -0.14941406]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.02832031,  0.28320312, -0.43164062,  ..., -0.05200195,\n",
      "          -0.31250000, -0.05761719],\n",
      "         [ 0.33789062, -0.15820312,  0.06738281,  ...,  0.01263428,\n",
      "          -0.23535156, -0.40820312],\n",
      "         [ 0.87500000, -0.15917969,  0.15722656,  ..., -0.21093750,\n",
      "          -0.15820312, -0.46875000],\n",
      "         ...,\n",
      "         [ 0.01159668,  0.25781250, -0.17578125,  ..., -0.10791016,\n",
      "          -0.08154297, -0.39648438],\n",
      "         [ 0.01159668,  0.25781250, -0.17578125,  ..., -0.10791016,\n",
      "          -0.08154297, -0.39648438],\n",
      "         [ 0.01159668,  0.25781250, -0.17578125,  ..., -0.10791016,\n",
      "          -0.08154297, -0.39648438]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.24511719,  0.32617188, -0.21289062,  ...,  0.28515625,\n",
      "           0.14453125, -0.07128906],\n",
      "         [ 0.39257812,  0.30273438, -0.67187500,  ...,  0.53125000,\n",
      "          -0.06347656,  0.16113281],\n",
      "         [ 0.21093750,  0.22070312, -0.51562500,  ...,  0.38671875,\n",
      "          -0.01031494,  0.15332031],\n",
      "         ...,\n",
      "         [ 0.04516602,  0.06225586, -0.40234375,  ...,  0.43359375,\n",
      "           0.04565430, -0.05541992],\n",
      "         [ 0.04516602,  0.06225586, -0.40234375,  ...,  0.43359375,\n",
      "           0.04565430, -0.05541992],\n",
      "         [ 0.04516602,  0.06225586, -0.40234375,  ...,  0.43359375,\n",
      "           0.04565430, -0.05541992]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.27343750,  0.09765625, -0.01562500,  ...,  0.35742188,\n",
      "           0.54687500, -0.30273438],\n",
      "         [ 0.07763672, -0.01538086, -0.02233887,  ...,  0.31640625,\n",
      "           0.13964844, -0.03369141],\n",
      "         [ 0.28710938,  0.01562500, -0.12988281,  ...,  0.05395508,\n",
      "           0.12890625, -0.05908203],\n",
      "         ...,\n",
      "         [-0.05517578,  0.04272461,  0.19726562,  ..., -0.04516602,\n",
      "          -0.04296875,  0.25585938],\n",
      "         [-0.05517578,  0.04272461,  0.19726562,  ..., -0.04516602,\n",
      "          -0.04296875,  0.25585938],\n",
      "         [-0.05517578,  0.04272461,  0.19726562,  ..., -0.04516602,\n",
      "          -0.04296875,  0.25585938]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.42773438, -0.08837891, -0.05419922,  ...,  0.44335938,\n",
      "          -0.36718750,  0.49023438],\n",
      "         [ 0.69140625, -0.00738525,  0.40234375,  ..., -0.30468750,\n",
      "           0.17578125,  0.12353516],\n",
      "         [ 0.64062500, -0.16992188,  0.21582031,  ..., -0.40625000,\n",
      "           0.30078125,  0.19238281],\n",
      "         ...,\n",
      "         [ 0.06835938, -0.22656250, -0.16406250,  ...,  0.11328125,\n",
      "          -0.08203125, -0.10986328],\n",
      "         [ 0.06835938, -0.22656250, -0.16406250,  ...,  0.11328125,\n",
      "          -0.08203125, -0.10986328],\n",
      "         [ 0.06835938, -0.22656250, -0.16406250,  ...,  0.11328125,\n",
      "          -0.08203125, -0.10986328]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.04101562,  0.03466797,  0.03088379,  ...,  0.04199219,\n",
      "           0.22949219,  0.21484375],\n",
      "         [ 0.49804688, -0.07519531,  0.16308594,  ..., -0.27539062,\n",
      "          -0.36328125,  0.35351562],\n",
      "         [ 0.34960938, -0.25390625,  0.03149414,  ..., -0.16894531,\n",
      "          -0.34765625,  0.47851562],\n",
      "         ...,\n",
      "         [-0.05883789,  0.38476562,  0.24511719,  ..., -0.19628906,\n",
      "          -0.06225586,  0.36328125],\n",
      "         [-0.05883789,  0.38476562,  0.24511719,  ..., -0.19628906,\n",
      "          -0.06225586,  0.36328125],\n",
      "         [-0.05883789,  0.38476562,  0.24511719,  ..., -0.19628906,\n",
      "          -0.06225586,  0.36328125]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.07080078, -0.01220703,  0.19140625,  ..., -0.06738281,\n",
      "          -0.03002930,  0.18652344],\n",
      "         [-0.14062500, -0.04418945, -0.24414062,  ..., -0.61718750,\n",
      "          -0.12695312,  0.28320312],\n",
      "         [-0.02221680, -0.18164062, -0.20312500,  ..., -0.60156250,\n",
      "           0.14941406,  0.48828125],\n",
      "         ...,\n",
      "         [-0.12792969,  0.34570312, -0.14843750,  ...,  0.06689453,\n",
      "          -0.03833008,  0.17089844],\n",
      "         [-0.12792969,  0.34570312, -0.14843750,  ...,  0.06689453,\n",
      "          -0.03833008,  0.17089844],\n",
      "         [-0.12792969,  0.34570312, -0.14843750,  ...,  0.06689453,\n",
      "          -0.03833008,  0.17089844]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.00271606,  0.00381470, -0.05566406,  ...,  0.12451172,\n",
      "          -0.20703125, -0.23535156],\n",
      "         [-0.14257812,  0.33398438,  0.09277344,  ..., -0.11328125,\n",
      "           0.22949219, -0.51171875],\n",
      "         [-0.14746094,  0.20605469, -0.08740234,  ..., -0.20214844,\n",
      "           0.19921875, -0.02502441],\n",
      "         ...,\n",
      "         [-0.18066406,  0.31250000,  0.27539062,  ...,  0.13378906,\n",
      "           0.02722168, -0.10009766],\n",
      "         [-0.18066406,  0.31250000,  0.27539062,  ...,  0.13378906,\n",
      "           0.02722168, -0.10009766],\n",
      "         [-0.18066406,  0.31250000,  0.27539062,  ...,  0.13378906,\n",
      "           0.02722168, -0.10009766]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.06982422, -0.06176758,  0.09228516,  ..., -0.06494141,\n",
      "           0.09765625, -0.11328125],\n",
      "         [ 0.17285156,  0.20019531, -0.28515625,  ...,  0.08935547,\n",
      "          -0.09570312,  0.18261719],\n",
      "         [ 0.04833984, -0.03015137, -0.02062988,  ..., -0.08056641,\n",
      "          -0.08984375,  0.03588867],\n",
      "         ...,\n",
      "         [ 0.16699219, -0.06250000,  0.49804688,  ...,  0.06494141,\n",
      "          -0.17089844,  0.24023438],\n",
      "         [ 0.16699219, -0.06250000,  0.49804688,  ...,  0.06494141,\n",
      "          -0.17089844,  0.24023438],\n",
      "         [ 0.16699219, -0.06250000,  0.49804688,  ...,  0.06494141,\n",
      "          -0.17089844,  0.24023438]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.15039062, -0.00360107,  0.42187500,  ...,  0.02514648,\n",
      "          -0.03540039,  0.17187500],\n",
      "         [-0.40820312, -0.01104736,  0.01519775,  ..., -0.74218750,\n",
      "          -0.29296875,  0.06396484],\n",
      "         [-0.21777344, -0.19042969,  0.14843750,  ..., -0.56640625,\n",
      "          -0.19140625, -0.12792969],\n",
      "         ...,\n",
      "         [-0.46484375, -0.42187500,  0.06127930,  ..., -0.38476562,\n",
      "          -0.40234375,  0.64062500],\n",
      "         [-0.46484375, -0.42187500,  0.06127930,  ..., -0.38476562,\n",
      "          -0.40234375,  0.64062500],\n",
      "         [-0.46484375, -0.42187500,  0.06127930,  ..., -0.38476562,\n",
      "          -0.40234375,  0.64062500]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-1.01562500, -0.02978516,  0.04492188,  ..., -0.02087402,\n",
      "          -0.17675781,  0.07470703],\n",
      "         [-0.32812500,  0.45312500, -0.17675781,  ...,  0.12060547,\n",
      "           0.14746094,  0.20117188],\n",
      "         [-0.25976562,  0.18554688,  0.12597656,  ...,  0.38867188,\n",
      "           0.17382812,  0.50390625],\n",
      "         ...,\n",
      "         [-1.29687500, -0.25781250, -0.54687500,  ..., -0.50781250,\n",
      "           0.73046875,  0.29687500],\n",
      "         [-1.29687500, -0.25781250, -0.54687500,  ..., -0.50781250,\n",
      "           0.73046875,  0.29687500],\n",
      "         [-1.29687500, -0.25781250, -0.54687500,  ..., -0.50781250,\n",
      "           0.73046875,  0.29687500]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.74609375,  0.91015625, -0.09423828,  ..., -1.07812500,\n",
      "           0.36132812, -0.49414062],\n",
      "         [ 0.18847656,  0.06738281,  0.00152588,  ..., -0.91015625,\n",
      "          -0.40820312, -0.69140625],\n",
      "         [ 0.33007812, -0.30078125, -0.59765625,  ..., -0.65234375,\n",
      "          -0.82421875, -0.14257812],\n",
      "         ...,\n",
      "         [-0.26953125,  1.15625000, -0.97265625,  ..., -0.43554688,\n",
      "          -0.82812500, -1.21093750],\n",
      "         [-0.26953125,  1.15625000, -0.97265625,  ..., -0.43554688,\n",
      "          -0.82812500, -1.21093750],\n",
      "         [-0.26953125,  1.15625000, -0.97265625,  ..., -0.43554688,\n",
      "          -0.82812500, -1.21093750]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.36328125,  1.42187500,  0.32812500,  ..., -0.31640625,\n",
      "           0.37304688, -0.17285156],\n",
      "         [-1.16406250, -1.00781250, -0.62500000,  ...,  0.12060547,\n",
      "           1.48437500,  2.20312500],\n",
      "         [-1.54687500, -0.76953125, -0.87890625,  ..., -0.23535156,\n",
      "           1.28125000,  2.25000000],\n",
      "         ...,\n",
      "         [-0.66406250,  0.85937500, -0.92578125,  ..., -0.53125000,\n",
      "           0.40039062,  0.50000000],\n",
      "         [-0.66406250,  0.85937500, -0.92578125,  ..., -0.53125000,\n",
      "           0.40039062,  0.50000000],\n",
      "         [-0.66406250,  0.85937500, -0.92578125,  ..., -0.53125000,\n",
      "           0.40039062,  0.50000000]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.48242188, -0.09130859,  0.46093750,  ...,  0.40820312,\n",
      "           0.18750000,  0.03369141],\n",
      "         [-0.48632812, -0.25585938,  0.50390625,  ...,  0.25585938,\n",
      "          -0.06201172, -0.03881836],\n",
      "         [-0.41210938, -0.40429688,  0.33398438,  ..., -0.02514648,\n",
      "           0.22265625, -0.12451172],\n",
      "         ...,\n",
      "         [-0.35351562, -0.04687500,  0.47851562,  ...,  0.20996094,\n",
      "           0.55078125, -0.11767578],\n",
      "         [-0.35351562, -0.04687500,  0.47851562,  ...,  0.20996094,\n",
      "           0.55078125, -0.11767578],\n",
      "         [-0.35351562, -0.04687500,  0.47851562,  ...,  0.20996094,\n",
      "           0.55078125, -0.11767578]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.98437500,  0.21972656, -0.22753906,  ..., -0.38085938,\n",
      "          -0.35546875, -0.84765625],\n",
      "         [-0.73437500, -0.21582031, -0.06445312,  ...,  0.23437500,\n",
      "           1.06250000,  0.30664062],\n",
      "         [-0.08398438,  0.57031250, -0.31054688,  ...,  0.13964844,\n",
      "           1.17968750,  0.27539062],\n",
      "         ...,\n",
      "         [-1.82812500,  0.09765625, -1.66406250,  ...,  0.74218750,\n",
      "          -0.18457031, -0.83984375],\n",
      "         [-1.82812500,  0.09765625, -1.66406250,  ...,  0.74218750,\n",
      "          -0.18457031, -0.83984375],\n",
      "         [-1.82812500,  0.09765625, -1.66406250,  ...,  0.74218750,\n",
      "          -0.18457031, -0.83984375]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-1.07421875e-01, -1.03125000e+00,  4.82421875e-01,  ...,\n",
      "           6.67968750e-01,  9.71679688e-02, -3.96484375e-01],\n",
      "         [ 1.10156250e+00, -3.17187500e+00,  4.31640625e-01,  ...,\n",
      "           1.61718750e+00,  1.87500000e-01,  1.36718750e-01],\n",
      "         [ 7.61718750e-01, -2.56250000e+00,  2.08007812e-01,  ...,\n",
      "           1.14843750e+00,  5.50781250e-01, -2.89916992e-03],\n",
      "         ...,\n",
      "         [ 1.15234375e-01, -4.27734375e-01,  1.46484375e-01,  ...,\n",
      "          -7.85827637e-04,  5.70312500e-01, -3.18359375e-01],\n",
      "         [ 1.15234375e-01, -4.27734375e-01,  1.46484375e-01,  ...,\n",
      "          -7.85827637e-04,  5.70312500e-01, -3.18359375e-01],\n",
      "         [ 1.15234375e-01, -4.27734375e-01,  1.46484375e-01,  ...,\n",
      "          -7.85827637e-04,  5.70312500e-01, -3.18359375e-01]]],\n",
      "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.06835938, -0.08496094,  0.13574219,  ..., -0.17089844,\n",
      "           0.56250000,  0.15722656],\n",
      "         [ 0.40429688,  0.10791016, -0.29492188,  ...,  0.20019531,\n",
      "          -0.16113281,  0.41406250],\n",
      "         [ 0.04980469, -0.14941406, -0.53125000,  ..., -0.09912109,\n",
      "          -0.18261719,  0.19921875],\n",
      "         ...,\n",
      "         [ 0.43164062, -0.59375000, -0.68750000,  ..., -0.19921875,\n",
      "          -0.55468750,  0.51953125],\n",
      "         [ 0.43164062, -0.59375000, -0.68750000,  ..., -0.19921875,\n",
      "          -0.55468750,  0.51953125],\n",
      "         [ 0.43164062, -0.59375000, -0.68750000,  ..., -0.19921875,\n",
      "          -0.55468750,  0.51953125]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.02539062, -0.07763672,  0.21289062,  ..., -0.05249023,\n",
      "           0.26562500, -0.14941406],\n",
      "         [ 0.49804688, -0.39257812,  0.00952148,  ...,  0.64062500,\n",
      "          -0.53515625, -0.23632812],\n",
      "         [ 0.52734375,  0.44921875, -0.12695312,  ...,  0.48437500,\n",
      "          -1.07031250, -0.54296875],\n",
      "         ...,\n",
      "         [-0.35937500,  1.87500000, -0.53515625,  ..., -1.00781250,\n",
      "          -0.27929688, -0.83203125],\n",
      "         [-0.35937500,  1.87500000, -0.53515625,  ..., -1.00781250,\n",
      "          -0.27929688, -0.83203125],\n",
      "         [-0.35937500,  1.87500000, -0.53515625,  ..., -1.00781250,\n",
      "          -0.27929688, -0.83203125]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[ 0.54687500,  0.21679688,  0.05273438,  ...,  0.29296875,\n",
      "          -0.31250000, -0.18750000],\n",
      "         [-0.13574219, -0.22460938,  0.41601562,  ...,  0.31640625,\n",
      "          -0.33789062,  0.21875000],\n",
      "         [ 0.15917969,  0.24023438,  0.25976562,  ...,  0.20019531,\n",
      "          -0.46484375,  0.07910156],\n",
      "         ...,\n",
      "         [-0.51562500, -0.89843750, -0.34960938,  ..., -0.14257812,\n",
      "           0.13378906,  0.87500000],\n",
      "         [-0.51562500, -0.89843750, -0.34960938,  ..., -0.14257812,\n",
      "           0.13378906,  0.87500000],\n",
      "         [-0.51562500, -0.89843750, -0.34960938,  ..., -0.14257812,\n",
      "           0.13378906,  0.87500000]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.94531250,  0.49609375,  0.21191406,  ...,  0.03222656,\n",
      "          -0.48242188,  0.06396484],\n",
      "         [-0.68750000,  0.75000000, -0.03808594,  ..., -0.71484375,\n",
      "          -0.66015625,  0.73046875],\n",
      "         [-0.46484375,  0.32812500,  0.40625000,  ..., -0.75390625,\n",
      "          -0.40039062,  0.85156250],\n",
      "         ...,\n",
      "         [ 0.15332031, -0.22753906, -0.33984375,  ..., -0.34375000,\n",
      "          -0.58984375, -0.15234375],\n",
      "         [ 0.15332031, -0.22753906, -0.33984375,  ..., -0.34375000,\n",
      "          -0.58984375, -0.15234375],\n",
      "         [ 0.15332031, -0.22753906, -0.33984375,  ..., -0.34375000,\n",
      "          -0.58984375, -0.15234375]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "torch torch.Size([1, 4128, 1280]) tensor([[[-0.63281250,  0.87890625,  0.66796875,  ...,  0.61328125,\n",
      "           0.17480469, -2.09375000],\n",
      "         [-0.58203125, -1.17968750,  1.18750000,  ..., -0.19433594,\n",
      "           0.83203125,  0.83203125],\n",
      "         [-1.21875000, -1.93750000,  0.50000000,  ...,  0.02380371,\n",
      "           0.55468750,  0.29687500],\n",
      "         ...,\n",
      "         [-0.59765625, -2.34375000,  0.19824219,  ..., -0.12695312,\n",
      "           0.96875000, -0.37890625],\n",
      "         [-0.59765625, -2.34375000,  0.19824219,  ..., -0.12695312,\n",
      "           0.96875000, -0.37890625],\n",
      "         [-0.59765625, -2.34375000,  0.19824219,  ..., -0.12695312,\n",
      "           0.96875000, -0.37890625]]], device='cuda:0', dtype=torch.bfloat16,\n",
      "       grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "inputs_jax = processor(images=image, return_tensors=\"jax\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "output_torch = model_torch(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jax (1, 4128, 1280) [[[-0.253906 -0.0654297 -0.0266113 ... 0.255859 -0.0126343 0.310547]\n",
      "  [-0.330078 -0.0166016 0.0986328 ... 0.22168 -0.0991211 0.480469]\n",
      "  [-0.341797 -0.0205078 0.111816 ... 0.220703 -0.104492 0.476562]\n",
      "  ...\n",
      "  [-0.539062 0.0266113 0.165039 ... 0.178711 -0.0561523 -0.0537109]\n",
      "  [-0.539062 0.0266113 0.165039 ... 0.178711 -0.0561523 -0.0537109]\n",
      "  [-0.539062 0.0266113 0.165039 ... 0.178711 -0.0561523 -0.0537109]]]\n",
      "jax (1, 4128, 1280) [[[-0.0515137 -0.0154419 -0.060791 ... 0.0239258 0.09375 -0.00466919]\n",
      "  [-0.181641 -0.0186768 -0.0498047 ... 0.0639648 0.298828 -0.0529785]\n",
      "  [-0.193359 -0.0236816 -0.0301514 ... 0.0600586 0.341797 -0.0429688]\n",
      "  ...\n",
      "  [0.057373 -0.000492096 -0.195312 ... -0.074707 0.114746 -0.118652]\n",
      "  [0.057373 -0.000492096 -0.195312 ... -0.074707 0.114746 -0.118652]\n",
      "  [0.057373 -0.000492096 -0.195312 ... -0.074707 0.114746 -0.118652]]]\n",
      "jax (1, 4128, 1280) [[[-0.0291748 0.10498 -0.0625 ... 0.0383301 -0.109863 -0.176758]\n",
      "  [-0.0311279 -0.0493164 -0.109375 ... -0.145508 -0.00619507 -0.0231934]\n",
      "  [-0.0236816 0.0197754 -0.0117798 ... -0.0717773 0.0473633 -0.0334473]\n",
      "  ...\n",
      "  [0.345703 -0.173828 -0.0820312 ... 0.165039 -0.0388184 -0.151367]\n",
      "  [0.345703 -0.173828 -0.0820312 ... 0.165039 -0.0388184 -0.151367]\n",
      "  [0.345703 -0.173828 -0.0820312 ... 0.165039 -0.0388184 -0.151367]]]\n",
      "jax (1, 4128, 1280) [[[0.261719 -0.216797 0.105957 ... 0.224609 0.0874023 0.0776367]\n",
      "  [0.25 -0.355469 -0.0270996 ... 0.120117 -0.0187988 0.185547]\n",
      "  [0.445312 -0.554688 0.332031 ... 0.332031 0.090332 0.291016]\n",
      "  ...\n",
      "  [0.582031 -0.326172 0.0698242 ... 0.0134888 0.294922 0.0693359]\n",
      "  [0.582031 -0.326172 0.0698242 ... 0.0134888 0.294922 0.0693359]\n",
      "  [0.582031 -0.326172 0.0698242 ... 0.0134888 0.294922 0.0693359]]]\n",
      "jax (1, 4128, 1280) [[[0.0167236 -0.18457 -0.199219 ... 0.0913086 0.181641 -0.0441895]\n",
      "  [0.132812 -0.18457 -0.423828 ... -0.0859375 -0.285156 -0.0402832]\n",
      "  [0.154297 -0.130859 -0.402344 ... 0.133789 -0.115723 -0.0349121]\n",
      "  ...\n",
      "  [0.388672 -0.216797 -0.0439453 ... 0.0541992 -0.034668 0.0140381]\n",
      "  [0.388672 -0.216797 -0.0439453 ... 0.0541992 -0.034668 0.0140381]\n",
      "  [0.388672 -0.216797 -0.0439453 ... 0.0541992 -0.034668 0.0140381]]]\n",
      "jax (1, 4128, 1280) [[[0.110352 -0.267578 -0.0683594 ... 0.0556641 -0.00105286 -0.115234]\n",
      "  [0.126953 0.0722656 -0.19043 ... 0.119629 0.0625 -0.255859]\n",
      "  [0.0683594 0.0991211 -0.242188 ... 0.074707 0.0349121 -0.296875]\n",
      "  ...\n",
      "  [0.460938 -0.161133 -0.0143433 ... -0.0233154 0.102051 -0.177734]\n",
      "  [0.460938 -0.161133 -0.0143433 ... -0.0233154 0.102051 -0.177734]\n",
      "  [0.460938 -0.161133 -0.0143433 ... -0.0233154 0.102051 -0.177734]]]\n",
      "jax (1, 4128, 1280) [[[0.605469 0.0227051 0.036377 ... -0.11084 0.273438 0.0874023]\n",
      "  [-0.00506592 -0.523438 0.0712891 ... -0.400391 -0.0549316 0.00582886]\n",
      "  [0.375 -0.0654297 0.251953 ... -0.302734 -0.110352 -0.417969]\n",
      "  ...\n",
      "  [0.710938 0.0228271 0.020874 ... -0.267578 -0.0583496 -0.195312]\n",
      "  [0.710938 0.0228271 0.020874 ... -0.267578 -0.0583496 -0.195312]\n",
      "  [0.710938 0.0228271 0.020874 ... -0.267578 -0.0583496 -0.195312]]]\n",
      "jax (1, 4128, 1280) [[[0.205078 0.392578 -0.121094 ... -0.182617 0.1875 -0.125]\n",
      "  [-0.0864258 0.296875 -0.320312 ... 0.227539 -0.11377 -0.0510254]\n",
      "  [-0.0571289 0.320312 -0.162109 ... 0.0168457 0.0151367 -0.0717773]\n",
      "  ...\n",
      "  [0.242188 0.330078 -0.0996094 ... -0.285156 0.125 -0.245117]\n",
      "  [0.242188 0.330078 -0.0996094 ... -0.285156 0.125 -0.245117]\n",
      "  [0.242188 0.330078 -0.0996094 ... -0.285156 0.125 -0.245117]]]\n",
      "jax (1, 4128, 1280) [[[-0.253906 -0.365234 -0.208008 ... -0.111816 -0.332031 -0.0693359]\n",
      "  [0.425781 0.273438 0.365234 ... 0.189453 -0.404297 -0.24707]\n",
      "  [-0.0458984 0.179688 0.157227 ... 0.0290527 -0.488281 -0.488281]\n",
      "  ...\n",
      "  [-0.0444336 -0.330078 0.106934 ... -0.0563965 -0.3125 -0.0169678]\n",
      "  [-0.0444336 -0.330078 0.106934 ... -0.0563965 -0.3125 -0.0169678]\n",
      "  [-0.0444336 -0.330078 0.106934 ... -0.0563965 -0.3125 -0.0169678]]]\n",
      "jax (1, 4128, 1280) [[[-0.175781 0.367188 0.10791 ... -0.241211 0.380859 0.128906]\n",
      "  [-0.796875 0.515625 0.640625 ... 0.291016 -0.0267334 0.208008]\n",
      "  [-0.796875 0.710938 0.597656 ... 0.40625 -0.380859 0.322266]\n",
      "  ...\n",
      "  [-0.0510254 0.283203 -0.0301514 ... -0.0708008 0.259766 -0.0795898]\n",
      "  [-0.0510254 0.283203 -0.0301514 ... -0.0708008 0.259766 -0.0795898]\n",
      "  [-0.0510254 0.283203 -0.0301514 ... -0.0708008 0.259766 -0.0795898]]]\n",
      "jax (1, 4128, 1280) [[[-0.181641 -0.104492 0.0629883 ... 0.0688477 0.232422 -0.147461]\n",
      "  [-1.10938 -0.859375 -0.265625 ... 0.136719 -0.147461 -0.453125]\n",
      "  [-1.15625 -1 -0.472656 ... -0.0639648 0.0244141 -0.233398]\n",
      "  ...\n",
      "  [-0.0830078 -0.455078 0.292969 ... -0.0164795 0.3125 0.0593262]\n",
      "  [-0.0830078 -0.455078 0.292969 ... -0.0164795 0.3125 0.0593262]\n",
      "  [-0.0830078 -0.455078 0.292969 ... -0.0164795 0.3125 0.0593262]]]\n",
      "jax (1, 4128, 1280) [[[-0.357422 -0.241211 0.353516 ... -0.195312 -0.169922 0.439453]\n",
      "  [-0.523438 -0.566406 -0.267578 ... 0.0246582 -0.632812 0.251953]\n",
      "  [0.11377 -0.296875 -0.373047 ... 0.90625 -0.515625 0.447266]\n",
      "  ...\n",
      "  [-0.371094 -0.208008 0.296875 ... 0.045166 0.0688477 0.361328]\n",
      "  [-0.371094 -0.208008 0.296875 ... 0.045166 0.0688477 0.361328]\n",
      "  [-0.371094 -0.208008 0.296875 ... 0.045166 0.0688477 0.361328]]]\n",
      "jax (1, 4128, 1280) [[[-0.109863 -0.136719 -0.273438 ... -0.12207 0.0230713 -0.287109]\n",
      "  [0.294922 -0.0500488 -0.140625 ... 0.0756836 0.125977 -0.523438]\n",
      "  [0.0288086 -0.458984 -0.189453 ... 0.263672 0.292969 -0.277344]\n",
      "  ...\n",
      "  [0.223633 -0.114746 -0.131836 ... -0.118164 0.298828 -0.209961]\n",
      "  [0.223633 -0.114746 -0.131836 ... -0.118164 0.298828 -0.209961]\n",
      "  [0.223633 -0.114746 -0.131836 ... -0.118164 0.298828 -0.209961]]]\n",
      "jax (1, 4128, 1280) [[[-0.172852 -0.129883 -0.302734 ... -0.0698242 -0.0913086 -0.339844]\n",
      "  [0.835938 0.223633 -0.300781 ... 0.0444336 -0.0397949 -0.691406]\n",
      "  [1.10156 0.206055 -0.104492 ... 0.365234 0.0649414 -0.71875]\n",
      "  ...\n",
      "  [0.621094 0.081543 0.0957031 ... 0.0786133 0.339844 -0.0164795]\n",
      "  [0.621094 0.081543 0.0957031 ... 0.0786133 0.339844 -0.0164795]\n",
      "  [0.621094 0.081543 0.0957031 ... 0.0786133 0.339844 -0.0164795]]]\n",
      "jax (1, 4128, 1280) [[[0.200195 0.0952148 -0.0393066 ... 0.486328 0.503906 -0.382812]\n",
      "  [-0.761719 0.433594 -0.523438 ... -1.42188 0.21875 1.07031]\n",
      "  [-0.769531 0.271484 -0.585938 ... -0.9375 0.310547 0.851562]\n",
      "  ...\n",
      "  [0.163086 0.574219 -0.455078 ... 0.00958252 0.5625 -0.0402832]\n",
      "  [0.163086 0.574219 -0.455078 ... 0.00958252 0.5625 -0.0402832]\n",
      "  [0.163086 0.574219 -0.455078 ... 0.00958252 0.5625 -0.0402832]]]\n",
      "jax (1, 4128, 1280) [[[-0.349609 -1.15625 -0.335938 ... -0.535156 0.0488281 0.125977]\n",
      "  [0.255859 -0.664062 -0.0563965 ... -0.925781 0.109863 0.214844]\n",
      "  [-0.0181885 -1.08594 -0.455078 ... -1.25781 0.105469 0.263672]\n",
      "  ...\n",
      "  [-0.0844727 -0.408203 -0.345703 ... 0.21582 -0.132812 0.196289]\n",
      "  [-0.0844727 -0.408203 -0.345703 ... 0.21582 -0.132812 0.196289]\n",
      "  [-0.0844727 -0.408203 -0.345703 ... 0.21582 -0.132812 0.196289]]]\n",
      "jax (1, 4128, 1280) [[[0.535156 0.0786133 -1.29688 ... 0.480469 -0.482422 -0.40625]\n",
      "  [-0.267578 0.21875 -0.578125 ... -0.496094 -0.101074 -0.0385742]\n",
      "  [-0.582031 0.398438 -0.421875 ... -0.585938 0.059082 0.234375]\n",
      "  ...\n",
      "  [0.472656 0.0688477 -0.117188 ... 0.302734 -0.0144043 -0.0849609]\n",
      "  [0.472656 0.0688477 -0.117188 ... 0.302734 -0.0144043 -0.0849609]\n",
      "  [0.472656 0.0688477 -0.117188 ... 0.302734 -0.0144043 -0.0849609]]]\n",
      "jax (1, 4128, 1280) [[[-1.6875 0.204102 1.07031 ... -0.376953 0.0522461 0.161133]\n",
      "  [-0.789062 0.163086 0.316406 ... -0.202148 0.163086 -0.578125]\n",
      "  [-0.207031 -0.628906 0.367188 ... -0.240234 -0.213867 -0.96875]\n",
      "  ...\n",
      "  [-0.154297 -0.632812 0.269531 ... -0.25 0.168945 0.154297]\n",
      "  [-0.154297 -0.632812 0.269531 ... -0.25 0.168945 0.154297]\n",
      "  [-0.154297 -0.632812 0.269531 ... -0.25 0.168945 0.154297]]]\n",
      "jax (1, 4128, 1280) [[[0.601562 -0.207031 0.486328 ... -0.126953 0.143555 -0.390625]\n",
      "  [-0.480469 0.699219 0.00872803 ... -0.00280762 -0.140625 -0.628906]\n",
      "  [-0.441406 0.589844 -0.0446777 ... -0.449219 -0.123535 -0.0444336]\n",
      "  ...\n",
      "  [0.365234 -0.34375 -0.188477 ... 0.0349121 -0.220703 -0.118164]\n",
      "  [0.365234 -0.34375 -0.188477 ... 0.0349121 -0.220703 -0.118164]\n",
      "  [0.365234 -0.34375 -0.188477 ... 0.0349121 -0.220703 -0.118164]]]\n",
      "jax (1, 4128, 1280) [[[0.507812 0.0498047 0.0109253 ... 0.145508 -0.169922 -0.00680542]\n",
      "  [-0.0668945 -0.0280762 -0.263672 ... 0.294922 -0.613281 0.117188]\n",
      "  [-0.0664062 -0.679688 0.314453 ... 0.478516 -0.683594 -0.12207]\n",
      "  ...\n",
      "  [0.59375 -0.149414 -0.384766 ... 0.134766 0.189453 -0.147461]\n",
      "  [0.59375 -0.149414 -0.384766 ... 0.134766 0.189453 -0.147461]\n",
      "  [0.59375 -0.149414 -0.384766 ... 0.134766 0.189453 -0.147461]]]\n",
      "jax (1, 4128, 1280) [[[0.0224609 0.273438 -0.429688 ... -0.0505371 -0.320312 -0.059082]\n",
      "  [0.332031 -0.15625 0.0554199 ... 0.0213623 -0.249023 -0.402344]\n",
      "  [0.871094 -0.155273 0.164062 ... -0.203125 -0.15918 -0.476562]\n",
      "  ...\n",
      "  [0.0120239 0.257812 -0.176758 ... -0.105469 -0.0810547 -0.398438]\n",
      "  [0.0120239 0.257812 -0.176758 ... -0.105469 -0.0810547 -0.398438]\n",
      "  [0.0120239 0.257812 -0.176758 ... -0.105469 -0.0810547 -0.398438]]]\n",
      "jax (1, 4128, 1280) [[[0.239258 0.324219 -0.210938 ... 0.28125 0.140625 -0.0839844]\n",
      "  [0.394531 0.298828 -0.667969 ... 0.53125 -0.0727539 0.165039]\n",
      "  [0.209961 0.226562 -0.511719 ... 0.394531 -0.00994873 0.151367]\n",
      "  ...\n",
      "  [0.0446777 0.0639648 -0.402344 ... 0.435547 0.0427246 -0.0534668]\n",
      "  [0.0446777 0.0639648 -0.402344 ... 0.435547 0.0427246 -0.0534668]\n",
      "  [0.0446777 0.0639648 -0.402344 ... 0.435547 0.0427246 -0.0534668]]]\n",
      "jax (1, 4128, 1280) [[[0.275391 0.0922852 -0.015625 ... 0.357422 0.546875 -0.294922]\n",
      "  [0.0727539 -0.0180664 -0.0217285 ... 0.308594 0.140625 -0.0349121]\n",
      "  [0.289062 0.0128174 -0.122559 ... 0.0644531 0.125977 -0.0563965]\n",
      "  ...\n",
      "  [-0.0568848 0.0476074 0.198242 ... -0.0429688 -0.0446777 0.255859]\n",
      "  [-0.0568848 0.0476074 0.198242 ... -0.0429688 -0.0446777 0.255859]\n",
      "  [-0.0568848 0.0476074 0.198242 ... -0.0429688 -0.0446777 0.255859]]]\n",
      "jax (1, 4128, 1280) [[[0.417969 -0.0791016 -0.0622559 ... 0.447266 -0.373047 0.472656]\n",
      "  [0.695312 -0.00686646 0.388672 ... -0.3125 0.158203 0.132812]\n",
      "  [0.644531 -0.163086 0.21582 ... -0.392578 0.285156 0.192383]\n",
      "  ...\n",
      "  [0.0678711 -0.224609 -0.163086 ... 0.112793 -0.081543 -0.111328]\n",
      "  [0.0678711 -0.224609 -0.163086 ... 0.112793 -0.081543 -0.111328]\n",
      "  [0.0678711 -0.224609 -0.163086 ... 0.112793 -0.081543 -0.111328]]]\n",
      "jax (1, 4128, 1280) [[[0.0397949 0.0356445 0.036377 ... 0.0395508 0.228516 0.213867]\n",
      "  [0.507812 -0.0913086 0.147461 ... -0.253906 -0.335938 0.347656]\n",
      "  [0.373047 -0.253906 0.0388184 ... -0.19043 -0.367188 0.484375]\n",
      "  ...\n",
      "  [-0.0588379 0.388672 0.245117 ... -0.196289 -0.0649414 0.363281]\n",
      "  [-0.0588379 0.388672 0.245117 ... -0.196289 -0.0649414 0.363281]\n",
      "  [-0.0588379 0.388672 0.245117 ... -0.196289 -0.0649414 0.363281]]]\n",
      "jax (1, 4128, 1280) [[[0.0737305 -0.0115967 0.188477 ... -0.0688477 -0.0292969 0.183594]\n",
      "  [-0.144531 -0.0344238 -0.246094 ... -0.601562 -0.131836 0.294922]\n",
      "  [-0.0196533 -0.183594 -0.203125 ... -0.609375 0.147461 0.474609]\n",
      "  ...\n",
      "  [-0.128906 0.341797 -0.146484 ... 0.0693359 -0.0393066 0.171875]\n",
      "  [-0.128906 0.341797 -0.146484 ... 0.0693359 -0.0393066 0.171875]\n",
      "  [-0.128906 0.341797 -0.146484 ... 0.0693359 -0.0393066 0.171875]]]\n",
      "jax (1, 4128, 1280) [[[-0.00125885 -0.00198364 -0.0544434 ... 0.121094 -0.205078 -0.233398]\n",
      "  [-0.133789 0.322266 0.0820312 ... -0.104004 0.225586 -0.484375]\n",
      "  [-0.157227 0.213867 -0.0693359 ... -0.198242 0.208984 -0.0446777]\n",
      "  ...\n",
      "  [-0.177734 0.3125 0.273438 ... 0.130859 0.0227051 -0.100586]\n",
      "  [-0.177734 0.3125 0.273438 ... 0.130859 0.0227051 -0.100586]\n",
      "  [-0.177734 0.3125 0.273438 ... 0.130859 0.0227051 -0.100586]]]\n",
      "jax (1, 4128, 1280) [[[-0.0639648 -0.0603027 0.0961914 ... -0.0617676 0.100586 -0.113281]\n",
      "  [0.15332 0.175781 -0.277344 ... 0.0654297 -0.112305 0.174805]\n",
      "  [0.050293 -0.0247803 -0.03125 ... -0.0756836 -0.0932617 0.0439453]\n",
      "  ...\n",
      "  [0.168945 -0.0617676 0.490234 ... 0.065918 -0.173828 0.246094]\n",
      "  [0.168945 -0.0617676 0.490234 ... 0.065918 -0.173828 0.246094]\n",
      "  [0.168945 -0.0617676 0.490234 ... 0.065918 -0.173828 0.246094]]]\n",
      "jax (1, 4128, 1280) [[[0.143555 -0.0100098 0.419922 ... 0.0214844 -0.0424805 0.172852]\n",
      "  [-0.419922 -0.00897217 0.0220947 ... -0.71875 -0.271484 0.0534668]\n",
      "  [-0.226562 -0.19043 0.141602 ... -0.570312 -0.204102 -0.109375]\n",
      "  ...\n",
      "  [-0.46875 -0.421875 0.057373 ... -0.380859 -0.410156 0.636719]\n",
      "  [-0.46875 -0.421875 0.057373 ... -0.380859 -0.410156 0.636719]\n",
      "  [-0.46875 -0.421875 0.057373 ... -0.380859 -0.410156 0.636719]]]\n",
      "jax (1, 4128, 1280) [[[-1.01562 -0.0344238 0.0583496 ... -0.0172119 -0.179688 0.0703125]\n",
      "  [-0.296875 0.453125 -0.15625 ... 0.131836 0.150391 0.196289]\n",
      "  [-0.259766 0.192383 0.132812 ... 0.386719 0.178711 0.5]\n",
      "  ...\n",
      "  [-1.29688 -0.265625 -0.546875 ... -0.511719 0.71875 0.296875]\n",
      "  [-1.29688 -0.265625 -0.546875 ... -0.511719 0.71875 0.296875]\n",
      "  [-1.29688 -0.265625 -0.546875 ... -0.511719 0.71875 0.296875]]]\n",
      "jax (1, 4128, 1280) [[[-0.730469 0.917969 -0.0878906 ... -1.07031 0.345703 -0.492188]\n",
      "  [0.164062 0.106934 -0.0201416 ... -0.914062 -0.40625 -0.730469]\n",
      "  [0.326172 -0.285156 -0.527344 ... -0.644531 -0.769531 -0.167969]\n",
      "  ...\n",
      "  [-0.255859 1.16406 -0.953125 ... -0.433594 -0.839844 -1.21875]\n",
      "  [-0.255859 1.16406 -0.953125 ... -0.433594 -0.839844 -1.21875]\n",
      "  [-0.255859 1.16406 -0.953125 ... -0.433594 -0.839844 -1.21875]]]\n",
      "jax (1, 4128, 1280) [[[0.351562 1.41406 0.332031 ... -0.316406 0.384766 -0.1875]\n",
      "  [-1.20312 -0.96875 -0.679688 ... 0.0756836 1.40625 2.0625]\n",
      "  [-1.60156 -0.839844 -0.898438 ... -0.234375 1.35938 2.3125]\n",
      "  ...\n",
      "  [-0.671875 0.863281 -0.917969 ... -0.542969 0.398438 0.496094]\n",
      "  [-0.671875 0.863281 -0.917969 ... -0.542969 0.398438 0.496094]\n",
      "  [-0.671875 0.863281 -0.917969 ... -0.542969 0.398438 0.496094]]]\n",
      "jax (1, 4128, 1280) [[[-0.480469 -0.0888672 0.470703 ... 0.416016 0.1875 0.0327148]\n",
      "  [-0.474609 -0.283203 0.464844 ... 0.232422 0.00271606 -0.0834961]\n",
      "  [-0.416016 -0.390625 0.371094 ... -0.0125732 0.206055 -0.0961914]\n",
      "  ...\n",
      "  [-0.357422 -0.0400391 0.486328 ... 0.204102 0.546875 -0.116211]\n",
      "  [-0.357422 -0.0400391 0.486328 ... 0.204102 0.546875 -0.116211]\n",
      "  [-0.357422 -0.0400391 0.486328 ... 0.204102 0.546875 -0.116211]]]\n",
      "jax (1, 4128, 1280) [[[-0.224609 -1.24219 -0.679688 ... 1.82812 0.443359 -0.273438]\n",
      "  [1.20312 -0.679688 -0.114746 ... 1.32812 0.367188 0.416016]\n",
      "  [1.67969 -0.628906 -0.423828 ... 1.57031 0.878906 0.566406]\n",
      "  ...\n",
      "  [-0.617188 -1 -1.5625 ... 2.17188 0.230469 -0.363281]\n",
      "  [-0.617188 -1 -1.5625 ... 2.17188 0.230469 -0.363281]\n",
      "  [-0.617188 -1 -1.5625 ... 2.17188 0.230469 -0.363281]]]\n",
      "jax (1, 4128, 1280) [[[0.578125 -1.46094 0.128906 ... 0.447266 -0.828125 0.102051]\n",
      "  [0.816406 -1.35156 0.204102 ... 0.757812 -0.0952148 0.462891]\n",
      "  [0.660156 -0.75 0.244141 ... 0.353516 -0.15625 0.392578]\n",
      "  ...\n",
      "  [0.347656 -1.21875 0.0371094 ... -0.118164 -0.597656 0.0869141]\n",
      "  [0.347656 -1.21875 0.0371094 ... -0.118164 -0.597656 0.0869141]\n",
      "  [0.347656 -1.21875 0.0371094 ... -0.118164 -0.597656 0.0869141]]]\n",
      "jax (1, 4128, 1280) [[[0.511719 -1.26562 2.8125 ... 1.02344 -0.285156 2.42188]\n",
      "  [-0.119629 -1.48438 2.79688 ... 0.871094 -0.419922 1.88281]\n",
      "  [-0.244141 -1.67188 2.76562 ... 0.835938 -0.40625 1.97656]\n",
      "  ...\n",
      "  [-0.318359 -2.01562 2.875 ... 0.707031 0.0603027 2.375]\n",
      "  [-0.318359 -2.01562 2.875 ... 0.707031 0.0603027 2.375]\n",
      "  [-0.318359 -2.01562 2.875 ... 0.707031 0.0603027 2.375]]]\n",
      "jax (1, 4128, 1280) [[[1.80469 8.1875 2.8125 ... 3.70312 -2.14062 0.535156]\n",
      "  [1.69531 7.46875 2.85938 ... 3.51562 -1.58594 0.589844]\n",
      "  [1.53125 6.875 2.92188 ... 3.57812 -1.30469 0.824219]\n",
      "  ...\n",
      "  [1.75781 8.875 2.48438 ... 3.23438 -2.79688 0.460938]\n",
      "  [1.75781 8.875 2.48438 ... 3.23438 -2.79688 0.460938]\n",
      "  [1.75781 8.875 2.48438 ... 3.23438 -2.79688 0.460938]]]\n",
      "jax (1, 4128, 1280) [[[-2.23438 -5.4375 -2.79688 ... -1.875 2.65625 -1.50781]\n",
      "  [-2.17188 -4.71875 -2.92188 ... -1.67969 2.40625 -2.0625]\n",
      "  [-2.25 -4.6875 -2.75 ... -1.75 2.375 -2.14062]\n",
      "  ...\n",
      "  [-2.14062 -5.03125 -3.09375 ... -1.78125 2.57812 -2]\n",
      "  [-2.14062 -5.03125 -3.09375 ... -1.78125 2.57812 -2]\n",
      "  [-2.14062 -5.03125 -3.09375 ... -1.78125 2.57812 -2]]]\n",
      "jax (1, 4128, 1280) [[[-1.04688 3 1.39844 ... -3.04688 -3.125 2.125]\n",
      "  [-1.10156 2.78125 1.80469 ... -3.21875 -2.96875 1.79688]\n",
      "  [-0.613281 2.82812 1.82031 ... -3.39062 -3.04688 1.67969]\n",
      "  ...\n",
      "  [-1.82031 2.51562 1.24219 ... -3.0625 -3.6875 1.96875]\n",
      "  [-1.82031 2.51562 1.24219 ... -3.0625 -3.6875 1.96875]\n",
      "  [-1.82031 2.51562 1.24219 ... -3.0625 -3.6875 1.96875]]]\n",
      "jax (1, 4128, 1280) [[[4.6875 -4.8125 -5.53125 ... -1.72656 1.08594 1.375]\n",
      "  [3.60938 -4.71875 -4.59375 ... -2.26562 1.35156 1.79688]\n",
      "  [3.21875 -4.8125 -4.65625 ... -2.09375 1.21094 1.96875]\n",
      "  ...\n",
      "  [4.4375 -4.9375 -5.90625 ... -1.99219 1.3125 2.03125]\n",
      "  [4.4375 -4.9375 -5.90625 ... -1.99219 1.3125 2.03125]\n",
      "  [4.4375 -4.9375 -5.90625 ... -1.99219 1.3125 2.03125]]]\n"
     ]
    }
   ],
   "source": [
    "output_jax = model(**inputs_jax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MllamaVisionModel, FlaxMllamaVisionModel\n",
    "from transformers import AutoProcessor, MllamaTextModel\n",
    "import requests\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image\n",
    "from huggingface_hub import login\n",
    "torch.set_printoptions(precision=8)\n",
    "jax.numpy.set_printoptions(precision=10)\n",
    "\n",
    "hf_token = \"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\"\n",
    "login(hf_token)\n",
    "checkpoint = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs_jax = processor(images=image, return_tensors=\"jax\")\n",
    "inputs = processor(images=image, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "\n",
    "def _prepare_aspect_ratio_attention_mask_jax(\n",
    "    aspect_ratio_mask: jnp.ndarray,\n",
    "    num_patches: int,\n",
    "    target_length: int,\n",
    "    dtype: jnp.dtype,\n",
    ") -> jnp.ndarray:\n",
    "    # Expand aspect ratio mask to target_length\n",
    "    batch_size, max_num_tiles = aspect_ratio_mask.shape\n",
    "    attention_mask = jnp.expand_dims(aspect_ratio_mask, (2, 3)).astype(dtype)  # (batch_size, max_num_tiles, 1, 1)\n",
    "    attention_mask = jnp.tile(attention_mask, (1, 1, target_length, 1))  # (batch_size, max_num_tiles, target_length, 1)\n",
    "\n",
    "    # Mask padding patches\n",
    "    pad_patches = target_length - num_patches\n",
    "    if pad_patches > 0:\n",
    "        attention_mask = attention_mask.at[:, :, -pad_patches:].set(0)\n",
    "\n",
    "    # Invert the mask (0 -> 1, 1 -> 0)\n",
    "    attention_mask = 1 - attention_mask\n",
    "\n",
    "    # Reshape to 2D and create 4D attention mask\n",
    "    attention_mask = attention_mask.reshape(batch_size, max_num_tiles * target_length, 1)\n",
    "    attention_mask = jnp.matmul(attention_mask, attention_mask.swapaxes(2, 1)) * jnp.finfo(dtype).min\n",
    "    attention_mask = jnp.expand_dims(attention_mask, axis=1)\n",
    "\n",
    "    return attention_mask\n",
    "\n",
    "\n",
    "def _prepare_aspect_ratio_attention_mask_torch(\n",
    "    aspect_ratio_mask: torch.Tensor,\n",
    "    num_patches: int,\n",
    "    target_length: int,\n",
    "    dtype: torch.dtype,\n",
    ") -> torch.Tensor:\n",
    "    # Expand aspect ratio mask to target_length\n",
    "    batch_size, max_num_tiles = aspect_ratio_mask.shape\n",
    "    attention_mask = aspect_ratio_mask.view(batch_size, max_num_tiles, 1, 1).to(dtype)\n",
    "    attention_mask = attention_mask.repeat(1, 1, target_length, 1) # (batch_size, max_num_tiles, target_length, 1)\n",
    "\n",
    "    # Mask padding patches\n",
    "    pad_patches = target_length - num_patches\n",
    "    attention_mask[:, :, -pad_patches:] = 0\n",
    "\n",
    "    # Invert the mask (0 -> 1, 1 -> 0)\n",
    "    attention_mask = 1 - attention_mask\n",
    "\n",
    "    # Reshape to 2D and create 4D attention mask\n",
    "    # (batch_size, 1, max_num_tiles * target_length, max_num_tiles * target_length)\n",
    "    attention_mask = attention_mask.reshape(batch_size, max_num_tiles * target_length, 1)\n",
    "    attention_mask = attention_mask @ attention_mask.transpose(-1, -2) * torch.finfo(dtype).min\n",
    "    attention_mask = attention_mask.unsqueeze(1)\n",
    "\n",
    "    return attention_mask\n",
    "\n",
    "import numpy as np\n",
    "def are_equivalent(torch_tensor, jax_array):\n",
    "    # Ensure both are on CPU for comparison\n",
    "    np_from_torch = torch_tensor.cpu().numpy()\n",
    "    np_from_jax = np.array(jax_array)\n",
    "\n",
    "    # # Compare shapes\n",
    "    # if np_from_torch.shape != np_from_jax.shape:\n",
    "    #     return False\n",
    "\n",
    "    # Compare dtypes\n",
    "    # if np_from_torch.dtype != np_from_jax.dtype:\n",
    "    #     return False\n",
    "\n",
    "    # Compare data\n",
    "    return np.allclose(np_from_torch, np_from_jax)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = inputs[\"aspect_ratio_mask\"].reshape(1, -1)\n",
    "torch_arr = _prepare_aspect_ratio_attention_mask_torch(\n",
    "            aspect_ratio_mask=attention_mask, # (batch_size * num_concurrent_media, 4)\n",
    "            num_patches=1025, # 1025 = 1024+1\n",
    "            target_length=1032, # 1032\n",
    "            dtype=torch.float16,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = inputs_jax[\"aspect_ratio_mask\"].reshape(1, -1)\n",
    "jax_arr = _prepare_aspect_ratio_attention_mask_jax(\n",
    "            aspect_ratio_mask=attention_mask, # (batch_size * num_concurrent_media, 4)\n",
    "            num_patches=1025, # 1025 = 1024+1\n",
    "            target_length=1032, # 1032\n",
    "            dtype=jnp.float32,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "are_equivalent(torch_arr, jax_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[     0.,      0.,     -0.,  ...,      0.,     -0.,     -0.],\n",
       "          [     0.,      0.,     -0.,  ...,      0.,     -0.,     -0.],\n",
       "          [     0.,      0.,     -0.,  ...,      0.,     -0.,     -0.],\n",
       "          ...,\n",
       "          [     0.,      0.,     -0.,  ..., -65504., -65504., -65504.],\n",
       "          [     0.,      0.,     -0.,  ..., -65504., -65504., -65504.],\n",
       "          [     0.,      0.,     -0.,  ..., -65504., -65504., -65504.]]]],\n",
       "       device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[-0.0000000e+00, -0.0000000e+00, -0.0000000e+00, ...,\n",
       "          -0.0000000e+00, -0.0000000e+00, -0.0000000e+00],\n",
       "         [-0.0000000e+00, -0.0000000e+00, -0.0000000e+00, ...,\n",
       "          -0.0000000e+00, -0.0000000e+00, -0.0000000e+00],\n",
       "         [-0.0000000e+00, -0.0000000e+00, -0.0000000e+00, ...,\n",
       "          -0.0000000e+00, -0.0000000e+00, -0.0000000e+00],\n",
       "         ...,\n",
       "         [-0.0000000e+00, -0.0000000e+00, -0.0000000e+00, ...,\n",
       "          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],\n",
       "         [-0.0000000e+00, -0.0000000e+00, -0.0000000e+00, ...,\n",
       "          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38],\n",
       "         [-0.0000000e+00, -0.0000000e+00, -0.0000000e+00, ...,\n",
       "          -3.4028235e+38, -3.4028235e+38, -3.4028235e+38]]]],      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jax_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 1, 1, 1]]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['aspect_ratio_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.53125000,  0.47265625, -0.35742188,  0.23925781, -2.00000000,\n",
       "        -0.24902344,  0.36718750, -0.90625000, -2.68750000, -4.12500000],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_torch.last_hidden_state[0,0,0,0,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.554688, 0.332031, -0.0800781, 4.34375, 7.125, -0.386719,\n",
       "       0.636719, -0.601562, -0.289062, -0.617188], dtype=bfloat16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax.last_hidden_state[0,0,0,0,-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MllamaVisionModel, FlaxMllamaVisionModel\n",
    "from transformers import AutoProcessor, MllamaTextModel\n",
    "import requests\n",
    "import torch\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from PIL import Image\n",
    "from huggingface_hub import login\n",
    "torch.set_printoptions(precision=8)\n",
    "\n",
    "hf_token = \"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\"\n",
    "login(hf_token)\n",
    "checkpoint = \"meta-llama/Llama-3.2-11B-Vision\"\n",
    "processor = AutoProcessor.from_pretrained(checkpoint)\n",
    "url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/0052a70beed5bf71b92610a43a52df6d286cd5f3/diffusers/rabbit.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "inputs_torch = processor(images=image, return_tensors=\"pt\")\n",
    "inputs_jax = processor(images=image, return_tensors=\"jax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "class TorchConv(nn.Module):\n",
    "    def __init__(self, dtype=torch.bfloat16):\n",
    "        super(TorchConv, self).__init__()\n",
    "        self.patch_embedding = nn.Conv2d(\n",
    "            in_channels=3, #3\n",
    "            out_channels=1280, #1280\n",
    "            kernel_size=14, #14\n",
    "            stride=14, #14\n",
    "            padding=\"valid\",\n",
    "            bias=False,\n",
    "            dtype=dtype,\n",
    "        )\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        pixel_values: torch.Tensor,\n",
    "\n",
    "    ):\n",
    "        batch_size, num_concurrent_media, num_tiles, num_channels, height, width = pixel_values.shape #(1, 1, 4, 3, 448, 448)\n",
    "\n",
    "        pixel_values = pixel_values.reshape(batch_size * num_concurrent_media * num_tiles, num_channels, height, width) #(4, 3, 448, 448)\n",
    "        # Patch embedding\n",
    "        patch_embeds = self.patch_embedding(pixel_values.to(torch.bfloat16).to('cuda')) # (batch_size * num_concurrent_media * num_tiles, hidden_size=1280, 32, 32)\n",
    "        return patch_embeds\n",
    "\n",
    "\n",
    "# Initialize the model\n",
    "torch_model = TorchConv(dtype=torch.bfloat16).to('cuda')\n",
    "\n",
    "\n",
    "# Get the parameters from the TorchConv model\n",
    "torch_params = torch_model.patch_embedding.weight\n",
    "# # Example PyTorch tensor\n",
    "# torch_params_32 = torch.randn(torch_params.shape, dtype=torch.float32)\n",
    "\n",
    "# # Permute the tensor's dimensions\n",
    "# torch_params_permuted = torch_params_32.permute(2, 3, 1, 0)\n",
    "\n",
    "# # Convert the PyTorch tensor to a NumPy array\n",
    "# torch_params_numpy = torch_params_permuted.detach().cpu().numpy()\n",
    "\n",
    "# # Convert the NumPy array to a JAX tensor with dtype bfloat16\n",
    "# jax_params = jnp.array(torch_params_numpy, dtype=jnp.bfloat16)\n",
    "# torch_params = torch.tensor(torch_params_32, dtype=torch.bfloat16)\n",
    "# torch_params = torch.nn.Parameter(torch.tensor(torch_params_32, dtype=torch.bfloat16, device='cuda'))\n",
    "# torch_model.patch_embedding.weight = torch_params\n",
    "torch_model.patch_embedding.weight = model_torch.patch_embedding.weight\n",
    "# Perform a forward pass through the model\n",
    "output_torch = torch_model(inputs_torch.pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as fnn\n",
    "class JaxConv(fnn.Module):\n",
    "  dtype: jnp.dtype = jnp.bfloat16\n",
    "\n",
    "  def setup(self):\n",
    "\n",
    "    self.patch_embedding = fnn.Conv(\n",
    "        1280,\n",
    "        kernel_size=(14, 14),\n",
    "        strides=(14, 14),\n",
    "        padding=\"VALID\",\n",
    "        use_bias=False,\n",
    "        dtype=self.dtype,\n",
    "        kernel_init=jax.nn.initializers.normal(),\n",
    "    )\n",
    " \n",
    "  def __call__(\n",
    "      self,\n",
    "      pixel_values: jnp.ndarray,\n",
    "  ):\n",
    "        batch_size, num_concurrent_media, num_tiles, num_channels, height, width = pixel_values.shape\n",
    "\n",
    "        pixel_values = pixel_values.reshape((batch_size * num_concurrent_media * num_tiles, num_channels, height, width))\n",
    "\n",
    "        # Patch embedding\n",
    "        patch_embeds = self.patch_embedding(pixel_values.transpose((0, 2, 3, 1)))\n",
    "\n",
    "        patch_embeds = patch_embeds.transpose((0, 3, 1, 2))\n",
    "\n",
    "        return patch_embeds\n",
    "        \n",
    "# Initialize the model\n",
    "flax_model = JaxConv()\n",
    "# Initialize parameters\n",
    "params = flax_model.init(jax.random.PRNGKey(0), jnp.ones((1, 1, 4, 3, 448, 448)))\n",
    "\n",
    "# # Convert PyTorch parameters to JAX parameters\n",
    "params = unfreeze(params)\n",
    "params['params']['patch_embedding']['kernel'] = model.params['vision_model']['patch_embedding']['kernel']\n",
    "params = freeze(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_jax = flax_model.apply(params, inputs_jax.pixel_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[-0.191406, -0.176758, -0.185547, ..., -0.175781, -0.174805,\n",
       "          -0.0688477],\n",
       "         [0.00186157, -0.0678711, -0.234375, ..., -0.175781, -0.172852,\n",
       "          -0.170898],\n",
       "         [0.0534668, 0.114258, 0.0119629, ..., -0.203125, -0.191406,\n",
       "          -0.192383],\n",
       "         ...,\n",
       "         [0.0219727, 0.0603027, 0.0556641, ..., -0.0135498, -0.0859375,\n",
       "          -0.121582],\n",
       "         [0.034668, 0.103516, 0.032959, ..., 0.00430298, 0.010376,\n",
       "          -0.111328],\n",
       "         [0.0181885, 0.0126953, 0.00482178, ..., 0.0419922, 0.0241699,\n",
       "          -0.0947266]],\n",
       "\n",
       "        [[0.0412598, 0.0356445, 0.0444336, ..., 0.0368652, 0.0410156,\n",
       "          0.176758],\n",
       "         [0.12207, 0.0373535, 0.090332, ..., 0.0291748, 0.0358887,\n",
       "          0.0664062],\n",
       "         [-0.0280762, 0.0534668, -0.0334473, ..., 0.0456543, 0.0317383,\n",
       "          0.0152588],\n",
       "         ...,\n",
       "         [-0.0566406, 0.0668945, 0.0385742, ..., 0.0158691, -0.022583,\n",
       "          0.0622559],\n",
       "         [0.0108032, 0.0429688, 0.0495605, ..., 0.0634766,\n",
       "          -0.000610352, 0.113281],\n",
       "         [0.00497437, 0.0568848, -0.0142212, ..., -0.0751953,\n",
       "          -0.0062561, 0.115723]],\n",
       "\n",
       "        [[-0.0961914, -0.287109, -0.386719, ..., -0.277344, -0.25,\n",
       "          0.139648],\n",
       "         [0.523438, 0.10498, 0.162109, ..., -0.242188, -0.275391,\n",
       "          -0.296875],\n",
       "         [0.0634766, -0.0185547, -0.203125, ..., -0.326172, -0.248047,\n",
       "          -0.21582],\n",
       "         ...,\n",
       "         [0.122559, -0.149414, -0.0917969, ..., 0.138672, -0.439453,\n",
       "          -0.273438],\n",
       "         [0.133789, -0.1875, 0.222656, ..., -0.335938, 0.375, 0.384766],\n",
       "         [-0.359375, -0.0527344, -0.150391, ..., 0.202148, 0.135742,\n",
       "          0.213867]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.451172, -0.410156, -0.402344, ..., -0.386719, -0.378906,\n",
       "          -0.224609],\n",
       "         [0.0898438, -0.157227, -0.181641, ..., -0.384766, -0.394531,\n",
       "          -0.416016],\n",
       "         [0.135742, 0.148438, 0.171875, ..., -0.5, -0.503906,\n",
       "          -0.464844],\n",
       "         ...,\n",
       "         [0.111328, -0.0615234, -0.213867, ..., 0.249023, 0.12793,\n",
       "          -0.419922],\n",
       "         [-0.0708008, -0.0563965, -0.134766, ..., 0.28125, 0.248047,\n",
       "          -0.378906],\n",
       "         [-0.267578, -0.158203, -0.0400391, ..., 0.324219, 0.25,\n",
       "          -0.104492]],\n",
       "\n",
       "        [[-0.136719, -0.427734, -0.332031, ..., -0.357422, -0.341797,\n",
       "          -2.20312],\n",
       "         [1.27344, 0.789062, 0.746094, ..., -0.355469, -0.423828,\n",
       "          -0.542969],\n",
       "         [-0.0466309, 0.621094, 1.03125, ..., -0.808594, -0.59375,\n",
       "          -0.503906],\n",
       "         ...,\n",
       "         [0.769531, 0.382812, -0.107422, ..., 0.361328, 3.76562,\n",
       "          -0.367188],\n",
       "         [-0.298828, 0.59375, 0.277344, ..., 0.0673828, 2.32812,\n",
       "          -0.386719],\n",
       "         [0.120117, 0.333984, 0.0795898, ..., 0.652344, 1.32812, 2.5]],\n",
       "\n",
       "        [[0.112793, 0.0751953, 0.0683594, ..., 0.0668945, 0.0664062,\n",
       "          0.106445],\n",
       "         [0.0795898, 0.117676, 0.0228271, ..., 0.0522461, 0.0703125,\n",
       "          0.065918],\n",
       "         [-0.00454712, 0.0388184, -0.0181885, ..., 0.0654297,\n",
       "          0.0673828, 0.0629883],\n",
       "         ...,\n",
       "         [-0.0124512, -0.0127563, 0.0255127, ..., -0.0588379, 0.036377,\n",
       "          0.0849609],\n",
       "         [-0.0742188, -0.0422363, 0.00994873, ..., -0.101562,\n",
       "          -0.0119629, 0.134766],\n",
       "         [0.043457, -0.0395508, -0.0280762, ..., -0.121582, -0.0532227,\n",
       "          0.0568848]]],\n",
       "\n",
       "\n",
       "       [[[-0.0134277, -0.0683594, 0.0361328, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.163086, -0.196289, -0.0834961, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.261719, -0.138672, -0.0473633, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         ...,\n",
       "         [-0.151367, -0.137695, -0.0412598, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.123535, -0.0378418, 0.0219727, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [-0.105957, 0.00878906, -0.0339355, ..., 0.18457, 0.18457,\n",
       "          0.18457]],\n",
       "\n",
       "        [[0.101562, 0.103516, -0.0786133, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.0480957, 0.0854492, -0.172852, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [-0.118164, 0.0922852, -0.162109, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         ...,\n",
       "         [0.0117188, 0.0466309, 0.0322266, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.052002, 0.034668, 0.020752, ..., -0.0625, -0.0625, -0.0625],\n",
       "         [0.0888672, 0.0554199, -0.0168457, ..., -0.0625, -0.0625,\n",
       "          -0.0625]],\n",
       "\n",
       "        [[-1, -0.613281, 0.785156, ..., 0.292969, 0.292969, 0.292969],\n",
       "         [-0.155273, 0.020874, -0.349609, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [-0.00613403, 0.359375, -0.202148, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         ...,\n",
       "         [-0.207031, -0.166016, 0.106934, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [-0.257812, 0.408203, -0.28125, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [-0.166016, 0.241211, -0.249023, ..., 0.292969, 0.292969,\n",
       "          0.292969]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.429688, -0.4375, 0.00369263, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.410156, -0.267578, -0.164062, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.337891, -0.182617, -0.110352, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         ...,\n",
       "         [-0.431641, -0.410156, -0.244141, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.373047, -0.211914, -0.175781, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [-0.314453, -0.185547, -0.246094, ..., 0.519531, 0.519531,\n",
       "          0.519531]],\n",
       "\n",
       "        [[0.433594, 0.675781, -0.527344, ..., 0.5, 0.5, 0.5],\n",
       "         [0.143555, -1.40625, -0.929688, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.0136719, -1.625, 1.01562, ..., 0.5, 0.5, 0.5],\n",
       "         ...,\n",
       "         [-0.402344, -0.511719, -0.863281, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.320312, -0.660156, -0.953125, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.878906, -1.05469, -0.207031, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "        [[0.0615234, 0.00187683, -0.0644531, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [0.0373535, 0.050293, -0.0654297, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         [-0.0634766, 0.15332, -0.0290527, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         ...,\n",
       "         [0.0515137, 0.0634766, 0.0568848, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         [0.0551758, 0.0424805, 0.0127563, ..., -0.0805664, -0.0805664,\n",
       "          -0.0805664],\n",
       "         [0.0766602, 0.0285645, -0.0483398, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664]]],\n",
       "\n",
       "\n",
       "       [[[0.0112305, 0.0727539, 0.0344238, ..., 0.0952148, 0.0786133,\n",
       "          -0.0446777],\n",
       "         [0.0351562, 0.00805664, 0.100586, ..., 0.0649414, 0.12207,\n",
       "          0.122559],\n",
       "         [-0.0368652, -0.059082, -0.0332031, ..., 0.107422, 0.116699,\n",
       "          0.0854492],\n",
       "         ...,\n",
       "         [0.0859375, 0.130859, 0.235352, ..., 0.0908203, 0.144531,\n",
       "          -0.0177002],\n",
       "         [0.0722656, 0.198242, 0.125977, ..., 0.0961914, 0.0585938,\n",
       "          0.0649414],\n",
       "         [0.132812, 0.208008, 0.158203, ..., 0.0539551, 0.0693359,\n",
       "          0.0218506]],\n",
       "\n",
       "        [[0.0456543, -0.0218506, 0.0678711, ..., -0.160156, -0.0289307,\n",
       "          0.146484],\n",
       "         [-0.00379944, -0.0717773, -0.0598145, ..., -0.0820312,\n",
       "          -0.0098877, -0.052002],\n",
       "         [0.045166, 0.00300598, 0.00233459, ..., -0.139648, 0.0493164,\n",
       "          -0.0253906],\n",
       "         ...,\n",
       "         [-0.0172119, -0.0568848, -0.0830078, ..., -0.00939941,\n",
       "          0.0272217, -0.0791016],\n",
       "         [-0.0220947, 0.0664062, 0.138672, ..., -0.0400391, 0.0194092,\n",
       "          -0.00485229],\n",
       "         [-0.145508, 0.019043, -0.0834961, ..., 0.135742, -0.0415039,\n",
       "          -0.0378418]],\n",
       "\n",
       "        [[-0.314453, -0.396484, 0.554688, ..., 0.40625, 0.144531,\n",
       "          0.0544434],\n",
       "         [-0.3125, 0.0351562, 0.106445, ..., 0.0103149, 0.441406,\n",
       "          0.166992],\n",
       "         [-0.203125, -0.171875, -0.198242, ..., -0.125, 0.296875,\n",
       "          0.118164],\n",
       "         ...,\n",
       "         [0.0708008, 0.09375, 0.15332, ..., 0.392578, -0.0908203,\n",
       "          0.0751953],\n",
       "         [-0.539062, 0.306641, -0.101562, ..., 0.173828, 0.53125,\n",
       "          0.164062],\n",
       "         [0.511719, 0.617188, 0.365234, ..., 0.425781, 0.229492,\n",
       "          0.106934]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.259766, 0.015625, 0.0942383, ..., 0.365234, 0.232422,\n",
       "          0.104492],\n",
       "         [-0.140625, -0.15625, -0.0976562, ..., 0.322266, 0.376953,\n",
       "          0.213867],\n",
       "         [-0.3125, -0.287109, -0.243164, ..., 0.330078, 0.427734,\n",
       "          0.304688],\n",
       "         ...,\n",
       "         [0.231445, 0.419922, 0.357422, ..., 0.180664, 0.115234,\n",
       "          0.21582],\n",
       "         [0.265625, 0.378906, 0.40625, ..., 0.147461, 0.208984,\n",
       "          0.233398],\n",
       "         [0.457031, 0.335938, 0.330078, ..., 0.115723, 0.0693359,\n",
       "          -0.0341797]],\n",
       "\n",
       "        [[-0.539062, -0.871094, 0.367188, ..., 0.0717773, 1.52344,\n",
       "          3.28125],\n",
       "         [0.00141907, -0.22168, 0.104492, ..., -0.65625, 0.59375,\n",
       "          0.722656],\n",
       "         [-0.112305, 0.161133, 0.0751953, ..., -0.890625, 1.21094,\n",
       "          1.64844],\n",
       "         ...,\n",
       "         [0.423828, 0.0732422, 0.130859, ..., 0.238281, -0.101562,\n",
       "          0.367188],\n",
       "         [-0.707031, 0.511719, 1.00781, ..., 0.0844727, 0.601562,\n",
       "          0.00311279],\n",
       "         [0.644531, 0.246094, 0.878906, ..., 0.929688, -0.365234,\n",
       "          0.460938]],\n",
       "\n",
       "        [[-0.0117798, -0.00634766, -0.0349121, ..., -0.0106812,\n",
       "          -0.0512695, 0.0834961],\n",
       "         [-0.0146484, -0.0605469, 0.0200195, ..., -0.0498047,\n",
       "          -0.0378418, -0.0429688],\n",
       "         [-0.0510254, -0.078125, -0.0130615, ..., -0.105469,\n",
       "          -0.0673828, -0.0546875],\n",
       "         ...,\n",
       "         [-0.0678711, -0.0537109, -0.050293, ..., -0.0373535,\n",
       "          -0.0220947, -0.106934],\n",
       "         [-0.0712891, -0.0251465, -0.0108032, ..., 0.0766602,\n",
       "          -0.0195312, 0.0488281],\n",
       "         [-0.0849609, -0.0273438, -0.0402832, ..., -0.0255127,\n",
       "          0.0303955, -0.0534668]]],\n",
       "\n",
       "\n",
       "       [[[-0.0332031, 0.00720215, -0.0375977, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [0.0415039, 0.0196533, -0.0563965, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [0.0834961, -0.0378418, 0.0218506, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         ...,\n",
       "         [0.0649414, 0.0766602, 0.0996094, ..., 0.18457, 0.18457,\n",
       "          0.18457],\n",
       "         [0.112793, 0.108398, 0.118652, ..., 0.18457, 0.18457, 0.18457],\n",
       "         [0.052002, 0.0673828, 0.0397949, ..., 0.18457, 0.18457,\n",
       "          0.18457]],\n",
       "\n",
       "        [[0.0544434, 0.0432129, 0.0649414, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.0227051, 3.19481e-05, 0.0693359, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.203125, -0.000888824, 0.0410156, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         ...,\n",
       "         [0.0534668, 0.0708008, -0.0957031, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [0.0585938, 0.0177002, 0.0541992, ..., -0.0625, -0.0625,\n",
       "          -0.0625],\n",
       "         [-0.00817871, 0.0131226, 0.0371094, ..., -0.0625, -0.0625,\n",
       "          -0.0625]],\n",
       "\n",
       "        [[0.347656, 0.128906, -0.310547, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [0.219727, 0.142578, -0.457031, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [1.01562, -0.322266, -0.359375, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         ...,\n",
       "         [0.28125, 0.193359, 0.371094, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [0.0649414, 0.0263672, 0.326172, ..., 0.292969, 0.292969,\n",
       "          0.292969],\n",
       "         [0.065918, -0.144531, 0.197266, ..., 0.292969, 0.292969,\n",
       "          0.292969]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-0.249023, -0.251953, -0.298828, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.00775146, -0.193359, -0.380859, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.10498, -0.324219, -0.271484, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         ...,\n",
       "         [0.176758, 0.123535, 0.125977, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.114258, 0.209961, 0.292969, ..., 0.519531, 0.519531,\n",
       "          0.519531],\n",
       "         [0.111816, 0.0556641, 0.166016, ..., 0.519531, 0.519531,\n",
       "          0.519531]],\n",
       "\n",
       "        [[-1.28906, -0.208008, -0.570312, ..., 0.5, 0.5, 0.5],\n",
       "         [1.16406, -0.369141, 0.335938, ..., 0.5, 0.5, 0.5],\n",
       "         [2.29688, 0.789062, -0.482422, ..., 0.5, 0.5, 0.5],\n",
       "         ...,\n",
       "         [-0.0466309, 0.457031, -0.484375, ..., 0.5, 0.5, 0.5],\n",
       "         [-0.157227, 0.123047, 0.259766, ..., 0.5, 0.5, 0.5],\n",
       "         [0.308594, -0.369141, 0.196289, ..., 0.5, 0.5, 0.5]],\n",
       "\n",
       "        [[0.0264893, -0.00463867, 0.0140381, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [-0.00106049, -0.0119019, 0.027832, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [-0.0267334, -0.0263672, 0.0776367, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         ...,\n",
       "         [-0.0186768, 0.0649414, -0.0581055, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [-0.00787354, -0.03125, 0.0262451, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664],\n",
       "         [0.0141602, 0.0223389, -0.0272217, ..., -0.0805664,\n",
       "          -0.0805664, -0.0805664]]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-1.91406250e-01, -1.76757812e-01, -1.85546875e-01,  ...,\n",
       "           -1.75781250e-01, -1.74804688e-01, -6.88476562e-02],\n",
       "          [ 1.86157227e-03, -6.78710938e-02, -2.34375000e-01,  ...,\n",
       "           -1.75781250e-01, -1.72851562e-01, -1.70898438e-01],\n",
       "          [ 5.34667969e-02,  1.14257812e-01,  1.19628906e-02,  ...,\n",
       "           -2.03125000e-01, -1.91406250e-01, -1.92382812e-01],\n",
       "          ...,\n",
       "          [ 2.19726562e-02,  6.03027344e-02,  5.56640625e-02,  ...,\n",
       "           -1.35498047e-02, -8.59375000e-02, -1.21582031e-01],\n",
       "          [ 3.46679688e-02,  1.03515625e-01,  3.29589844e-02,  ...,\n",
       "            4.30297852e-03,  1.03759766e-02, -1.11328125e-01],\n",
       "          [ 1.81884766e-02,  1.26953125e-02,  4.82177734e-03,  ...,\n",
       "            4.19921875e-02,  2.41699219e-02, -9.47265625e-02]],\n",
       "\n",
       "         [[ 4.12597656e-02,  3.56445312e-02,  4.44335938e-02,  ...,\n",
       "            3.68652344e-02,  4.10156250e-02,  1.76757812e-01],\n",
       "          [ 1.22070312e-01,  3.73535156e-02,  9.03320312e-02,  ...,\n",
       "            2.91748047e-02,  3.58886719e-02,  6.64062500e-02],\n",
       "          [-2.80761719e-02,  5.34667969e-02, -3.34472656e-02,  ...,\n",
       "            4.56542969e-02,  3.17382812e-02,  1.52587891e-02],\n",
       "          ...,\n",
       "          [-5.66406250e-02,  6.68945312e-02,  3.85742188e-02,  ...,\n",
       "            1.58691406e-02, -2.25830078e-02,  6.22558594e-02],\n",
       "          [ 1.08032227e-02,  4.29687500e-02,  4.95605469e-02,  ...,\n",
       "            6.34765625e-02, -6.10351562e-04,  1.13281250e-01],\n",
       "          [ 4.97436523e-03,  5.68847656e-02, -1.42211914e-02,  ...,\n",
       "           -7.51953125e-02, -6.25610352e-03,  1.15722656e-01]],\n",
       "\n",
       "         [[-9.61914062e-02, -2.87109375e-01, -3.86718750e-01,  ...,\n",
       "           -2.77343750e-01, -2.50000000e-01,  1.39648438e-01],\n",
       "          [ 5.23437500e-01,  1.04980469e-01,  1.62109375e-01,  ...,\n",
       "           -2.42187500e-01, -2.75390625e-01, -2.96875000e-01],\n",
       "          [ 6.34765625e-02, -1.85546875e-02, -2.03125000e-01,  ...,\n",
       "           -3.26171875e-01, -2.48046875e-01, -2.15820312e-01],\n",
       "          ...,\n",
       "          [ 1.22558594e-01, -1.49414062e-01, -9.17968750e-02,  ...,\n",
       "            1.38671875e-01, -4.39453125e-01, -2.73437500e-01],\n",
       "          [ 1.33789062e-01, -1.87500000e-01,  2.22656250e-01,  ...,\n",
       "           -3.35937500e-01,  3.75000000e-01,  3.84765625e-01],\n",
       "          [-3.59375000e-01, -5.27343750e-02, -1.50390625e-01,  ...,\n",
       "            2.02148438e-01,  1.35742188e-01,  2.13867188e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.51171875e-01, -4.10156250e-01, -4.02343750e-01,  ...,\n",
       "           -3.86718750e-01, -3.78906250e-01, -2.24609375e-01],\n",
       "          [ 8.98437500e-02, -1.57226562e-01, -1.81640625e-01,  ...,\n",
       "           -3.84765625e-01, -3.94531250e-01, -4.16015625e-01],\n",
       "          [ 1.35742188e-01,  1.48437500e-01,  1.71875000e-01,  ...,\n",
       "           -5.00000000e-01, -5.03906250e-01, -4.64843750e-01],\n",
       "          ...,\n",
       "          [ 1.11328125e-01, -6.15234375e-02, -2.13867188e-01,  ...,\n",
       "            2.49023438e-01,  1.27929688e-01, -4.19921875e-01],\n",
       "          [-7.08007812e-02, -5.63964844e-02, -1.34765625e-01,  ...,\n",
       "            2.81250000e-01,  2.48046875e-01, -3.78906250e-01],\n",
       "          [-2.67578125e-01, -1.58203125e-01, -4.00390625e-02,  ...,\n",
       "            3.24218750e-01,  2.50000000e-01, -1.04492188e-01]],\n",
       "\n",
       "         [[-1.36718750e-01, -4.27734375e-01, -3.32031250e-01,  ...,\n",
       "           -3.57421875e-01, -3.41796875e-01, -2.20312500e+00],\n",
       "          [ 1.27343750e+00,  7.89062500e-01,  7.46093750e-01,  ...,\n",
       "           -3.55468750e-01, -4.23828125e-01, -5.42968750e-01],\n",
       "          [-4.66308594e-02,  6.21093750e-01,  1.03125000e+00,  ...,\n",
       "           -8.08593750e-01, -5.93750000e-01, -5.03906250e-01],\n",
       "          ...,\n",
       "          [ 7.69531250e-01,  3.82812500e-01, -1.07421875e-01,  ...,\n",
       "            3.61328125e-01,  3.76562500e+00, -3.67187500e-01],\n",
       "          [-2.98828125e-01,  5.93750000e-01,  2.77343750e-01,  ...,\n",
       "            6.73828125e-02,  2.32812500e+00, -3.86718750e-01],\n",
       "          [ 1.20117188e-01,  3.33984375e-01,  7.95898438e-02,  ...,\n",
       "            6.52343750e-01,  1.32812500e+00,  2.50000000e+00]],\n",
       "\n",
       "         [[ 1.12792969e-01,  7.51953125e-02,  6.83593750e-02,  ...,\n",
       "            6.68945312e-02,  6.64062500e-02,  1.06445312e-01],\n",
       "          [ 7.95898438e-02,  1.17675781e-01,  2.28271484e-02,  ...,\n",
       "            5.22460938e-02,  7.03125000e-02,  6.59179688e-02],\n",
       "          [-4.54711914e-03,  3.88183594e-02, -1.81884766e-02,  ...,\n",
       "            6.54296875e-02,  6.73828125e-02,  6.29882812e-02],\n",
       "          ...,\n",
       "          [-1.24511719e-02, -1.27563477e-02,  2.55126953e-02,  ...,\n",
       "           -5.88378906e-02,  3.63769531e-02,  8.49609375e-02],\n",
       "          [-7.42187500e-02, -4.22363281e-02,  9.94873047e-03,  ...,\n",
       "           -1.01562500e-01, -1.19628906e-02,  1.34765625e-01],\n",
       "          [ 4.34570312e-02, -3.95507812e-02, -2.80761719e-02,  ...,\n",
       "           -1.21582031e-01, -5.32226562e-02,  5.68847656e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.34277344e-02, -6.83593750e-02,  3.61328125e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-1.63085938e-01, -1.96289062e-01, -8.34960938e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-2.61718750e-01, -1.38671875e-01, -4.73632812e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          ...,\n",
       "          [-1.51367188e-01, -1.37695312e-01, -4.12597656e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-1.23535156e-01, -3.78417969e-02,  2.19726562e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [-1.05957031e-01,  8.78906250e-03, -3.39355469e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01]],\n",
       "\n",
       "         [[ 1.01562500e-01,  1.03515625e-01, -7.86132812e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 4.80957031e-02,  8.54492188e-02, -1.72851562e-01,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [-1.18164062e-01,  9.22851562e-02, -1.62109375e-01,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          ...,\n",
       "          [ 1.17187500e-02,  4.66308594e-02,  3.22265625e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 5.20019531e-02,  3.46679688e-02,  2.07519531e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 8.88671875e-02,  5.54199219e-02, -1.68457031e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02]],\n",
       "\n",
       "         [[-1.00000000e+00, -6.13281250e-01,  7.85156250e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-1.55273438e-01,  2.08740234e-02, -3.49609375e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-6.13403320e-03,  3.59375000e-01, -2.02148438e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          ...,\n",
       "          [-2.07031250e-01, -1.66015625e-01,  1.06933594e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-2.57812500e-01,  4.08203125e-01, -2.81250000e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [-1.66015625e-01,  2.41210938e-01, -2.49023438e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-4.29687500e-01, -4.37500000e-01,  3.69262695e-03,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-4.10156250e-01, -2.67578125e-01, -1.64062500e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-3.37890625e-01, -1.82617188e-01, -1.10351562e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          ...,\n",
       "          [-4.31640625e-01, -4.10156250e-01, -2.44140625e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-3.73046875e-01, -2.11914062e-01, -1.75781250e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [-3.14453125e-01, -1.85546875e-01, -2.46093750e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01]],\n",
       "\n",
       "         [[ 4.33593750e-01,  6.75781250e-01, -5.27343750e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 1.43554688e-01, -1.40625000e+00, -9.29687500e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-1.36718750e-02, -1.62500000e+00,  1.01562500e+00,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          ...,\n",
       "          [-4.02343750e-01, -5.11718750e-01, -8.63281250e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-3.20312500e-01, -6.60156250e-01, -9.53125000e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-8.78906250e-01, -1.05468750e+00, -2.07031250e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01]],\n",
       "\n",
       "         [[ 6.15234375e-02,  1.87683105e-03, -6.44531250e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 3.73535156e-02,  5.02929688e-02, -6.54296875e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-6.34765625e-02,  1.53320312e-01, -2.90527344e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          ...,\n",
       "          [ 5.15136719e-02,  6.34765625e-02,  5.68847656e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 5.51757812e-02,  4.24804688e-02,  1.27563477e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 7.66601562e-02,  2.85644531e-02, -4.83398438e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02]]],\n",
       "\n",
       "\n",
       "        [[[ 1.12304688e-02,  7.27539062e-02,  3.44238281e-02,  ...,\n",
       "            9.52148438e-02,  7.86132812e-02, -4.46777344e-02],\n",
       "          [ 3.51562500e-02,  8.05664062e-03,  1.00585938e-01,  ...,\n",
       "            6.49414062e-02,  1.22070312e-01,  1.22558594e-01],\n",
       "          [-3.68652344e-02, -5.90820312e-02, -3.32031250e-02,  ...,\n",
       "            1.07421875e-01,  1.16699219e-01,  8.54492188e-02],\n",
       "          ...,\n",
       "          [ 8.59375000e-02,  1.30859375e-01,  2.35351562e-01,  ...,\n",
       "            9.08203125e-02,  1.44531250e-01, -1.77001953e-02],\n",
       "          [ 7.22656250e-02,  1.98242188e-01,  1.25976562e-01,  ...,\n",
       "            9.61914062e-02,  5.85937500e-02,  6.49414062e-02],\n",
       "          [ 1.32812500e-01,  2.08007812e-01,  1.58203125e-01,  ...,\n",
       "            5.39550781e-02,  6.93359375e-02,  2.18505859e-02]],\n",
       "\n",
       "         [[ 4.56542969e-02, -2.18505859e-02,  6.78710938e-02,  ...,\n",
       "           -1.60156250e-01, -2.89306641e-02,  1.46484375e-01],\n",
       "          [-3.79943848e-03, -7.17773438e-02, -5.98144531e-02,  ...,\n",
       "           -8.20312500e-02, -9.88769531e-03, -5.20019531e-02],\n",
       "          [ 4.51660156e-02,  3.00598145e-03,  2.33459473e-03,  ...,\n",
       "           -1.39648438e-01,  4.93164062e-02, -2.53906250e-02],\n",
       "          ...,\n",
       "          [-1.72119141e-02, -5.68847656e-02, -8.30078125e-02,  ...,\n",
       "           -9.39941406e-03,  2.72216797e-02, -7.91015625e-02],\n",
       "          [-2.20947266e-02,  6.64062500e-02,  1.38671875e-01,  ...,\n",
       "           -4.00390625e-02,  1.94091797e-02, -4.85229492e-03],\n",
       "          [-1.45507812e-01,  1.90429688e-02, -8.34960938e-02,  ...,\n",
       "            1.35742188e-01, -4.15039062e-02, -3.78417969e-02]],\n",
       "\n",
       "         [[-3.14453125e-01, -3.96484375e-01,  5.54687500e-01,  ...,\n",
       "            4.06250000e-01,  1.44531250e-01,  5.44433594e-02],\n",
       "          [-3.12500000e-01,  3.51562500e-02,  1.06445312e-01,  ...,\n",
       "            1.03149414e-02,  4.41406250e-01,  1.66992188e-01],\n",
       "          [-2.03125000e-01, -1.71875000e-01, -1.98242188e-01,  ...,\n",
       "           -1.25000000e-01,  2.96875000e-01,  1.18164062e-01],\n",
       "          ...,\n",
       "          [ 7.08007812e-02,  9.37500000e-02,  1.53320312e-01,  ...,\n",
       "            3.92578125e-01, -9.08203125e-02,  7.51953125e-02],\n",
       "          [-5.39062500e-01,  3.06640625e-01, -1.01562500e-01,  ...,\n",
       "            1.73828125e-01,  5.31250000e-01,  1.64062500e-01],\n",
       "          [ 5.11718750e-01,  6.17187500e-01,  3.65234375e-01,  ...,\n",
       "            4.25781250e-01,  2.29492188e-01,  1.06933594e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.59765625e-01,  1.56250000e-02,  9.42382812e-02,  ...,\n",
       "            3.65234375e-01,  2.32421875e-01,  1.04492188e-01],\n",
       "          [-1.40625000e-01, -1.56250000e-01, -9.76562500e-02,  ...,\n",
       "            3.22265625e-01,  3.76953125e-01,  2.13867188e-01],\n",
       "          [-3.12500000e-01, -2.87109375e-01, -2.43164062e-01,  ...,\n",
       "            3.30078125e-01,  4.27734375e-01,  3.04687500e-01],\n",
       "          ...,\n",
       "          [ 2.31445312e-01,  4.19921875e-01,  3.57421875e-01,  ...,\n",
       "            1.80664062e-01,  1.15234375e-01,  2.15820312e-01],\n",
       "          [ 2.65625000e-01,  3.78906250e-01,  4.06250000e-01,  ...,\n",
       "            1.47460938e-01,  2.08984375e-01,  2.33398438e-01],\n",
       "          [ 4.57031250e-01,  3.35937500e-01,  3.30078125e-01,  ...,\n",
       "            1.15722656e-01,  6.93359375e-02, -3.41796875e-02]],\n",
       "\n",
       "         [[-5.39062500e-01, -8.71093750e-01,  3.67187500e-01,  ...,\n",
       "            7.17773438e-02,  1.52343750e+00,  3.28125000e+00],\n",
       "          [ 1.41906738e-03, -2.21679688e-01,  1.04492188e-01,  ...,\n",
       "           -6.56250000e-01,  5.93750000e-01,  7.22656250e-01],\n",
       "          [-1.12304688e-01,  1.61132812e-01,  7.51953125e-02,  ...,\n",
       "           -8.90625000e-01,  1.21093750e+00,  1.64843750e+00],\n",
       "          ...,\n",
       "          [ 4.23828125e-01,  7.32421875e-02,  1.30859375e-01,  ...,\n",
       "            2.38281250e-01, -1.01562500e-01,  3.67187500e-01],\n",
       "          [-7.07031250e-01,  5.11718750e-01,  1.00781250e+00,  ...,\n",
       "            8.44726562e-02,  6.01562500e-01,  3.11279297e-03],\n",
       "          [ 6.44531250e-01,  2.46093750e-01,  8.78906250e-01,  ...,\n",
       "            9.29687500e-01, -3.65234375e-01,  4.60937500e-01]],\n",
       "\n",
       "         [[-1.17797852e-02, -6.34765625e-03, -3.49121094e-02,  ...,\n",
       "           -1.06811523e-02, -5.12695312e-02,  8.34960938e-02],\n",
       "          [-1.46484375e-02, -6.05468750e-02,  2.00195312e-02,  ...,\n",
       "           -4.98046875e-02, -3.78417969e-02, -4.29687500e-02],\n",
       "          [-5.10253906e-02, -7.81250000e-02, -1.30615234e-02,  ...,\n",
       "           -1.05468750e-01, -6.73828125e-02, -5.46875000e-02],\n",
       "          ...,\n",
       "          [-6.78710938e-02, -5.37109375e-02, -5.02929688e-02,  ...,\n",
       "           -3.73535156e-02, -2.20947266e-02, -1.06933594e-01],\n",
       "          [-7.12890625e-02, -2.51464844e-02, -1.08032227e-02,  ...,\n",
       "            7.66601562e-02, -1.95312500e-02,  4.88281250e-02],\n",
       "          [-8.49609375e-02, -2.73437500e-02, -4.02832031e-02,  ...,\n",
       "           -2.55126953e-02,  3.03955078e-02, -5.34667969e-02]]],\n",
       "\n",
       "\n",
       "        [[[-3.32031250e-02,  7.20214844e-03, -3.75976562e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 4.15039062e-02,  1.96533203e-02, -5.63964844e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 8.34960938e-02, -3.78417969e-02,  2.18505859e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          ...,\n",
       "          [ 6.49414062e-02,  7.66601562e-02,  9.96093750e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 1.12792969e-01,  1.08398438e-01,  1.18652344e-01,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01],\n",
       "          [ 5.20019531e-02,  6.73828125e-02,  3.97949219e-02,  ...,\n",
       "            1.84570312e-01,  1.84570312e-01,  1.84570312e-01]],\n",
       "\n",
       "         [[ 5.44433594e-02,  4.32128906e-02,  6.49414062e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 2.27050781e-02,  3.19480896e-05,  6.93359375e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 2.03125000e-01, -8.88824463e-04,  4.10156250e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          ...,\n",
       "          [ 5.34667969e-02,  7.08007812e-02, -9.57031250e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [ 5.85937500e-02,  1.77001953e-02,  5.41992188e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02],\n",
       "          [-8.17871094e-03,  1.31225586e-02,  3.71093750e-02,  ...,\n",
       "           -6.25000000e-02, -6.25000000e-02, -6.25000000e-02]],\n",
       "\n",
       "         [[ 3.47656250e-01,  1.28906250e-01, -3.10546875e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 2.19726562e-01,  1.42578125e-01, -4.57031250e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 1.01562500e+00, -3.22265625e-01, -3.59375000e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          ...,\n",
       "          [ 2.81250000e-01,  1.93359375e-01,  3.71093750e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 6.49414062e-02,  2.63671875e-02,  3.26171875e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01],\n",
       "          [ 6.59179688e-02, -1.44531250e-01,  1.97265625e-01,  ...,\n",
       "            2.92968750e-01,  2.92968750e-01,  2.92968750e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.49023438e-01, -2.51953125e-01, -2.98828125e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 7.75146484e-03, -1.93359375e-01, -3.80859375e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 1.04980469e-01, -3.24218750e-01, -2.71484375e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          ...,\n",
       "          [ 1.76757812e-01,  1.23535156e-01,  1.25976562e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 1.14257812e-01,  2.09960938e-01,  2.92968750e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01],\n",
       "          [ 1.11816406e-01,  5.56640625e-02,  1.66015625e-01,  ...,\n",
       "            5.19531250e-01,  5.19531250e-01,  5.19531250e-01]],\n",
       "\n",
       "         [[-1.28906250e+00, -2.08007812e-01, -5.70312500e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 1.16406250e+00, -3.69140625e-01,  3.35937500e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 2.29687500e+00,  7.89062500e-01, -4.82421875e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          ...,\n",
       "          [-4.66308594e-02,  4.57031250e-01, -4.84375000e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [-1.57226562e-01,  1.23046875e-01,  2.59765625e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01],\n",
       "          [ 3.08593750e-01, -3.69140625e-01,  1.96289062e-01,  ...,\n",
       "            5.00000000e-01,  5.00000000e-01,  5.00000000e-01]],\n",
       "\n",
       "         [[ 2.64892578e-02, -4.63867188e-03,  1.40380859e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-1.06048584e-03, -1.19018555e-02,  2.78320312e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-2.67333984e-02, -2.63671875e-02,  7.76367188e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          ...,\n",
       "          [-1.86767578e-02,  6.49414062e-02, -5.81054688e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [-7.87353516e-03, -3.12500000e-02,  2.62451172e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02],\n",
       "          [ 1.41601562e-02,  2.23388672e-02, -2.72216797e-02,  ...,\n",
       "           -8.05664062e-02, -8.05664062e-02, -8.05664062e-02]]]],\n",
       "       device='cuda:0', dtype=torch.bfloat16, grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[1.5507771, 1.477785 , 1.4047928, 1.3172023, 1.2442101, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.5215802, 1.4631865, 1.3901944, 1.3172023, 1.2442101, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.5069818, 1.4339896, 1.3609976, 1.2880055, 1.2296118, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.477785 , 1.3901944, 1.3172023, 1.2442101, 1.2150133, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.4047928, 1.3463992, 1.3026038, 1.2442101, 1.2150133, 1.2296118,\n",
       "        1.2442101, 1.2442101, 1.273407 , 1.273407 ],\n",
       "       [1.3318007, 1.3026038, 1.2880055, 1.273407 , 1.273407 , 1.2588086,\n",
       "        1.2588086, 1.2588086, 1.2880055, 1.2880055],\n",
       "       [1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.273407 ,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055],\n",
       "       [1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.2880055, 1.273407 ,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055],\n",
       "       [1.2296118, 1.2588086, 1.2880055, 1.3026038, 1.3026038, 1.2880055,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055],\n",
       "       [1.1858164, 1.2150133, 1.2588086, 1.273407 , 1.273407 , 1.273407 ,\n",
       "        1.273407 , 1.273407 , 1.2880055, 1.2880055]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_jax.pixel_values[0,0,0,0,:10,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.named_modules at 0x7ef9b8d478b0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_torch.named_modules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43moutput_torch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlast_hidden_state\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[:, :, :, \u001b[38;5;241m0\u001b[39m, i:(i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10\u001b[39m)]\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 4"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "output_torch['last_hidden_state'][:, :, :, 0, i:(i+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[5.65625, -5.25, -5.375, 5.8125, 4.90625, -4.21875, 1.55469,\n",
       "          -3.15625, 0.984375, 3.90625],\n",
       "         [6.34375, -3.03125, -6.4375, 6.03125, 7.8125, -3.59375,\n",
       "          2.48438, -7.15625, -0.753906, 4.1875],\n",
       "         [14, -4.09375, -7.625, 2.76562, 11.8125, -10.5, 0.722656,\n",
       "          -6.59375, 0.808594, 5.59375],\n",
       "         [4.21875, 3.5, -2.51562, -3.89062, -1.25, 0.566406, 4.65625,\n",
       "          2.09375, 8.8125, 4.5625]]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax1['last_hidden_state'][:, :, :, 0, i:(i+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[5.65625, -5.25, -5.375, 5.8125, 4.90625, -4.21875, 1.55469,\n",
       "          -3.15625, 0.984375, 3.90625],\n",
       "         [6.34375, -3.03125, -6.4375, 6.03125, 7.8125, -3.59375,\n",
       "          2.48438, -7.15625, -0.753906, 4.1875],\n",
       "         [14, -4.09375, -7.625, 2.76562, 11.8125, -10.5, 0.722656,\n",
       "          -6.59375, 0.808594, 5.59375],\n",
       "         [4.21875, 3.5, -2.51562, -3.89062, -1.25, 0.566406, 4.65625,\n",
       "          2.09375, 8.8125, 4.5625]]]], dtype=bfloat16)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_jax2['last_hidden_state'][:, :, :, 0, i:(i+10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jax import tree_util\n",
    "\n",
    "def print_detailed_info(name, param):\n",
    "    print(f\"{name}   {param.shape}; {param.dtype}\")\n",
    "\n",
    "tree_util.tree_map_with_path(\n",
    "    lambda path, x: print_detailed_info(\"\".join(str(p) for p in path), x),\n",
    "    model.params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model_torch.named_parameters():\n",
    "    print(f\"[\\\"{name}\\\"]   {param.shape}; {param.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_torch.state_dict()[\"transformer.layers.31.self_attn.q_proj.weight\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.params['vision_model']['transformer']['layers.31']['self_attn']['q_proj']['kernel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_jax['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_jax['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
